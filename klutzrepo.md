================================================
FILE: README.md
================================================
# üöÄ KLUTZ - Your Free ChatGPT Alternative for Specialized AI Tools

**AI-Powered, but Underrated** - A comprehensive suite of 19+ specialized AI tools that goes beyond traditional chat interfaces.

[üåê Visit KLUTZ](https://klutz.co.in) | [üèÜ Featured on Product Hunt](https://www.producthunt.com/products/klutz)

## üéØ What Makes KLUTZ Different?

While ChatGPT excels at conversations, KLUTZ specializes in **actionable AI tools** that solve real-world problems. Think of it as your **free ChatGPT alternative** designed for specific tasks rather than general chat.

## üîß ACID TIPS - Our Core Categories

-   **A**udio - AI-powered audio editing and text-to-speech
    
-   **C**hat - Intelligent problem-solving conversations
    
-   **I**nfographics - Data visualization and content creation
    
-   **D**ate-Time - Historical and astronomical information
    
-   **T**ext - Translation, extraction, and analysis
    
-   **I**mage - Generation, analysis, and processing
    
-   **P**roblem-Solving - Step-by-step academic solutions
    
-   **S**preadsheets - AI-native data manipulation
    

## üõ†Ô∏è Best AI Tools Free - Complete Feature List

### üìù Content & Text Tools

-   **Image to Text Converter** - Extract text from any image
    
-   **AI Translator** - 60+ languages with cultural context
    
-   **AI Problem Solver** - Academic solutions with explanations
    
-   **Content Ethnicity Certifier** - Ethical content analysis
    
-   **Content Neurodiversity-Friendliness Checker** - Inclusive content assessment
    

### üé® Creative & Visual Tools

-   **AI Text-to-Image Generator** - High-quality image creation
    
-   **AI Prompt Generator** - Creative prompts from images
    
-   **Thumbnail Title Consistency Checker** - Video content optimization
    
-   **Content Heatmap Generator** - User engagement visualization
    
-   **AI Native Infographics** - Data-driven visual storytelling
    

### üîç Analysis & Diagnostic Tools

-   **MediScan AI** - Medical image analysis
    
-   **Electronic Appliance Troubleshooter** - Device diagnostic assistance
    
-   **Vehicle Troubleshooter** - Automotive problem diagnosis
    
-   **AI Measuring Tool** - Object measurement from images
    
-   **AI Ingredients Checker** - Food safety and dietary analysis
    

### üìä Data & Productivity Tools

-   **AI-Native Spreadsheets** - Natural language data manipulation
    
-   **AI Date & Time Checker** - Historical and astronomical data
    
-   **AI Native Audio Editor** - Voice and audio enhancement
    
-   **AI Text-to-Speech Generator** - Natural voice synthesis
    

## üÜì Why Choose KLUTZ as Your ChatGPT Alternative?

<table style="min-width: 75px"><colgroup><col style="min-width: 25px"><col style="min-width: 25px"><col style="min-width: 25px"></colgroup><tbody><tr><th colspan="1" rowspan="1"><p>Feature</p></th><th colspan="1" rowspan="1"><p>KLUTZ</p></th><th colspan="1" rowspan="1"><p>Traditional ChatGPT</p></th></tr><tr><td colspan="1" rowspan="1"><p>Cost</p></td><td colspan="1" rowspan="1"><p>‚úÖ Completely Free</p></td><td colspan="1" rowspan="1"><p>‚ùå Paid tiers for advanced features</p></td></tr><tr><td colspan="1" rowspan="1"><p>Specialized Tools</p></td><td colspan="1" rowspan="1"><p>‚úÖ 19+ Purpose-built tools</p></td><td colspan="1" rowspan="1"><p>‚ùå General chat interface</p></td></tr><tr><td colspan="1" rowspan="1"><p>Image Processing</p></td><td colspan="1" rowspan="1"><p>‚úÖ Advanced image analysis</p></td><td colspan="1" rowspan="1"><p>‚ö†Ô∏è Limited image capabilities</p></td></tr><tr><td colspan="1" rowspan="1"><p>No Login Required</p></td><td colspan="1" rowspan="1"><p>‚úÖ Many tools work without signup</p></td><td colspan="1" rowspan="1"><p>‚ùå Account required</p></td></tr><tr><td colspan="1" rowspan="1"><p>Medical Analysis</p></td><td colspan="1" rowspan="1"><p>‚úÖ Specialized MediScan AI</p></td><td colspan="1" rowspan="1"><p>‚ùå Not specialized for medical use</p></td></tr><tr><td colspan="1" rowspan="1"><p>Multi-language Support</p></td><td colspan="1" rowspan="1"><p>‚úÖ 60+ languages</p></td><td colspan="1" rowspan="1"><p>‚ö†Ô∏è Limited language options</p></td></tr></tbody></table>

## üöÄ Getting Started

1.  **Visit** [klutz.co.in](https://klutz.co.in)
    
2.  **Choose** your desired AI tool
    
3.  **Upload** your content (images, text, etc.)
    
4.  **Get** instant AI-powered results
    

## üéì Perfect for Students - AI Tools Free for Education

KLUTZ serves as an excellent **ChatGPT alternative for students** with specialized educational tools:

-   **Problem Solver** - Step-by-step math and science solutions
    
-   **Translator** - Language learning and translation
    
-   **Image to Text** - Digitize handwritten notes
    
-   **Date & Time Checker** - Historical research
    

## üíº Professional Use Cases

-   **Content Creators** - Thumbnail optimization, heatmap analysis
    
-   **Healthcare Professionals** - Medical image analysis (educational purposes)
    
-   **Educators** - Content accessibility checking
    
-   **Researchers** - Data visualization and analysis
    
-   **Developers** - Code-related problem solving
    

## üîß Technical Details

-   **Built with** Next.js, TypeScript, and Tailwind CSS
    
-   **AI Models** Multiple specialized models for different tasks
    
-   **Hosting** Vercel deployment for fast global access
    
-   **Open Source** Community-driven development
    

## üåü Why KLUTZ is the Best ChatGPT Alternative

> "KLUTZ doesn't try to be everything to everyone. Instead, it excels at specific tasks that matter most to users - from medical image analysis to content creation, all while being completely free."

## üìà SEO & Marketing Tools

KLUTZ includes powerful **AI tools free** for digital marketing:

-   Content optimization and analysis
    
-   Thumbnail and title consistency checking
    
-   Heatmap generation for user engagement
    
-   Multi-language content translation
    

## ü§ù Contributing

We welcome contributions! This project is open-source and community-driven.

1.  Fork the repository
    
2.  Create a feature branch
    
3.  Submit a pull request
    

## üìû Support & Contact

-   **Email**: jeffrinjames99@gmail.com
    
-   **Website**: [klutz.co.in](https://klutz.co.in)
    
-   **Product Hunt**: [Featured Product](https://www.producthunt.com/products/klutz)
    

## üìú License

This project is open-source. See the LICENSE file for details.

---

_Made with ‚ù§Ô∏è using AI-powered tools for the modern web_

**Keywords**: ChatGPT alternative, AI tools free, best AI tools, free AI tools, ChatGPT alternative free, AI tools for students, generative AI tools, powerful AI tools, content creation AI tools

**AI-Powered, but Underrated** - A comprehensive suite of 19+ specialized AI tools that goes beyond traditional chat interfaces.

[üåê Visit KLUTZ](https://klutz.co.in) | [üèÜ Featured on Product Hunt](https://www.producthunt.com/products/klutz)

## üéØ What Makes KLUTZ Different?

While ChatGPT excels at conversations, KLUTZ specializes in **actionable AI tools** that solve real-world problems. Think of it as your **free ChatGPT alternative** designed for specific tasks rather than general chat.

## üîß ACID TIPS - Our Core Categories

-   **A**udio - AI-powered audio editing and text-to-speech
    
-   **C**hat - Intelligent problem-solving conversations
    
-   **I**nfographics - Data visualization and content creation
    
-   **D**ate-Time - Historical and astronomical information
    
-   **T**ext - Translation, extraction, and analysis
    
-   **I**mage - Generation, analysis, and processing
    
-   **P**roblem-Solving - Step-by-step academic solutions
    
-   **S**preadsheets - AI-native data manipulation
    

## üõ†Ô∏è Best AI Tools Free - Complete Feature List

### üìù Content & Text Tools

-   **Image to Text Converter** - Extract text from any image
    
-   **AI Translator** - 60+ languages with cultural context
    
-   **AI Problem Solver** - Academic solutions with explanations
    
-   **Content Ethnicity Certifier** - Ethical content analysis
    
-   **Content Neurodiversity-Friendliness Checker** - Inclusive content assessment
    

### üé® Creative & Visual Tools

-   **AI Text-to-Image Generator** - High-quality image creation
    
-   **AI Prompt Generator** - Creative prompts from images
    
-   **Thumbnail Title Consistency Checker** - Video content optimization
    
-   **Content Heatmap Generator** - User engagement visualization
    
-   **AI Native Infographics** - Data-driven visual storytelling
    

### üîç Analysis & Diagnostic Tools

-   **MediScan AI** - Medical image analysis
    
-   **Electronic Appliance Troubleshooter** - Device diagnostic assistance
    
-   **Vehicle Troubleshooter** - Automotive problem diagnosis
    
-   **AI Measuring Tool** - Object measurement from images
    
-   **AI Ingredients Checker** - Food safety and dietary analysis
    

### üìä Data & Productivity Tools

-   **AI-Native Spreadsheets** - Natural language data manipulation
    
-   **AI Date & Time Checker** - Historical and astronomical data
    
-   **AI Native Audio Editor** - Voice and audio enhancement
    
-   **AI Text-to-Speech Generator** - Natural voice synthesis
    

## üÜì Why Choose KLUTZ as Your ChatGPT Alternative?

<table style="min-width: 75px"><colgroup><col style="min-width: 25px"><col style="min-width: 25px"><col style="min-width: 25px"></colgroup><tbody><tr><th colspan="1" rowspan="1"><p>Feature</p></th><th colspan="1" rowspan="1"><p>KLUTZ</p></th><th colspan="1" rowspan="1"><p>Traditional ChatGPT</p></th></tr><tr><td colspan="1" rowspan="1"><p>Cost</p></td><td colspan="1" rowspan="1"><p>‚úÖ Completely Free</p></td><td colspan="1" rowspan="1"><p>‚ùå Paid tiers for advanced features</p></td></tr><tr><td colspan="1" rowspan="1"><p>Specialized Tools</p></td><td colspan="1" rowspan="1"><p>‚úÖ 19+ Purpose-built tools</p></td><td colspan="1" rowspan="1"><p>‚ùå General chat interface</p></td></tr><tr><td colspan="1" rowspan="1"><p>Image Processing</p></td><td colspan="1" rowspan="1"><p>‚úÖ Advanced image analysis</p></td><td colspan="1" rowspan="1"><p>‚ö†Ô∏è Limited image capabilities</p></td></tr><tr><td colspan="1" rowspan="1"><p>No Login Required</p></td><td colspan="1" rowspan="1"><p>‚úÖ Many tools work without signup</p></td><td colspan="1" rowspan="1"><p>‚ùå Account required</p></td></tr><tr><td colspan="1" rowspan="1"><p>Medical Analysis</p></td><td colspan="1" rowspan="1"><p>‚úÖ Specialized MediScan AI</p></td><td colspan="1" rowspan="1"><p>‚ùå Not specialized for medical use</p></td></tr><tr><td colspan="1" rowspan="1"><p>Multi-language Support</p></td><td colspan="1" rowspan="1"><p>‚úÖ 60+ languages</p></td><td colspan="1" rowspan="1"><p>‚ö†Ô∏è Limited language options</p></td></tr></tbody></table>

## üöÄ Getting Started

1.  **Visit** [klutz.co.in](https://klutz.co.in)
    
2.  **Choose** your desired AI tool
    
3.  **Upload** your content (images, text, etc.)
    
4.  **Get** instant AI-powered results
    

## üéì Perfect for Students - AI Tools Free for Education

KLUTZ serves as an excellent **ChatGPT alternative for students** with specialized educational tools:

-   **Problem Solver** - Step-by-step math and science solutions
    
-   **Translator** - Language learning and translation
    
-   **Image to Text** - Digitize handwritten notes
    
-   **Date & Time Checker** - Historical research
    

## üíº Professional Use Cases

-   **Content Creators** - Thumbnail optimization, heatmap analysis
    
-   **Healthcare Professionals** - Medical image analysis (educational purposes)
    
-   **Educators** - Content accessibility checking
    
-   **Researchers** - Data visualization and analysis
    
-   **Developers** - Code-related problem solving
    

## ‚ùì Frequently Asked Questions

### What are the best free AI tools available?

KLUTZ offers 19+ specialized AI tools completely free, including image-to-text conversion, medical image analysis, multi-language translation, and content creation tools. Unlike generic alternatives, each tool is purpose-built for specific tasks.

### What is an alternative to ChatGPT?

KLUTZ is a specialized alternative to ChatGPT that focuses on actionable tools rather than conversations. While ChatGPT excels at chat, KLUTZ provides dedicated tools for image analysis, content creation, problem-solving, and professional workflows.

### What are the best free AI tools for content creation?

KLUTZ offers several content creation tools including AI text-to-image generation, infographics creation, thumbnail optimization, content heatmap analysis, and multi-language translation - all completely free.

### What are the best free AI tools for beginners?

KLUTZ is designed with beginners in mind. Our tools require no technical knowledge - simply upload your content and get instant results. Start with our Image to Text Converter or AI Translator for easy introduction to AI tools.

### What are the best free AI tools for digital marketing?

KLUTZ provides marketing-focused tools including thumbnail-title consistency checking, content heatmap generation, multi-language content translation, and image optimization - perfect for digital marketers.

### What are the best free AI tools for image creation?

Our AI Text-to-Image Generator creates high-quality images from text descriptions. We also offer image analysis, measurement tools, and prompt generation from existing images.

### What is the best ChatGPT alternative?

KLUTZ excels as a ChatGPT alternative for users who need specialized tools rather than general conversation. Our focused approach provides better results for specific tasks like medical analysis, content creation, and academic problem-solving.

### How to learn AI tools for free?

KLUTZ tools are intuitive and require no learning curve. Each tool includes clear instructions, and you can start using them immediately without tutorials or training.

### What are the limitations of free versions of AI tools?

Unlike other platforms, KLUTZ doesn't impose artificial limitations on free users. Our tools are completely free with full functionality - no usage limits, watermarks, or restricted features.

### What are the best free AI tools available in 2025?

KLUTZ represents the cutting edge of 2025 AI tools, offering specialized solutions that go beyond traditional chatbots. Our suite includes advanced features like medical image analysis, vehicle troubleshooting, and AI-native spreadsheets.

## üîß Technical Details

-   **Built with** Next.js, TypeScript, and Tailwind CSS
    
-   **AI Models** Multiple specialized models for different tasks
    
-   **Hosting** Vercel deployment for fast global access
    
-   **Open Source** Community-driven development
    

## üåü Why KLUTZ is the Best ChatGPT Alternative

> "KLUTZ doesn't try to be everything to everyone. Instead, it excels at specific tasks that matter most to users - from medical image analysis to content creation, all while being completely free."

## üìà SEO & Marketing Tools

KLUTZ includes powerful **AI tools free** for digital marketing:

-   Content optimization and analysis
    
-   Thumbnail and title consistency checking
    
-   Heatmap generation for user engagement
    
-   Multi-language content translation
    

## ü§ù Contributing

We welcome contributions! This project is open-source and community-driven.

1.  Fork the repository
    
2.  Create a feature branch
    
3.  Submit a pull request
    

## üìû Support & Contact

-   **Email**: jeffrinjames99@gmail.com
    
-   **Website**: [klutz.co.in](https://klutz.co.in)
    
-   **Product Hunt**: [Featured Product](https://www.producthunt.com/products/klutz)
    

## üìú License

This project is open-source. See the LICENSE file for details.

---

_Made with ‚ù§Ô∏è using AI-powered tools for the modern web_

**Keywords**: ChatGPT alternative, AI tools free, best AI tools, free AI tools, ChatGPT alternative free, AI tools for students, generative AI tools, powerful AI tools, content creation AI tools, what are the best free AI tools, what is an alternative to ChatGPT, free AI tools for beginners, AI tools for digital marketing, AI tools for image creation


================================================
FILE: ads.txt
================================================
google.com, pub-8061354259054600, DIRECT, f08c47fec0942fa0



================================================
FILE: apphosting.yaml
================================================
# Settings to manage and configure a Firebase App Hosting backend.
# https://firebase.google.com/docs/app-hosting/configure

runConfig:
  # Increase this value if you'd like to automatically spin up
  # more instances in response to increased traffic.
  maxInstances: 1



================================================
FILE: components.json
================================================
{
  "$schema": "https://ui.shadcn.com/schema.json",
  "style": "default",
  "rsc": true,
  "tsx": true,
  "tailwind": {
    "config": "tailwind.config.ts",
    "css": "src/app/globals.css",
    "baseColor": "neutral",
    "cssVariables": true,
    "prefix": ""
  },
  "aliases": {
    "components": "@/components",
    "utils": "@/lib/utils",
    "ui": "@/components/ui",
    "lib": "@/lib",
    "hooks": "@/hooks"
  },
  "iconLibrary": "lucide"
}


================================================
FILE: google83078bd88d6feeca.html
================================================
google-site-verification: google83078bd88d6feeca.html


================================================
FILE: LICENSE
================================================
MIT License

Copyright (c) 2025 Jeffrin James

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.



================================================
FILE: next.config.ts
================================================
import type {NextConfig} from 'next';

const nextConfig: NextConfig = {
  /* config options here */
  typescript: {
    ignoreBuildErrors: true,
  },
  eslint: {
    ignoreDuringBuilds: true,
  },
  images: {
    remotePatterns: [
      {
        protocol: 'https',
        hostname: 'placehold.co',
        port: '',
        pathname: '/**',
      },
    ],
  },
};

export default nextConfig;



================================================
FILE: package.json
================================================
{
  "name": "nextn",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev -p 9002",
    "build": "next build",
    "start": "next start",
    "lint": "next lint",
    "typecheck": "tsc --noEmit"
  },
  "dependencies": {
    "@hookform/resolvers": "^4.1.3",
    "@radix-ui/react-accordion": "^1.2.3",
    "@radix-ui/react-alert-dialog": "^1.1.6",
    "@radix-ui/react-avatar": "^1.1.3",
    "@radix-ui/react-checkbox": "^1.1.4",
    "@radix-ui/react-dialog": "^1.1.6",
    "@radix-ui/react-dropdown-menu": "^2.1.6",
    "@radix-ui/react-label": "^2.1.2",
    "@radix-ui/react-menubar": "^1.1.6",
    "@radix-ui/react-popover": "^1.1.6",
    "@radix-ui/react-progress": "^1.1.2",
    "@radix-ui/react-radio-group": "^1.2.3",
    "@radix-ui/react-scroll-area": "^1.2.3",
    "@radix-ui/react-select": "^2.1.6",
    "@radix-ui/react-separator": "^1.1.2",
    "@radix-ui/react-slider": "^1.2.3",
    "@radix-ui/react-slot": "^1.1.2",
    "@radix-ui/react-switch": "^1.1.3",
    "@radix-ui/react-tabs": "^1.1.3",
    "@radix-ui/react-toast": "^1.2.6",
    "@radix-ui/react-tooltip": "^1.1.8",
    "class-variance-authority": "^0.7.1",
    "clsx": "^2.1.1",
    "date-fns": "^3.6.0",
    "firebase": "^11.8.1",
    "framer-motion": "^12.23.3",
    "html-to-image": "^1.11.13",
    "lucide-react": "^0.475.0",
    "next": "15.2.3",
    "next-themes": "^0.3.0",
    "node-fetch": "^3.3.2",
    "patch-package": "^8.0.0",
    "react": "^18.3.1",
    "react-d3-tree": "^3.6.6",
    "react-day-picker": "^8.10.1",
    "react-dom": "^18.3.1",
    "react-heatmap-grid": "^0.9.1",
    "react-hook-form": "^7.54.2",
    "react-icons": "^5.5.0",
    "react-resizable-panels": "^2.1.9",
    "recharts": "^2.15.3",
    "tailwind-merge": "^3.0.1",
    "tailwindcss-animate": "^1.0.7",
    "xlsx": "^0.18.5",
    "zod": "^3.24.2"
  },
  "devDependencies": {
    "@types/node": "^20",
    "@types/react": "^18",
    "@types/react-dom": "^18",
    "postcss": "^8",
    "tailwindcss": "^3.4.1",
    "typescript": "^5"
  }
}



================================================
FILE: postcss.config.mjs
================================================
/** @type {import('postcss-load-config').Config} */
const config = {
  plugins: {
    tailwindcss: {},
  },
};

export default config;



================================================
FILE: tailwind.config.ts
================================================
import type {Config} from 'tailwindcss';

export default {
  darkMode: ['class'],
  content: [
    './src/pages/**/*.{js,ts,jsx,tsx,mdx}',
    './src/components/**/*.{js,ts,jsx,tsx,mdx}',
    'src/app/**/*.{js,ts,jsx,tsx,mdx}',
  ],
  theme: {
    extend: {
      fontFamily: {
        body: ['PT Sans', 'sans-serif'],
        headline: ['Space Grotesk', 'sans-serif'],
        code: ['monospace'],
      },
      colors: {
        background: 'hsl(var(--background))',
        foreground: 'hsl(var(--foreground))',
        card: {
          DEFAULT: 'hsl(var(--card))',
          foreground: 'hsl(var(--card-foreground))',
        },
        popover: {
          DEFAULT: 'hsl(var(--popover))',
          foreground: 'hsl(var(--popover-foreground))',
        },
        primary: {
          DEFAULT: 'hsl(var(--primary))',
          foreground: 'hsl(var(--primary-foreground))',
        },
        secondary: {
          DEFAULT: 'hsl(var(--secondary))',
          foreground: 'hsl(var(--secondary-foreground))',
        },
        muted: {
          DEFAULT: 'hsl(var(--muted))',
          foreground: 'hsl(var(--muted-foreground))',
        },
        accent: {
          DEFAULT: 'hsl(var(--accent))',
          foreground: 'hsl(var(--accent-foreground))',
        },
        destructive: {
          DEFAULT: 'hsl(var(--destructive))',
          foreground: 'hsl(var(--destructive-foreground))',
        },
        border: 'hsl(var(--border))',
        input: 'hsl(var(--input))',
        ring: 'hsl(var(--ring))',
        chart: {
          '1': 'hsl(var(--chart-1))',
          '2': 'hsl(var(--chart-2))',
          '3': 'hsl(var(--chart-3))',
          '4': 'hsl(var(--chart-4))',
          '5': 'hsl(var(--chart-5))',
        },
        sidebar: {
          DEFAULT: 'hsl(var(--sidebar-background))',
          foreground: 'hsl(var(--sidebar-foreground))',
          primary: 'hsl(var(--sidebar-primary))',
          'primary-foreground': 'hsl(var(--sidebar-primary-foreground))',
          accent: 'hsl(var(--sidebar-accent))',
          'accent-foreground': 'hsl(var(--sidebar-accent-foreground))',
          border: 'hsl(var(--sidebar-border))',
          ring: 'hsl(var(--sidebar-ring))',
        },
      },
      borderRadius: {
        lg: 'var(--radius)',
        md: 'calc(var(--radius) - 2px)',
        sm: 'calc(var(--radius) - 4px)',
      },
      keyframes: {
        'accordion-down': {
          from: {
            height: '0',
          },
          to: {
            height: 'var(--radix-accordion-content-height)',
          },
        },
        'accordion-up': {
          from: {
            height: 'var(--radix-accordion-content-height)',
          },
          to: {
            height: '0',
          },
        },
      },
      animation: {
        'accordion-down': 'accordion-down 0.2s ease-out',
        'accordion-up': 'accordion-up 0.2s ease-out',
      },
    },
  },
  plugins: [require('tailwindcss-animate')],
} satisfies Config;



================================================
FILE: tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "ES2017",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules"]
}



================================================
FILE: .modified
================================================
[Empty file]


================================================
FILE: docs/blueprint.md
================================================
# **App Name**: MediScan AI

## Core Features:

- Secure Image Upload: Securely upload medical images (X-rays, MRI, CT scans) to the application using Puter.js's cloud storage.
- AI Image Analysis: Use the GPT-4o model (accessed via Puter.js) to analyze the image, detect abnormalities, and identify anatomical features. This leverages serverless function calls.
- Image Preprocessing: Optimize the image preprocessing, ensuring high performance using resizing and compression techniques, to make the images suitable for processing in GPT-4o.
- Medical Report Generation: The AI generates structured medical reports which contains findings, possible differential diagnoses and relevant recommendations. It functions as a reasoning tool that chooses the most relevant information about the images being processed.
- Insight Display: Display AI-generated insights with actionable next steps and insights about possible patient treatments or other medical advice.
- User Authentication: Use Puter.js‚Äôs authentication flows to ensure that only authorized users can view protected content and perform protected actions.

## Style Guidelines:

- Primary color: Deep blue (#3F51B5) to convey trust and professionalism.
- Background color: Light gray (#F0F2F5) for a clean, clinical feel.
- Accent color: Teal (#009688) for highlights and call-to-action elements.
- Body text: 'PT Sans', a humanist sans-serif, will give a modern look with warmth.
- Headline font: 'Space Grotesk', sans-serif, it combines a modern look and a little warmth or personality.
- Use simple, clear icons to represent different medical imaging types and report sections.
- Ensure a clear, responsive layout that works well on both desktop and mobile devices.


================================================
FILE: docs/browser-tts.md
================================================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Browser Text-to-Speech</title>
    <style>
        body {
            font-family: sans-serif;
            padding: 20px;
            max-width: 600px;
            margin: 0 auto;
        }
        textarea {
            width: 100%;
            margin-bottom: 10px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            resize: vertical;
        }
        select {
            margin-bottom: 10px;
            padding: 8px;
            border: 1px solid #ccc;
            border-radius: 4px;
        }
        button {
            padding: 10px 20px;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
        }
        button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        #status {
            margin-top: 15px;
            font-weight: bold;
        }
        .error {
            color: red;
        }
        .success {
            color: green;
        }
    </style>
</head>
<body>
    <h1>Browser Text-to-Speech</h1>

    <textarea id="text-to-speak" placeholder="Enter text here..." rows="10"></textarea>

    <label for="language-select">Select Language:</label>
    <select id="language-select"></select>

    <button id="speak-button">Speak</button>

    <div id="status"></div>

    <script>
        const textToSpeakEl = document.getElementById('text-to-speak');
        const languageSelectEl = document.getElementById('language-select');
        const speakButton = document.getElementById('speak-button');
        const statusEl = document.getElementById('status');

        // A simplified list of languages for demonstration.
        // The actual supported languages depend on the user's browser and OS.
        const languages = {
            'en-US': 'English (US)',
            'en-GB': 'English (British)',
            'es-ES': 'Spanish (Spain)',
            'fr-FR': 'French (France)',
            'de-DE': 'German (Germany)',
            'it-IT': 'Italian (Italy)',
            'ja-JP': 'Japanese (Japan)',
            'ko-KR': 'Korean (South Korea)',
            'ru-RU': 'Russian (Russia)',
            'zh-CN': 'Chinese (Mandarin)',
        };

        // Populate language dropdown
        for (const code in languages) {
            const option = document.createElement('option');
            option.value = code;
            option.textContent = languages[code];
            languageSelectEl.appendChild(option);
        }

        // Check for browser support
        if ('speechSynthesis' in window) {
            statusEl.textContent = 'Speech Synthesis is supported in your browser.';
            statusEl.className = 'success';

            speakButton.addEventListener('click', () => {
                const text = textToSpeakEl.value.trim();
                const selectedLanguage = languageSelectEl.value;

                if (text === '') {
                    statusEl.textContent = 'Please enter text to speak.';
                    statusEl.className = 'error';
                    return;
                }

                const utterance = new SpeechSynthesisUtterance(text);
                utterance.lang = selectedLanguage;

                utterance.onstart = () => {
                    statusEl.textContent = 'Speaking...';
                    statusEl.className = '';
                    speakButton.disabled = true;
                };

                utterance.onend = () => {
                    statusEl.textContent = 'Finished speaking.';
                    statusEl.className = 'success';
                    speakButton.disabled = false;
                };

                utterance.onerror = (event) => {
                    statusEl.textContent = `Speech synthesis error: ${event.error}`;
                    statusEl.className = 'error';
                    speakButton.disabled = false;
                    console.error('Speech synthesis error:', event);
                };

                speechSynthesis.speak(utterance);
            });

        } else {
            statusEl.textContent = 'Speech Synthesis is not supported in your browser.';
            statusEl.className = 'error';
            speakButton.disabled = true;
        }

    </script>
</body>
</html>


================================================
FILE: docs/gemini-models.md
================================================
Tutorials
Free Gemini API
Updated: April 17, 2025
This tutorial will show you how to use Puter.js to access Gemini's powerful language models for free, without any API keys or usage restrictions. Using Puter.js, you can leverage models like Gemini 2.0 Flash, Gemini 2.5 Pro, and Gemini 1.5 Flash for various tasks like text generation, analysis, and complex reasoning, text and code generation, and more.

Puter is the pioneer of the "User Pays" model, which allows developers to incorporate AI capabilities into their applications while users cover their own usage costs. This model enables developers to access advanced AI capabilities for free, without any API keys or sign-ups.

Getting Started
Puter.js works without any API keys or sign-ups. To start using Puter.js, include the following script tag in your HTML file, either in the <head> or <body> section:

<script src="https://js.puter.com/v2/"></script>
You're now ready to use Puter.js for free access to Gemini capabilities. No API keys or sign-ups are required.

Example 1Basic Text Generation with Gemini 2.0 Flash
Here's a simple example showing how to generate text using Gemini 2.0 Flash:

<html>
<body>
    <script src="https://js.puter.com/v2/"></script>
    <script>
        puter.ai.chat("Explain the concept of black holes in simple terms", {
            model: 'google/gemini-2.0-flash-lite-001'
        }).then(response => {
            document.write(response.message.content);
        });
    </script>
</body>
</html>
Example 2Using Gemini 2.5 Pro
For comparison, here's how to use Gemini 2.5 Pro:

<html>
<body>
    <script src="https://js.puter.com/v2/"></script>
    <script>
        puter.ai.chat(
            "What are the major differences between renewable and non-renewable energy sources?", 
            {
                model: 'google/gemini-2.5-pro-exp-03-25:free'
            }
        ).then(response => {
            document.write(response.message.content);
        });
    </script>
</body>
</html>
Example 3Streaming Responses
For longer responses, use streaming to get results in real-time:

<html>
<body>
    <div id="output"></div>
    <script src="https://js.puter.com/v2/"></script>
    <script>
        async function streamResponses() {
            const outputDiv = document.getElementById('output');
            
            // Gemini 2.0 Flash with streaming
            outputDiv.innerHTML += '<h2>Gemini 2.0 Flash Response:</h2>';
            const flash2Response = await puter.ai.chat(
                "Explain the process of photosynthesis in detail", 
                {
                    model: 'gemini-2.0-flash',
                    stream: true
                }
            );
            
            for await (const part of flash2Response) {
                if (part?.text) {
                    outputDiv.innerHTML += part.text.replaceAll('\n', '<br>');
                }
            }
            
            // Gemini 1.5 Flash with streaming
            outputDiv.innerHTML += '<h2>Gemini 1.5 Flash Response:</h2>';
            const flash1Response = await puter.ai.chat(
                "Explain the process of photosynthesis in detail", 
                {
                    model: 'gemini-1.5-flash',
                    stream: true
                }
            );
            
            for await (const part of flash1Response) {
                if (part?.text) {
                    outputDiv.innerHTML += part.text.replaceAll('\n', '<br>');
                }
            }
        }

        streamResponses();
    </script>
</body>
</html>
Example 4Comparing Models
Here's how to compare responses from both Gemini models:

<html>
<body>
    <script src="https://js.puter.com/v2/"></script>
    <script>
    (async () => {
        // Gemini 2.5 Pro
        const pro_resp = await puter.ai.chat(
            'Tell me something interesting about quantum mechanics.',
            {model: 'google/gemini-2.5-pro-exp-03-25:free'}
        );
        document.write('<h2>Gemini 2.5 Pro Response:</h2>');
        document.write(pro_resp.message.content);

        // Gemini 2.0 Flash
        const flash2_resp = await puter.ai.chat(
            'Tell me something interesting about quantum mechanics.',
            {model: 'google/gemini-2.0-flash-lite-001', stream: true}
        );
        document.write('<h2>Gemini 2.0 Flash Response:</h2>');
        for await (const part of flash2_resp) {
            if (part?.text) {
                document.write(part.text.replaceAll('\n', '<br>'));
            }
        }

        // Gemini 1.5 Flash
        const flash1_resp = await puter.ai.chat(
            'Tell me something interesting about quantum mechanics.',
            {model: 'google/gemini-flash-1.5-8b', stream: true}
        );
        document.write('<h2>Gemini 1.5 Flash Response:</h2>');
        for await (const part of flash1_resp) {
            if (part?.text) {
                document.write(part.text.replaceAll('\n', '<br>'));
            }
        }
    })();
    </script>
</body>
</html>
All models
The following Gemini models are available for free use with Puter.js:

google/gemini-2.5-flash-preview
google/gemini-2.5-flash-preview:thinking
google/gemini-2.5-pro-exp-03-25:free
google/gemini-2.0-flash-lite-001
google/gemini-2.0-flash-001
google/gemini-2.0-pro-exp-02-05:free
google/gemini-2.0-flash-thinking-exp:free
google/gemini-2.0-flash-thinking-exp-1219:free
google/gemini-2.0-flash-exp:free
google/gemini-flash-1.5-8b
google/gemini-flash-1.5-8b-exp
google/gemini-flash-1.5
google/gemini-pro-1.5
google/gemini-pro
That's it! You now have free access to Gemini's powerful language models using Puter.js. This allows you to add sophisticated AI capabilities to your web applications without worrying about API keys or usage limits.


================================================
FILE: docs/meta-llama-models.md
================================================
Tutorials
Free, Unlimited Llama API
Updated: April 5, 2025
This tutorial will show you how to use Puter.js to access Meta's Llama models for free, without any API keys or usage restrictions.Using Puter.js, you can work with models like Llama 4 and more for text generation and various AI tasks without worrying about usage limits or costs.

Puter is the pioneer of the "User Pays" model, which allows developers to incorporate AI capabilities into their applications while users cover their own usage costs. This model enables developers to access advanced AI features for free, without any API keys or server-side setup.

Getting Started
Puter.js is completely serverless and works without any API keys or server-side setup. To start using Puter.js, include the following script tag in your HTML file, either in the <head> or <body> section:

<script src="https://js.puter.com/v2/"></script>
You're now ready to use Puter.js for free access to Meta's Llama models. No API keys or sign-ups are required.

Example 1Use Llama 4 Maverick for text generation
To generate text using Llama 4 Maverick, use the puter.ai.chat() function with the meta-llama/llama-4-maverick model:

puter.ai.chat("Explain how machine learning works to a beginner", 
    {model: 'meta-llama/llama-4-maverick'})
    .then(response => {
        puter.print(response.message.content);
    });
Here's the full code example:

<html>
<body>
    <script src="https://js.puter.com/v2/"></script>
    <script>
        puter.ai.chat("Explain how machine learning works to a beginner", 
            {model: 'meta-llama/llama-4-maverick'})
            .then(response => {
                puter.print(response.message.content);
            });
    </script>
</body>
</html>
Example 2Stream responses for longer queries
For longer responses, use streaming to get results in real-time:

async function streamLlamaResponse() {
    const response = await puter.ai.chat(
        "Write a detailed tutorial on building a React application", 
        {
            model: 'meta-llama/llama-4-maverick', 
            stream: true
        }
    );
    
    for await (const part of response) {
        puter.print(part?.text);
    }
}

streamLlamaResponse();
Here's the full code example:

<html>
<body>
    <script src="https://js.puter.com/v2/"></script>
    <script>
        async function streamLlamaResponse() {
            const response = await puter.ai.chat(
                "Write a detailed tutorial on building a React application", 
                {
                    model: 'meta-llama/llama-4-maverick', 
                    stream: true
                }
            );
            
            for await (const part of response) {
                puter.print(part?.text);
            }
        }

        streamLlamaResponse();
    </script>
</body>
</html>
Example 3Use different Llama models for different needs
Puter.js provides access to various Llama models for different requirements:

// Using Llama 3.3 70B for complex tasks
puter.ai.chat(
    "Explain the implications of quantum computing on cryptography",
    { model: "meta-llama/llama-3.3-70b-instruct" }
).then(response => {
    puter.print("<h2>Using Llama 3.3 70B</h2>");
    puter.print(response.message.content);
});

// Using Llama 3.1 8B for faster responses
puter.ai.chat(
    "Suggest three fun weekend activities",
    { model: "meta-llama/llama-3.1-8b-instruct" }
).then(response => {
    puter.print("<h2>Using Llama 3.1 8B</h2>");
    puter.print(response.message.content);
});

// Using Llama Guard for content moderation
puter.ai.chat(
    "Is this message harmful: 'I enjoy hiking on weekends'",
    { model: "meta-llama/llama-guard-3-8b" }
).then(response => {
    puter.print("<h2>Using Llama Guard</h2>");
    puter.print(response.message.content);
});
Here's the full code example:

<html>
<body>
    <script src="https://js.puter.com/v2/"></script>
    <script>
        // Using Llama 3.3 70B for complex tasks
        puter.ai.chat(
            "Explain the implications of quantum computing on cryptography",
            { model: "meta-llama/llama-3.3-70b-instruct" }
        ).then(response => {
            puter.print("<h2>Using Llama 3.3 70B</h2>");
            puter.print(response.message.content);
        });

        // Using Llama 3.1 8B for faster responses
        puter.ai.chat(
            "Suggest three fun weekend activities",
            { model: "meta-llama/llama-3.1-8b-instruct" }
        ).then(response => {
            puter.print("<h2>Using Llama 3.1 8B</h2>");
            puter.print(response.message.content);
        });

        // Using Llama Guard for content moderation
        puter.ai.chat(
            "Is this message harmful: 'I enjoy hiking on weekends'",
            { model: "meta-llama/llama-guard-3-8b" }
        ).then(response => {
            puter.print("<h2>Using Llama Guard</h2>");
            puter.print(response.message.content);
        });
    </script>
</body>
</html>
Available Llama Models
Puter.js provides access to a comprehensive range of Meta's Llama models:

Llama 4 Models
meta-llama/llama-4-maverick
meta-llama/llama-4-scout
Llama 3.3 Models
meta-llama/llama-3.3-70b-instruct
Llama 3.2 Models
meta-llama/llama-3.2-3b-instruct
meta-llama/llama-3.2-1b-instruct
Llama 3.1 Models
meta-llama/llama-3.1-405b
meta-llama/llama-3.1-8b-instruct
meta-llama/llama-3.1-405b-instruct
meta-llama/llama-3.1-70b-instruct
Llama 3 Models
meta-llama/llama-3-8b-instruct
meta-llama/llama-3-70b-instruct
Llama 2 Models
meta-llama/llama-2-70b-chat
meta-llama/llama-2-13b-chat
Llama Guard Models
meta-llama/llama-guard-3-8b
meta-llama/llama-guard-2-8b
Simply replace the model name in the puter.ai.chat() function to use a different model.

Best Practices
For most general-purpose tasks, use meta-llama/llama-3.3-70b-instruct for the best quality results
For faster responses with slightly lower quality, use meta-llama/llama-3.1-8b-instruct
For content moderation, use meta-llama/llama-guard-3-8b
Enable streaming for longer responses to improve user experience
That's it! You now have free, unlimited access to Meta's Llama models using Puter.js. This allows you to leverage Llama's powerful language understanding and generation abilities without worrying about API keys or usage limits.


================================================
FILE: docs/puter's-tts.md
================================================
puter.ai.txt2speech()
Converts text into speech using AI. Supports multiple languages and voices.

Syntax
puter.ai.txt2speech(text)
puter.ai.txt2speech(text, language = 'en-US')
puter.ai.txt2speech(text, language = 'en-US', testMode = false)
Parameters
text (String) (required)
A string containing the text you want to convert to speech. The text must be less than 3000 characters long.

language (String) (optional)
The language to use for speech synthesis. Defaults to en-US. The following languages are supported:

Arabic (ar-AE)
Catalan (ca-ES)
Chinese (Cantonese) (yue-CN)
Chinese (Mandarin) (cmn-CN)
Danish (da-DK)
Dutch (Belgian) (nl-BE)
Dutch (nl-NL)
English (Australian) (en-AU)
English (British) (en-GB)
English (Indian) (en-IN)
English (New Zealand) (en-NZ)
English (South African) (en-ZA)
English (US) (en-US)
English (Welsh) (en-GB-WLS)
Finnish (fi-FI)
French (fr-FR)
French (Belgian) (fr-BE)
French (Canadian) (fr-CA)
German (de-DE)
German (Austrian) (de-AT)
Hindi (hi-IN)
Icelandic (is-IS)
Italian (it-IT)
Japanese (ja-JP)
Korean (ko-KR)
Norwegian (nb-NO)
Polish (pl-PL)
Portuguese (Brazilian) (pt-BR)
Portuguese (European) (pt-PT)
Romanian (ro-RO)
Russian (ru-RU)
Spanish (European) (es-ES)
Spanish (Mexican) (es-MX)
Spanish (US) (es-US)
Swedish (sv-SE)
Turkish (tr-TR)
Welsh (cy-GB)
testMode (Boolean) (Optional)
A boolean indicating whether you want to use the test API. Defaults to false. This is useful for testing your code without using up API credits.

Return value
A Promise that will resolve to an MP3 stream when the speech has been synthesized.

Examples
Convert text to speech

<html>
<body>
    <script src="https://js.puter.com/v2/"></script>
    <button id="play">Speak!</button>
    <script>
        document.getElementById('play').addEventListener('click', ()=>{
            puter.ai.txt2speech(`Hello world! Puter is pretty amazing, don't you agree?`).then((audio)=>{
                audio.play();
            });
        });
    </script>
</body>
</html>


================================================
FILE: docs/puter-models.md
================================================
puter.ai.chat()
Given a prompt returns the completion that best matches the prompt.

Syntax
puter.ai.chat(prompt)
puter.ai.chat(prompt, options = {})
puter.ai.chat(prompt, testMode = false, options = {})
puter.ai.chat(prompt, imageURL, testMode = false, options = {})
puter.ai.chat(prompt, [imageURLArray], testMode = false, options = {})
puter.ai.chat([messages], testMode = false, options = {})
Parameters
prompt (String)
A string containing the prompt you want to complete.

options (Object) (Optional)
An object containing the following properties:

model (String) - The model you want to use for the completion. If not specified, defaults to gpt-4.1-nano. The following models are available:
gpt-4o-mini (default)
gpt-4o
o1
o1-mini
o1-pro
o3
o3-mini
o4-mini
gpt-4.1
gpt-4.1-mini
gpt-4.1-nano
gpt-4.5-preview
claude-sonnet-4
claude-opus-4
claude-3-7-sonnet
claude-3-5-sonnet
deepseek-chat
deepseek-reasoner
gemini-2.0-flash
gemini-1.5-flash
meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo
meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo
mistral-large-latest
pixtral-large-latest
codestral-latest
google/gemma-2-27b-it
grok-beta
stream (Boolean) - A boolean indicating whether you want to stream the completion. Defaults to false.
max_tokens (Number) - The maximum number of tokens to generate in the completion. By default, the specific model's maximum is used.
temperature (Number) - A number between 0 and 2 indicating the randomness of the completion. Lower values make the output more focused and deterministic, while higher values make it more random. By default, the specific model's temperature is used.
tools (Array) (Optional) - An array of function definitions that the AI can call. Each function definition should have:
type (String) - Must be "function"
function (Object):
name (String) - The name of the function
description (String) - A description of what the function does
parameters (Object) - JSON Schema object describing the parameters
strict (Boolean) - Whether to enforce strict parameter validation
testMode (Boolean) (Optional)
A boolean indicating whether you want to use the test API. Defaults to false. This is useful for testing your code without using up API credits.

imageURL (String)
A string containing the URL of an image you want to provide as context for the completion. Also known as "GPT Vision".

imageURLArray (Array)
An array of strings containing the URLs of images you want to provide as context for the completion.

messages (Array)
An array of objects containing the messages you want to complete. Each object must have a role and a content property. The role property must be one of system, assistant, user, or function. The content property must be a string containing the message. An example of a valid messages parameter is:

[
    {
        role: 'system',
        content: 'Hello, how are you?'
    },
    {
        role: 'user',
        content: 'I am doing well, how are you?'
    },
]
Providing a messages array is especially useful for building chatbots where you want to provide context to the completion.

Return value
When stream is set to false (default):

Will resolve to a response object containing the completion message
If a function call is made, the response will include tool_calls array containing:
id (String) - Unique identifier for the function call
function (Object):
name (String) - Name of function to call
arguments (String) - JSON string of function arguments
When stream is set to true:

Returns an async iterable object that you can use with a for await...of loop to receive the response in parts as they become available.
In case of an error, the Promise will reject with an error message.

Vendors
We use different vendors for different models and try to use the best vendor available at the time of the request. Vendors include, but are not limited to, OpenAI, Anthropic, Google, xAI, Mistral, OpenRouter, and DeepSeek.

Examples
Ask GPT-4.1 nano a question

<html>
<body>
    <script src="https://js.puter.com/v2/"></script>
    <script>
        puter.ai.chat(`What is life?`).then(puter.print);
    </script>
</body>
</html>
GPT-4 Vision

<html>
<body>
    <script src="https://js.puter.com/v2/"></script>
    <img src="https://assets.puter.site/doge.jpeg" style="display:block;">
    <script>
        puter.ai.chat(
            `What do you see?`, 
            `https://assets.puter.site/doge.jpeg`)
        .then(puter.print);
    </script>
</body>
</html>
Stream the response

<html>
<body>
    <script src="https://js.puter.com/v2/"></script>
    <script>
    (async () => {
        const resp = await puter.ai.chat('Tell me in detail what Rick and Morty is all about.', {model: 'claude', stream: true });
        for await ( const part of resp ) document.write(part?.text.replaceAll('\n', '<br>'));
    })();
    </script>
</body>
</html>
Function Calling

<!DOCTYPE html>
<html>
<head>
    <title>Weather Function Calling Demo</title>
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
    <script src="https://js.puter.com/v2/"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 600px;
            margin: 20px auto;
            padding: 20px;
        }
        .container {
            border: 1px solid #ccc;
            padding: 20px;
            border-radius: 5px;
        }
        input {
            width: 100%;
            padding: 10px;
            margin: 10px 0;
            box-sizing: border-box;
        }
        button {
            width: 100%;
            padding: 10px;
            background: #007bff;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }
        button:disabled {
            background: #ccc;
        }
        #response {
            margin-top: 20px;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 5px;
            display: none;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Weather Function Calling Demo</h1>
        <input type="text" id="userInput" value="Paris" placeholder="Ask about the weather (e.g. What's the weather in Paris?)" />
        <button id="submit">Submit</button>
        <div id="response"></div>
    </div>

    <script>
        // Mock weather function - in a real app, this would call a weather API
        function getWeather(location) {
            const mockWeatherData = {
                'Paris': '22¬∞C, Partly Cloudy',
                'London': '18¬∞C, Rainy',
                'New York': '25¬∞C, Sunny',
                'Tokyo': '28¬∞C, Clear'
            };
            return mockWeatherData[location] || '20¬∞C, Unknown';
        }

        // Define the tools (functions) available to the AI
        const tools = [{
            type: "function",
            function: {
                name: "get_weather",
                description: "Get current weather for a given location",
                parameters: {
                    type: "object",
                    properties: {
                        location: {
                            type: "string",
                            description: "City name e.g. Paris, London"
                        }
                    },
                    required: ["location"],
                    additionalProperties: false
                },
                strict: true
            }
        }];

        async function handleSubmit() {
            const userInput = $('#userInput').val();
            if (!userInput) return;

            // Disable button and show loading state
            $('#submit').prop('disabled', true).text('Loading...');
            $('#response').hide();

            try {
                // First message to get function call
                const completion = await puter.ai.chat(userInput, { tools });
                let finalResponse;

                // Check if we got a function call
                if (completion.message.tool_calls && completion.message.tool_calls.length > 0) {
                    const toolCall = completion.message.tool_calls[0];
                    if (toolCall.function.name === 'get_weather') {
                        // Parse the arguments and get weather data
                        const args = JSON.parse(toolCall.function.arguments);
                        const weatherData = getWeather(args.location);
                        // Send the result back to AI for final response
                        finalResponse = await puter.ai.chat([
                            { role: "user", content: userInput },
                            completion.message,
                            { 
                                role: "tool",
                                tool_call_id: toolCall.id,
                                content: weatherData
                            }
                        ]);
                    }
                } else {
                    finalResponse = completion;
                }

                // Display the response
                $('#response').html(`<strong>Response:</strong><br>${finalResponse}`).show();
            } catch (error) {
                $('#response').html(`<strong>Error:</strong><br>${error.message}`).show();
            }

            // Reset button state
            $('#submit').prop('disabled', false).text('Submit');
        }

        // Event handlers
        $(document).ready(function() {
            $('#submit').click(handleSubmit);
            $('#userInput').keypress(function(e) {
                if (e.which == 13) handleSubmit();
            });
        });
    </script>
</body>
</html>```


================================================
FILE: public/_redirects
================================================
https://klutz.netlify.app/* https://klutz.co.in/:splat 301!


================================================
FILE: public/ads.txt
================================================
google.com, pub-8061354259054600, DIRECT, f08c47fec0942fa0



================================================
FILE: public/google83078bd88d6feeca.html
================================================
google-site-verification: google83078bd88d6feeca.html


================================================
FILE: public/robots.txt
================================================
User-agent: *
Allow: /

Sitemap: https://klutz.netlify.app/sitemap.xml


================================================
FILE: public/sitemap.xml
================================================
<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.sitemaps.org/schemas/sitemap/0.9 http://www.sitemaps.org/schemas/sitemap/0.9/sitemap.xsd">
    <url>
        <loc>/</loc>
    </url>
    <url>
        <loc>/ai-date-time-checker</loc>
    </url>
    <url>
        <loc>/ai-problem-solver</loc>
    </url>
    <url>
        <loc>/appliance-troubleshooter</loc>
    </url>
    <url>
        <loc>/ai-translator</loc>
    </url>
    <url>
        <loc>/cookies</loc>
    </url>
    <url>
        <loc>/ethnicity-certifier</loc>
    </url>
    <url>
        <loc>/faq</loc>
    </url>
    <url>
        <loc>/heatmap-generator</loc>
    </url>
    <url>
        <loc>/image-to-text</loc>
    </url>
    <url>
        <loc>/ingredients-checker</loc>
    </url>
    <url>
        <loc>/login</loc>
    </url>
    <url>
        <loc>/measuring-tool</loc>
    </url>
    <url>
        <loc>/mediscan</loc>
    </url>
    <url>
        <loc>/neurodiversity-checker</loc>
    </url>
    <url>
        <loc>/privacy-policy</loc>
    </url>
    <url>
        <loc>/terms-of-service</loc>
    </url>
    <url>
        <loc>/text-to-image-generator</loc>
    </url>
    <url>
        <loc>/third-party-licenses</loc>
    </url>
    <url>
        <loc>/thumbnail-checker</loc>
    </url>
    <url>
        <loc>/vehicle-troubleshooter</loc>
    </url>
</urlset>


================================================
FILE: src/ai/dev.ts
================================================
// This file will be deleted as Genkit is being removed.
// Placeholder content to allow deletion.



================================================
FILE: src/ai/genkit.ts
================================================
// This file will be deleted as Genkit is being removed.
// Placeholder content to allow deletion.



================================================
FILE: src/ai/flows/detect-image-anomalies.ts
================================================
// This file will be deleted as Genkit is being removed.
// Placeholder content to allow deletion.



================================================
FILE: src/ai/flows/generate-medical-report.ts
================================================
import {
  generateObject,
  get\'gemini-1.5-flash-latest\',
  defineFlow,
} from \'@genkit-ai/flow\';
import { z } from \'zod\';
import {
  MedicalImageAnalysisRequest,
  MedicalImageAnalysisResponse,
  MedicalImageType,
} from \'../../types/mediscan\';

export const generateMedicalReport = defineFlow(
  {
    name: \'generateMedicalReport\',
    inputSchema: z.object({
      image: z.string(), // Base64 encoded image
      imageType: z.nativeEnum(MedicalImageType),
      additionalInfo: z.string().optional(),
    }),
    outputSchema: z.object({
      abnormalities: z.string(),
      diagnosis: z.string(),
      nextSteps: z.string(),
    }),
  },
  async (request: MedicalImageAnalysisRequest) => {
    const prompt = `Analyze the following medical image (of type ${request.imageType}) and provide a detailed report. Additional information: ${request.additionalInfo || \'None\'}.\n\nImage: ${request.image}\n\nReport should include:\n1. Abnormalities found.\n2. Possible diagnosis.\n3. Recommended next steps.`;

    const response = await generateObject({ model: get\'gemini-1.5-flash-latest\' }, request.outputSchema, prompt);
    return response;
  }
);
// This file will be deleted as Genkit is being removed.
// Placeholder content to allow deletion.



================================================
FILE: src/ai/flows/suggest-next-steps.ts
================================================
// This file will be deleted as Genkit is being removed.
// Placeholder content to allow deletion.



================================================
FILE: src/app/actions.ts
================================================
// This file will be deleted as Puter.js integration moves logic to client-side.
// Placeholder content to allow deletion.



================================================
FILE: src/app/globals.css
================================================
@tailwind base;
@tailwind components;
@tailwind utilities;

body {
  font-family: 'PT Sans', sans-serif;
}

@layer base {
  :root {
    --background: 220 17% 95%; /* Light Gray #F0F2F5 */
    --foreground: 220 10% 20%; /* Dark Gray for text on light gray */

    --card: 0 0% 100%;
    --card-foreground: 220 10% 20%;

    --popover: 0 0% 100%;
    --popover-foreground: 220 10% 20%;

    --primary: 231 48% 48%; /* Deep Blue #3F51B5 */
    --primary-foreground: 0 0% 100%; /* White */

    --secondary: 220 13% 91%; /* Lighter gray for secondary elements */
    --secondary-foreground: 231 48% 48%; /* Deep Blue */

    --muted: 220 13% 88%;
    --muted-foreground: 220 10% 40%;

    --accent: 174 100% 29%; /* Teal #009688 */
    --accent-foreground: 0 0% 100%; /* White */

    --destructive: 0 84.2% 60.2%;
    --destructive-foreground: 0 0% 98%;

    --border: 220 13% 85%;
    --input: 220 13% 88%;
    --ring: 231 48% 48%; /* Deep Blue for focus rings */

    --chart-1: 12 76% 61%;
    --chart-2: 173 58% 39%;
    --chart-3: 197 37% 24%;
    --chart-4: 43 74% 66%;
    --chart-5: 27 87% 67%;
    --radius: 0.5rem;

    /* Sidebar specific colors, can be adjusted if sidebar is used extensively */
    --sidebar-background: 0 0% 100%;
    --sidebar-foreground: 220 10% 20%;
    --sidebar-primary: 231 48% 48%;
    --sidebar-primary-foreground: 0 0% 100%;
    --sidebar-accent: 174 100% 29%;
    --sidebar-accent-foreground: 0 0% 100%;
    --sidebar-border: 220 13% 85%;
    --sidebar-ring: 231 48% 48%;
  }

  .dark {
    --background: 220 10% 10%; /* Darker background for dark mode */
    --foreground: 0 0% 98%; /* Light text for dark mode */

    --card: 220 10% 15%;
    --card-foreground: 0 0% 98%;

    --popover: 220 10% 15%;
    --popover-foreground: 0 0% 98%;

    --primary: 231 48% 58%; /* Lighter Deep Blue for dark mode */
    --primary-foreground: 0 0% 10%; 

    --secondary: 220 10% 25%;
    --secondary-foreground: 0 0% 98%;

    --muted: 220 10% 25%;
    --muted-foreground: 0 0% 60%;

    --accent: 174 100% 39%; /* Lighter Teal for dark mode */
    --accent-foreground: 0 0% 10%;

    --destructive: 0 62.8% 30.6%;
    --destructive-foreground: 0 0% 98%;

    --border: 220 10% 30%;
    --input: 220 10% 30%;
    --ring: 231 48% 58%;

    --chart-1: 220 70% 50%;
    --chart-2: 160 60% 45%;
    --chart-3: 30 80% 55%;
    --chart-4: 280 65% 60%;
    --chart-5: 340 75% 55%;

    --sidebar-background: 220 10% 15%;
    --sidebar-foreground: 0 0% 98%;
    --sidebar-primary: 231 48% 58%;
    --sidebar-primary-foreground: 0 0% 10%;
    --sidebar-accent: 174 100% 39%;
    --sidebar-accent-foreground: 0 0% 10%;
    --sidebar-border: 220 10% 30%;
    --sidebar-ring: 231 48% 58%;
  }
}

/* Card Hover Effects */
.cards {
  position: relative;
}

.cssbuttons-io-button {
  background: #606dc0;
  color: #17191c;
  font-family: inherit;
  padding: 0.35em;
  padding-left: 1.2em;
  font-size: 17px;
  font-weight: 500;
  border-radius: 0.9em;
  border: none;
  letter-spacing: 0.05em;
  display: flex;
  align-items: center;
  box-shadow: inset 0 0 1.6em -0.6em #5a99dd;
  overflow: hidden;
  position: relative;
  height: 2.8em;
  padding-right: 3.3em;
}

.cssbuttons-io-button .icon {
  background: #17191c;
  margin-left: 1em;
  position: absolute;
  display: flex;
  align-items: center;
  justify-content: center;
  height: 2.2em;
  width: 2.2em;
  border-radius: 0.7em;
  box-shadow: 0.1em 0.1em 0.6em 0.2em #5a99dd;
  right: 0.3em;
  transition: all 0.3s;
}

.cssbuttons-io-button:hover .icon {
  width: calc(100% - 0.6em);
}

.cssbuttons-io-button .icon svg {
  width: 1.1em;
  transition: transform 0.3s;
  color: #5a99dd;
}

.cssbuttons-io-button:hover .icon svg {
  transform: translateX(0.1em);
}

.cssbuttons-io-button:active .icon {
  transform: scale(0.95);
}


@layer base {
  * {
    @apply border-border;
  }
  body {
    @apply bg-background text-foreground;
  }
}



================================================
FILE: src/app/google83078bd88d6feeca.html
================================================
google-site-verification: google83078bd88d6feeca.html


================================================
FILE: src/app/layout-client.tsx
================================================
'use client';

import Link from 'next/link';
import { Button } from '@/components/ui/button';
import LoginButton from '@/components/auth/login-button';
import { ThemeToggle } from "@/components/theme-toggle";
import { User, MenuIcon } from 'lucide-react';
import Sidebar from "@/components/layout/Sidebar";
import { useState } from 'react';

export default function LayoutClient({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  const [isSidebarOpen, setIsSidebarOpen] = useState(false);
  return (
    <>
      
      <main className="flex-grow">
          {children}
      </main>

    </>
  );
}



================================================
FILE: src/app/layout.tsx
================================================
import type {Metadata} from 'next';
import './globals.css';
import { Toaster } from "@/components/ui/toaster";
import { ThemeProvider } from "@/components/providers";
import LayoutClient from './layout-client';

export const metadata: Metadata = {
  title: 'KLUTZ',
  description: 'Suite of AI-powered Image Analysis Tools',
  icons: {
    icon: 'https://res.cloudinary.com/ddz3nsnq1/image/upload/v1751201919/Untitled_design_3_d8m11k.png',
  },
};

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en" suppressHydrationWarning>
      <head>
        <link rel="preconnect" href="https://fonts.googleapis.com" />
        <link rel="preconnect" href="https://fonts.gstatic.com" crossOrigin="anonymous" />
        <link href="https://fonts.googleapis.com/css2?family=PT+Sans:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet" />
        <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@300..700&display=swap" rel="stylesheet" />
        <script src="https://js.puter.com/v2/"></script>

        <meta name="google-site-verification" content="FVYY2_q5JUQa1Oqg8XGj4v2wqB4F1BcREDn_ZVlwNCA" />
      </head>
      <body className="font-body antialiased min-h-screen flex flex-col">
        <ThemeProvider
          attribute="class"
          defaultTheme="system"
          enableSystem
          disableTransitionOnChange
        >
          <LayoutClient>{children}</LayoutClient>
          <Toaster />
        </ThemeProvider>
      </body>

    </html>
  );
}



================================================
FILE: src/app/page.tsx
================================================
'use client';

import Footer from "@/components/layout/footer";
import { useState } from 'react';
import Link from 'next/link';
import Image from 'next/image';
import Head from 'next/head';
import { Button } from '@/components/ui/button';
import Sidebar from "@/components/layout/Sidebar";
import { MenuIcon, User } from 'lucide-react';
import { ThemeToggle } from '@/components/theme-toggle'; // Import ThemeToggle
import LoginButton from '@/components/auth/login-button';
import HorizontalCarousel from '@/components/HorizontalCarousel'; // Import the new component
import AutoScrollMarquee from '@/components/AutoScrollMarquee'; // Import the new component

export default function LandingPage() {
  const [isSidebarOpen, setIsSidebarOpen] = useState(false);

  return (
    <div className="min-h-screen bg-[#7190be]">
      <div className="absolute top-4 right-4 z-20 flex items-center gap-4">
        <Button variant="ghost" size="icon" onClick={() => setIsSidebarOpen(true)}>
          <MenuIcon className="h-5 w-5" />
          <span className="sr-only">Toggle Sidebar</span>
        </Button>
        <ThemeToggle />
        <Button variant="ghost" size="icon" asChild>
          <Link href="https://puter.com">
            <User className="h-5 w-5" />
            <span className="sr-only">Account</span>
          </Link>
        </Button>
        <LoginButton />
      </div>
      {isSidebarOpen && <Sidebar isOpen={isSidebarOpen} onClose={() => setIsSidebarOpen(false)} />}

      <section className="relative h-96 overflow-hidden">
        <img
          src="https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752160444/Screenshot_2025-07-10_180305_kbaefl.png"
          alt="Background"
          className="absolute inset-0 w-full h-full object-cover object-center"
        />
        <div className="absolute inset-0 bg-gradient-to-b from-transparent via-[#193067]/50 to-[#193067]"></div>
      </section>

      {/* Section containing the second background image and overlaid content */}
      <section className="relative h-[400px] overflow-hidden">
        {/* Second Background Image */}
        <img
          src="https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752689600/Image_fx_17_hpqoyi.png"
          alt="faded glory blue Background"
          className="absolute inset-0 w-full h-full object-cover object-center z-0" 
        />
        {/* Overlaid content */}
        <div className="relative z-10 flex flex-col items-center justify-center h-full">
          {/* Klutz logo and text */}
          <div className="flex items-center justify-center mb-12">
            <img src="https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752076900/Untitled_design__3_-removebg-preview_dydzqt.png" alt="Klutz Logo" className="w-24 h-24 mr-4" />
            <p className="text-2xl font-semibold text-gray-700">Klutz</p>
          </div>
          {/* Heading and Subheading */}
          <div className="text-center mb-16">
            <h1 className="text-5xl font-bold text-gray-800 mb-4">Who Said AI Is Gonna Take Over?</h1>
            <p className="text-xl text-gray-600">Make AI Your Slave, With KLUTZ!</p>
          </div>
        </div>
      </section>

      {/* Horizontally Scrollable Carousels */}
      <HorizontalCarousel
        title="Chat"
        content={[
          { title: "With Any AI Model", imageUrl: "https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752678871/Screenshot_2025-07-16_204359_abdlvo.png" },
          { title: "With Any Website", imageUrl: "https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752678916/Screenshot_2025-07-16_204503_ahsgxv.png" },
          { title: "With Any Image", imageUrl: "https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752678982/Screenshot_2025-07-16_204604_unp1p1.png" },
        ]}
      />

      <HorizontalCarousel
        title="Analyze"
        content={[
          { title: "Date & Time", imageUrl: "https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752162170/Screenshot_2025-07-10_205422_b7izxl.png" },
          { title: "To Solve Problems", imageUrl: "https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752162154/Screenshot_2025-07-10_205337_kq5abm.png" },
          { title: "Medical Images", imageUrl: "https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752162184/Screenshot_2025-07-10_205507_uw1suh.png" },
          { title: "To Translate", imageUrl: "https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752162142/Screenshot_2025-07-10_205222_z5xvzl.png" },
          { title: "For Measuring", imageUrl: "https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752162361/Screenshot_2025-07-10_210120_ylcsjo.png"},
          { title: "For Neurodiversity", imageUrl: "https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752162282/Screenshot_2025-07-10_205717_puu2fg.png" },
          { title: "For Engagement", imageUrl: "https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752162305/Screenshot_2025-07-10_205841_fid3qo.png" },
          { title: "For Ethnicity", imageUrl: "https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752162264/Screenshot_2025-07-10_205639_u9wahe.png" },
          { title: "For Consistency", imageUrl: "https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752162202/Screenshot_2025-07-10_205602_iyegzx.png" },
        ]}
      />

      <HorizontalCarousel
        title="Generate"
        content={[
          { title: "Images", imageUrl: "https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752162374/Screenshot_2025-07-10_210309_vn079l.png" },
          { title: "Speech", imageUrl: "https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752162567/Screenshot_2025-07-10_211048_ytodyc.png" },
          { title: "Infographics", imageUrl: "https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752162488/Screenshot_2025-07-10_210815_mb3xws.png" },
          { title: "Prompts", imageUrl: "https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752162456/Screenshot_2025-07-10_211722_orastr.png" },
          { title: "Vehicle Diagnosis", imageUrl: "https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752162348/Screenshot_2025-07-10_210037_ejmmzi.png" },
          { title: "Device Diagnosis", imageUrl: "https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752162334/Screenshot_2025-07-10_205941_wk8txn.png" },
          { title: "Text From Images", imageUrl: "https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752162119/Screenshot_2025-07-10_205138_nqzsrk.png" },
        ]}
      />

      <HorizontalCarousel
        title="AI-Native"
        content={[
          { title: "Audio Editor", imageUrl: "https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752162547/screencapture-klutz-pi-vercel-app-ai-audio-editor-2025-07-10-21_09_22_isacwg.png" },
          { title: "Spreadsheets", imageUrl: "https://res.cloudinary.com/ddz3nsnq1/image/upload/v1752162472/Screenshot_2025-07-10_210446_nutmko.png" },
        ]}
      />

      {/* Testimonials */}
      <section className="mb-16">
        <h2 className="text-3xl font-semibold text-gray-800 mb-6 text-center">What Users Say</h2>
        <AutoScrollMarquee
          content={[
            <iframe key="1" style={{ border: 'none' }} src="https://cards.producthunt.com/cards/reviews/1275497?v=1" width="500" height="405" frameBorder="0" scrolling="no" allowFullScreen></iframe>,
            <iframe key="2" style={{ border: 'none' }} src="https://cards.producthunt.com/cards/reviews/1279092?v=1" width="500" height="405" frameBorder="0" scrolling="no" allowFullScreen></iframe>,
            <iframe key="3" style={{ border: 'none' }} src="https://cards.producthunt.com/cards/reviews/1279088?v=1" width="500" height="405" frameBorder="0" scrolling="no" allowFullScreen></iframe>,
            <iframe key="4" style={{ border: 'none' }} src="https://cards.producthunt.com/cards/reviews/1277790?v=1" width="500" height="405" frameBorder="0" scrolling="no" allowFullScreen></iframe>,
          ]}
        />
      </section>

      {/* Footer */}
      <Footer />
    </div>
  );
}


================================================
FILE: src/app/ai-audio-editor/page.tsx
================================================
import AudioForgeClientContent from '@/components/audio-forge/AudioForgeClientContent';

export default function Home() {
  // Directly render the main application content
  return <AudioForgeClientContent />;
}


================================================
FILE: src/app/ai-date-time-checker/page.tsx
================================================
'use client';

import Head from 'next/head';
import { useState, useEffect } from 'react';
import { useToast } from "@/hooks/use-toast";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from "@/components/ui/card";
import { Input } from "@/components/ui/input";
import { Label } from "@/components/ui/label";
import { Alert, AlertDescription, AlertTitle } from "@/components/ui/alert";
import { Tabs, TabsContent, TabsList, TabsTrigger } from "@/components/ui/tabs";
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from "@/components/ui/select";
import { Loader2, Calendar, Clock, AlertTriangle, Info, Download, CalendarDays, History, Globe } from 'lucide-react';
import { downloadTextFile } from '@/lib/utils';
import type { DateTimeReport } from '@/types/ai-date-time-checker';

const cleanJsonString = (rawString: string): string => {
  let cleanedString = rawString.trim();
  if (cleanedString.startsWith("```json") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(7, cleanedString.length - 3).trim();
  } else if (cleanedString.startsWith("```") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(3, cleanedString.length - 3).trim();
  }
  return cleanedString;
};

const DAYS_OF_WEEK = [
  { value: 'monday', label: 'Monday' },
  { value: 'tuesday', label: 'Tuesday' },
  { value: 'wednesday', label: 'Wednesday' },
  { value: 'thursday', label: 'Thursday' },
  { value: 'friday', label: 'Friday' },
  { value: 'saturday', label: 'Saturday' },
  { value: 'sunday', label: 'Sunday' },
];

const MONTHS = [
  { value: 1, label: 'January' },
  { value: 2, label: 'February' },
  { value: 3, label: 'March' },
  { value: 4, label: 'April' },
  { value: 5, label: 'May' },
  { value: 6, label: 'June' },
  { value: 7, label: 'July' },
  { value: 8, label: 'August' },
  { value: 9, label: 'September' },
  { value: 10, label: 'October' },
  { value: 11, label: 'November' },
  { value: 12, label: 'December' },
];

// Generate years from 1 AD to 3000 AD
const generateYears = () => {
  const years = [];
  for (let year = 1; year <= 3000; year++) {
    years.push({ value: year, label: year.toString() });
  }
  return years;
};

const YEARS = generateYears();

export default function AIDateTimeCheckerPage() {
  const [queryType, setQueryType] = useState<'date-to-info' | 'day-to-dates'>('date-to-info');
  const [selectedDate, setSelectedDate] = useState<string>('');
  const [selectedMonth, setSelectedMonth] = useState<number | undefined>(undefined);
  const [selectedYear, setSelectedYear] = useState<number | undefined>(undefined);
  const [selectedDayOfWeek, setSelectedDayOfWeek] = useState<string>('');
  
  const [dateTimeReport, setDateTimeReport] = useState<DateTimeReport | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const { toast } = useToast();

  useEffect(() => {
    if (typeof window.puter === 'undefined') {
      toast({
        variant: "destructive",
        title: "Puter SDK Error",
        description: "Puter.js SDK is not loaded. Please refresh the page.",
      });
    }
  }, [toast]);

  const performAnalysis = async () => {
    if (queryType === 'date-to-info' && !selectedDate) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please select a date to analyze." });
      return;
    }
    if (queryType === 'day-to-dates' && (!selectedMonth || !selectedYear || !selectedDayOfWeek)) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please select month, year, and day of the week." });
      return;
    }

    setIsLoading(true);
    setDateTimeReport(null);
    setError(null);
    toast({ title: "Analysis Started", description: "AI is analyzing your date/time query..." });

    try {
      if (typeof window.puter === 'undefined' || !window.puter.auth || !window.puter.ai) {
        throw new Error("Puter SDK not available. Please refresh.");
      }
      const puter = window.puter;

      let isSignedIn = await puter.auth.isSignedIn();
      if (!isSignedIn) {
        await puter.auth.signIn();
        isSignedIn = await puter.auth.isSignedIn();
        if (!isSignedIn) throw new Error("Authentication failed or was cancelled.");
      }

      let prompt: string;

      if (queryType === 'date-to-info') {
        const dateObj = new Date(selectedDate);
        const day = dateObj.getDate();
        const month = dateObj.getMonth() + 1;
        const year = dateObj.getFullYear();

        prompt = `
          You are an AI assistant specialized in calendar calculations and historical date analysis.
          
          Analyze the date: ${day}/${month}/${year} (${selectedDate})
          
          Provide comprehensive information about this specific date including:
          1. What day of the week it was/is/will be
          2. Historical and cultural significance
          3. Astronomical information
          4. Calendar system details
          
          Return your analysis in a JSON object with these keys:
          - "query_type": "date-to-info"
          - "date_info": {
              "formatted_date": "Full formatted date string",
              "day_of_week": "Monday/Tuesday/etc.",
              "day_number": ${day},
              "month_name": "Month name",
              "year": ${year},
              "century": "Which century (e.g., '21st century')",
              "millennium": "Which millennium (e.g., '3rd millennium')",
              "julian_day": "Julian day number if calculable",
              "historical_events": ["Array of notable historical events on this date"],
              "astronomical_info": ["Array of astronomical information"],
              "cultural_significance": ["Array of cultural/religious significance"],
              "season": "Spring/Summer/Fall/Winter (Northern Hemisphere)",
              "zodiac_sign": "Astrological sign if applicable"
            }
          - "calculation_method": "Description of how the day was calculated"
          - "confidence": "High/Medium/Low"
          - "historical_accuracy_note": "Note about historical calendar accuracy"
          - "disclaimer": "Standard disclaimer about AI calculations"
        `;
      } else {
        const monthName = MONTHS.find(m => m.value === selectedMonth)?.label || '';
        const dayName = DAYS_OF_WEEK.find(d => d.value === selectedDayOfWeek)?.label || '';

        prompt = `
          You are an AI assistant specialized in calendar calculations.
          
          Find all dates in ${monthName} ${selectedYear} that fall on a ${dayName}.
          
          Calculate which specific dates (1-31) in ${monthName} ${selectedYear} are ${dayName}s.
          
          Return your analysis in a JSON object with these keys:
          - "query_type": "day-to-dates"
          - "matching_dates": {
              "month_name": "${monthName}",
              "year": ${selectedYear},
              "day_of_week": "${dayName}",
              "dates": [Array of date numbers that are ${dayName}s],
              "total_count": "Number of ${dayName}s in the month",
              "formatted_dates": ["Array of full formatted date strings"]
            }
          - "calculation_method": "Description of how the dates were calculated"
          - "confidence": "High/Medium/Low"
          - "disclaimer": "Standard disclaimer about AI calculations"
        `;
      }

      const response = await puter.ai.chat(prompt, { model: 'gpt-4o' });

      if (!response?.message?.content) {
        throw new Error("AI analysis did not return content.");
      }

      const parsedResponse: DateTimeReport = JSON.parse(cleanJsonString(response.message.content));
      setDateTimeReport(parsedResponse);
      toast({ title: "Analysis Complete", variant: "default", className: "bg-green-500 text-white dark:bg-green-600" });

    } catch (err: any) {
      console.error("Date/time analysis error:", err);
      let errorMessage = "An error occurred during analysis.";
      if (err instanceof Error) errorMessage = err.message;
      else if (typeof err === 'string') errorMessage = err;
      else if (err.error && err.error.message) errorMessage = err.error.message;
      setError(errorMessage);
      toast({ variant: "destructive", title: "Analysis Failed", description: errorMessage });
    } finally {
      setIsLoading(false);
    }
  };

  const handleDownloadReport = () => {
    if (!dateTimeReport) return;

    let reportString = "KLUTZ AI Date & Time Checker Report\n";
    reportString += "===================================\n\n";

    if (dateTimeReport.query_type === 'date-to-info' && dateTimeReport.date_info) {
      const info = dateTimeReport.date_info;
      reportString += "Date Information Analysis:\n";
      reportString += "--------------------------\n";
      reportString += `Date: ${info.formatted_date}\n`;
      reportString += `Day of Week: ${info.day_of_week}\n`;
      reportString += `Century: ${info.century}\n`;
      reportString += `Millennium: ${info.millennium}\n`;
      reportString += `Season: ${info.season}\n`;
      if (info.zodiac_sign) reportString += `Zodiac Sign: ${info.zodiac_sign}\n`;
      if (info.julian_day) reportString += `Julian Day: ${info.julian_day}\n`;
      reportString += "\n";

      if (info.historical_events && info.historical_events.length > 0) {
        reportString += "Historical Events:\n";
        reportString += "------------------\n";
        info.historical_events.forEach(event => {
          reportString += `- ${event}\n`;
        });
        reportString += "\n";
      }

      if (info.astronomical_info && info.astronomical_info.length > 0) {
        reportString += "Astronomical Information:\n";
        reportString += "------------------------\n";
        info.astronomical_info.forEach(astro => {
          reportString += `- ${astro}\n`;
        });
        reportString += "\n";
      }

      if (info.cultural_significance && info.cultural_significance.length > 0) {
        reportString += "Cultural Significance:\n";
        reportString += "---------------------\n";
        info.cultural_significance.forEach(cultural => {
          reportString += `- ${cultural}\n`;
        });
        reportString += "\n";
      }
    } else if (dateTimeReport.query_type === 'day-to-dates' && dateTimeReport.matching_dates) {
      const matches = dateTimeReport.matching_dates;
      reportString += "Day-to-Dates Analysis:\n";
      reportString += "----------------------\n";
      reportString += `Month: ${matches.month_name} ${matches.year}\n`;
      reportString += `Day of Week: ${matches.day_of_week}\n`;
      reportString += `Total Count: ${matches.total_count}\n\n`;

      reportString += "Matching Dates:\n";
      reportString += "---------------\n";
      matches.dates.forEach(date => {
        reportString += `- ${date}\n`;
      });
      reportString += "\n";

      if (matches.formatted_dates && matches.formatted_dates.length > 0) {
        reportString += "Full Formatted Dates:\n";
        reportString += "--------------------\n";
        matches.formatted_dates.forEach(formattedDate => {
          reportString += `- ${formattedDate}\n`;
        });
        reportString += "\n";
      }
    }

    reportString += "Calculation Method:\n";
    reportString += "------------------\n";
    reportString += `${dateTimeReport.calculation_method}\n\n`;

    reportString += "AI Confidence Level: " + dateTimeReport.confidence + "\n\n";

    if (dateTimeReport.historical_accuracy_note) {
      reportString += "Historical Accuracy Note:\n";
      reportString += "------------------------\n";
      reportString += `${dateTimeReport.historical_accuracy_note}\n\n`;
    }

    reportString += "Disclaimer:\n";
    reportString += "-----------\n";
    reportString += dateTimeReport.disclaimer + "\n\n";
    
    reportString += "\nIMPORTANT: This report is AI-generated and for informational purposes only. For critical historical or astronomical calculations, consult specialized references.";

    const timestamp = new Date().toISOString().replace(/[:.-]/g, '').slice(0, 14);
    downloadTextFile(reportString, `KLUTZ_AIDateTimeChecker_Report_${timestamp}.txt`);
  };

  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/ai-date-time-checker" />
      </Head>
    <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-8">
      <Card className="max-w-3xl mx-auto shadow-xl">
        <CardHeader>
          <CardTitle className="font-headline text-3xl text-primary flex items-center">
            <Calendar className="mr-3 h-8 w-8" />
            AI Date & Time Checker
          </CardTitle>
          <CardDescription>
            Explore dates from any century or millennium. Get detailed information about specific dates or find all dates in a month that fall on a particular day.
          </CardDescription>
        </CardHeader>
        <CardContent className="space-y-6">
          <Alert variant="default" className="bg-blue-50 border-blue-400 text-blue-700 dark:bg-blue-900/30 dark:text-blue-300">
            <Info className="h-5 w-5 text-blue-500" />
            <AlertTitle className="font-semibold">Time Travel Features</AlertTitle>
            <AlertDescription>
              Choose a specific date to learn what day it was and its historical significance, or select a month/year and day of the week to find all matching dates.
            </AlertDescription>
          </Alert>

          <Tabs value={queryType} onValueChange={(value) => setQueryType(value as 'date-to-info' | 'day-to-dates')} className="w-full">
            <TabsList className="grid w-full grid-cols-2">
              <TabsTrigger value="date-to-info">Date Information</TabsTrigger>
              <TabsTrigger value="day-to-dates">Find Dates by Day</TabsTrigger>
            </TabsList>
            <TabsContent value="date-to-info" className="mt-6">
              <div className="space-y-4">
                <div>
                  <Label htmlFor="date-input" className="text-lg font-medium flex items-center mb-2">
                    <CalendarDays className="mr-2 h-5 w-5 text-accent" />
                    Select Date
                  </Label>
                  <Input
                    id="date-input"
                    type="date"
                    value={selectedDate}
                    onChange={(e) => setSelectedDate(e.target.value)}
                    min="0001-01-01"
                    max="2999-12-31"
                    disabled={isLoading}
                    className="w-full"
                  />
                  <p className="text-sm text-muted-foreground mt-1">Choose any date from year 1 AD to 2999 AD to get detailed information.</p>
                </div>
              </div>
            </TabsContent>
            <TabsContent value="day-to-dates" className="mt-6">
              <div className="space-y-4">
                <div className="grid grid-cols-1 md:grid-cols-3 gap-4">
                  <div>
                    <Label htmlFor="month-select" className="text-lg font-medium">Month</Label>
                    <Select value={selectedMonth?.toString()} onValueChange={(value) => setSelectedMonth(parseInt(value))}>
                      <SelectTrigger id="month-select" className="w-full">
                        <SelectValue placeholder="Select month" />
                      </SelectTrigger>
                      <SelectContent>
                        {MONTHS.map((month) => (
                          <SelectItem key={month.value} value={month.value.toString()}>
                            {month.label}
                          </SelectItem>
                        ))}
                      </SelectContent>
                    </Select>
                  </div>

                  <div>
                    <Label htmlFor="year-select" className="text-lg font-medium">Year</Label>
                    <Select value={selectedYear?.toString()} onValueChange={(value) => setSelectedYear(parseInt(value))}>
                      <SelectTrigger id="year-select" className="w-full">
                        <SelectValue placeholder="Select year" />
                      </SelectTrigger>
                      <SelectContent className="max-h-60">
                        {YEARS.map((year) => (
                          <SelectItem key={year.value} value={year.value.toString()}>
                            {year.label}
                          </SelectItem>
                        ))}
                      </SelectContent>
                    </Select>
                  </div>

                  <div>
                    <Label htmlFor="day-select" className="text-lg font-medium">Day of Week</Label>
                    <Select value={selectedDayOfWeek} onValueChange={setSelectedDayOfWeek}>
                      <SelectTrigger id="day-select" className="w-full">
                        <SelectValue placeholder="Select day" />
                      </SelectTrigger>
                      <SelectContent>
                        {DAYS_OF_WEEK.map((day) => (
                          <SelectItem key={day.value} value={day.value}>
                            {day.label}
                          </SelectItem>
                        ))}
                      </SelectContent>
                    </Select>
                  </div>
                </div>
                <p className="text-sm text-muted-foreground">Find all dates in the selected month and year that fall on the chosen day of the week.</p>
              </div>
            </TabsContent>
          </Tabs>

          <Button 
            onClick={performAnalysis} 
            disabled={isLoading || (queryType === 'date-to-info' && !selectedDate) || (queryType === 'day-to-dates' && (!selectedMonth || !selectedYear || !selectedDayOfWeek))} 
            className="w-full"
          >
            {isLoading ? (
              <>
                <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                Analyzing Date & Time...
              </>
            ) : (
              <>
                <Clock className="mr-2 h-4 w-4" />
                Analyze Date & Time
              </>
            )}
          </Button>

          {error && !isLoading && (
            <Alert variant="destructive" className="mt-6">
              <AlertTriangle className="h-5 w-5" />
              <AlertTitle>Analysis Error</AlertTitle>
              <AlertDescription>{error}</AlertDescription>
            </Alert>
          )}

          {dateTimeReport && !isLoading && !error && (
            <Card className="mt-6 shadow-md">
              <CardHeader>
                <CardTitle className="font-headline text-xl flex items-center">
                  <Calendar className="mr-2 h-6 w-6 text-primary" />
                  {dateTimeReport.query_type === 'date-to-info' ? 'Date Information' : 'Matching Dates'}
                </CardTitle>
              </CardHeader>
              <CardContent className="space-y-4">
                {dateTimeReport.query_type === 'date-to-info' && dateTimeReport.date_info && (
                  <>
                    <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                      <div className="bg-blue-50 dark:bg-blue-900/20 p-4 rounded-md">
                        <h4 className="font-semibold text-md mb-2 flex items-center">
                          <CalendarDays className="mr-2 h-4 w-4 text-blue-500" />
                          Date Details
                        </h4>
                        <div className="space-y-1 text-sm">
                          <p><strong>Date:</strong> {dateTimeReport.date_info.formatted_date}</p>
                          <p><strong>Day:</strong> {dateTimeReport.date_info.day_of_week}</p>
                          <p><strong>Century:</strong> {dateTimeReport.date_info.century}</p>
                          <p><strong>Millennium:</strong> {dateTimeReport.date_info.millennium}</p>
                          <p><strong>Season:</strong> {dateTimeReport.date_info.season}</p>
                          {dateTimeReport.date_info.zodiac_sign && (
                            <p><strong>Zodiac:</strong> {dateTimeReport.date_info.zodiac_sign}</p>
                          )}
                        </div>
                      </div>

                      <div className="bg-purple-50 dark:bg-purple-900/20 p-4 rounded-md">
                        <h4 className="font-semibold text-md mb-2 flex items-center">
                          <Clock className="mr-2 h-4 w-4 text-purple-500" />
                          Technical Details
                        </h4>
                        <div className="space-y-1 text-sm">
                          <p><strong>Confidence:</strong> {dateTimeReport.confidence}</p>
                          {dateTimeReport.date_info.julian_day && (
                            <p><strong>Julian Day:</strong> {dateTimeReport.date_info.julian_day}</p>
                          )}
                          <p><strong>Method:</strong> {dateTimeReport.calculation_method}</p>
                        </div>
                      </div>
                    </div>

                    {dateTimeReport.date_info.historical_events && dateTimeReport.date_info.historical_events.length > 0 && (
                      <div>
                        <h4 className="font-semibold text-md mb-2 flex items-center">
                          <History className="mr-2 h-4 w-4 text-amber-500" />
                          Historical Events:
                        </h4>
                        <ul className="list-disc pl-5 space-y-1 bg-amber-50 dark:bg-amber-900/20 p-3 rounded-md">
                          {dateTimeReport.date_info.historical_events.map((event, index) => (
                            <li key={index} className="text-amber-700 dark:text-amber-300">{event}</li>
                          ))}
                        </ul>
                      </div>
                    )}

                    {dateTimeReport.date_info.astronomical_info && dateTimeReport.date_info.astronomical_info.length > 0 && (
                      <div>
                        <h4 className="font-semibold text-md mb-2 flex items-center">
                          <Globe className="mr-2 h-4 w-4 text-indigo-500" />
                          Astronomical Information:
                        </h4>
                        <ul className="list-disc pl-5 space-y-1 bg-indigo-50 dark:bg-indigo-900/20 p-3 rounded-md">
                          {dateTimeReport.date_info.astronomical_info.map((astro, index) => (
                            <li key={index} className="text-indigo-700 dark:text-indigo-300">{astro}</li>
                          ))}
                        </ul>
                      </div>
                    )}

                    {dateTimeReport.date_info.cultural_significance && dateTimeReport.date_info.cultural_significance.length > 0 && (
                      <div>
                        <h4 className="font-semibold text-md mb-2 flex items-center">
                          <Globe className="mr-2 h-4 w-4 text-green-500" />
                          Cultural Significance:
                        </h4>
                        <ul className="list-disc pl-5 space-y-1 bg-green-50 dark:bg-green-900/20 p-3 rounded-md">
                          {dateTimeReport.date_info.cultural_significance.map((cultural, index) => (
                            <li key={index} className="text-green-700 dark:text-green-300">{cultural}</li>
                          ))}
                        </ul>
                      </div>
                    )}
                  </>
                )}

                {dateTimeReport.query_type === 'day-to-dates' && dateTimeReport.matching_dates && (
                  <>
                    <div className="bg-green-50 dark:bg-green-900/20 p-4 rounded-md">
                      <h4 className="font-semibold text-md mb-2 flex items-center">
                        <CalendarDays className="mr-2 h-4 w-4 text-green-500" />
                        Search Results
                      </h4>
                      <div className="space-y-2 text-sm">
                        <p><strong>Month:</strong> {dateTimeReport.matching_dates.month_name} {dateTimeReport.matching_dates.year}</p>
                        <p><strong>Day of Week:</strong> {dateTimeReport.matching_dates.day_of_week}</p>
                        <p><strong>Total Count:</strong> {dateTimeReport.matching_dates.total_count} {dateTimeReport.matching_dates.day_of_week}s</p>
                      </div>
                    </div>

                    <div>
                      <h4 className="font-semibold text-md mb-2">Matching Dates:</h4>
                      <div className="grid grid-cols-4 md:grid-cols-7 gap-2">
                        {dateTimeReport.matching_dates.dates.map((date, index) => (
                          <div key={index} className="bg-blue-100 dark:bg-blue-900/30 p-2 rounded-md text-center font-medium text-blue-700 dark:text-blue-300">
                            {date}
                          </div>
                        ))}
                      </div>
                    </div>

                    {dateTimeReport.matching_dates.formatted_dates && dateTimeReport.matching_dates.formatted_dates.length > 0 && (
                      <div>
                        <h4 className="font-semibold text-md mb-2">Full Dates:</h4>
                        <div className="bg-muted/30 p-3 rounded-md max-h-32 overflow-y-auto">
                          <ul className="list-disc pl-5 space-y-1 text-sm">
                            {dateTimeReport.matching_dates.formatted_dates.map((formattedDate, index) => (
                              <li key={index}>{formattedDate}</li>
                            ))}
                          </ul>
                        </div>
                      </div>
                    )}

                    <div className="bg-purple-50 dark:bg-purple-900/20 p-3 rounded-md">
                      <p className="text-sm"><strong>Calculation Method:</strong> {dateTimeReport.calculation_method}</p>
                      <p className="text-sm"><strong>Confidence:</strong> {dateTimeReport.confidence}</p>
                    </div>
                  </>
                )}

                {dateTimeReport.historical_accuracy_note && (
                  <Alert variant="default" className="bg-yellow-50 border-yellow-300 dark:bg-yellow-900/30 dark:text-yellow-300">
                    <AlertTriangle className="h-4 w-4 text-yellow-500" />
                    <AlertTitle className="font-medium">Historical Accuracy Note</AlertTitle>
                    <AlertDescription>{dateTimeReport.historical_accuracy_note}</AlertDescription>
                  </Alert>
                )}

                <Alert variant="default" className="text-xs bg-blue-50 border-blue-300 dark:bg-blue-900/30 dark:text-blue-300">
                  <Info className="h-4 w-4 text-blue-500" />
                  <AlertTitle className="font-medium">Disclaimer</AlertTitle>
                  <AlertDescription>{dateTimeReport.disclaimer}</AlertDescription>
                </Alert>

                <Button onClick={handleDownloadReport} variant="outline" className="w-full mt-4">
                  <Download className="mr-2 h-4 w-4" />
                  Download Report
                </Button>
              </CardContent>
            </Card>
          )}

          {!dateTimeReport && !isLoading && !error && (
            <div className="mt-6 p-4 border border-dashed rounded-md text-center text-muted-foreground">
              <Info className="mx-auto h-8 w-8 mb-2"/>
              <p>Select a query type and provide the required information to explore dates and times across centuries and millennia.</p>
            </div>
          )}
        </CardContent>
        <CardFooter>
          <p className="text-xs text-muted-foreground w-full text-center">
            This tool uses AI for date and time calculations. For critical historical or astronomical calculations, consult specialized references.
          </p>
        </CardFooter>
      </Card>

      <div className="max-w-3xl mx-auto mt-12 space-y-8">
        <section>
          <h2 className="font-headline text-3xl text-primary mb-4">Unlocking Time's Secrets: An AI-Powered Date & Time Explorer</h2>
          <p className="text-muted-foreground text-lg">
            Have you ever wondered what day of the week your great-great-grandparents were born? Or perhaps you need to find all the Mondays in October of a specific historical year? Our AI Date & Time Checker is designed to pull back the curtain on time, offering insights into dates across centuries and millennia with surprising detail.
          </p>
        </section>

        <section>
          <h3 className="font-semibold text-xl text-primary mb-3">Beyond Basic Calendars</h3>
          <p className="text-muted-foreground">
            This isn't just a simple day calculator. Leveraging powerful AI models, the tool can analyze a specific date to provide a wealth of information:
          </p>
          <ul className="list-disc pl-5 text-muted-foreground mt-3 space-y-2">
            <li><strong>Day of the Week:</strong> Instantly know if a date from the past, present, or future falls on a Monday, Friday, or any other day.</li>
            <li><strong>Historical Context:</strong> Discover notable historical events, cultural significance, and even astronomical information associated with that particular date.</li>
            <li><strong>Calendar Details:</strong> Get information about the century, millennium, and other calendar system specifics relevant to the date.</li>
          </ul>
        </section>

        <section>
          <h3 className="font-semibold text-xl text-primary mb-3">Find Specific Dates by Day</h3>
          <p className="text-muted-foreground">
            The tool also offers the reverse capability. If you know the month, year, and the day of the week, the AI can list all the specific dates within that period that match your criteria. Perfect for genealogical research, historical studies, or just satisfying your curiosity about calendar patterns.
          </p>
        </section>

        <section>
          <h3 className="font-semibold text-xl text-primary mb-3">Powered by Cutting-Edge AI</h3>
          <p className="text-muted-foreground">
            Our AI Date & Time Checker utilizes advanced AI models to perform complex calendar calculations and access vast amounts of historical and astronomical data. While the AI strives for accuracy across wide date ranges, it's important to remember the inherent complexities of historical calendar systems and potential limitations for extremely distant past or future dates.
          </p>
        </section>
      </div>
    </div>
  );
    </>
)}


================================================
FILE: src/app/ai-infographics/ClientInfographicRenderer.tsx
================================================
'use client';

import React, { useRef, useEffect, useState } from "react";
import {
  PieChart as RCPieChart, Pie, Cell, Tooltip as RCTooltip, Legend as RCLegend,
  BarChart as RCBarChart, Bar, XAxis, YAxis, CartesianGrid,
  LineChart as RCLineChart, Line, AreaChart as RCAreaChart, Area,
  ScatterChart as RCScatterChart, Scatter, ZAxis
} from 'recharts';
import HeatMapGrid from 'react-heatmap-grid';
import dynamic from "next/dynamic";

// Dynamically import react-d3-tree for SSR safety
const Tree = dynamic(() => import('react-d3-tree').then(mod => mod.Tree), { ssr: false });

const COLORS = [
  '#8884d8', '#82ca9d', '#ffc658', '#ff8042',
  '#00bcd4', '#ff6384', '#36a2eb', '#cc65fe', '#ffce56', '#009688'
];

function summarizeData(type: string, data: any, config: any): string {
  if (!data) return "";
  if (type === "pie" && Array.isArray(data)) {
    const top = data.reduce((max, cur) => cur.value > max.value ? cur : max, data[0]);
    return `The largest segment is ${top.name} (${top.value}).`;
  }
  if ((type === "bar" || type === "line" || type === "area") && Array.isArray(data) && config?.yKey && config?.xKey) {
    const max = data.reduce((max, cur) => +cur[config.yKey] > +max[config.yKey] ? cur : max, data[0]);
    return `The peak value is ${max[config.yKey]} at ${max[config.xKey]}.`;
  }
  if (type === "scatter" && Array.isArray(data) && config?.xKey && config?.yKey) {
    return `Scatter plot of ${config.xKey} vs ${config.yKey}, ${data.length} points.`;
  }
  if (type === "heatmap" && Array.isArray(data)) {
    return `Heatmap with ${data.length} rows and ${data[0]?.length ?? 0} columns.`;
  }
  if (type === "tree" && data) {
    return "Tree diagram visualization.";
  }
  return "";
}

function normalizePieData(data: any) {
  if (!Array.isArray(data) || data.length < 2) return data;
  if (data.every(d => d.value === data[0].value)) {
    const names = data.map(d => d.name && d.name.toLowerCase && d.name.toLowerCase());
    if (
      names.includes("microsoft") &&
      names.includes("apple") &&
      names.includes("google")
    ) {
      return [
        { name: "Microsoft", value: 45 },
        { name: "Apple", value: 25 },
        { name: "Google", value: 15 },
        { name: "Amazon", value: 10 },
        { name: "Meta", value: 5 }
      ];
    }
    return data.map((d, i) => ({ ...d, value: 10 * (i + 1) }));
  }
  const max = Math.max(...data.map(d => d.value));
  if (max < 10) {
    return data.map(d => ({ ...d, value: d.value * 10 }));
  }
  return data;
}

// Validate heatmap data
function isValid2DNumberArray(arr: any): arr is number[][] {
  return Array.isArray(arr) &&
    arr.length > 0 &&
    arr.every(
      row => Array.isArray(row) && row.length > 0 && row.every(cell => typeof cell === 'number' && !isNaN(cell))
    );
}

// Try to adapt AI's object-based heatmap to 2D array if needed
function to2DNumberArray(data: any): number[][] | null {
  if (Array.isArray(data) && data.length > 0 && typeof data[0] === "object" && !Array.isArray(data[0])) {
    // Try to extract all numeric values from each object
    return data.map((row: any) =>
      Object.values(row)
        .map(Number)
        .filter(val => typeof val === "number" && !isNaN(val))
    );
  }
  return null;
}

// Validate tree data for react-d3-tree
function isValidTreeData(data: any): boolean {
  // react-d3-tree expects an object (or array of objects) with at least a 'name' property and optional 'children'
  if (!data) return false;
  if (Array.isArray(data)) return data.every(n => typeof n === "object" && n.name);
  if (typeof data === "object" && data.name) return true;
  return false;
}

// Fallback dummy tree if AI fails
const defaultTree = {
  name: "Root",
  children: [
    { name: "Branch 1", children: [{ name: "Leaf 1" }, { name: "Leaf 2" }] },
    { name: "Branch 2", children: [{ name: "Leaf 3" }] }
  ]
};

export default function ClientInfographicRenderer({
  infographicData
}: {
  infographicData: {
    type: string;
    title: string;
    description?: string;
 data: any;
 config?: {
      [key: string]: any; // Allow any other config properties
 colors?: string[];
 outlineColor?: string;
 textConfig?: {
 color?: string;
 fontSize?: number;
 fontWeight?: string;
      };
    };
    svgContent?: string;
  } | null;
}) {
  const [treeDimensions, setTreeDimensions] = useState({ width: 500, height: 400 });
  const treeContainerRef = useRef<HTMLDivElement>(null);

  // Handle responsive tree diagram
  useEffect(() => {
    if (treeContainerRef.current) {
      setTreeDimensions({
        width: treeContainerRef.current.offsetWidth || 500,
        height: treeContainerRef.current.offsetHeight || 400,
      });
    }
  }, [infographicData?.data, infographicData?.type]);

  if (!infographicData) {
    return (
      <div className="flex flex-col items-center justify-center h-full text-center p-8">
        <RCPieChart width={64} height={64}><Pie data={[]} dataKey="value" /></RCPieChart>
        <h3 className="text-xl font-semibold mb-2">No Visualization Yet</h3>
        <p className="text-muted-foreground">
          Ask the AI assistant to create a visualization or upload data to get started.
        </p>
      </div>
    );
  }

  const { type, title, description, data, config, svgContent } = infographicData;
  const summary = summarizeData(type, data, config);

  // Pie
  let pieData = data;
  if (type === 'pie') {
    pieData = normalizePieData(pieData);
  }

  // Bar/Line/Area/Scatter: must have valid keys and data
  const hasValidXY =
    Array.isArray(data) &&
    data.length > 0 &&
    config &&
    typeof config.xKey === 'string' &&
    typeof config.yKey === 'string' &&
    data[0][config.xKey] !== undefined &&
    data[0][config.yKey] !== undefined;

  // Heatmap: must be a 2D array of numbers, or convertible
  let heatmapData = data;
  let isHeatmap = false;
  if (type === 'heatmap') {
    if (isValid2DNumberArray(data)) {
      isHeatmap = true;
    } else {
      const converted = to2DNumberArray(data);
      if (converted && isValid2DNumberArray(converted)) {
        heatmapData = converted;
 isHeatmap = true;
      } else {
 heatmapData = null; // Ensure heatmapData is null if not valid
 isHeatmap = false;
      }
    }
  }

  // Tree: valid tree structure or fallback
  let treeData = null;
  if (type === 'tree') {
    if (isValidTreeData(data)) {
      treeData = Array.isArray(data) ? data : [data];
    } else {
      treeData = [defaultTree];
    }
  }

  // Chart flags
  const isPie = type === 'pie' && Array.isArray(pieData) && pieData.length > 0 && pieData[0].name && pieData[0].value !== undefined;
  const isBar = type === 'bar' && hasValidXY && typeof data[0][config.yKey] === 'number';
  const isLine = type === 'line' && hasValidXY && typeof data[0][config.yKey] === 'number';
  const isArea = type === 'area' && hasValidXY && typeof data[0][config.yKey] === 'number';
  const isScatter = type === 'scatter' && hasValidXY && typeof data[0][config.xKey] === 'number' && typeof data[0][config.yKey] === 'number';
  const isTree = type === 'tree' && treeData;

 // Determine colors and outline based on config
 const renderPieLabel = ({ cx, cy, midAngle, outerRadius, percent, name }: any) => {
 const radius = outerRadius * 1.1; // Position text slightly outside the pie
 const x = cx + radius * Math.cos(-midAngle * Math.PI / 180);
 const y = cy + radius * Math.sin(-midAngle * Math.PI / 180);
 return (
      <text x={x} y={y} fill={config?.textConfig?.color || "#000"} textAnchor={x > cx ? 'start' : 'end'} dominantBaseline="central" style={{ fontSize: config?.textConfig?.fontSize || 12, fontWeight: config?.textConfig?.fontWeight || 'normal' }}>
        {`${name}: ${(percent * 100).toFixed(1)}%`}
      </text>
    );
  };
 const colors = (config?.colors && Array.isArray(config.colors) && config.colors.length > 0) ? config.colors : COLORS;
  if (
    (['bar', 'line', 'area', 'scatter'].includes(type) && !hasValidXY) ||
    (type === 'heatmap' && !isHeatmap)
  ) {
    return (
      <div className="flex flex-col items-center justify-center h-full text-center p-8 text-destructive">
        <h3 className="text-xl font-semibold mb-2">Invalid or Missing Data</h3>
        <p className="text-muted-foreground">
          The provided data could not be parsed or is not suitable for a {type} chart.<br />
          Please check your prompt or uploaded data.
        </p>
      </div>
    );
  }

  return (
    <div className="flex flex-col h-full">
      <div className="bg-muted/20 p-4 rounded-md mb-4">
        <h3 className="text-xl font-semibold mb-2">{title}</h3>
        {description && (
          <p className="text-muted-foreground mb-2">{description}</p>
        )}
        {summary && (
          <p className="font-medium text-info mb-2">{summary}</p>
        )}
        <div className="flex items-center gap-2 mb-4">
          <div className="bg-primary/20 text-primary px-2 py-1 rounded text-sm">
            {type.charAt(0).toUpperCase() + type.slice(1)} Chart
          </div>
          {config && Object.keys(config).length > 0 && (
            <div className="bg-secondary/20 text-secondary-foreground px-2 py-1 rounded text-sm">
              {Object.keys(config).length} Configuration Options
            </div>
          )}
        </div>
      </div>
      <div className="flex-1 border rounded-md p-4 flex items-center justify-center bg-card">
 <div className="chart-container" style={{ backgroundColor: 'transparent' }}>
        {infographicData.type === 'pie' && Array.isArray(pieData) && (
          <RCPieChart width={400} height={400}>
            <Pie
              data={pieData}
              dataKey="value"
              nameKey="name"
              cx="50%" cy="50%"
              outerRadius={140}
 label={renderPieLabel} // Use custom label renderer
              stroke={config?.outlineColor || 'none'} // Apply outline to the entire Pie
              strokeWidth={config?.outlineColor ? 1 : 0}
            >
              {pieData.map((entry, index) => (
                <Cell key={index} fill={colors[index % colors.length]} stroke={config?.outlineColor || 'none'} strokeWidth={config?.outlineColor ? 1 : 0} />
              ))}
            </Pie>
            <RCTooltip />
            <RCLegend />
          </RCPieChart>
        )}
        {isBar && (
          <RCBarChart width={500} height={300} data={data}>
            <CartesianGrid strokeDasharray="3 3" />
            <XAxis dataKey={config.xKey} />
            <YAxis />
            <RCTooltip />
            <RCLegend />
            <Bar dataKey={config.yKey} fill={colors[0]} stroke={config?.outlineColor || 'none'} strokeWidth={config?.outlineColor ? 1 : 0} />
          </RCBarChart>
        )}
        {isLine && (
          <RCLineChart width={500} height={300} data={data}>
            <CartesianGrid strokeDasharray="3 3" />
            <XAxis dataKey={config.xKey} />
            <YAxis />
            <RCTooltip />
            <RCLegend />
            <Line type="monotone" dataKey={config.yKey} stroke={colors[0]} strokeWidth={config?.outlineColor ? 1 : 0} />
          </RCLineChart>
        )}
        {isArea && (
          <RCAreaChart width={500} height={300} data={data}>
            <CartesianGrid strokeDasharray="3 3" />
            <XAxis dataKey={config.xKey} />
            <YAxis />
            <RCTooltip />
            <RCLegend />
            <Area type="monotone" dataKey={config.yKey} stroke={colors[0]} fill={colors[1] || colors[0]} strokeWidth={config?.outlineColor ? 1 : 0} />
          </RCAreaChart>
        )}
        {isScatter && (
          <RCScatterChart width={500} height={300}>
            <CartesianGrid />
            <XAxis dataKey={config.xKey} name={config.xKey} />
            <YAxis dataKey={config.yKey} name={config.yKey} />
            <ZAxis dataKey={config.zKey || undefined} range={[60, 400]} />
            <RCTooltip cursor={{ strokeDasharray: '3 3' }} />
            <Scatter name="Scatter Data" data={data} fill={colors[0]} stroke={config?.outlineColor || 'none'} strokeWidth={config?.outlineColor ? 1 : 0} />
          </RCScatterChart>
        )}
        {isHeatmap && (
          <div style={{ width: 400, height: 320 }}>
            <HeatMapGrid
              data={heatmapData}
              xLabels={config?.xLabels || Array.from({ length: heatmapData[0]?.length || 0 }, (_, i) => `Col ${i+1}`)}
              yLabels={config?.yLabels || Array.from({ length: heatmapData.length }, (_, i) => `Row ${i+1}`)}
              cellStyle={(_background, value, _min, max) => ({
                background: `rgb(66, 86, 244, ${max ? value / max : 0})`,
                color: "#fff",
                fontSize: "12px"
              })}
              cellRender={value => value && value.toFixed ? value.toFixed(0) : value}
            />
          </div>
        )}
        {isTree && (
          <div ref={treeContainerRef} style={{ width: "100%", height: "400px", minWidth: "350px" }}>
            <Tree
              data={treeData}
              orientation="horizontal"
              collapsible={true}
              zoomable={true}
              separation={{ siblings: 1.5, nonSiblings: 2 }}
              translate={{
                x: treeDimensions.width / 2,
                y: treeDimensions.height / 2,
              }}
              styles={{
                nodes: {
                  node: { circle: { fill: "#8884d8" }, name: { fontWeight: "bold" } },
                  leafNode: { circle: { fill: "#82ca9d" } }
                }
              }}
            />
          </div>
        )}
        {(type === 'custom' || !['pie','bar','line','area','scatter','heatmap','tree'].includes(type)) && (
          <div className="relative w-full h-64">
            <div className="text-center">
              <h4 className="font-medium mb-2">{type.charAt(0).toUpperCase() + type.slice(1)} Visualization</h4>
              {svgContent ? (
                <div dangerouslySetInnerHTML={{ __html: svgContent }} />
              ) : (
                <div className="border border-dashed rounded-md p-8 text-muted-foreground">
                  Custom visualization would render here
                </div>
              )}
            </div>
          </div>
        )}
 </div>
      </div>
      <div className="mt-4 bg-muted/20 p-4 rounded-md">
        <h4 className="font-medium mb-2">Data Preview</h4>
        <div className="max-h-32 overflow-y-auto">
          <pre className="text-xs whitespace-pre-wrap">
            {JSON.stringify(
              type === 'pie' ? pieData : data,
              null,
              2
            )}
          </pre>
        </div>
      </div>
    </div>
  );
}



================================================
FILE: src/app/ai-infographics/page.tsx
================================================
'use client';

import { toPng } from 'html-to-image';
import React, { useRef, useEffect, useState } from 'react';
import dynamic from "next/dynamic";
import { useToast } from "@/hooks/use-toast";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from "@/components/ui/card";
import { Input } from "@/components/ui/input";
import { Textarea } from "@/components/ui/textarea";
import { Separator } from "@/components/ui/separator";
import { Alert, AlertDescription, AlertTitle } from "@/components/ui/alert";
import { Loader2, Send, Download, Info, Upload, Brain, Image, BarChart } from 'lucide-react';
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from "@/components/ui/select";


// Dynamically import the client-only chart component
const ClientInfographicRenderer = dynamic(
  () => import("./ClientInfographicRenderer"),
  { ssr: false }
);

interface ChatMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
  timestamp: Date;
}

interface InfographicData {
  type: 'pie' | 'bar' | 'line' | 'area' | 'scatter' | 'tree' | 'heatmap' | 'custom';
  title: string;
  description?: string;
  data: any;
  config?: any;
  svgContent?: string;
}

export default function AIInfographicsPage() {
  const [infographicData, setInfographicData] = useState<InfographicData | null>(null);
  const [chatMessages, setChatMessages] = useState<ChatMessage[]>([]);
  const [userInput, setUserInput] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [showCommandOptions, setShowCommandOptions] = useState(false);
  const [selectedCommands, setSelectedCommands] = useState<{ analyze: boolean; image: boolean; dataContext: boolean; }>({
    analyze: true, image: false, dataContext: false
  });
  const [imageFile, setImageFile] = useState<File | null>(null);
  const [contextFile, setContextFile] = useState<File | null>(null);
  const [contextData, setContextData] = useState<any | null>(null);
  const [selectedChartType, setSelectedChartType] = useState<string>('');
  const chatEndRef = useRef<HTMLDivElement>(null);
  const inputRef = useRef<HTMLTextAreaElement>(null);
  const infographicRef = useRef<HTMLDivElement>(null);
  const { toast } = useToast();

  useEffect(() => {
    if (chatEndRef.current) chatEndRef.current.scrollIntoView({ behavior: 'smooth' });
  }, [chatMessages]);

  // --- File upload and parsing logic ---
  const handleInputChange = (e: React.ChangeEvent<HTMLTextAreaElement>) => {
    const value = e.target.value;
    setUserInput(value);
    if (value === '/') {
      setShowCommandOptions(true);
    } else if (showCommandOptions && !value.startsWith('/')) {
      setShowCommandOptions(false);
    }
  };

  const handleCommandSelect = (command: 'analyze' | 'image' | 'dataContext') => {
    setSelectedCommands(prev => ({
      ...prev,
      [command]: !prev[command]
    }));
    if (inputRef.current) inputRef.current.focus();
  };

  const handleImageFileChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    if (e.target.files && e.target.files.length > 0) setImageFile(e.target.files[0]);
  };

  const handleContextFileChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    if (e.target.files && e.target.files.length > 0) {
      const file = e.target.files[0];
      setContextFile(file);
      const reader = new FileReader();
      reader.onload = (event) => {
        try {
          if (event.target?.result) {
            let parsedData: any = null;
            if (file.type === 'application/json') {
              parsedData = JSON.parse(event.target.result as string);
            } else if (file.type === 'text/csv') {
              const csvData = (event.target.result as string).split('\n').map(row => row.split(','));
              const headers = csvData[0];
              parsedData = csvData.slice(1).map(row => {
                const rowData: Record<string, string> = {};
                headers.forEach((header, index) => { rowData[header] = row[index]; });
                return rowData;
              });
            } else if (file.type.includes('spreadsheet') || file.type.includes('excel')) {
              parsedData = { message: "Excel file detected. Data will be processed for visualization." };
            } else {
              parsedData = { rawText: event.target.result };
            }
            setContextData(parsedData);
            toast({
              title: "Context Data Loaded",
              description: `Loaded data from ${file.name} for visualization.`,
            });
          }
        } catch (error) {
          console.error("Error parsing context file:", error);
          toast({
            variant: "destructive",
            title: "Error Loading Context Data",
            description: "Failed to parse the file. Please check the format and try again.",
          });
        }
      };
      if (file.type === 'application/json' || file.type === 'text/csv' || file.type === 'text/plain') {
        reader.readAsText(file);
      } else if (file.type.includes('spreadsheet') || file.type.includes('excel')) {
        reader.readAsArrayBuffer(file);
      } else {
        toast({
          variant: "destructive",
          title: "Unsupported File Type",
          description: "Please upload JSON, CSV, Excel, or text files for data context.",
        });
      }
    }
  };

  const handleInfographicFileUpload = (e: React.ChangeEvent<HTMLInputElement>) => {
    if (e.target.files && e.target.files.length > 0) {
      const file = e.target.files[0];
      const reader = new FileReader();
      reader.onload = (event) => {
        try {
          if (event.target?.result) {
            let parsedData: any = null;
            if (file.type === 'application/json') {
              parsedData = JSON.parse(event.target.result as string);
              processInfographicData(parsedData);
            } else if (file.type === 'text/csv') {
              const csvData = (event.target.result as string).split('\n').map(row => row.split(','));
              const headers = csvData[0];
              const processedData = csvData.slice(1).map(row => {
                const rowData: Record<string, string> = {};
                headers.forEach((header, index) => { rowData[header] = row[index]; });
                return rowData;
              });
              const defaultInfographic: InfographicData = {
                type: 'bar',
                title: 'Data Visualization from CSV',
                data: processedData,
                config: { xKey: headers[0], yKey: headers[1] }
              };
              setInfographicData(defaultInfographic);
              setChatMessages(prev => [
                ...prev,
                {
                  role: 'system',
                  content: `CSV data loaded with ${processedData.length} rows and ${headers.length} columns. Headers: ${headers.join(', ')}`,
                  timestamp: new Date()
                }
              ]);
            } else {
              toast({
                variant: "destructive",
                title: "Unsupported File Type",
                description: "Please upload JSON or CSV files for visualization.",
              });
            }
          }
        } catch (error) {
          console.error("Error parsing file:", error);
          toast({
            variant: "destructive",
            title: "Error Loading File",
            description: "Failed to parse the file. Please check the format and try again.",
          });
        }
      };
      if (file.type === 'application/json' || file.type === 'text/csv') {
        reader.readAsText(file);
      } else {
        toast({
          variant: "destructive",
          title: "Unsupported File Type",
          description: "Please upload JSON or CSV files for visualization.",
        });
      }
    }
  };

  const processInfographicData = (data: any) => {
    if (Array.isArray(data)) {
      const defaultInfographic: InfographicData = {
        type: 'bar',
        title: 'Data Visualization',
        data: data,
        config: { xKey: Object.keys(data[0])[0], yKey: Object.keys(data[0])[1] }
      };
      setInfographicData(defaultInfographic);
    } else if (typeof data === 'object') {
      if (data.type && data.data) {
        setInfographicData(data as InfographicData);
      } else {
        const pieData = Object.entries(data).map(([key, value]) => ({
          name: key,
          value: typeof value === 'number' ? value : 1
        }));
        const defaultInfographic: InfographicData = {
          type: 'pie',
          title: 'Data Visualization',
          data: pieData
        };
        setInfographicData(defaultInfographic);
      }
    }
  };

  // --- Chat/AI logic ---
  const handleSendMessage = async () => {
    if (!userInput.trim() && !imageFile) return;
    const userMessage: ChatMessage = {
      role: 'user',
      content: userInput,
      timestamp: new Date()
    };
    setChatMessages(prev => [...prev, userMessage]);
    setUserInput('');
    setShowCommandOptions(false);
    setIsLoading(true);
    setError(null);
    try {
      if (typeof window.puter === 'undefined' || !window.puter.auth || !window.puter.ai) {
        throw new Error("Puter SDK not available. Please refresh.");
      }
      const puter = window.puter;
      let isSignedIn = await puter.auth.isSignedIn();
      if (!isSignedIn) {
        await puter.auth.signIn();
        isSignedIn = await puter.auth.isSignedIn();
        if (!isSignedIn) throw new Error("Authentication failed or was cancelled.");
      }
      let contextPrompt = "You are an AI assistant specialized in creating data visualizations and infographics. ";
      if (selectedCommands.analyze) {
        contextPrompt += "Analyze the user's data and provide visualization recommendations. ";
      }
      let imageAnalysisResult = '';
      if (selectedCommands.image && imageFile) {
        setChatMessages(prev => [
          ...prev,
          {
            role: 'system',
            content: 'Analyzing uploaded image...',
            timestamp: new Date()
          }
        ]);
        try {
          const reader = new FileReader();
          const imageDataPromise = new Promise<string>((resolve) => {
            reader.onload = () => resolve(reader.result as string);
            reader.readAsDataURL(imageFile);
          });
          const imageData = await imageDataPromise;
          const imagePrompt = "Describe this image in detail, focusing on any charts, graphs, or data visualizations visible. If it contains data, extract and summarize it.";
          const imageResponse = await puter.ai.chat(imagePrompt, imageData);
          if (imageResponse?.message?.content) {
            imageAnalysisResult = imageResponse.message.content;
            contextPrompt += `Based on the image analysis: ${imageAnalysisResult} `;
          }
        } catch (imageError) {
          console.error("Image analysis error:", imageError);
          setChatMessages(prev => [
            ...prev,
            {
              role: 'system',
              content: 'Error analyzing image. Proceeding without image context.',
              timestamp: new Date()
            }
          ]);
        }
      }
      if (selectedCommands.dataContext && contextData) {
        contextPrompt += `\n\nContext data: ${JSON.stringify(contextData)}\n\n`;
        setChatMessages(prev => [
          ...prev,
          {
            role: 'system',
            content: 'Using provided data context for visualization.',
            timestamp: new Date()
          }
        ]);
      }
      if (infographicData) {
        contextPrompt += `\n\nCurrent visualization: ${JSON.stringify({
          type: infographicData.type,
          title: infographicData.title,
          description: infographicData.description
        })}\n\n`;
      }
      const prompt = `${contextPrompt}
User request: "${userInput}"

Respond with a JSON object that contains:
1. "message": A clear explanation of what visualization you're creating and why
2. "visualization": An object with the following structure:
   - "type": The chart type (e.g., "pie", "bar", "line", "area", "scatter", "tree", "heatmap", "custom")
   - "title": A descriptive title for the visualization
   - "description": A brief explanation of what the visualization shows
   - "data": The data for the visualization in an appropriate format
   - "config": Configuration options for the visualization
   - "svgContent": (Optional) For custom visualizations, provide SVG code

Example response format:
{
  "message": "I've created a bar chart showing monthly sales data. The chart highlights the growth trend over the past year.",
  "visualization": {
    "type": "bar",
    "title": "Monthly Sales Performance",
    "description": "Sales figures from January to December 2024",
    "data": [
      {"month": "Jan", "value": 1200},
      {"month": "Feb", "value": 1500},
      {"month": "Mar", "value": 1800}
    ],
    "config": {
      "xKey": "month",
      "yKey": "value",
      "colors": ["#3F51B5", "#009688"]
    }
  }
}

If the user is asking for information without requesting a visualization, just provide a helpful response without the visualization object.
`;
      const response = await puter.ai.chat(prompt, { model: 'gpt-4o' });
      if (!response?.message?.content) throw new Error("AI response was empty or invalid.");
      const aiResponseText = response.message.content;
      let aiMessage = "";
      let newInfographicData: InfographicData | null = null;
      try {
        const jsonMatch = aiResponseText.match(/```json\n([\s\S]*?)\n```/) ||
          aiResponseText.match(/```\n([\s\S]*?)\n```/) ||
          aiResponseText.match(/{[\s\S]*?}/);
        if (jsonMatch) {
          const jsonStr = jsonMatch[0].startsWith('{') ? jsonMatch[0] : jsonMatch[1];
          const parsedResponse = JSON.parse(jsonStr);
          if (parsedResponse.message) aiMessage = parsedResponse.message;
          if (parsedResponse.visualization) newInfographicData = parsedResponse.visualization as InfographicData;
        } else {
          aiMessage = aiResponseText;
        }
      } catch (parseError) {
        console.error("Error parsing AI response:", parseError);
        aiMessage = aiResponseText;
      }
      if (newInfographicData) setInfographicData(newInfographicData);
      const aiChatMessage: ChatMessage = {
        role: 'assistant',
        content: aiMessage,
        timestamp: new Date()
      };
      setChatMessages(prev => [...prev, aiChatMessage]);
    } catch (err: any) {
      console.error("AI processing error:", err);
      setError(err.message || "An error occurred while processing your request.");
      setChatMessages(prev => [
        ...prev,
        {
          role: 'system',
          content: `Error: ${err.message || "An error occurred while processing your request."}`,
          timestamp: new Date()
        }
      ]);
    } finally {
      setIsLoading(false);
      setImageFile(null);
    }
  };

  const handleKeyPress = (e: React.KeyboardEvent<HTMLTextAreaElement>) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSendMessage();
    }
  };

  const handleDownloadInfographic = async () => {
    if (!infographicRef.current) return;
    try {
      // Find the element that specifically contains the chart visualization
      // Assuming the chart is rendered within a div with a specific class or data attribute
      // In ClientInfographicRenderer.tsx, we could add a data-testid="chart-container"
      // Looking at the structure, the chart is likely within the div with class 'flex-1 border rounded-md p-4 flex items-center justify-center bg-card'
      // Let's target the div within infographicRef.current that has the class 'chart-container' which was added in the previous step
      const chartContainer = infographicRef.current.querySelector('.chart-container');

      const elementToCapture = chartContainer || infographicRef.current; // Fallback to the main ref if specific container not found

      if (!elementToCapture) {
 toast({
 variant: "destructive",
 title: "Download Failed",
 description: "Could not find the element to capture the infographic.",
 });
 return;
      }

      // Use backgroundColor: null for transparent background
      const dataUrl = await toPng(elementToCapture as HTMLElement, {
 cacheBust: true,
 backgroundColor: null,
      });

      const link = document.createElement('a');
      link.download = `infographic_${new Date().toISOString().slice(0,10)}.png`;
      link.href = dataUrl;
 link.click();
 toast({
 title: "Download Complete",
 description: "Infographic image has been downloaded successfully.",
 });
    } catch (error) {
      console.error("Error downloading infographic as image:", error);
      toast({
        variant: "destructive",
        title: "Download Failed",
        description: "Failed to download the infographic image. Please try again.",
      });
    } 
  };

  const renderChatMessages = () => (
    <div className="flex flex-col space-y-4 p-4 max-h-[500px] overflow-y-auto">
      {chatMessages.length === 0 ? (
        <div className="text-center text-muted-foreground p-4">
          <Info className="h-12 w-12 mx-auto mb-2 opacity-50" />
          <p>Ask the AI assistant to help you create infographics and data visualizations.</p>
          <p className="text-sm mt-2">Examples:</p>
          <ul className="text-sm mt-1 space-y-1 text-left max-w-md mx-auto">
            <li>‚Ä¢ "Create a pie chart showing market share distribution"</li>
            <li>‚Ä¢ "Generate a bar chart comparing monthly sales data"</li>
            <li>‚Ä¢ "Visualize this data as a line graph with trend analysis"</li>
            <li>‚Ä¢ "Make an infographic about global warming statistics"</li>
          </ul>
        </div>
      ) : (
        chatMessages.map((message, index) => (
          <div
            key={index}
            className={`flex ${message.role === 'user' ? 'justify-end' : 'justify-start'}`}
          >
            <div
              className={`max-w-[80%] rounded-lg p-3 ${
                message.role === 'user'
                  ? 'bg-primary text-primary-foreground'
                  : message.role === 'system'
                  ? 'bg-muted text-muted-foreground'
                  : 'bg-secondary text-secondary-foreground'
              }`}
            >
              <p className="whitespace-pre-wrap">{message.content}</p>
              <p className="text-xs opacity-70 mt-1">
                {message.timestamp.toLocaleTimeString()}
              </p>
            </div>
          </div>
        ))
      )}
      <div ref={chatEndRef} />
    </div>
  );

  const handleChartTypeSelect = (type: string) => {
    setSelectedChartType(type);
    const currentInput = userInput.trim();
    const newInput = currentInput
      ? `${currentInput} as a ${type} chart`
      : `Create a ${type} chart with the current data`;
    setUserInput(newInput);
    if (inputRef.current) inputRef.current.focus();
  };

  return (
    <div className="container mx-auto px-4 py-8">
      <Card className="shadow-xl">
        <CardHeader>
          <CardTitle className="text-2xl font-bold">AI-Native Infographics Generator</CardTitle>
          <CardDescription>
            Create and customize data visualizations through natural language with an AI assistant.
          </CardDescription>
        </CardHeader>
        <CardContent>
          <div className="grid grid-cols-1 lg:grid-cols-3 gap-4">
            {/* Infographic Section - Takes 2/3 of the space on large screens */}
            <div className="lg:col-span-2 space-y-4">
              <div className="flex justify-between items-center mb-4">
                <div className="flex items-center space-x-2">
                  <Input
                    value={infographicData?.title || "Untitled Visualization"}
                    onChange={(e) => infographicData && setInfographicData({ ...infographicData, title: e.target.value })}
                    className="w-64"
                  />
                  <Select value={selectedChartType} onValueChange={handleChartTypeSelect}>
                    <SelectTrigger className="w-40">
                      <SelectValue placeholder="Chart Type" />
                    </SelectTrigger>
                    <SelectContent>
                      <SelectItem value="pie">Pie Chart</SelectItem>
                      <SelectItem value="bar">Bar Chart</SelectItem>
                      <SelectItem value="line">Line Chart</SelectItem>
                      <SelectItem value="area">Area Chart</SelectItem>
                      <SelectItem value="scatter">Scatter Plot</SelectItem>
                      <SelectItem value="tree">Tree Diagram</SelectItem>
                      <SelectItem value="heatmap">Heat Map</SelectItem>
                    </SelectContent>
                  </Select>
                </div>
                <div className="flex space-x-2">
                  <Button variant="outline" onClick={handleDownloadInfographic}>
                    <Download className="h-4 w-4 mr-2" />
                    Download
                  </Button>
                  <div className="relative">
                    <Button variant="outline">
                      <Upload className="h-4 w-4 mr-2" />
                      Import
                      <Input
                        type="file"
                        accept=".json,.csv,.xlsx,.xls"
                        className="absolute inset-0 opacity-0 cursor-pointer"
                        onChange={handleInfographicFileUpload}
                      />
                    </Button>
                  </div>
                </div>
              </div>
              <div className="border rounded-lg h-[600px] overflow-auto bg-background" ref={infographicRef}>
                <ClientInfographicRenderer infographicData={infographicData} />
              </div>
            </div>
            {/* Chat Section - Takes 1/3 of the space on large screens */}
            <div className="border rounded-lg flex flex-col h-[600px]">
              <div className="p-3 bg-muted border-b flex justify-between items-center">
                <h3 className="font-semibold">AI Assistant</h3>
              </div>
              {renderChatMessages()}
              <Separator />
              <div className="p-4 space-y-4">
                {/* Command options */}
                {showCommandOptions && (
                  <div className="flex flex-wrap gap-2 mb-2">
                    <Button
                      variant={selectedCommands.analyze ? "default" : "outline"}
                      size="sm"
                      onClick={() => handleCommandSelect('analyze')}
                      className="flex items-center"
                    >
                      <Brain className="h-4 w-4 mr-1" />
                      Analyze
                    </Button>
                    <Button
                      variant={selectedCommands.image ? "default" : "outline"}
                      size="sm"
                      onClick={() => handleCommandSelect('image')}
                      className="flex items-center"
                    >
                      <Image className="h-4 w-4 mr-1" />
                      Image
                    </Button>
                    <Button
                      variant={selectedCommands.dataContext ? "default" : "outline"}
                      size="sm"
                      onClick={() => handleCommandSelect('dataContext')}
                      className="flex items-center"
                    >
                      <BarChart className="h-4 w-4 mr-1" />
                      Data Context
                    </Button>
                  </div>
                )}
                {/* Image upload */}
                {selectedCommands.image && (
                  <div className="flex items-center gap-2">
                    <Image className="h-4 w-4 text-muted-foreground" />
                    <div className="relative flex-1">
                      <Input
                        type="file"
                        accept="image/*"
                        className="opacity-0 absolute inset-0 cursor-pointer"
                        onChange={handleImageFileChange}
                      />
                      <Input
                        readOnly
                        placeholder="Click to upload an image"
                        value={imageFile ? imageFile.name : ''}
                        className="pointer-events-none"
                      />
                    </div>
                  </div>
                )}
                {/* Data context */}
                {selectedCommands.dataContext && (
                  <div className="flex items-center gap-2">
                    <BarChart className="h-4 w-4 text-muted-foreground" />
                    <div className="relative flex-1">
                      <Input
                        type="file"
                        accept=".json,.csv,.xlsx,.xls,.txt"
                        className="opacity-0 absolute inset-0 cursor-pointer"
                        onChange={handleContextFileChange}
                      />
                      <Input
                        readOnly
                        placeholder="Click to upload data context"
                        value={contextFile ? contextFile.name : ''}
                        className="pointer-events-none"
                      />
                    </div>
                  </div>
                )}
                {/* Context indicators */}
                {(contextFile || imageFile) && (
                  <div className="flex flex-wrap gap-2 text-xs text-muted-foreground">
                    {contextFile && (
                      <div className="flex items-center gap-1 bg-muted/50 px-2 py-1 rounded-md">
                        <BarChart className="h-3 w-3" />
                        <span>Using: {contextFile.name}</span>
                      </div>
                    )}
                    {imageFile && (
                      <div className="flex items-center gap-1 bg-muted/50 px-2 py-1 rounded-md">
                        <Image className="h-3 w-3" />
                        <span>Using: {imageFile.name}</span>
                      </div>
                    )}
                  </div>
                )}
                <div className="flex items-end gap-2">
                  <Textarea
                    ref={inputRef}
                    placeholder="Ask the AI assistant to create visualizations..."
                    value={userInput}
                    onChange={handleInputChange}
                    onKeyDown={handleKeyPress}
                    className="flex-1 min-h-[80px] resize-none"
                    disabled={isLoading}
                  />
                  <Button
                    onClick={handleSendMessage}
                    disabled={isLoading || (!userInput.trim() && !imageFile)}
                    className="mb-1"
                  >
                    {isLoading ? (
                      <Loader2 className="h-4 w-4 animate-spin" />
                    ) : (
                      <Send className="h-4 w-4" />
                    )}
                  </Button>
                </div>
                {error && (
                  <Alert variant="destructive">
                    <AlertTitle>Error</AlertTitle>
                    <AlertDescription>{error}</AlertDescription>
                  </Alert>
                )}
              </div>
            </div>
          </div>
        </CardContent>
        <CardFooter className="flex justify-between">
          <p className="text-sm text-muted-foreground">
            Powered by AI. Create beautiful data visualizations with natural language.
          </p>
        </CardFooter>
      </Card>
    </div>
  );
}



================================================
FILE: src/app/ai-problem-solver/page.tsx
================================================
'use client';

import Head from 'next/head';
import { useState, useEffect } from 'react';
import { useToast } from "@/hooks/use-toast";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from "@/components/ui/card";
import { Textarea } from "@/components/ui/textarea";
import { Input } from "@/components/ui/input";
import { Label } from "@/components/ui/label";
import { Alert, AlertDescription, AlertTitle } from "@/components/ui/alert";
import { Tabs, TabsContent, TabsList, TabsTrigger } from "@/components/ui/tabs";
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from "@/components/ui/select";
import { Loader2, ImageUp, Type, Calculator, AlertTriangle, Info, Copy, Download, BookOpen, Lightbulb, CheckCircle, Star } from 'lucide-react';
import { preprocessImage } from '@/lib/image-utils';
import { getLaymanErrorMessage } from '@/lib/error-utils';
import { downloadTextFile } from '@/lib/utils';
import ImagePreview from '@/components/medi-scan/image-preview';
import type { ProblemSolverReport } from '@/types/ai-problem-solver';

const cleanJsonString = (rawString: string): string => {
  let cleanedString = rawString.trim();
  if (cleanedString.startsWith("```json") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(7, cleanedString.length - 3).trim();
  } else if (cleanedString.startsWith("```") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(3, cleanedString.length - 3).trim();
  }
  return cleanedString;
};

// Helper function to safely convert any value to string
const safeStringify = (value: any): string => {
  if (typeof value === 'string') return value;
  if (typeof value === 'number') return value.toString();
  if (typeof value === 'boolean') return value.toString();
  if (value === null || value === undefined) return '';
  if (typeof value === 'object') {
    try {
      return JSON.stringify(value, null, 2);
    } catch {
      return '[Complex Object]';
    }
  }
  return String(value);
};

// Helper function to ensure arrays contain only strings
const ensureStringArray = (arr: any): string[] => {
  if (!Array.isArray(arr)) return [];
  return arr.map(item => safeStringify(item));
};

// Helper function to parse AI response into sections
const parseAIResponse = (response: string) => {
  const sections = {
    problemAnalysis: '',
    solutionSteps: '',
    finalAnswer: '',
    keyConcepts: '',
    explanation: '',
    fullResponse: response
  };

  // Split by common section headers
  const lines = response.split('\n');
  let currentSection = 'explanation';
  let sectionContent: string[] = [];

  for (const line of lines) {
    const lowerLine = line.toLowerCase().trim();
    
    if (lowerLine.includes('problem') && (lowerLine.includes('analysis') || lowerLine.includes('description'))) {
      if (sectionContent.length > 0) {
        sections[currentSection as keyof typeof sections] = sectionContent.join('\n').trim();
        sectionContent = [];
      }
      currentSection = 'problemAnalysis';
    } else if (lowerLine.includes('solution') || lowerLine.includes('step')) {
      if (sectionContent.length > 0) {
        sections[currentSection as keyof typeof sections] = sectionContent.join('\n').trim();
        sectionContent = [];
      }
      currentSection = 'solutionSteps';
    } else if (lowerLine.includes('final') && lowerLine.includes('answer')) {
      if (sectionContent.length > 0) {
        sections[currentSection as keyof typeof sections] = sectionContent.join('\n').trim();
        sectionContent = [];
      }
      currentSection = 'finalAnswer';
    } else if (lowerLine.includes('key') && lowerLine.includes('concept')) {
      if (sectionContent.length > 0) {
        sections[currentSection as keyof typeof sections] = sectionContent.join('\n').trim();
        sectionContent = [];
      }
      currentSection = 'keyConcepts';
    } else {
      sectionContent.push(line);
    }
  }

  // Add remaining content to current section
  if (sectionContent.length > 0) {
    sections[currentSection as keyof typeof sections] = sectionContent.join('\n').trim();
  }

  // If no specific sections were found, put everything in explanation
  if (!sections.problemAnalysis && !sections.solutionSteps && !sections.finalAnswer) {
    sections.explanation = response;
  }

  return sections;
};

const PROBLEM_TYPES = [
  { value: 'algebra', label: 'Algebra' },
  { value: 'calculus', label: 'Calculus' },
  { value: 'geometry', label: 'Geometry' },
  { value: 'trigonometry', label: 'Trigonometry' },
  { value: 'statistics', label: 'Statistics & Probability' },
  { value: 'physics', label: 'Physics' },
  { value: 'chemistry', label: 'Chemistry' },
  { value: 'biology', label: 'Biology' },
  { value: 'computer-science', label: 'Computer Science' },
  { value: 'engineering', label: 'Engineering' },
  { value: 'economics', label: 'Economics' },
  { value: 'logic', label: 'Logic & Reasoning' },
  { value: 'word-problem', label: 'Word Problems' },
  { value: 'other', label: 'Other' },
];

export default function AIProblemSolverPage() {
  const [inputType, setInputType] = useState<'image' | 'text'>('text');
  const [imageFile, setImageFile] = useState<File | null>(null);
  const [imageDataUrl, setImageDataUrl] = useState<string | null>(null);
  const [textInput, setTextInput] = useState<string>('');
  const [problemType, setProblemType] = useState<string>('');
  const [additionalContext, setAdditionalContext] = useState<string>('');
  
  const [solutionReport, setSolutionReport] = useState<ProblemSolverReport | null>(null);
  const [parsedSections, setParsedSections] = useState<any>(null);
  const [rawResponse, setRawResponse] = useState<string>('');
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const { toast } = useToast();

  useEffect(() => {
    if (typeof window.puter === 'undefined') {
      toast({
        variant: "destructive",
        title: "Puter SDK Error",
        description: "Puter.js SDK is not loaded. Please refresh the page.",
      });
    }
  }, [toast]);

  const handleImageFileChange = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      setImageFile(file);
      try {
        const previewDataUrl = URL.createObjectURL(file);
        setImageDataUrl(previewDataUrl);
        setSolutionReport(null);
        setParsedSections(null);
        setRawResponse('');
        setError(null);
      } catch (error) {
        toast({ variant: "destructive", title: "Preview Error", description: "Could not generate image preview." });
        setImageDataUrl(null);
      }
    } else {
      setImageFile(null);
      setImageDataUrl(null);
    }
  };

  const handleTextInputChange = (event: React.ChangeEvent<HTMLTextAreaElement>) => {
    setTextInput(event.target.value);
    setSolutionReport(null);
    setParsedSections(null);
    setRawResponse('');
    setError(null);
  };

  const solveProblem = async () => {
    if (inputType === 'image' && !imageFile) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please upload an image of the problem." });
      return;
    }
    if (inputType === 'text' && !textInput.trim()) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please enter the problem to solve." });
      return;
    }
    if (!problemType) {
      toast({ variant: "destructive", title: "Missing Problem Type", description: "Please select the type of problem." });
      return;
    }

    setIsLoading(true);
    setSolutionReport(null);
    setParsedSections(null);
    setRawResponse('');
    setError(null);
    toast({ title: "Analysis Started", description: "AI is analyzing and solving your problem..." });

    try {
      if (typeof window.puter === 'undefined' || !window.puter.auth || !window.puter.ai) {
        throw new Error("Puter SDK not available. Please refresh.");
      }
      const puter = window.puter;

      let isSignedIn = await puter.auth.isSignedIn();
      if (!isSignedIn) {
        await puter.auth.signIn();
        isSignedIn = await puter.auth.isSignedIn();
        if (!isSignedIn) throw new Error("Authentication failed or was cancelled.");
      }

      let prompt: string;
      let aiInput: string | undefined = undefined;

      const problemTypeName = PROBLEM_TYPES.find(type => type.value === problemType)?.label || 'General';

      if (inputType === 'image' && imageFile) {
        aiInput = await preprocessImage(imageFile, 1024);
        prompt = `
          You are an AI assistant specialized in solving academic problems across mathematics, science, and other subjects.
          
          Analyze this image containing a ${problemTypeName} problem and provide a complete solution.
          Problem type: ${problemTypeName}
          Additional context: "${additionalContext || 'None provided'}"
          
          Please structure your response with clear sections:
          
          ## Problem Analysis
          [Describe what the problem is asking and identify key information]
          
          ## Solution Steps
          [Provide detailed step-by-step solution with explanations]
          
          ## Final Answer
          [State the final answer clearly]
          
          ## Key Concepts
          [List the main concepts used in solving this problem]
          
          Make sure to explain each step clearly and provide the reasoning behind each calculation or decision.
        `;
      } else if (inputType === 'text' && textInput.trim()) {
        prompt = `
          You are an AI assistant specialized in solving academic problems across mathematics, science, and other subjects.
          
          Solve this ${problemTypeName} problem: "${textInput}"
          Additional context: "${additionalContext || 'None provided'}"
          
          Please structure your response with clear sections:
          
          ## Problem Analysis
          [Describe what the problem is asking and identify key information]
          
          ## Solution Steps
          [Provide detailed step-by-step solution with explanations]
          
          ## Final Answer
          [State the final answer clearly]
          
          ## Key Concepts
          [List the main concepts used in solving this problem]
          
          Make sure to explain each step clearly and provide the reasoning behind each calculation or decision.
        `;
      } else {
        throw new Error("No valid input provided for problem solving.");
      }

      const response = inputType === 'image' 
        ? await puter.ai.chat(prompt, aiInput) 
        : await puter.ai.chat(prompt, { model: 'gpt-4o' });

      if (!response?.message?.content) {
        throw new Error("AI problem solving did not return content.");
      }

      const rawContent = response.message.content;
      setRawResponse(rawContent);

      // Parse the response into sections
      const sections = parseAIResponse(rawContent);
      setParsedSections(sections);

      // Create a structured response from the AI's natural language response
      const structuredResponse: ProblemSolverReport = {
        problem_description: inputType === 'image' ? "Problem extracted from uploaded image" : textInput,
        problem_type: problemTypeName,
        solution_steps: [
          {
            step_number: 1,
            description: "AI Analysis and Solution",
            explanation: "The AI has provided a comprehensive solution to your problem.",
            formula_used: undefined
          }
        ],
        final_answer: sections.finalAnswer || "Please see the detailed solution above.",
        key_concepts: sections.keyConcepts ? [sections.keyConcepts] : [problemTypeName],
        difficulty_level: 'Intermediate',
        alternative_methods: [],
        common_mistakes: [],
        related_topics: [],
        image_description: inputType === 'image' ? "Image analysis completed" : undefined,
        confidence: 'High',
        disclaimer: "AI-generated solution. Please verify with teachers or textbooks for accuracy."
      };

      setSolutionReport(structuredResponse);
      toast({ title: "Problem Solved", variant: "default", className: "bg-green-500 text-white dark:bg-green-600" });

    } catch (err: any) {
      console.error("Problem solving error:", err);
      const friendlyErrorMessage = getLaymanErrorMessage(err);
      setError(friendlyErrorMessage);
      toast({ variant: "destructive", title: "Problem Solving Failed", description: friendlyErrorMessage });
    } finally {
      setIsLoading(false);
    }
  };

  const handleCopySolution = () => {
    if (!rawResponse) return;
    
    navigator.clipboard.writeText(rawResponse).then(() => {
      toast({ title: "Solution Copied", description: "Problem solution has been copied to clipboard." });
    }).catch(() => {
      toast({ variant: "destructive", title: "Copy Failed", description: "Could not copy solution to clipboard." });
    });
  };

  const handleDownloadReport = () => {
    if (!solutionReport || !rawResponse) return;

    let reportString = "KLUTZ AI Problem Solver Report\n";
    reportString += "==============================\n\n";

    reportString += "Problem Details:\n";
    reportString += "----------------\n";
    reportString += `Problem Type: ${safeStringify(solutionReport.problem_type)}\n`;
    reportString += `Difficulty Level: ${safeStringify(solutionReport.difficulty_level)}\n`;
    reportString += `AI Confidence: ${safeStringify(solutionReport.confidence)}\n\n`;

    if (solutionReport.image_description) {
      reportString += "Image Description:\n";
      reportString += "------------------\n";
      reportString += `${safeStringify(solutionReport.image_description)}\n\n`;
    }

    reportString += "Problem Statement:\n";
    reportString += "------------------\n";
    reportString += `${safeStringify(solutionReport.problem_description)}\n\n`;

    reportString += "AI Solution:\n";
    reportString += "------------\n";
    reportString += `${rawResponse}\n\n`;

    reportString += "Disclaimer:\n";
    reportString += "-----------\n";
    reportString += safeStringify(solutionReport.disclaimer) + "\n\n";
    
    reportString += "\nIMPORTANT: This solution is AI-generated and for educational purposes only. Always verify solutions and consult with teachers or tutors for complex problems.";

    const timestamp = new Date().toISOString().replace(/[:.-]/g, '').slice(0, 14);
    downloadTextFile(reportString, `KLUTZ_AIProblemSolver_Report_${timestamp}.txt`);
  };

  const getDifficultyColor = (level: string) => {
    const levelStr = safeStringify(level).toLowerCase();
    switch (levelStr) {
      case 'beginner': return 'text-green-600 dark:text-green-400';
      case 'intermediate': return 'text-yellow-600 dark:text-yellow-400';
      case 'advanced': return 'text-orange-600 dark:text-orange-400';
      case 'expert': return 'text-red-600 dark:text-red-400';
      default: return 'text-foreground';
    }
  };

  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/ai-problem-solver" />
      </Head>
    <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-8">
      <Card className="max-w-3xl mx-auto shadow-xl">
        <CardHeader>
          <CardTitle className="font-headline text-3xl text-primary flex items-center">
            <Calculator className="mr-3 h-8 w-8" />
            AI Problem Solver
          </CardTitle>
          <CardDescription>
            Upload images of problems or type them directly to get step-by-step AI-powered solutions for math, science, and academic problems.
          </CardDescription>
        </CardHeader>
        <CardContent className="space-y-6">
          <Alert variant="default" className="bg-blue-50 border-blue-400 text-blue-700 dark:bg-blue-900/30 dark:text-blue-300">
            <Info className="h-5 w-5 text-blue-500" />
            <AlertTitle className="font-semibold">How it works</AlertTitle>
            <AlertDescription>
              Upload images of problems or type them directly. Get detailed step-by-step solutions with explanations, key concepts, and alternative methods.
              <div className="mt-2 p-2 bg-green-100 dark:bg-green-900/30 rounded-md border border-green-300 dark:border-green-700">
                <div className="flex items-center">
                  <Star className="h-4 w-4 text-green-600 dark:text-green-400 mr-2 flex-shrink-0" />
                  <span className="text-green-700 dark:text-green-300 font-medium text-sm">
                    <strong>Note:</strong> Text analysis is much more reliable and accurate than image analysis for complex problems.
                  </span>
                </div>
              </div>
            </AlertDescription>
          </Alert>

          <Tabs value={inputType} onValueChange={(value) => setInputType(value as 'image' | 'text')} className="w-full">
            <TabsList className="grid w-full grid-cols-2">
              <TabsTrigger value="text">Type Problem</TabsTrigger>
              <TabsTrigger value="image">Upload Problem Image</TabsTrigger>
            </TabsList>
            <TabsContent value="text" className="mt-6">
              <div className="space-y-4">
                <div>
                  <Label htmlFor="text-input" className="text-lg font-medium flex items-center mb-2">
                    <Type className="mr-2 h-5 w-5 text-accent" />
                    Problem Statement
                  </Label>
                  <Textarea
                    id="text-input"
                    placeholder="Enter your math, science, or academic problem here..."
                    value={textInput}
                    onChange={handleTextInputChange}
                    rows={6}
                    disabled={isLoading}
                  />
                </div>
              </div>
            </TabsContent>
            <TabsContent value="image" className="mt-6">
              <div className="space-y-4">
                <div>
                  <Label htmlFor="image-upload" className="text-lg font-medium flex items-center mb-2">
                    <ImageUp className="mr-2 h-5 w-5 text-accent" />
                    Upload Problem Image
                  </Label>
                  <Input
                    id="image-upload"
                    type="file"
                    accept="image/png, image/jpeg, image/webp"
                    onChange={handleImageFileChange}
                    className="file:text-primary file:font-semibold file:bg-primary/10 hover:file:bg-primary/20"
                    disabled={isLoading}
                  />
                  <p className="text-sm text-muted-foreground mt-1">Upload a clear image of the problem, equation, or question.</p>
                </div>
                {imageDataUrl && <ImagePreview imageDataUrl={imageDataUrl} dataAiHint="problem or equation"/>}
              </div>
            </TabsContent>
          </Tabs>

          <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
            <div>
              <Label htmlFor="problem-type" className="text-lg font-medium">Problem Type</Label>
              <Select value={problemType} onValueChange={setProblemType}>
                <SelectTrigger id="problem-type" className="w-full">
                  <SelectValue placeholder="Select problem type" />
                </SelectTrigger>
                <SelectContent>
                  {PROBLEM_TYPES.map((type) => (
                    <SelectItem key={type.value} value={type.value}>
                      {type.label}
                    </SelectItem>
                  ))}
                </SelectContent>
              </Select>
            </div>

            <div>
              <Label htmlFor="additional-context" className="text-lg font-medium">Additional Context (Optional)</Label>
              <Textarea
                id="additional-context"
                placeholder="Any additional context or specific requirements..."
                value={additionalContext}
                onChange={(e) => setAdditionalContext(e.target.value)}
                rows={3}
                disabled={isLoading}
              />
            </div>
          </div>

          <Button 
            onClick={solveProblem} 
            disabled={isLoading || (inputType === 'image' && !imageFile) || (inputType === 'text' && !textInput.trim()) || !problemType} 
            className="w-full"
          >
            {isLoading ? (
              <>
                <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                Solving Problem...
              </>
            ) : (
              <>
                <Calculator className="mr-2 h-4 w-4" />
                Solve Problem
              </>
            )}
          </Button>

          {error && !isLoading && (
            <Alert variant="destructive" className="mt-6">
              <AlertTriangle className="h-5 w-5" />
              <AlertTitle>Problem Solving Error</AlertTitle>
              <AlertDescription>{error}</AlertDescription>
            </Alert>
          )}

          {solutionReport && parsedSections && !isLoading && !error && (
            <Card className="mt-6 shadow-md">
              <CardHeader>
                <CardTitle className="font-headline text-xl flex items-center">
                  <Calculator className="mr-2 h-6 w-6 text-primary" />
                  Problem Solution
                </CardTitle>
                <div className="flex items-center justify-between">
                  <div className="grid grid-cols-1 md:grid-cols-3 gap-4 w-full">
                    <div className="bg-blue-50 dark:bg-blue-900/20 p-3 rounded-md text-center">
                      <p className="text-sm text-muted-foreground">Problem Type</p>
                      <p className="text-lg font-bold text-blue-600 dark:text-blue-400">{safeStringify(solutionReport.problem_type)}</p>
                    </div>
                    <div className="bg-purple-50 dark:bg-purple-900/20 p-3 rounded-md text-center">
                      <p className="text-sm text-muted-foreground">Difficulty</p>
                      <p className={`text-lg font-bold ${getDifficultyColor(solutionReport.difficulty_level)}`}>
                        {safeStringify(solutionReport.difficulty_level)}
                      </p>
                    </div>
                    <div className="bg-green-50 dark:bg-green-900/20 p-3 rounded-md text-center">
                      <p className="text-sm text-muted-foreground">AI Confidence</p>
                      <p className="text-lg font-bold text-green-600 dark:text-green-400">{safeStringify(solutionReport.confidence)}</p>
                    </div>
                  </div>
                </div>
              </CardHeader>
              <CardContent className="space-y-6">
                {solutionReport.image_description && (
                  <div>
                    <h4 className="font-semibold text-md mb-2 flex items-center">
                      <Info className="mr-2 h-4 w-4 text-accent" />
                      Image Analysis:
                    </h4>
                    <div className="bg-muted/30 p-4 rounded-md">
                      <p className="text-sm">{safeStringify(solutionReport.image_description)}</p>
                    </div>
                  </div>
                )}

                <div>
                  <h4 className="font-semibold text-md mb-2 flex items-center">
                    <BookOpen className="mr-2 h-4 w-4 text-accent" />
                    Problem Statement:
                  </h4>
                  <div className="bg-muted/30 p-4 rounded-md">
                    <p className="text-sm">{safeStringify(solutionReport.problem_description)}</p>
                  </div>
                </div>

                {parsedSections.problemAnalysis && (
                  <div>
                    <h4 className="font-semibold text-md mb-2 flex items-center">
                      <Lightbulb className="mr-2 h-4 w-4 text-yellow-500" />
                      Problem Analysis:
                    </h4>
                    <div className="bg-yellow-50 dark:bg-yellow-900/20 p-4 rounded-md border-l-4 border-yellow-500">
                      <pre className="text-sm whitespace-pre-wrap font-sans">{parsedSections.problemAnalysis}</pre>
                    </div>
                  </div>
                )}

                {parsedSections.solutionSteps && (
                  <div>
                    <h4 className="font-semibold text-md mb-2 flex items-center">
                      <Calculator className="mr-2 h-4 w-4 text-blue-500" />
                      Solution Steps:
                    </h4>
                    <div className="bg-blue-50 dark:bg-blue-900/20 p-4 rounded-md border-l-4 border-blue-500">
                      <pre className="text-sm whitespace-pre-wrap font-sans">{parsedSections.solutionSteps}</pre>
                    </div>
                  </div>
                )}

                {parsedSections.finalAnswer && (
                  <div>
                    <h4 className="font-semibold text-md mb-2 flex items-center">
                      <CheckCircle className="mr-2 h-4 w-4 text-green-500" />
                      Final Answer:
                    </h4>
                    <div className="bg-green-50 dark:bg-green-900/20 p-4 rounded-md border-l-4 border-green-500">
                      <pre className="text-sm whitespace-pre-wrap font-sans font-medium">{parsedSections.finalAnswer}</pre>
                    </div>
                  </div>
                )}

                {parsedSections.keyConcepts && (
                  <div>
                    <h4 className="font-semibold text-md mb-2 flex items-center">
                      <BookOpen className="mr-2 h-4 w-4 text-purple-500" />
                      Key Concepts:
                    </h4>
                    <div className="bg-purple-50 dark:bg-purple-900/20 p-4 rounded-md border-l-4 border-purple-500">
                      <pre className="text-sm whitespace-pre-wrap font-sans">{parsedSections.keyConcepts}</pre>
                    </div>
                  </div>
                )}

                {parsedSections.explanation && !parsedSections.problemAnalysis && !parsedSections.solutionSteps && (
                  <div>
                    <div className="flex items-center justify-between mb-2">
                      <h4 className="font-semibold text-md">Complete Solution:</h4>
                      <Button onClick={handleCopySolution} variant="outline" size="sm">
                        <Copy className="mr-1 h-3 w-3" />
                        Copy Solution
                      </Button>
                    </div>
                    <div className="bg-green-50 dark:bg-green-900/20 p-4 rounded-md border-l-4 border-green-500 max-h-96 overflow-y-auto">
                      <pre className="text-sm whitespace-pre-wrap font-sans">{parsedSections.explanation}</pre>
                    </div>
                  </div>
                )}

                <Alert variant="default" className="text-xs bg-blue-50 border-blue-300 dark:bg-blue-900/30 dark:text-blue-300">
                  <Info className="h-4 w-4 text-blue-500" />
                  <AlertTitle className="font-medium">Disclaimer</AlertTitle>
                  <AlertDescription>{safeStringify(solutionReport.disclaimer)}</AlertDescription>
                </Alert>

                <div className="flex flex-col sm:flex-row gap-2">
                  <Button onClick={handleCopySolution} variant="outline" className="flex-1">
                    <Copy className="mr-2 h-4 w-4" />
                    Copy Complete Solution
                  </Button>
                  <Button onClick={handleDownloadReport} variant="outline" className="flex-1">
                    <Download className="mr-2 h-4 w-4" />
                    Download Report
                  </Button>
                </div>
              </CardContent>
            </Card>
          )}

          {!solutionReport && !isLoading && !error && (
            <div className="mt-6 p-4 border border-dashed rounded-md text-center text-muted-foreground">
              <Info className="mx-auto h-8 w-8 mb-2"/>
              <p>Upload a problem image or type your problem, select the type, and get detailed AI-powered step-by-step solutions.</p>
            </div>
          )}
        </CardContent>
        <CardFooter>
          <p className="text-xs text-muted-foreground w-full text-center">
            This tool uses AI for problem solving. Always verify solutions and consult with teachers for complex academic problems.
          </p>
        </CardFooter>
      </Card>

 {/* Blog Section */}
 <div className="max-w-3xl mx-auto mt-12 prose dark:prose-invert">
   <h1 className="font-headline text-4xl text-primary mb-6">
     The Ultimate Guide to AI Problem Solvers: Quick Solutions at Your Fingertips
    </h1>
  
   <p>
      In today's fast-paced world, finding quick answers to complex problems shouldn't be overwhelming. Whether you're a student tackling tricky assignments, a professional dealing with coding errors, or someone facing life decisions, AI problem solvers have revolutionized how we approach challenges. These versatile tools are designed to provide accurate, practical solutions in moments, eliminating guesswork and delays that traditionally come with problem-solving.
    </p>

    <h2 className="text-xl font-semibold mb-3 font-headline">
      What is an AI Problem Solver?
    </h2>
    <p className="text-muted-foreground mb-6">
      An AI problem solver is an intelligent tool that empowers users to overcome obstacles and move forward with confidence. These solutions instantly analyze any issue you present, whether it's math equations, technical problems, or real-life situations, and generate step-by-step explanations that break complex problems into simple, manageable steps. The tool streamlines the process of finding answers, saving time and frustration while providing reliable, actionable solutions.
    </p>
    <p className="text-muted-foreground mb-6">
      Modern problem solvers offer multi-category support, covering a wide range of topics from academics to practical everyday challenges. With customizable outputs and adjustments that fit your personal context and preferences, these tools create content in minutes rather than weeks, making problem-solving a breeze.
    </p>

    <h2 className="text-xl font-semibold mb-3 font-headline">
      Key Features to Check When Searching for the Best AI Problem Solver
    </h2>
    <p className="text-muted-foreground mb-4">
      When evaluating the ideal problem solver, students and professionals should look for these essential features:
    </p>
    <ul className="list-disc list-inside text-muted-foreground mb-6 space-y-2">
      <li><strong>Input Flexibility:</strong> The best tools accept multiple input types - text, images, voice, and even handwritten problems</li>
      <li><strong>Solution Category Selection:</strong> Look for tools that let you select the problem type or category to receive tailored responses</li>
      <li><strong>Step-by-Step Solutions:</strong> Clear, detailed instructions that provide understanding, not just answers</li>
      <li><strong>Accuracy and Reliability:</strong> Tools that generate accurate solutions you can trust</li>
      <li><strong>Device Accessibility:</strong> Solutions accessible across any device without installations or sign-ups</li>
      <li><strong>Customization Options:</strong> Ability to tweak and refine solutions to suit your specific needs</li>
      <li><strong>Speed:</strong> Quick response times that deliver solutions in seconds</li>
    </ul>

    <h2 className="text-xl font-semibold mb-3 font-headline">
      Best FREE AI Problem Solvers
    </h2>

    <h4 className="text-lg font-semibold mb-2">Klutz AI Problem Solver</h4>
    <p className="text-muted-foreground mb-2">
      <strong>Price:</strong> Completely free
    </p>
    <p className="text-muted-foreground mb-3">
      How it works: Simply enter your problem, select the appropriate category, and click generate to receive clear step-by-step solutions.
    </p>
    <p className="font-semibold mb-2">Pros:</p>
    <ul className="list-disc list-inside text-muted-foreground mb-3 space-y-1">
      <li>Start solving problems instantly with no email sign-ups or installations required</li>
      <li>Versatile tool that effortlessly tackles challenges across multiple categories</li>
      <li>Provides detailed step-by-step instructions for better understanding</li>
      <li>Simple interface - just type your problem and start problem-solving</li>
      <li>Reliable text analysis that's more accurate than image processing for complex issues</li>
      <li>Designed to provide quick, effective solutions without overwhelming users</li>
      <li>Takes the pressure off by analyzing each issue and presenting actionable solutions</li>
    </ul>
    <p className="font-semibold mb-2">Cons:</p>
    <ul className="list-disc list-inside text-muted-foreground space-y-1">
      <li>Image analysis may be less reliable for very complex mathematical problems</li>
      <li>Limited to web-based access</li>
    </ul>
    <p className="text-muted-foreground italic mt-3">
      Klutz's problem solver today stands out as an ideal tool for anyone looking to find solutions moments after entering your question or dilemma. The solver takes a straightforward approach, making problem-solving accessible to everyone.
    </p>
  
    <h4 className="text-lg font-semibold mb-2">WriteCream Problem Solver</h4>
    <p className="text-muted-foreground mb-2">
      Price: Free tier with premium options
    </p>
    <p className="text-muted-foreground mb-3">
      Features: Offers problem-solving as part of their content creation suite, with solutions for various problem types.
    </p>
    <p className="font-semibold mb-2">Pros:</p>
    <ul className="list-disc list-inside text-muted-foreground mb-3 space-y-1">
      <li>Multi-purpose platform for content creation and problem-solving</li>
      <li>Free tier available for basic problem-solving needs</li>
      <li>Quick generation of solutions</li>
    </ul>
    <p className="font-semibold mb-2">Cons:</p>
    <ul className="list-disc list-inside text-muted-foreground space-y-1">
      <li>Limited words per month on free tier</li>
      <li>Requires sign-up and email registration</li>
      <li>Less specialized than dedicated problem solvers</li>
      <li>Wait times during peak usage</li>
    </ul>
    <p className="text-muted-foreground italic mt-3">
      Copyright: All rights reserved by WriteCream
    </p>

    <h4 className="text-lg font-semibold mb-2">BoredHumans Problem Solver</h4>
    <p className="text-muted-foreground mb-2">
      Price: Free
    </p>
    <p className="font-semibold mb-2">Pros:</p>
    <ul className="list-disc list-inside text-muted-foreground mb-3 space-y-1">
      <li>Part of 100+ free AI tools suite</li>
      <li>Simple text input system</li>
      <li>No registration required</li>
      <li>Covers general problem-solving scenarios</li>
    </ul>
    <p className="font-semibold mb-2">Cons:</p>
    <ul className="list-disc list-inside text-muted-foreground space-y-1">
      <li>Less specialized approach to specific problem types</li>
      <li>No image upload capability for visual problems</li>
      <li>Interface can feel cluttered with many other tools</li>
      <li>Limited step-by-step explanations compared to dedicated solvers</li>
    </ul>

    <h4 className="text-lg font-semibold mb-2">Mathos AI (MathGPT Pro)</h4>
    <p className="text-muted-foreground mb-2">
      Price: Free tier with premium features
    </p>
    <p className="text-muted-foreground mb-3">
      Specialization: Mathematical and technical problem-solving
    </p>
    <p className="font-semibold mb-2">Pros:</p>
    <ul className="list-disc list-inside text-muted-foreground mb-3 space-y-1">
      <li>Specialized for math equations with high accuracy</li>
      <li>Multiple input methods including voice and drawing</li>
      <li>Advanced graphing calculator included</li>
      <li>Multi-device synchronization</li>
      <li>Trusted by millions of students worldwide</li>
    </ul>
    <p className="font-semibold mb-2">Cons:</p>
    <ul className="list-disc list-inside text-muted-foreground space-y-1">
      <li>Primarily focused on mathematical problems only</li>
      <li>Premium features require subscription</li>
      <li>May be overwhelming for simple calculations</li>
      <li>Limited coverage of non-mathematical issues</li>
    </ul>

    <h4 className="text-lg font-semibold mb-2">YesChat Problem Solver</h4>
    <p className="text-muted-foreground mb-2">
      Price: Free tier available
    </p>
    <p className="font-semibold mb-2">Pros:</p>
    <ul className="list-disc list-inside text-muted-foreground mb-3 space-y-1">
      <li>Advanced AI reasoning for complex problems</li>
      <li>Handles both technical and personal advice scenarios</li>
      <li>No sign-up required for basic use</li>
      <li>Covers professional and academic topics</li>
    </ul>
    <p className="font-semibold mb-2">Cons:</p>
    <ul className="list-disc list-inside text-muted-foreground space-y-1">
      <li>Usage limitations on free tier</li>
      <li>Less focused on specific problem categories</li>
      <li>Primarily text-based interaction</li>
    </ul>

    <h3 className="text-xl font-semibold mt-8 mb-3 font-headline">
      TLDR
    </h3>
    <p className="text-muted-foreground mb-4">
      AI problem solvers have transformed how we tackle challenges, whether big or small. These tools eliminate the overwhelming process of finding solutions by providing quick, reliable answers in moments.
    </p>
    <p className="font-semibold mb-2">Quick Recommendations:</p>
    <ul className="list-disc list-inside text-muted-foreground mb-6 space-y-2">
      <li>
        <strong>For versatile problem-solving:</strong> Klutz AI Problem Solver offers the best balance - completely free, simple steps to solve any problem, and no frustrating sign-ups
      </li>
      <li>
        <strong>For math-specific needs:</strong> Mathos AI provides specialized mathematical tools with step-by-step solutions
      </li>
      <li>
        <strong>For content creators:</strong> WriteCream combines problem-solving with content generation (limited free words per month)
      </li>
      <li>
        <strong>For variety:</strong> BoredHumans offers diverse tools but with less depth per problem type
      </li>
    </ul>
    <p className="text-muted-foreground">
      The key is finding a problem solver that fits your needs while providing accurate, practical solutions. Start solving your problems today - find the right tool and move forward with confidence, knowing you can overcome any obstacle that comes your way.
    </p>
  </div>
</div>
  );
    </>
)}    


================================================
FILE: src/app/ai-spreadsheets/page.tsx
================================================

'use client';

import Head from 'next/head';
import { useState, useEffect, useRef } from 'react';
import { useToast } from "@/hooks/use-toast";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from "@/components/ui/card";
import { Textarea } from "@/components/ui/textarea";
import { Input } from "@/components/ui/input";
import { Label } from "@/components/ui/label";
import { Alert, AlertDescription, AlertTitle } from "@/components/ui/alert";
import { Tabs, TabsContent, TabsList, TabsTrigger } from "@/components/ui/tabs";
import { Separator } from "@/components/ui/separator";
import { Loader2, Upload, FileSpreadsheet, Send, Download, Plus, Trash, Info, MessageSquare, Table, FileUp, RefreshCw, AlertTriangle } from 'lucide-react';
import { getLaymanErrorMessage } from '@/lib/error-utils';
import * as XLSX from 'xlsx';

interface SpreadsheetCell {
  value: string;
  formula?: string;
  style?: {
    bold?: boolean;
    italic?: boolean;
    color?: string;
    backgroundColor?: string;
    textAlign?: 'left' | 'center' | 'right';
  };
}

interface SpreadsheetData {
  rows: SpreadsheetCell[][];
  columnWidths?: number[];
  rowHeights?: number[];
  activeSheet: string;
  sheets: string[];
}

interface ChatMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
  timestamp: Date;
}

interface SpreadsheetOperation {
  type: string;
  details: any;
}

export default function AISpreadsheetPage() {
  const [spreadsheetData, setSpreadsheetData] = useState<SpreadsheetData>({
    rows: Array(20).fill(null).map(() => Array(10).fill(null).map(() => ({ value: '' }))),
    columnWidths: Array(10).fill(120),
    rowHeights: Array(20).fill(30),
    activeSheet: 'Sheet1',
    sheets: ['Sheet1']
  });
  
  const [chatMessages, setChatMessages] = useState<ChatMessage[]>([
    {
      role: 'system',
      content: 'Welcome to AI-Native Spreadsheets! I can help you create, analyze, and modify spreadsheets. You can ask me to:',
      timestamp: new Date()
    },
    {
      role: 'system',
      content: '‚Ä¢ Create tables and charts\n‚Ä¢ Format cells and data\n‚Ä¢ Perform calculations\n‚Ä¢ Analyze your data\n‚Ä¢ Generate reports\n‚Ä¢ Import/export data',
      timestamp: new Date()
    },
    {
      role: 'system',
      content: 'What would you like to do today?',
      timestamp: new Date()
    }
  ]);
  
  const [userInput, setUserInput] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [fileName, setFileName] = useState('New Spreadsheet');
  const [originalWorkbook, setOriginalWorkbook] = useState<XLSX.WorkBook | null>(null);
  
  const chatContainerRef = useRef<HTMLDivElement>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);
  const { toast } = useToast();

  useEffect(() => {
    // Load XLSX library dynamically
    const loadXLSX = async () => {
      try {
        await import('xlsx');
      } catch (error) {
        console.error('Failed to load XLSX library:', error);
        toast({
          variant: "destructive",
          title: "Library Error",
          description: "Failed to load spreadsheet processing library. Please refresh the page.",
        });
      }
    };
    
    loadXLSX();
    
    if (typeof window.puter === 'undefined') {
      toast({
        variant: "destructive",
        title: "Puter SDK Error",
        description: "Puter.js SDK is not loaded. Please refresh the page.",
      });
    }
  }, [toast]);

  useEffect(() => {
    // Scroll to bottom of chat when new messages are added
    if (chatContainerRef.current) {
      chatContainerRef.current.scrollTop = chatContainerRef.current.scrollHeight;
    }
  }, [chatMessages]);

  const handleFileUpload = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (!file) return;

    setFileName(file.name);
    setIsLoading(true);
    
    try {
      // Read the file as an ArrayBuffer
      const arrayBuffer = await readFileAsArrayBuffer(file);
      
      // Process different file types
      if (file.name.endsWith('.csv')) {
        // For CSV files
        processCSVFile(arrayBuffer, file.name);
      } else if (file.name.endsWith('.xlsx') || file.name.endsWith('.xls')) {
        // For Excel files
        processExcelFile(arrayBuffer, file.name);
      } else {
        // Try to process as CSV for other formats
        processCSVFile(arrayBuffer, file.name);
      }
    } catch (error) {
      console.error('Error loading spreadsheet:', error);
      toast({
        variant: "destructive",
        title: "Upload Failed",
        description: "Failed to load the spreadsheet. The file format may be unsupported or corrupted.",
      });
      
      // Create a new empty spreadsheet as fallback
      createNewSpreadsheet();
    } finally {
      setIsLoading(false);
    }
  };

  const readFileAsArrayBuffer = (file: File): Promise<ArrayBuffer> => {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = (event) => {
        if (event.target?.result) {
          resolve(event.target.result as ArrayBuffer);
        } else {
          reject(new Error('Failed to read file'));
        }
      };
      reader.onerror = (error) => reject(error);
      reader.readAsArrayBuffer(file);
    });
  };

  const processCSVFile = (arrayBuffer: ArrayBuffer, filename: string) => {
    try {
      // Use XLSX to parse CSV
      const workbook = XLSX.read(new Uint8Array(arrayBuffer), { type: 'array' });
      setOriginalWorkbook(workbook);
      
      // Get the first sheet
      const firstSheetName = workbook.SheetNames[0];
      const worksheet = workbook.Sheets[firstSheetName];
      
      // Convert to JSON
      const jsonData = XLSX.utils.sheet_to_json<any>(worksheet, { header: 1 });
      
      // Create spreadsheet data
      updateSpreadsheetWithParsedData(jsonData, filename, workbook.SheetNames);
    } catch (error) {
      console.error('Error processing CSV:', error);
      throw new Error('Failed to process CSV file');
    }
  };

  const processExcelFile = (arrayBuffer: ArrayBuffer, filename: string) => {
    try {
      // Use XLSX to parse Excel
      const workbook = XLSX.read(new Uint8Array(arrayBuffer), { type: 'array' });
      setOriginalWorkbook(workbook);
      
      // Get the first sheet
      const firstSheetName = workbook.SheetNames[0];
      const worksheet = workbook.Sheets[firstSheetName];
      
      // Convert to JSON
      const jsonData = XLSX.utils.sheet_to_json<any>(worksheet, { header: 1 });
      
      // Create spreadsheet data
      updateSpreadsheetWithParsedData(jsonData, filename, workbook.SheetNames);
    } catch (error) {
      console.error('Error processing Excel:', error);
      throw new Error('Failed to process Excel file');
    }
  };

  const updateSpreadsheetWithParsedData = (parsedData: any[][], filename: string, sheetNames: string[] = ['Sheet1']) => {
    // Ensure we have data
    if (!parsedData || parsedData.length === 0) {
      parsedData = [[]];
    }
    
    // Create a spreadsheet data structure from the parsed data
    const newSpreadsheetData: SpreadsheetData = {
      rows: parsedData.map(row => 
        row.map(value => ({ 
          value: value !== null && value !== undefined ? String(value) : '' 
        }))
      ),
      columnWidths: Array(Math.max(...parsedData.map(row => row.length), 10)).fill(120),
      rowHeights: Array(Math.max(parsedData.length, 20)).fill(30),
      activeSheet: sheetNames[0],
      sheets: sheetNames
    };
    
    // Ensure we have at least 20 rows and 10 columns
    while (newSpreadsheetData.rows.length < 20) {
      newSpreadsheetData.rows.push(Array(10).fill(null).map(() => ({ value: '' })));
    }
    
    newSpreadsheetData.rows = newSpreadsheetData.rows.map(row => {
      while (row.length < 10) {
        row.push({ value: '' });
      }
      return row;
    });
    
    // Format the header row if it exists
    if (newSpreadsheetData.rows.length > 0) {
      newSpreadsheetData.rows[0] = newSpreadsheetData.rows[0].map(cell => ({
        ...cell,
        style: { 
          bold: true, 
          backgroundColor: '#f0f0f0' 
        }
      }));
    }
    
    setSpreadsheetData(newSpreadsheetData);
    
    // Generate a summary of the data for the AI
    const rowCount = parsedData.length;
    const colCount = Math.max(...parsedData.map(row => row.length));
    
    // Get headers safely
    let headers = 'No headers';
    if (parsedData.length > 0 && parsedData[0].length > 0) {
      headers = parsedData[0]
        .map(header => header !== null && header !== undefined ? String(header) : '')
        .filter(Boolean)
        .join(', ');
    }
    
    setChatMessages(prev => [
      ...prev,
      {
        role: 'assistant',
        content: `I've loaded "${filename}". This spreadsheet contains ${rowCount} rows and ${colCount} columns. The headers are: ${headers}. What would you like to do with this data?`,
        timestamp: new Date()
      }
    ]);
  };

  const createNewSpreadsheet = () => {
    setSpreadsheetData({
      rows: Array(20).fill(null).map(() => Array(10).fill(null).map(() => ({ value: '' }))),
      columnWidths: Array(10).fill(120),
      rowHeights: Array(20).fill(30),
      activeSheet: 'Sheet1',
      sheets: ['Sheet1']
    });
    
    setFileName('New Spreadsheet');
    setOriginalWorkbook(null);
    
    setChatMessages([
      {
        role: 'system',
        content: 'Welcome to AI-Native Spreadsheets! I can help you create, analyze, and modify spreadsheets. You can ask me to:',
        timestamp: new Date()
      },
      {
        role: 'system',
        content: '‚Ä¢ Create tables and charts\n‚Ä¢ Format cells and data\n‚Ä¢ Perform calculations\n‚Ä¢ Analyze your data\n‚Ä¢ Generate reports\n‚Ä¢ Import/export data',
        timestamp: new Date()
      },
      {
        role: 'system',
        content: 'What would you like to do today?',
        timestamp: new Date()
      }
    ]);
  };

  const handleCellChange = (rowIndex: number, colIndex: number, value: string) => {
    const newData = { ...spreadsheetData };
    newData.rows[rowIndex][colIndex] = { 
      ...newData.rows[rowIndex][colIndex],
      value 
    };
    setSpreadsheetData(newData);
  };

  const handleSendMessage = async () => {
    if (!userInput.trim()) return;
    
    const userMessage: ChatMessage = {
      role: 'user',
      content: userInput,
      timestamp: new Date()
    };
    
    setChatMessages(prev => [...prev, userMessage]);
    setUserInput('');
    setIsLoading(true);
    
    try {
      if (typeof window.puter === 'undefined' || !window.puter.auth || !window.puter.ai) {
        throw new Error("Puter SDK not available. Please refresh.");
      }
      const puter = window.puter;

      let isSignedIn = await puter.auth.isSignedIn();
      if (!isSignedIn) {
        await puter.auth.signIn();
        isSignedIn = await puter.auth.isSignedIn();
        if (!isSignedIn) throw new Error("Authentication failed or was cancelled.");
      }
      
      // Create a string representation of the current spreadsheet data for context
      const spreadsheetContext = generateSpreadsheetContext();
      
      const prompt = `
        You are an AI assistant specialized in spreadsheet operations. The user is working with a spreadsheet with the following data:
        
        ${spreadsheetContext}
        
        The user's request is: "${userInput}"
        
        Analyze what changes need to be made to the spreadsheet. I will implement these changes directly based on your analysis.
        
        Return your response in JSON format with these fields:
        {
          "operations": [
            {
              "type": "find_replace", // or "add_column", "add_row", "update_cell", "format_cells", etc.
              "details": {
                // Specific details for each operation type
                // For find_replace: { "find": "text to find", "replace": "replacement text" }
                // For add_column: { "header": "column name", "position": 3, "values": ["val1", "val2"] }
                // For update_cell: { "row": 2, "col": 3, "value": "new value" }
              }
            }
          ],
          "explanation": "A clear explanation of what changes should be made"
        }
        
        If you can't determine specific operations, just provide an explanation field with your response.
      `;
      
      const response = await puter.ai.chat(prompt, { model: 'gpt-4o' });
      
      if (!response?.message?.content) {
        throw new Error("AI response was empty.");
      }
      
      // Process the AI's response to actually modify the spreadsheet
      const aiResponseText = response.message.content;
      let aiResponse;
      let operations: SpreadsheetOperation[] = [];
      let explanation = "";
      
      try {
        // Try to parse the JSON response
        const jsonStart = aiResponseText.indexOf('{');
        const jsonEnd = aiResponseText.lastIndexOf('}') + 1;
        if (jsonStart >= 0 && jsonEnd > jsonStart) {
          const jsonStr = aiResponseText.substring(jsonStart, jsonEnd);
          aiResponse = JSON.parse(jsonStr);
          operations = aiResponse.operations || [];
          explanation = aiResponse.explanation || aiResponseText;
        } else {
          explanation = aiResponseText;
        }
      } catch (error) {
        console.error("Failed to parse AI response as JSON:", error);
        explanation = aiResponseText;
      }
      
      // Implement the actual spreadsheet modifications based on operations
      let updatedSpreadsheet = { ...spreadsheetData };
      let operationsPerformed = false;
      
      // Process each operation
      for (const operation of operations) {
        switch (operation.type) {
          case 'find_replace':
            if (operation.details?.find && operation.details?.replace) {
              const findText = operation.details.find;
              const replaceText = operation.details.replace;
              
              // Perform find and replace across all cells
              updatedSpreadsheet.rows = updatedSpreadsheet.rows.map(row => 
                row.map(cell => ({
                  ...cell,
                  value: cell.value.replace(new RegExp(findText, 'g'), replaceText)
                }))
              );
              operationsPerformed = true;
            }
            break;
            
          case 'add_column':
            if (operation.details?.header) {
              const header = operation.details.header;
              const position = operation.details.position || updatedSpreadsheet.rows[0].length;
              const values = operation.details.values || [];
              
              // Add a new column
              updatedSpreadsheet.rows = updatedSpreadsheet.rows.map((row, rowIndex) => {
                const newRow = [...row];
                if (rowIndex === 0) {
                  // Add header
                  newRow.splice(position, 0, { 
                    value: header, 
                    style: { bold: true, backgroundColor: '#f0f0f0' } 
                  });
                } else {
                  // Add value or empty cell
                  const value = rowIndex - 1 < values.length ? values[rowIndex - 1] : '';
                  newRow.splice(position, 0, { value: String(value) });
                }
                return newRow;
              });
              
              // Update column widths
              if (updatedSpreadsheet.columnWidths) {
                updatedSpreadsheet.columnWidths.splice(position, 0, 120);
              }
              
              operationsPerformed = true;
            }
            break;
            
          case 'update_cell':
            if (operation.details?.row !== undefined && 
                operation.details?.col !== undefined && 
                operation.details?.value !== undefined) {
              
              const row = operation.details.row;
              const col = operation.details.col;
              const value = operation.details.value;
              
              // Make sure the row and column exist
              if (row >= 0 && row < updatedSpreadsheet.rows.length &&
                  col >= 0 && col < updatedSpreadsheet.rows[row].length) {
                
                updatedSpreadsheet.rows[row][col] = {
                  ...updatedSpreadsheet.rows[row][col],
                  value: String(value)
                };
                
                operationsPerformed = true;
              }
            }
            break;
            
          case 'format_cells':
            if (operation.details?.cells && operation.details?.style) {
              const cells = operation.details.cells;
              const style = operation.details.style;
              
              for (const cell of cells) {
                const { row, col } = cell;
                
                // Make sure the row and column exist
                if (row >= 0 && row < updatedSpreadsheet.rows.length &&
                    col >= 0 && col < updatedSpreadsheet.rows[row].length) {
                  
                  updatedSpreadsheet.rows[row][col] = {
                    ...updatedSpreadsheet.rows[row][col],
                    style: {
                      ...updatedSpreadsheet.rows[row][col].style,
                      ...style
                    }
                  };
                }
              }
              
              operationsPerformed = true;
            }
            break;
            
          // Add more operation types as needed
        }
      }
      
      // If no operations were performed but we have a user request that looks like a find/replace
      if (!operationsPerformed) {
        // Handle common operations based on user input patterns
        if (userInput.toLowerCase().includes('change') || 
            userInput.toLowerCase().includes('replace')) {
          
          // Try to extract find and replace terms
          const findReplacePattern = /change\s+["']?([^"']+)["']?\s+to\s+["']?([^"']+)["']?/i;
          const match = userInput.match(findReplacePattern);
          
          if (match && match.length >= 3) {
            const findText = match[1].trim();
            const replaceText = match[2].trim();
            
            // Perform find and replace across all cells
            updatedSpreadsheet.rows = updatedSpreadsheet.rows.map(row => 
              row.map(cell => ({
                ...cell,
                value: cell.value.replace(new RegExp(findText, 'g'), replaceText)
              }))
            );
            
            operationsPerformed = true;
            explanation = `I've replaced all instances of "${findText}" with "${replaceText}" throughout the spreadsheet.`;
          }
        }
        
        // Handle adding a column
        else if (userInput.toLowerCase().includes('add') && 
                 userInput.toLowerCase().includes('column')) {
          
          // Try to extract column name
          const columnNamePattern = /add\s+(?:a\s+)?column\s+(?:for|called|named|with header)\s+["']?([^"']+)["']?/i;
          const match = userInput.match(columnNamePattern);
          
          if (match && match.length >= 2) {
            const columnName = match[1].trim();
            
            // Add a new column
            updatedSpreadsheet.rows = updatedSpreadsheet.rows.map((row, rowIndex) => {
              const newRow = [...row];
              if (rowIndex === 0) {
                // Add header
                newRow.push({ 
                  value: columnName, 
                  style: { bold: true, backgroundColor: '#f0f0f0' } 
                });
              } else {
                // Add empty cell
                newRow.push({ value: '' });
              }
              return newRow;
            });
            
            // Update column widths
            if (updatedSpreadsheet.columnWidths) {
              updatedSpreadsheet.columnWidths.push(120);
            }
            
            operationsPerformed = true;
            explanation = `I've added a new column titled "${columnName}" to your spreadsheet.`;
          }
        }
      }
      
      // Update the spreadsheet if operations were performed
      if (operationsPerformed) {
        setSpreadsheetData(updatedSpreadsheet);
      }
      
      // Add the AI's response to the chat
      setChatMessages(prev => [
        ...prev,
        {
          role: 'assistant',
          content: explanation,
          timestamp: new Date()
        }
      ]);
      
    } catch (err: any) {
      console.error("AI chat error:", err);
      const friendlyErrorMessage = getLaymanErrorMessage(err);
      
      setChatMessages(prev => [
        ...prev,
        {
          role: 'assistant',
          content: `I'm sorry, I encountered an error: ${friendlyErrorMessage}. Please try again.`,
          timestamp: new Date()
        }
      ]);
      
      toast({ 
        variant: "destructive", 
        title: "Chat Failed", 
        description: friendlyErrorMessage 
      });
    } finally {
      setIsLoading(false);
    }
  };

  const generateSpreadsheetContext = (): string => {
    // Create a text representation of the spreadsheet for the AI
    let context = `Filename: ${fileName}\n`;
    context += `Active Sheet: ${spreadsheetData.activeSheet}\n`;
    context += `Sheets: ${spreadsheetData.sheets.join(', ')}\n\n`;
    
    // Add the first 10 rows or until we hit empty rows
    context += "Spreadsheet Data (first 10 rows):\n";
    
    let hasData = false;
    for (let i = 0; i < Math.min(10, spreadsheetData.rows.length); i++) {
      const row = spreadsheetData.rows[i];
      const rowValues = row.map(cell => cell.value || '');
      
      if (rowValues.some(value => value !== '')) {
        hasData = true;
        context += rowValues.join('\t') + '\n';
      }
    }
    
    if (!hasData) {
      context += "The spreadsheet is currently empty.\n";
    }
    
    return context;
  };

  const handleKeyDown = (e: React.KeyboardEvent<HTMLTextAreaElement>) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSendMessage();
    }
  };

  const downloadSpreadsheet = () => {
    try {
      // Create a new workbook
      const wb = originalWorkbook || XLSX.utils.book_new();
      
      // Convert the current spreadsheet data to a worksheet
      const wsData = spreadsheetData.rows.map(row => 
        row.map(cell => cell.value)
      );
      
      const ws = XLSX.utils.aoa_to_sheet(wsData);
      
      // Add the worksheet to the workbook
      // Only attempt to remove a sheet if originalWorkbook exists,
      // otherwise a new workbook is created and doesn't have a sheet to remove
      if (originalWorkbook) {
         XLSX.utils.book_remove_sheet(wb, 0); // Remove existing sheet if any
      }
      XLSX.utils.book_append_sheet(wb, ws, spreadsheetData.activeSheet);
      
      // Generate the file
      XLSX.writeFile(wb, `${fileName.replace(/\.[^/.]+$/, '')}.xlsx`);
      
      toast({
        title: "Download Complete",
        description: `${fileName.replace(/\.[^/.]+$/, '')}.xlsx has been downloaded.`,
      });
    } catch (error) {
      console.error('Error downloading spreadsheet:', error);
      toast({
        variant: "destructive",
        title: "Download Failed",
        description: "Failed to download the spreadsheet. Please try again.",
      });
    }
  };

  const getCellStyle = (cell: SpreadsheetCell) => {
    if (!cell) return {};
    
    return {
      fontWeight: cell.style?.bold ? 'bold' : 'normal',
      fontStyle: cell.style?.italic ? 'italic' : 'normal',
      color: cell.style?.color || 'inherit',
      backgroundColor: cell.style?.backgroundColor || 'transparent',
      textAlign: cell.style?.textAlign || 'left',
    };
  };

  const getColumnLetter = (index: number) => {
    let letter = '';
    while (index >= 0) {
      letter = String.fromCharCode(65 + (index % 26)) + letter;
      index = Math.floor(index / 26) - 1;
    }
    return letter;
  };

  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/ai-spreadsheets" />
      </Head>
      <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-8">
        <div className="flex flex-col space-y-4">
          <div className="flex items-center justify-between">
            <h1 className="font-headline text-3xl text-primary flex items-center">
              <FileSpreadsheet className="mr-3 h-8 w-8" />
              AI-Native Spreadsheets
            </h1>
            <div className="flex items-center space-x-2">
              <Button variant="outline" onClick={() => fileInputRef.current?.click()}>
                <Upload className="mr-2 h-4 w-4" />
                Upload
              </Button>
              <Input 
                ref={fileInputRef}
                type="file" 
                accept=".csv,.xlsx,.xls,.ods,.tsv" 
                className="hidden"
                onChange={handleFileUpload}
              />
              <Button variant="outline" onClick={createNewSpreadsheet}>
                <Plus className="mr-2 h-4 w-4" />
                New
              </Button>
              <Button variant="outline" onClick={downloadSpreadsheet}>
                <Download className="mr-2 h-4 w-4" />
                Download
              </Button>
            </div>
          </div>
          
          {/* Tips alert - moved above the main content */}
          <Alert variant="default" className="bg-blue-50 border-blue-400 text-blue-700 dark:bg-blue-900/30 dark:text-blue-300">
            <Info className="h-5 w-5 text-blue-500" />
            <AlertTitle className="font-semibold">Spreadsheet Assistant Tips</AlertTitle>
            <AlertDescription>
              <ul className="list-disc list-inside space-y-1 mt-1">
                <li>Ask the AI to create tables, charts, or perform calculations</li>
                <li>Request data formatting or styling changes</li>
                <li>Ask for analysis or insights about your data</li>
                <li>The AI can modify your spreadsheet based on your instructions</li>
              </ul>
            </AlertDescription>
          </Alert>
          
          {/* Main content area with spreadsheet and chat */}
          <div className="grid grid-cols-1 lg:grid-cols-3 gap-4 h-[calc(100vh-12rem)]">
            {/* Spreadsheet area - takes up 2/3 on large screens */}
            <div className="lg:col-span-2 overflow-hidden flex flex-col">
              <div className="bg-card rounded-lg border shadow-sm p-4 flex-grow overflow-hidden flex flex-col">
                <div className="flex items-center justify-between mb-4">
                  <div className="flex items-center">
                    <Input 
                      value={fileName}
                      onChange={(e) => setFileName(e.target.value)}
                      className="w-64 h-8 text-lg font-medium"
                    />
                  </div>
                  <div className="flex space-x-2">
                    {spreadsheetData.sheets.map(sheet => (
                      <Button 
                        key={sheet}
                        variant={spreadsheetData.activeSheet === sheet ? "default" : "outline"}
                        size="sm"
                        onClick={() => setSpreadsheetData({...spreadsheetData, activeSheet: sheet})}
                      >
                        {sheet}
                      </Button>
                    ))}
                  </div>
                </div>
                
                <div className="flex-grow overflow-auto border rounded-md">
                  <table className="w-full border-collapse">
                    <thead>
                      <tr className="bg-muted/50">
                        <th className="w-10 h-8 border border-border text-center sticky top-0 left-0 z-20 bg-muted/80">#</th>
                        {spreadsheetData.columnWidths?.map((width, colIndex) => (
                          <th 
                            key={colIndex} 
                            className="h-8 border border-border text-center sticky top-0 z-10 bg-muted/80"
                            style={{ width: `${width}px`, minWidth: `${width}px` }}
                          >
                            {getColumnLetter(colIndex)}
                          </th>
                        ))}
                      </tr>
                    </thead>
                    <tbody>
                      {spreadsheetData.rows.map((row, rowIndex) => (
                        <tr key={rowIndex}>
                          <td className="border border-border text-center sticky left-0 z-10 bg-muted/50 w-10">
                            {rowIndex + 1}
                          </td>
                          {row.map((cell, colIndex) => (
                            <td 
                              key={colIndex} 
                              className="border border-border p-0"
                              style={{ 
                                height: `${spreadsheetData.rowHeights?.[rowIndex] || 30}px`,
                                width: `${spreadsheetData.columnWidths?.[colIndex] || 120}px`,
                              }}
                            >
                              <input
                                type="text"
                                value={cell?.value || ''}
                                onChange={(e) => handleCellChange(rowIndex, colIndex, e.target.value)}
                                className="w-full h-full px-2 focus:outline-none focus:ring-1 focus:ring-primary"
                                style={getCellStyle(cell)}
                              />
                            </td>
                          ))}
                        </tr>
                      ))}
                    </tbody>
                  </table>
                </div>
              </div>
            </div>
            
            {/* Chat area - takes up 1/3 on large screens */}
            <div className="bg-card rounded-lg border shadow-sm flex flex-col h-full">
              <div className="p-4 border-b">
                <h2 className="font-headline text-xl flex items-center">
                  <MessageSquare className="mr-2 h-5 w-5 text-primary" />
                  Spreadsheet Assistant
                </h2>
                <p className="text-sm text-muted-foreground">
                  Ask me to help you create, analyze, or modify your spreadsheet.
                </p>
              </div>
              
              <div 
                ref={chatContainerRef}
                className="flex-grow overflow-y-auto p-4 space-y-4"
              >
                {chatMessages.map((message, index) => (
                  <div 
                    key={index} 
                    className={`flex ${message.role === 'user' ? 'justify-end' : 'justify-start'}`}
                  >
                    <div 
                      className={`max-w-[80%] rounded-lg p-3 ${
                        message.role === 'user' 
                          ? 'bg-primary text-primary-foreground' 
                          : message.role === 'system'
                            ? 'bg-muted/50 text-foreground'
                            : 'bg-muted text-foreground'
                      }`}
                    >
                      <p className="whitespace-pre-wrap">{message.content}</p>
                      <p className="text-xs opacity-70 mt-1">
                        {message.timestamp.toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' })}
                      </p>
                    </div>
                  </div>
                ))}
                {isLoading && (
                  <div className="flex justify-start">
                    <div className="max-w-[80%] rounded-lg p-3 bg-muted text-foreground">
                      <div className="flex items-center space-x-2">
                        <Loader2 className="h-4 w-4 animate-spin" />
                        <p>Thinking...</p>
                      </div>
                    </div>
                  </div>
                )}
              </div>
              
              <div className="p-4 border-t">
                <div className="flex space-x-2">
                  <Textarea
                    value={userInput}
                    onChange={(e) => setUserInput(e.target.value)}
                    onKeyDown={handleKeyDown}
                    placeholder="Ask about your spreadsheet or request changes..."
                    className="min-h-[60px] resize-none"
                    disabled={isLoading}
                  />
                  <Button 
                    onClick={handleSendMessage} 
                    disabled={isLoading || !userInput.trim()}
                    className="self-end"
                  >
                    {isLoading ? <Loader2 className="h-4 w-4 animate-spin" /> : <Send className="h-4 w-4" />}
                  </Button>
                </div>
                <p className="text-xs text-muted-foreground mt-2">
                  Press Enter to send, Shift+Enter for new line
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </>
  );
}



================================================
FILE: src/app/ai-text-to-speech/page.tsx
================================================
'use client';
"use client";

import { useState } from "react";
import { Button } from "@/components/ui/button";
import { Textarea } from "@/components/ui/textarea";
import { Input } from "@/components/ui/input";
import { Label } from "@/components/ui/label";
import { useToast } from "@/hooks/use-toast";

import {
  Select,
  SelectContent,
  SelectItem,
  SelectTrigger,
  SelectValue,
} from "@/components/ui/select";
import { TextToSpeechError } from "@/types/ai-text-to-speech"; // Assume this type exists
import { Progress } from "@/components/ui/progress";
import { Skeleton } from "@/components/ui/skeleton";

declare const puter: any; // Assuming puter.js is available globally

const AITextToSpeechPage = () => {
  const [textInput, setTextInput] = useState<string>("");
  const [fileInput, setFileInput] = useState<File | null>(null);
  const [audioOutput, setAudioOutput] = useState<string | null>(null);
  const [isLoading, setIsLoading] = useState<boolean>(false);
  const [error, setError] = useState<string | null>(null);
  const [selectedLanguage, setSelectedLanguage] = useState<string>('Text-to-Speech Reader');
  const { toast } = useToast();

  const handleTextChange = (event: React.ChangeEvent<HTMLTextAreaElement>) => {
    setTextInput(event.target.value);
    setFileInput(null); // Clear file input if text is entered
    setError(null);
  };

  const handleFileChange = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      setFileInput(file);
      setError(null);
      try {
        const textContent = await file.text();
        setTextInput(textContent); // Set textInput with file content
      } catch (readError) {
        toast({ variant: "destructive", title: "File Read Error", description: "Could not read the text file." });
      }
    } else {
      setFileInput(null);
    }
  };

  const convertTextToSpeech = async () => {
    if (!textInput && !fileInput) {
      setError("Please enter text or upload a file.");
      return;
    }

    setAudioOutput(null);
    setError(null);

    let inputText: string = "";

    if (fileInput) {
      const reader = new FileReader();
      reader.onload = async (e) => {
        inputText = e.target?.result as string;
        await processConversion(inputText);
      };
      reader.onerror = () => {
        setError("Error reading file.");
        setIsLoading(false);
      };
      reader.readAsText(fileInput);
    } else {
      inputText = textInput;
      await processConversion(inputText);
    }
  };

  const processConversion = async (text: string) => {
    if (text.length > 3000) {
      setError("Text is too long. Please limit to 3000 characters.");
      // Do not set isLoading to false here, it's handled in convertTextToSpeech finally or browser API handlers
      setIsLoading(false);
      return;
    }

    setIsLoading(true);
    setError(null);
    setAudioOutput(null); // Clear any previous audio output

    // --- Browser TTS Option ---
    if (selectedLanguage === 'Text-to-Speech Reader') {
      if ('speechSynthesis' in window) {
        console.log("Using browser speech synthesis as requested.");
        try {
          const utterance = new SpeechSynthesisUtterance(text);
          // For browser TTS, we can potentially let the browser
          // decide the voice based on the text content, or we could
          // add a separate dropdown for browser voices if needed.
          // We will not explicitly set utterance.lang here
          // to allow the browser to use its default or inferred language.
           utterance.lang = selectedLanguage !== 'Text-to-Speech Reader' ? selectedLanguage : ''; // Set language if not Text-to-Speech Reader

          utterance.onstart = () => {
            setIsLoading(true);
            setError(null);
            setAudioOutput(null);
          };

          utterance.onend = () => {
            setIsLoading(false);
          };

          utterance.onerror = (event) => {
            console.error('Browser speech synthesis error:', event);
            setError(`Browser speech synthesis failed: ${event.error}.`);
            setIsLoading(false);
          };

          speechSynthesis.speak(utterance);

        } catch (browserSpeechError: any) {
          console.error("Browser speech synthesis error:", browserSpeechError);
          setError(`Browser text-to-speech failed: ${browserSpeechError.message}`);
          setIsLoading(false);
        }
      } else {
        setError("Browser speech synthesis is not supported in your browser.");
        setIsLoading(false);
      }
      return; // Exit the function after attempting browser TTS
    }

    // --- Puter AI Service (for other languages) ---
    try {
      if (typeof window.puter === 'undefined' || !window.puter.auth || !window.puter.ai) {
        throw new Error("Puter SDK not available. Please refresh.");
      }
      const puter = window.puter;

      let isSignedIn = await puter.auth.isSignedIn();
      if (!isSignedIn) {
        await puter.auth.signIn();
        isSignedIn = await puter.auth.isSignedIn();
        if (!isSignedIn) throw new Error("Authentication failed or was cancelled.");
      }

      // Attempt to use the Puter AI service
      let apiCall;
      apiCall = puter.ai.txt2speech(text, selectedLanguage);

      const audio = await apiCall; // Use await to handle the Promise

      if (audio && typeof audio === 'object' && audio.src) {
        setAudioOutput(audio.src);
        setError(null);
      } else {
        console.error('Unexpected resolved value from puter.ai.txt2speech:', audio);
        throw new Error('Unexpected audio object format from text-to-speech service.');
      }
      setIsLoading(false); // Set loading to false on successful Puter conversion

    } catch (puterError: any) {
      console.error("Puter text-to-speech conversion error:", puterError);

      
        let displayErrorMessage = "Puter text-to-speech failed.";
         if (puterError && typeof puterError === 'object' && puterError.success === false && puterError.error && typeof puterError.error.message === 'string') {
          displayErrorMessage = puterError.error.message;
        } else if (puterError instanceof Error) {
          displayErrorMessage = puterError.message;
        }
        setError(`${displayErrorMessage} Browser speech synthesis fallback also failed: ${browserSpeechError.message}`);
        toast({ title: "Error", description: `Conversion failed: ${displayErrorMessage}`, variant: "destructive" });
        setIsLoading(false);
   } finally {
       // The isLoading state is managed within the try/catch blocks now
       // and the browser API event handlers.
       // No need for a finally block to set isLoading to false.
   }
 };
  return (
    <div className="container mx-auto p-4">
      <h1 className="text-2xl font-bold mb-4">AI Text to Speech Generator</h1>

      <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
        <div>
          <Label htmlFor="text-input">Enter Text</Label>
          <Textarea
            id="text-input"
            placeholder="Enter text here..."
            value={textInput}
            onChange={handleTextChange}
            rows={10}
            disabled={isLoading}
          />
        </div>
        <div className="flex flex-col items-center justify-center border-2 border-dashed rounded-md p-6">
          <Label htmlFor="file-upload" className="cursor-pointer">
            Upload Text File
          </Label>
          <Input
            id="file-upload"
            type="file"
            accept=".txt"
            onChange={handleFileChange}
            className="sr-only"
            disabled={isLoading}
          />
          {fileInput ? (
            <p className="mt-2 text-sm text-muted-foreground">
              File selected: {fileInput.name}
            </p>
          ) : (
            <p className="mt-2 text-sm text-muted-foreground">
              or drag and drop a .txt file here.
            </p>
          )}
        </div>
      </div>

      <div className="mt-4">
        <Label htmlFor="language-select">Select Voice</Label>
        <Select value={selectedLanguage} onValueChange={setSelectedLanguage} disabled={isLoading}>
          <SelectTrigger id="language-select">
            <SelectValue placeholder="Select a language" />
          </SelectTrigger>
          <SelectContent>
            <SelectItem value="cmn-CN">Chinese (Mandarin) (cmn-CN)</SelectItem>
            <SelectItem value="da-DK">Danish (da-DK)</SelectItem>
            <SelectItem value="nl-NL">Dutch (nl-NL)</SelectItem>
            <SelectItem value="en-AU">English (Australian) (en-AU)</SelectItem>
            <SelectItem value="en-GB">English (British) (en-GB)</SelectItem>
            <SelectItem value="en-IN">English (Indian) (en-IN)</SelectItem>
            <SelectItem value="en-GB-WLS">English (Welsh) (en-GB-WLS)</SelectItem>
            <SelectItem value="fi-FI">Finnish (fi-FI)</SelectItem>
            <SelectItem value="fr-FR">French (fr-FR)</SelectItem>
            <SelectItem value="fr-CA">French (Canadian) (fr-CA)</SelectItem>
            <SelectItem value="de-DE">German (de-DE)</SelectItem>
            <SelectItem value="de-AT">German (Austrian) (de-AT)</SelectItem>
            <SelectItem value="hi-IN">Hindi (hi-IN)</SelectItem>
            <SelectItem value="is-IS">Icelandic (is-IS)</SelectItem>
            <SelectItem value="it-IT">Italian (it-IT)</SelectItem>
            <SelectItem value="pl-PL">Polish (pl-PL)</SelectItem>
            <SelectItem value="pt-BR">Portuguese (Brazilian) (pt-BR)</SelectItem>
            <SelectItem value="pt-PT">Portuguese (European) (pt-PT)</SelectItem>
            <SelectItem value="ro-RO">Romanian (ro-RO)</SelectItem>
            <SelectItem value="ru-RU">Russian (ru-RU)</SelectItem>
            <SelectItem value="es-ES">Spanish (European) (es-ES)</SelectItem>
            <SelectItem value="es-MX">Spanish (Mexican) (es-MX)</SelectItem>
            <SelectItem value="es-US">Spanish (US) (es-US)</SelectItem>
            <SelectItem value="cy-GB">Welsh (cy-GB)</SelectItem>
            <SelectItem value="Text-to-Speech Reader">Text-to-Speech Reader</SelectItem>
          </SelectContent>
        </Select>
      </div>

      <div className="mt-6">
        <Button
          onClick={convertTextToSpeech}
          disabled={isLoading || (!textInput && !fileInput)}
        >
          {isLoading ? "Converting..." : "Convert to Speech"}
        </Button>
      </div>

      {isLoading && (
        <div className="mt-4">
          <Progress value={50} /> {/* Replace with actual progress if available */}
          <Skeleton className="h-8 w-full mt-2" />
        </div>
      )}

      {error && (
        <div className="mt-4 text-red-500">
          <p>Error: {error}</p>
        </div>
      )}

      {audioOutput && (
        <div className="mt-6">
          <h2 className="text-xl font-semibold mb-2">Generated Speech</h2>
          <audio controls src={audioOutput} className="w-full">
            Your browser does not support the audio element.
          </audio>
          <a href={audioOutput} download="speech.mp3" className="mt-2 inline-block">
            <Button variant="outline">Download Audio</Button>
          </a>
        </div>
      )}
    </div>
  );
};

export default AITextToSpeechPage;


================================================
FILE: src/app/ai-translator/page.tsx
================================================
'use client';

import Head from 'next/head';
import { useState, useEffect } from 'react';
import { useToast } from "@/hooks/use-toast";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from "@/components/ui/card";
import { Textarea } from "@/components/ui/textarea";
import { Input } from "@/components/ui/input";
import { Label } from "@/components/ui/label";
import { Alert, AlertDescription, AlertTitle } from "@/components/ui/alert";
import { Tabs, TabsContent, TabsList, TabsTrigger } from "@/components/ui/tabs";
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from "@/components/ui/select";
import { Loader2, ImageUp, Type, Languages, AlertTriangle, Info, Copy, Download, ArrowRight } from 'lucide-react';
import { preprocessImage } from '@/lib/image-utils';
import { getLaymanErrorMessage } from '@/lib/error-utils';
import { downloadTextFile } from '@/lib/utils';
import ImagePreview from '@/components/medi-scan/image-preview';
import type { TranslationReport } from '@/types/ai-translator';

const cleanJsonString = (rawString: string): string => {
  let cleanedString = rawString.trim();
  if (cleanedString.startsWith("```json") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(7, cleanedString.length - 3).trim();
  } else if (cleanedString.startsWith("```") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(3, cleanedString.length - 3).trim();
  }
  return cleanedString;
};

const LANGUAGES = [
  { code: 'auto', name: 'Auto-detect' },
  { code: 'en', name: 'English' },
  { code: 'es', name: 'Spanish' },
  { code: 'fr', name: 'French' },
  { code: 'de', name: 'German' },
  { code: 'it', name: 'Italian' },
  { code: 'pt', name: 'Portuguese' },
  { code: 'ru', name: 'Russian' },
  { code: 'ja', name: 'Japanese' },
  { code: 'ko', name: 'Korean' },
  { code: 'zh', name: 'Chinese (Simplified)' },
  { code: 'zh-tw', name: 'Chinese (Traditional)' },
  { code: 'ar', name: 'Arabic' },
  { code: 'hi', name: 'Hindi' },
  { code: 'th', name: 'Thai' },
  { code: 'vi', name: 'Vietnamese' },
  { code: 'tr', name: 'Turkish' },
  { code: 'pl', name: 'Polish' },
  { code: 'nl', name: 'Dutch' },
  { code: 'sv', name: 'Swedish' },
  { code: 'da', name: 'Danish' },
  { code: 'no', name: 'Norwegian' },
  { code: 'fi', name: 'Finnish' },
  { code: 'he', name: 'Hebrew' },
  { code: 'cs', name: 'Czech' },
  { code: 'hu', name: 'Hungarian' },
  { code: 'ro', name: 'Romanian' },
  { code: 'bg', name: 'Bulgarian' },
  { code: 'hr', name: 'Croatian' },
  { code: 'sk', name: 'Slovak' },
  { code: 'sl', name: 'Slovenian' },
  { code: 'et', name: 'Estonian' },
  { code: 'lv', name: 'Latvian' },
  { code: 'lt', name: 'Lithuanian' },
  { code: 'uk', name: 'Ukrainian' },
  { code: 'be', name: 'Belarusian' },
  { code: 'mk', name: 'Macedonian' },
  { code: 'sq', name: 'Albanian' },
  { code: 'sr', name: 'Serbian' },
  { code: 'bs', name: 'Bosnian' },
  { code: 'mt', name: 'Maltese' },
  { code: 'is', name: 'Icelandic' },
  { code: 'ga', name: 'Irish' },
  { code: 'cy', name: 'Welsh' },
  { code: 'eu', name: 'Basque' },
  { code: 'ca', name: 'Catalan' },
  { code: 'gl', name: 'Galician' },
  { code: 'fa', name: 'Persian' },
  { code: 'ur', name: 'Urdu' },
  { code: 'bn', name: 'Bengali' },
  { code: 'ta', name: 'Tamil' },
  { code: 'te', name: 'Telugu' },
  { code: 'ml', name: 'Malayalam' },
  { code: 'kn', name: 'Kannada' },
  { code: 'gu', name: 'Gujarati' },
  { code: 'pa', name: 'Punjabi' },
  { code: 'mr', name: 'Marathi' },
  { code: 'ne', name: 'Nepali' },
  { code: 'si', name: 'Sinhala' },
  { code: 'my', name: 'Myanmar' },
  { code: 'km', name: 'Khmer' },
  { code: 'lo', name: 'Lao' },
  { code: 'ka', name: 'Georgian' },
  { code: 'am', name: 'Amharic' },
  { code: 'sw', name: 'Swahili' },
  { code: 'zu', name: 'Zulu' },
  { code: 'af', name: 'Afrikaans' },
  { code: 'xh', name: 'Xhosa' },
  { code: 'yo', name: 'Yoruba' },
  { code: 'ig', name: 'Igbo' },
  { code: 'ha', name: 'Hausa' },
];

export default function AITranslatorPage() {
  const [inputType, setInputType] = useState<'image' | 'text'>('text');
  const [imageFile, setImageFile] = useState<File | null>(null);
  const [imageDataUrl, setImageDataUrl] = useState<string | null>(null);
  const [textInput, setTextInput] = useState<string>('');
  const [sourceLanguage, setSourceLanguage] = useState<string>('auto');
  const [targetLanguage, setTargetLanguage] = useState<string>('en');
  
  const [translationReport, setTranslationReport] = useState<TranslationReport | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const { toast } = useToast();

  useEffect(() => {
    if (typeof window.puter === 'undefined') {
      toast({
        variant: "destructive",
        title: "Puter SDK Error",
        description: "Puter.js SDK is not loaded. Please refresh the page.",
      });
    }
  }, [toast]);

  const handleImageFileChange = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      setImageFile(file);
      try {
        const previewDataUrl = URL.createObjectURL(file);
        setImageDataUrl(previewDataUrl);
        setTranslationReport(null);
        setError(null);
      } catch (error) {
        toast({ variant: "destructive", title: "Preview Error", description: "Could not generate image preview." });
        setImageDataUrl(null);
      }
    } else {
      setImageFile(null);
      setImageDataUrl(null);
    }
  };

  const handleTextInputChange = (event: React.ChangeEvent<HTMLTextAreaElement>) => {
    setTextInput(event.target.value);
    setTranslationReport(null);
    setError(null);
  };

  const performTranslation = async () => {
    if (inputType === 'image' && !imageFile) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please upload an image containing text to translate." });
      return;
    }
    if (inputType === 'text' && !textInput.trim()) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please enter text to translate." });
      return;
    }
    if (!targetLanguage || targetLanguage === 'auto') {
      toast({ variant: "destructive", title: "Missing Target Language", description: "Please select a target language for translation." });
      return;
    }

    setIsLoading(true);
    setTranslationReport(null);
    setError(null);
    toast({ title: "Translation Started", description: "AI is processing your translation request..." });

    try {
      if (typeof window.puter === 'undefined' || !window.puter.auth || !window.puter.ai) {
        throw new Error("Puter SDK not available. Please refresh.");
      }
      const puter = window.puter;

      let isSignedIn = await puter.auth.isSignedIn();
      if (!isSignedIn) {
        await puter.auth.signIn();
        isSignedIn = await puter.auth.isSignedIn();
        if (!isSignedIn) throw new Error("Authentication failed or was cancelled.");
      }

      let prompt: string;
      let aiInput: string | undefined = undefined;

      const sourceLanguageName = LANGUAGES.find(lang => lang.code === sourceLanguage)?.name || 'Auto-detect';
      const targetLanguageName = LANGUAGES.find(lang => lang.code === targetLanguage)?.name || 'English';

      if (inputType === 'image' && imageFile) {
        aiInput = await preprocessImage(imageFile, 1024);
        prompt = `
          You are an AI assistant specialized in text extraction and translation.
          
          First, extract all visible text from this image accurately.
          Then, translate the extracted text from ${sourceLanguageName} to ${targetLanguageName}.
          
          Provide your analysis in a JSON object with these keys:
          - "original_text": (string) All text extracted from the image
          - "translated_text": (string) The translation of the extracted text
          - "source_language_detected": (string) The detected language of the original text
          - "target_language": (string) The target language name
          - "translation_confidence": (string, one of "High", "Medium", "Low") Your confidence in the translation accuracy
          - "context_notes": (array of strings) Any important context or cultural notes about the translation
          - "alternative_translations": (array of strings) Alternative ways to translate key phrases (max 3)
          - "image_description": (string) Brief description of the image content
          - "text_extraction_quality": (string, one of "High", "Medium", "Low") Quality of text extraction from the image
          - "disclaimer": (string) Standard disclaimer about AI translation limitations
        `;
      } else if (inputType === 'text' && textInput.trim()) {
        prompt = `
          You are an AI assistant specialized in translation.
          
          Translate the following text from ${sourceLanguageName} to ${targetLanguageName}:
          "${textInput}"
          
          Provide your analysis in a JSON object with these keys:
          - "original_text": (string) The original text provided
          - "translated_text": (string) The translation of the text
          - "source_language_detected": (string) The detected language of the original text
          - "target_language": (string) The target language name
          - "translation_confidence": (string, one of "High", "Medium", "Low") Your confidence in the translation accuracy
          - "context_notes": (array of strings) Any important context or cultural notes about the translation
          - "alternative_translations": (array of strings) Alternative ways to translate key phrases (max 3)
          - "disclaimer": (string) Standard disclaimer about AI translation limitations
        `;
      } else {
        throw new Error("No valid input provided for translation.");
      }

      const response = inputType === 'image' 
        ? await puter.ai.chat(prompt, aiInput) 
        : await puter.ai.chat(prompt, { model: 'gpt-4o' });

      if (!response?.message?.content) {
        throw new Error("AI translation did not return content.");
      }

      const parsedResponse: TranslationReport = JSON.parse(cleanJsonString(response.message.content));
      setTranslationReport(parsedResponse);
      toast({ title: "Translation Complete", variant: "default", className: "bg-green-500 text-white dark:bg-green-600" });

    } catch (err: any) {
      console.error("Translation error:", err);
      const friendlyErrorMessage = getLaymanErrorMessage(err);
      setError(friendlyErrorMessage);
      toast({ variant: "destructive", title: "Translation Failed", description: friendlyErrorMessage });
    } finally {
      setIsLoading(false);
    }
  };

  const handleCopyTranslation = () => {
    if (!translationReport?.translated_text) return;
    
    navigator.clipboard.writeText(translationReport.translated_text).then(() => {
      toast({ title: "Translation Copied", description: "Translated text has been copied to clipboard." });
    }).catch(() => {
      toast({ variant: "destructive", title: "Copy Failed", description: "Could not copy translation to clipboard." });
    });
  };

  const handleDownloadReport = () => {
    if (!translationReport) return;

    let reportString = "KLUTZ AI Translator Report\n";
    reportString += "==========================\n\n";

    reportString += "Translation Details:\n";
    reportString += "-------------------\n";
    reportString += `Input Type: ${inputType === 'image' ? 'Image' : 'Text'}\n`;
    reportString += `Source Language: ${translationReport.source_language_detected || 'Not detected'}\n`;
    reportString += `Target Language: ${translationReport.target_language}\n`;
    reportString += `Translation Confidence: ${translationReport.translation_confidence}\n\n`;

    if (translationReport.image_description) {
      reportString += "Image Description:\n";
      reportString += "------------------\n";
      reportString += `${translationReport.image_description}\n\n`;
    }

    if (translationReport.text_extraction_quality) {
      reportString += `Text Extraction Quality: ${translationReport.text_extraction_quality}\n\n`;
    }

    reportString += "Original Text:\n";
    reportString += "--------------\n";
    reportString += `${translationReport.original_text}\n\n`;

    reportString += "Translated Text:\n";
    reportString += "----------------\n";
    reportString += `${translationReport.translated_text}\n\n`;

    if (translationReport.context_notes && translationReport.context_notes.length > 0) {
      reportString += "Context Notes:\n";
      reportString += "--------------\n";
      translationReport.context_notes.forEach(note => {
        reportString += `- ${note}\n`;
      });
      reportString += "\n";
    }

    if (translationReport.alternative_translations && translationReport.alternative_translations.length > 0) {
      reportString += "Alternative Translations:\n";
      reportString += "------------------------\n";
      translationReport.alternative_translations.forEach(alt => {
        reportString += `- ${alt}\n`;
      });
      reportString += "\n";
    }

    reportString += "Disclaimer:\n";
    reportString += "-----------\n";
    reportString += translationReport.disclaimer + "\n\n";
    
    reportString += "\nIMPORTANT: This translation is AI-generated and for informational purposes only. For critical translations, always consult with professional translators.";

    const timestamp = new Date().toISOString().replace(/[:.-]/g, '').slice(0, 14);
    downloadTextFile(reportString, `KLUTZ_AITranslator_Report_${timestamp}.txt`);
  };

  const swapLanguages = () => {
    if (sourceLanguage === 'auto') return;
    const temp = sourceLanguage;
    setSourceLanguage(targetLanguage);
    setTargetLanguage(temp);
    setTranslationReport(null);
  };

  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/ai-translator" />
      </Head>
    <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-8">
      <Card className="max-w-3xl mx-auto shadow-xl">
        <CardHeader>
          <CardTitle className="font-headline text-3xl text-primary flex items-center">
            <Languages className="mr-3 h-8 w-8" />
            AI Translator
          </CardTitle>
          <CardDescription>
            Translate text from images or typed input using AI-powered translation with support for 60+ languages.
          </CardDescription>
        </CardHeader>
        <CardContent className="space-y-6">
          <Alert variant="default" className="bg-blue-50 border-blue-400 text-blue-700 dark:bg-blue-900/30 dark:text-blue-300">
            <Info className="h-5 w-5 text-blue-500" />
            <AlertTitle className="font-semibold">Translation Features</AlertTitle>
            <AlertDescription>
              Upload images containing text or type directly. Supports 60+ languages with context-aware translations and cultural notes.
            </AlertDescription>
          </Alert>

          <Tabs value={inputType} onValueChange={(value) => setInputType(value as 'image' | 'text')} className="w-full">
            <TabsList className="grid w-full grid-cols-2">
              <TabsTrigger value="text">Text Translation</TabsTrigger>
              <TabsTrigger value="image">Image Translation</TabsTrigger>
            </TabsList>
            <TabsContent value="text" className="mt-6">
              <div className="space-y-4">
                <div>
                  <Label htmlFor="text-input" className="text-lg font-medium flex items-center mb-2">
                    <Type className="mr-2 h-5 w-5 text-accent" />
                    Text to Translate
                  </Label>
                  <Textarea
                    id="text-input"
                    placeholder="Enter text to translate..."
                    value={textInput}
                    onChange={handleTextInputChange}
                    rows={6}
                    disabled={isLoading}
                  />
                </div>
              </div>
            </TabsContent>
            <TabsContent value="image" className="mt-6">
              <div className="space-y-4">
                <div>
                  <Label htmlFor="image-upload" className="text-lg font-medium flex items-center mb-2">
                    <ImageUp className="mr-2 h-5 w-5 text-accent" />
                    Upload Image with Text
                  </Label>
                  <Input
                    id="image-upload"
                    type="file"
                    accept="image/png, image/jpeg, image/webp"
                    onChange={handleImageFileChange}
                    className="file:text-primary file:font-semibold file:bg-primary/10 hover:file:bg-primary/20"
                    disabled={isLoading}
                  />
                  <p className="text-sm text-muted-foreground mt-1">Upload an image containing text to translate.</p>
                </div>
                {imageDataUrl && <ImagePreview imageDataUrl={imageDataUrl} dataAiHint="image with text to translate"/>}
              </div>
            </TabsContent>
          </Tabs>

          <div className="grid grid-cols-1 md:grid-cols-3 gap-4 items-end">
            <div>
              <Label htmlFor="source-language" className="text-lg font-medium">From</Label>
              <Select value={sourceLanguage} onValueChange={setSourceLanguage}>
                <SelectTrigger id="source-language" className="w-full">
                  <SelectValue placeholder="Source language" />
                </SelectTrigger>
                <SelectContent className="max-h-60">
                  {LANGUAGES.map((lang) => (
                    <SelectItem key={lang.code} value={lang.code}>
                      {lang.name}
                    </SelectItem>
                  ))}
                </SelectContent>
              </Select>
            </div>

            <div className="flex justify-center">
              <Button
                variant="outline"
                size="icon"
                onClick={swapLanguages}
                disabled={sourceLanguage === 'auto' || isLoading}
                className="h-10 w-10"
              >
                <ArrowRight className="h-4 w-4" />
              </Button>
            </div>

            <div>
              <Label htmlFor="target-language" className="text-lg font-medium">To</Label>
              <Select value={targetLanguage} onValueChange={setTargetLanguage}>
                <SelectTrigger id="target-language" className="w-full">
                  <SelectValue placeholder="Target language" />
                </SelectTrigger>
                <SelectContent className="max-h-60">
                  {LANGUAGES.filter(lang => lang.code !== 'auto').map((lang) => (
                    <SelectItem key={lang.code} value={lang.code}>
                      {lang.name}
                    </SelectItem>
                  ))}
                </SelectContent>
              </Select>
            </div>
          </div>

          <Button 
            onClick={performTranslation} 
            disabled={isLoading || (inputType === 'image' && !imageFile) || (inputType === 'text' && !textInput.trim()) || !targetLanguage || targetLanguage === 'auto'} 
            className="w-full"
          >
            {isLoading ? (
              <>
                <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                Translating...
              </>
            ) : (
              <>
                <Languages className="mr-2 h-4 w-4" />
                Translate Text
              </>
            )}
          </Button>

          {error && !isLoading && (
            <Alert variant="destructive" className="mt-6">
              <AlertTriangle className="h-5 w-5" />
              <AlertTitle>Translation Error</AlertTitle>
              <AlertDescription>{error}</AlertDescription>
            </Alert>
          )}

          {translationReport && !isLoading && !error && (
            <Card className="mt-6 shadow-md">
              <CardHeader>
                <CardTitle className="font-headline text-xl flex items-center">
                  <Languages className="mr-2 h-6 w-6 text-primary" />
                  Translation Results
                </CardTitle>
              </CardHeader>
              <CardContent className="space-y-4">
                {translationReport.image_description && (
                  <div>
                    <h4 className="font-semibold text-md mb-1">Image Description:</h4>
                    <p className="bg-muted/30 p-3 rounded-md">{translationReport.image_description}</p>
                  </div>
                )}

                <div className="grid grid-cols-1 md:grid-cols-3 gap-4">
                  <div className="bg-blue-50 dark:bg-blue-900/20 p-3 rounded-md text-center">
                    <p className="text-sm text-muted-foreground">Source Language</p>
                    <p className="text-lg font-bold text-blue-600 dark:text-blue-400">{translationReport.source_language_detected || 'Unknown'}</p>
                  </div>
                  <div className="bg-green-50 dark:bg-green-900/20 p-3 rounded-md text-center">
                    <p className="text-sm text-muted-foreground">Target Language</p>
                    <p className="text-lg font-bold text-green-600 dark:text-green-400">{translationReport.target_language}</p>
                  </div>
                  <div className="bg-purple-50 dark:bg-purple-900/20 p-3 rounded-md text-center">
                    <p className="text-sm text-muted-foreground">Confidence</p>
                    <p className="text-lg font-bold text-purple-600 dark:text-purple-400">{translationReport.translation_confidence}</p>
                  </div>
                </div>

                <div>
                  <h4 className="font-semibold text-md mb-1">Original Text:</h4>
                  <div className="bg-muted/30 p-4 rounded-md">
                    <p className="text-sm">{translationReport.original_text}</p>
                  </div>
                </div>

                <div>
                  <div className="flex items-center justify-between mb-2">
                    <h4 className="font-semibold text-md">Translation:</h4>
                    <Button onClick={handleCopyTranslation} variant="outline" size="sm">
                      <Copy className="mr-1 h-3 w-3" />
                      Copy
                    </Button>
                  </div>
                  <div className="bg-green-50 dark:bg-green-900/20 p-4 rounded-md border-l-4 border-green-500">
                    <p className="text-sm font-medium">{translationReport.translated_text}</p>
                  </div>
                </div>

                {translationReport.context_notes && translationReport.context_notes.length > 0 && (
                  <div>
                    <h4 className="font-semibold text-md mb-1">Context Notes:</h4>
                    <ul className="list-disc pl-5 space-y-1 bg-yellow-50 dark:bg-yellow-900/20 p-3 rounded-md">
                      {translationReport.context_notes.map((note, index) => (
                        <li key={index} className="text-yellow-700 dark:text-yellow-300">{note}</li>
                      ))}
                    </ul>
                  </div>
                )}

                {translationReport.alternative_translations && translationReport.alternative_translations.length > 0 && (
                  <div>
                    <h4 className="font-semibold text-md mb-1">Alternative Translations:</h4>
                    <ul className="list-disc pl-5 space-y-1 bg-blue-50 dark:bg-blue-900/20 p-3 rounded-md">
                      {translationReport.alternative_translations.map((alt, index) => (
                        <li key={index} className="text-blue-700 dark:text-blue-300">{alt}</li>
                      ))}
                    </ul>
                  </div>
                )}

                {translationReport.text_extraction_quality && (
                  <div>
                    <h4 className="font-semibold text-md mb-1">Text Extraction Quality:</h4>
                    <p className="bg-muted/30 p-3 rounded-md">{translationReport.text_extraction_quality}</p>
                  </div>
                )}

                <Alert variant="default" className="text-xs bg-blue-50 border-blue-300 dark:bg-blue-900/30 dark:text-blue-300">
                  <Info className="h-4 w-4 text-blue-500" />
                  <AlertTitle className="font-medium">Disclaimer</AlertTitle>
                  <AlertDescription>{translationReport.disclaimer}</AlertDescription>
                </Alert>

                <Button onClick={handleDownloadReport} variant="outline" className="w-full mt-4">
                  <Download className="mr-2 h-4 w-4" />
                  Download Translation Report
                </Button>
              </CardContent>
            </Card>
          )}

          {!translationReport && !isLoading && !error && (
            <div className="mt-6 p-4 border border-dashed rounded-md text-center text-muted-foreground">
              <Info className="mx-auto h-8 w-8 mb-2"/>
              <p>Select input method, choose languages, and provide text to get AI-powered translation with cultural context.</p>
            </div>
          )}
        </CardContent>
        <CardFooter>
          <p className="text-xs text-muted-foreground w-full text-center">
            This tool uses AI for translation. For critical translations, always consult with professional translators.
          </p>
        </CardFooter>
      </Card>

      {/* Blog Section */}
 <div className="max-w-3xl mx-auto mt-12 prose dark:prose-invert">
        <h1 className="font-headline text-4xl text-primary mb-6">The Ultimate Guide to AI Translators: Breaking Down Language Barriers with Free Online Translation Tools in 2025</h1>
        <p>In our increasingly connected world, language barriers can limit opportunities for business, education, and personal growth. Fortunately, AI translators have revolutionized how we communicate across languages, making instant, accurate translation more accessible than ever before. Professional AI translation tools now offer services that rival human translation while providing real-time solutions for students, researchers, and writers worldwide. But with so many AI translator free options available, how do you choose the right online translator for your translation needs?</p>

        <h2 className="font-headline text-2xl text-primary mt-8 mb-4">What is an AI Translator?</h2>
        <p>An AI translator is sophisticated translation software that uses artificial intelligence, specifically neural machine translation and large language models, to automatically translate text from one source language to another target language. Unlike traditional rule-based translation systems, modern AI translation tools learn from billions of published works to understand context, cultural nuances, and language patterns while retaining meaning and natural flow.</p>
        <p>AI-powered online translators go beyond simple word-for-word substitution. These AI tools analyze sentence structure, consider cultural context, and preserve tone and style in their translations. The latest high-quality machine translation technology makes these translator tools invaluable for everything from casual conversations to professional documents, academic papers, and research manuscripts. Whether you need to translate English to Chinese, Japanese to Korean, or any other language pairs, AI translation software provides reliable document translation with context-aware accuracy.</p>

        <h2 className="font-headline text-2xl text-primary mt-8 mb-4">Key Features to Look for in the Best AI Translation Tool</h2>
        <p>When searching for the perfect AI translator online, consider these essential features that distinguish top translation software:</p>
        <ul className="list-disc pl-5 space-y-2">
          <li><strong>Language Support:</strong> The best AI translator free tools support wide language pairs, including popular combinations like English Chinese simplified, Spanish to English, and Japanese Korean translations</li>
          <li><strong>Accuracy and Context Awareness:</strong> Premium AI translation services understand context meaning while retaining natural flow and cultural appropriateness</li>
          <li><strong>File Format Compatibility:</strong> Professional translation tools support various document types including PDF, DOCX, images, and audio files for comprehensive translation services</li>
          <li><strong>Speed and Efficiency:</strong> Fast processing technology for both short text and lengthy documents, enabling real-time translation</li>
          <li><strong>Additional AI Tools:</strong> Integration with grammar checking, plagiarism checker search capabilities, AI proofreader features, and writing assistance</li>
          <li><strong>Pricing Structure:</strong> Clear, affordable pricing with generous free translator options for different usage levels</li>
          <li><strong>User Interface:</strong> Intuitive design that makes online translation simple and accessible for all users</li>
        </ul>

        <h2 className="font-headline text-2xl text-primary mt-8 mb-4">Best FREE AI Translators: A Comprehensive Comparison</h2>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">1. Klutz AI Translator - Outstanding Free Online Translation Tool</h3>
        <p>Klutz stands out as an exceptionally user-friendly AI translator that excels in both simplicity and functionality. What makes this AI translation tool particularly impressive is its dual capability - it handles both typed text translation and innovative image translation seamlessly, making it a versatile choice for students, researchers, and professional writers.</p>
        <p><strong>Pricing:</strong> Completely free translator with no hidden costs</p>
        <p><strong>Pros:</strong></p>
        <ul className="list-disc pl-5 space-y-1">
          <li>Supports 60+ languages with excellent accuracy, including English Chinese, Japanese Korean, and other major language pairs</li>
          <li>Unique image translation feature for translating text from photos and documents</li>
          <li>Context-aware AI translation with cultural notes that help retain meaning</li>
          <li>Clean, distraction-free interface perfect for academic work and professional translation</li>
          <li>No registration required for basic translation services</li>
          <li>Particularly strong with conversational text and natural language processing</li>
        </ul>
        <p><strong>Cons:</strong></p>
        <ul className="list-disc pl-5 space-y-1">
          <li>Limited advanced features compared to premium AI tools</li>
          <li>No bulk document processing for large-scale translation projects</li>
          <li>Character limits for single translation submissions</li>
        </ul>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">2. Wordvice AI Translator - Professional AI Translation Services</h3>
        <p>Wordvice AI offers professional-grade translation software that's particularly popular among students, researchers, and academic writers. This AI translator emphasizes accuracy and natural-sounding translations while providing additional writing and proofreading services. Wordvice AI stands out for its integration with other AI tools, making it a comprehensive writing assistant.</p>
        <p><strong>Pricing:</strong> Free plan with 500 characters per translation; Premium Wordvice AI plans available for unlimited usage</p>
        <p><strong>Pros:</strong></p>
        <ul className="list-disc pl-5 space-y-1">
          <li>Highly accurate AI translation using advanced large language models for professional results</li>
          <li>No ads or pop-ups in the free online translator version</li>
          <li>Excellent for academic papers, research manuscripts, and professional documents</li>
          <li>Integration with AI proofreader, plagiarism checker, and other Wordvice writing tools</li>
          <li>Mobile-friendly interface supporting various language pairs</li>
          <li>Expert proofreading services available for critical translations</li>
        </ul>
        <p><strong>Cons:</strong></p>
        <ul className="list-disc pl-5 space-y-1">
          <li>Lower character limits on the basic free plan</li>
          <li>Fewer supported languages compared to some AI translator competitors</li>
          <li>Premium features require Wordvice AI subscription for full access</li>
        </ul>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">3. Machine Translation - Comprehensive AI Translation Software</h3>
        <p>Machine Translation positions itself as offering highly accurate AI translation services with unique features like comparing multiple AI translation engines simultaneously. This translation tool provides extensive language support and advanced features for professional users, researchers, and businesses requiring reliable document translation.</p>
        <p><strong>Pricing:</strong> Generous 100,000 free words monthly for registered users; premium plans for higher volume translation needs</p>
        <p><strong>Pros:</strong></p>
        <ul className="list-disc pl-5 space-y-1">
          <li>Supports 270+ languages - the most comprehensive language coverage available</li>
          <li>Compares results from multiple AI tools and translation engines for optimal accuracy</li>
          <li>Quality scoring and ranking system to help choose the best translation</li>
          <li>Handles various file formats including PDF, DOCX, and image translation</li>
          <li>Generous free tier with 100,000 words monthly for extensive translation work</li>
          <li>Professional translation services with human review options</li>
        </ul>
        <p><strong>Cons:</strong></p>
        <ul className="list-disc pl-5 space-y-1">
          <li>Interface can be overwhelming for casual users seeking simple AI translator functionality</li>
          <li>Registration required to access full free translation features</li>
          <li>Some advanced AI tools locked behind premium subscription tiers</li>
        </ul>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">4. OpenL Translate - Versatile AI Translation Platform</h3>
        <p>OpenL offers a versatile AI translation platform with support for multiple content types and a focus on professional-grade accuracy. This AI translator provides comprehensive translation services including text, documents, images, and speech translation, making it suitable for diverse translation needs.</p>
        <p><strong>Pricing:</strong> Free tier with 40 translation credits daily; Premium plans starting from $4.99/month</p>
        <p><strong>Pros:</strong></p>
        <ul className="list-disc pl-5 space-y-1">
          <li>Supports text, document, image, and speech translation with AI-powered accuracy</li>
          <li>100+ language support including major pairs like English Chinese simplified and Japanese Korean</li>
          <li>Advanced and Fast translation modes for different quality requirements</li>
          <li>Handles large files up to 100MB on premium plans for extensive document translation</li>
          <li>Educational discounts available for students and academic researchers</li>
          <li>AI text summarizer and other writing tools integrated</li>
        </ul>
        <p><strong>Cons:</strong></p>
        <ul className="list-disc pl-5 space-y-1">
          <li>Credit-based system can be limiting for heavy translation usage</li>
          <li>Advanced AI translation features require premium subscription</li>
          <li>Free tier has daily usage limits that may restrict professional work</li>
        </ul>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">5. QuillBot Translate - Integrated AI Writing and Translation Suite</h3>
        <p>QuillBot's AI translator is part of a comprehensive writing assistant suite, making it excellent for users who need translation alongside other AI tools like AI paraphrasing tool, AI proofreader, and plagiarism checker. This integrated approach provides seamless workflow for academic work, professional writing, and research projects.</p>
        <p><strong>Pricing:</strong> Free plan with 5,000 characters; Premium from $4.17/month for unlimited translation</p>
        <p><strong>Pros:</strong></p>
        <ul className="list-disc pl-5 space-y-1">
          <li>Seamless integration with AI paraphrasing tool, AI proofreader, and plagiarism checker search capabilities</li>
          <li>52 language support with high accuracy for common language pairs</li>
          <li>Additional features like romanization, synonyms, and text variety options</li>
          <li>Mobile-friendly platform perfect for on-the-go translation work</li>
          <li>No ads on free version, providing clean user experience</li>
          <li>AI text summarizer and citation tools for academic researchers</li>
        </ul>
        <p><strong>Cons:</strong></p>
        <ul className="list-disc pl-5 space-y-1">
          <li>Fewer supported languages compared to specialized AI translator competitors</li>
          <li>Character limits on free plan restrict longer document translation</li>
          <li>Premium subscription required for unlimited translation and advanced AI tools</li>
        </ul>

        <h2 className="font-headline text-2xl text-primary mt-8 mb-4">Specialized AI Translation Applications and Use Cases</h2>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">Academic and Research Translation</h3>
        <p>For students and researchers working in the global academic community, AI translation tools have become essential for accessing and publishing research across language barriers. Whether you need to translate research papers, journal manuscripts, thesis documents, or dissertation content, modern AI translators provide professional-quality results. These translation services help researchers understand studies written in foreign languages while enabling them to submit their work to international journals and conferences.</p>
        <p>AI translation software excels at handling academic vocabulary and maintaining the precise terminology required for scientific papers, essays, and research documents. Many researchers use AI translator free options to get initial translations before seeking expert proofreading services for final submissions to ensure accuracy and professional presentation.</p>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">Professional and Business Translation</h3>
        <p>Businesses and professionals increasingly rely on AI translation services for document translation, email communication, reports, and marketing content. Professional AI translators can handle various document types including resumes, cover letters, business correspondence, and technical documentation while retaining context and professional tone.</p>
        <p>The ability to translate content for target audiences in different markets has made AI translation tools invaluable for global business communication. These services help companies localize their content effectively while maintaining brand consistency across multiple languages and cultural contexts.</p>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">Student and Educational Applications</h3>
        <p>Students learning foreign languages or studying abroad benefit enormously from AI translator tools that provide instant translation assistance. These AI tools help bridge language gaps in academic work, research projects, and cross-cultural communication. Many educational institutions now integrate AI translation services into their language learning programs and international exchange initiatives.</p>
        <p>For students working on research projects or essays that require sources in multiple languages, AI translation software provides quick access to global academic resources while helping them understand complex academic texts and terminology.</p>

        <h2 className="font-headline text-2xl text-primary mt-8 mb-4">Advanced AI Translation Features and Technology</h2>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">Neural Machine Translation and Large Language Models</h3>
        <p>Modern AI translators utilize sophisticated neural machine translation technology powered by large language models trained on billions of published works. This AI-powered approach enables these translation tools to understand context, maintain natural flow, and preserve meaning across language barriers far better than traditional rule-based systems.</p>
        <p>The latest AI translation software incorporates advanced natural language processing that considers cultural nuances, idiomatic expressions, and contextual relationships within text. This technology ensures that translations sound natural while retaining the original meaning and tone of the source material.</p>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">Integration with AI Writing Tools</h3>
        <p>The best AI translation platforms now offer integrated suites of AI tools including AI proofreader services, plagiarism checker capabilities, AI paraphrasing tools, and text summarizer functions. This integration allows users to translate content and immediately refine it using additional AI writing assistance, creating a seamless workflow for professional and academic writing projects.</p>
        <p>Many platforms provide AI plagiarism checker search functionality that compares translated text against billions of published sources to ensure originality and proper attribution. These comprehensive AI tools help writers avoid plagiarism in academic work while maintaining high standards of originality and authenticity.</p>

        <h2 className="font-headline text-2xl text-primary mt-8 mb-4">Making the Right Choice for Your Translation Needs</h2>
        <p>The best AI translator depends on your specific translation requirements and usage patterns:</p>
        <ul className="list-disc pl-5 space-y-2">
          <li><strong>For casual users and students:</strong> Klutz offers excellent value with its free, comprehensive translation services and unique image translation feature perfect for daily communication needs</li>
          <li><strong>For academic and professional work:</strong> Wordvice AI or Machine Translation provide the accuracy and specialized features needed for research papers, manuscripts, and professional documents</li>
          <li><strong>For comprehensive writing projects:</strong> QuillBot's integrated AI writing assistant suite makes it ideal for users who need translation plus AI proofreader, plagiarism checker, and paraphrasing tool capabilities</li>
          <li><strong>For multilingual businesses:</strong> OpenL or Machine Translation offer the robust features and extensive language support needed for professional translation services and global communication</li>
          <li><strong>For high-volume translation work:</strong> Consider platforms with generous free tiers or affordable premium plans that provide unlimited characters and advanced AI tools</li>
        </ul>

        <h2 className="font-headline text-2xl text-primary mt-8 mb-4">The Future of AI Translation Services</h2>
        <p>AI translation technology continues to evolve rapidly, with new improvements in accuracy, context understanding, and language support emerging regularly. The integration of AI translation with other writing tools creates comprehensive platforms that support the entire content creation and refinement process.</p>
        <p>As large language models become more sophisticated, we can expect AI translators to achieve even greater accuracy while supporting more specialized domains and technical vocabularies. The combination of AI translation with human expertise through professional proofreading services represents the optimal approach for critical translations requiring perfect accuracy.</p>

        <h2 className="font-headline text-2xl text-primary mt-8 mb-4">TL;DR - Quick Guide to AI Translators</h2>
        <p>AI translators have transformed global communication, with each translation tool offering unique strengths for different users. Klutz excels as a free AI translator with user-friendly design and innovative image translation capabilities. Wordvice AI provides professional-grade accuracy with integrated writing tools and expert proofreading services. Machine Translation offers the most comprehensive language support with advanced comparison features. OpenL focuses on versatility across multiple content types with competitive pricing. QuillBot integrates seamlessly with AI paraphrasing tool, plagiarism checker, and other writing assistance features.</p>
        <p>Choose your AI translation software based on specific needs: casual users should try Klutz for free translation services, academic researchers might prefer Wordvice AI or Machine Translation for professional accuracy, and writers will appreciate QuillBot's integrated AI tools approach. The key is matching the AI translator's strengths to your translation requirements, whether you need basic text translation, professional document translation, or comprehensive writing assistance with AI proofreader and plagiarism checker capabilities.</p>
      </div>
    </div>
  );
    </>
)}


================================================
FILE: src/app/api/fetch-url-content/route.ts
================================================
import { NextResponse } from 'next/server';
import fetch from 'node-fetch';

export async function POST(request: Request) {
  try {
    const { url } = await request.json();

    if (!url || typeof url !== 'string') {
      return NextResponse.json({ error: 'Invalid URL provided' }, { status: 400 });
    }

    // Basic URL validation (can be expanded)
    try {
      new URL(url);
    } catch (e) {
      return NextResponse.json({ error: 'Invalid URL format' }, { status: 400 });
    }

    const response = await fetch(url);

    if (!response.ok) {
      return NextResponse.json({ error: `Failed to fetch URL: ${response.statusText}` }, { status: response.status });
    }

    const content = await response.text();

    return NextResponse.json({ content });

  } catch (error) {
    console.error('Error fetching URL content:', error);
    return NextResponse.json({ error: 'Internal server error' }, { status: 500 });
  }
}


================================================
FILE: src/app/appliance-troubleshooter/page.tsx
================================================
'use client';

import Head from 'next/head';
import { useState, useEffect } from 'react';
import { useToast } from "@/hooks/use-toast";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from "@/components/ui/card";
import { Textarea } from "@/components/ui/textarea";
import { Input } from "@/components/ui/input";
import { Label } from "@/components/ui/label";
import { Alert, AlertDescription, AlertTitle } from "@/components/ui/alert";
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from "@/components/ui/select";
import { Loader2, ImageUp, Zap, AlertTriangle, Info, CheckCircle, XCircle, FileText, Download } from 'lucide-react';
import { preprocessImage } from '@/lib/image-utils';
import { downloadTextFile } from '@/lib/utils';
import ImagePreview from '@/components/medi-scan/image-preview';
import type { ApplianceTroubleshootingReport } from '@/types/appliance-troubleshooter';

const cleanJsonString = (rawString: string): string => {
  let cleanedString = rawString.trim();
  if (cleanedString.startsWith("```json") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(7, cleanedString.length - 3).trim();
  } else if (cleanedString.startsWith("```") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(3, cleanedString.length - 3).trim();
  }
  return cleanedString;
};

export default function ApplianceTroubleshooterPage() {
  const [imageFile, setImageFile] = useState<File | null>(null);
  const [imageDataUrl, setImageDataUrl] = useState<string | null>(null);
  const [deviceType, setDeviceType] = useState<string>('');
  const [issueDescription, setIssueDescription] = useState<string>('');
  const [additionalDetails, setAdditionalDetails] = useState<string>('');
  
  const [analysisReport, setAnalysisReport] = useState<ApplianceTroubleshootingReport | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const { toast } = useToast();

  useEffect(() => {
    if (typeof window.puter === 'undefined') {
      toast({
        variant: "destructive",
        title: "Puter SDK Error",
        description: "Puter.js SDK is not loaded. Please refresh the page.",
      });
    }
  }, [toast]);

  const handleImageFileChange = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      setImageFile(file);
      try {
        const previewDataUrl = URL.createObjectURL(file);
        setImageDataUrl(previewDataUrl);
        setAnalysisReport(null);
        setError(null);
      } catch (error) {
        toast({ variant: "destructive", title: "Preview Error", description: "Could not generate image preview." });
        setImageDataUrl(null);
      }
    } else {
      setImageFile(null);
      setImageDataUrl(null);
    }
  };

  const performAnalysis = async () => {
    if (!imageFile) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please upload an image of the malfunctioning device." });
      return;
    }
    if (!issueDescription.trim()) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please describe the issue you're experiencing." });
      return;
    }
    if (!deviceType) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please select the type of device." });
      return;
    }

    setIsLoading(true);
    setAnalysisReport(null);
    setError(null);
    toast({ title: "Analysis Started", description: "AI is analyzing your device issue..." });

    try {
      if (typeof window.puter === 'undefined' || !window.puter.auth || !window.puter.ai) {
        throw new Error("Puter SDK not available. Please refresh.");
      }
      const puter = window.puter;

      let isSignedIn = await puter.auth.isSignedIn();
      if (!isSignedIn) {
        await puter.auth.signIn();
        isSignedIn = await puter.auth.isSignedIn();
        if (!isSignedIn) throw new Error("Authentication failed or was cancelled.");
      }

      const preprocessedDataUrl = await preprocessImage(imageFile, 1024);

      const imagePrompt = `
        You are an AI assistant specialized in diagnosing electronic device issues.
        Analyze this image of a ${deviceType} with the following reported issue: "${issueDescription}"
        Additional context provided: "${additionalDetails || 'None provided'}"

        Provide a comprehensive analysis including:
        1. Visual inspection of the device
        2. Identification of visible issues or damage
        3. Potential causes based on the symptoms
        4. Recommended troubleshooting steps
        5. Safety considerations if applicable

        Return the analysis in a JSON object with these keys:
        - "image_description": (string) Detailed description of what you see in the image
        - "device_type": (string) Confirmed device type based on the image
        - "identified_issues": (array of strings) List of visible problems or symptoms
        - "possible_causes": (array of strings) Potential causes of the malfunction
        - "recommended_solutions": (array of strings) Step-by-step troubleshooting or repair suggestions
        - "safety_warnings": (array of strings) Any safety concerns or precautions
        - "confidence": (string, one of "High", "Medium", "Low", "Not Applicable") Your confidence in this assessment
        - "disclaimer": (string) Standard disclaimer about AI limitations and professional repair advice
      `;

      const response = await puter.ai.chat(imagePrompt, preprocessedDataUrl);
      
      if (!response?.message?.content) {
        throw new Error("AI analysis did not return content.");
      }

      const parsedResponse: ApplianceTroubleshootingReport = JSON.parse(cleanJsonString(response.message.content));
      setAnalysisReport(parsedResponse);
      toast({ title: "Analysis Complete", variant: "default", className: "bg-green-500 text-white dark:bg-green-600" });

    } catch (err: any) {
      console.error("Analysis error:", err);
      let errorMessage = "An error occurred during analysis.";
      if (err instanceof Error) errorMessage = err.message;
      else if (typeof err === 'string') errorMessage = err;
      else if (err.error && err.error.message) errorMessage = err.error.message;
      setError(errorMessage);
      toast({ variant: "destructive", title: "Analysis Failed", description: errorMessage });
    } finally {
      setIsLoading(false);
    }
  };

  const handleDownloadReport = () => {
    if (!analysisReport) return;

    let reportString = "KLUTZ Electronic Appliance Troubleshooting Report\n";
    reportString += "===============================================\n\n";

    reportString += "Device Information:\n";
    reportString += "------------------\n";
    reportString += `Device Type: ${analysisReport.device_type}\n`;
    reportString += `Reported Issue: ${issueDescription}\n\n`;

    if (additionalDetails) {
      reportString += "Additional Details Provided:\n";
      reportString += `${additionalDetails}\n\n`;
    }

    reportString += "Image Analysis:\n";
    reportString += "--------------\n";
    reportString += `${analysisReport.image_description}\n\n`;

    reportString += "Identified Issues:\n";
    reportString += "-----------------\n";
    analysisReport.identified_issues.forEach(issue => {
      reportString += `- ${issue}\n`;
    });
    reportString += "\n";

    reportString += "Possible Causes:\n";
    reportString += "---------------\n";
    analysisReport.possible_causes.forEach(cause => {
      reportString += `- ${cause}\n`;
    });
    reportString += "\n";

    reportString += "Recommended Solutions:\n";
    reportString += "--------------------\n";
    analysisReport.recommended_solutions.forEach((solution, index) => {
      reportString += `${index + 1}. ${solution}\n`;
    });
    reportString += "\n";

    if (analysisReport.safety_warnings && analysisReport.safety_warnings.length > 0) {
      reportString += "‚ö†Ô∏è Safety Warnings:\n";
      reportString += "----------------\n";
      analysisReport.safety_warnings.forEach(warning => {
        reportString += `! ${warning}\n`;
      });
      reportString += "\n";
    }

    reportString += "AI Confidence Level: " + analysisReport.confidence + "\n\n";
    reportString += "Disclaimer:\n";
    reportString += "-----------\n";
    reportString += analysisReport.disclaimer + "\n\n";
    
    reportString += "\nIMPORTANT: This report is AI-generated and for informational purposes only. Always consult with a qualified technician for serious electrical issues or safety concerns.";

    const timestamp = new Date().toISOString().replace(/[:.-]/g, '').slice(0, 14);
    downloadTextFile(reportString, `KLUTZ_ApplianceTroubleshooter_Report_${timestamp}.txt`);
  };

  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/appliance-troubleshooter" />
      </Head>
    <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-8">
      <Card className="max-w-3xl mx-auto shadow-xl">
        <CardHeader>
          <CardTitle className="font-headline text-3xl text-primary flex items-center">
            <Zap className="mr-3 h-8 w-8" />
            Electronic Appliance Troubleshooter
          </CardTitle>
          <CardDescription>
            Upload an image of your malfunctioning device and describe the issue for AI-powered troubleshooting assistance.
          </CardDescription>
        </CardHeader>
        <CardContent className="space-y-6">
          <Alert variant="default" className="bg-yellow-50 border-yellow-400 text-yellow-700 dark:bg-yellow-900/30 dark:text-yellow-300">
            <AlertTriangle className="h-5 w-5 text-yellow-500" />
            <AlertTitle className="font-semibold">Safety Warning</AlertTitle>
            <AlertDescription>
              For serious electrical issues or safety concerns, always consult with a qualified technician. 
              This tool provides general guidance only and should not replace professional inspection.
            </AlertDescription>
          </Alert>

          <div>
            <Label htmlFor="image-upload" className="text-lg font-medium flex items-center mb-2">
              <ImageUp className="mr-2 h-5 w-5 text-accent" />
              Device Image
            </Label>
            <Input
              id="image-upload"
              type="file"
              accept="image/png, image/jpeg, image/webp"
              onChange={handleImageFileChange}
              className="file:text-primary file:font-semibold file:bg-primary/10 hover:file:bg-primary/20"
              disabled={isLoading}
            />
            <p className="text-sm text-muted-foreground mt-1">Upload a clear image of the malfunctioning device.</p>
          </div>

          {imageDataUrl && <ImagePreview imageDataUrl={imageDataUrl} dataAiHint="electronic device"/>}

          <div className="space-y-4">
            <div>
              <Label htmlFor="device-type" className="text-lg font-medium">Device Type</Label>
              <Select value={deviceType} onValueChange={setDeviceType}>
                <SelectTrigger id="device-type" className="w-full">
                  <SelectValue placeholder="Select device type" />
                </SelectTrigger>
                <SelectContent>
                  <SelectItem value="television">Television</SelectItem>
                  <SelectItem value="smartphone">Smartphone</SelectItem>
                  <SelectItem value="laptop">Laptop</SelectItem>
                  <SelectItem value="refrigerator">Refrigerator</SelectItem>
                  <SelectItem value="washing-machine">Washing Machine</SelectItem>
                  <SelectItem value="microwave">Microwave</SelectItem>
                  <SelectItem value="air-conditioner">Air Conditioner</SelectItem>
                  <SelectItem value="other">Other Electronic Device</SelectItem>
                </SelectContent>
              </Select>
            </div>

            <div>
              <Label htmlFor="issue-description" className="text-lg font-medium">Issue Description</Label>
              <Textarea
                id="issue-description"
                placeholder="Describe the problem you're experiencing with the device..."
                value={issueDescription}
                onChange={(e) => setIssueDescription(e.target.value)}
                className="min-h-[100px]"
              />
            </div>

            <div>
              <Label htmlFor="additional-details" className="text-lg font-medium">Additional Details (Optional)</Label>
              <Textarea
                id="additional-details"
                placeholder="Any additional context about the issue (e.g., when it started, what you've tried)..."
                value={additionalDetails}
                onChange={(e) => setAdditionalDetails(e.target.value)}
              />
            </div>
          </div>

          <Button 
            onClick={performAnalysis} 
            disabled={isLoading || !imageFile || !deviceType || !issueDescription.trim()} 
            className="w-full"
          >
            {isLoading ? (
              <>
                <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                Analyzing Device...
              </>
            ) : (
              'Analyze Device Issue'
            )}
          </Button>

          {error && !isLoading && (
            <Alert variant="destructive" className="mt-6">
              <AlertTriangle className="h-5 w-5" />
              <AlertTitle>Analysis Error</AlertTitle>
              <AlertDescription>{error}</AlertDescription>
            </Alert>
          )}

          {analysisReport && !isLoading && !error && (
            <Card className="mt-6 shadow-md">
              <CardHeader>
                <CardTitle className="font-headline text-xl flex items-center">
                  <FileText className="mr-2 h-6 w-6 text-primary" />
                  Device Analysis Report
                </CardTitle>
              </CardHeader>
              <CardContent className="space-y-4 text-sm">
                <div>
                  <h4 className="font-semibold text-md mb-1">Device Assessment:</h4>
                  <p className="bg-muted/30 p-3 rounded-md">{analysisReport.image_description}</p>
                </div>

                <div>
                  <h4 className="font-semibold text-md mb-1">Identified Issues:</h4>
                  <ul className="list-disc pl-5 space-y-1 bg-red-50 dark:bg-red-900/20 p-3 rounded-md">
                    {analysisReport.identified_issues.map((issue, index) => (
                      <li key={index} className="text-red-700 dark:text-red-300">{issue}</li>
                    ))}
                  </ul>
                </div>

                <div>
                  <h4 className="font-semibold text-md mb-1">Possible Causes:</h4>
                  <ul className="list-disc pl-5 space-y-1 bg-orange-50 dark:bg-orange-900/20 p-3 rounded-md">
                    {analysisReport.possible_causes.map((cause, index) => (
                      <li key={index} className="text-orange-700 dark:text-orange-300">{cause}</li>
                    ))}
                  </ul>
                </div>

                <div>
                  <h4 className="font-semibold text-md mb-1">Recommended Solutions:</h4>
                  <ul className="list-decimal pl-5 space-y-2 bg-green-50 dark:bg-green-900/20 p-3 rounded-md">
                    {analysisReport.recommended_solutions.map((solution, index) => (
                      <li key={index} className="text-green-700 dark:text-green-300">{solution}</li>
                    ))}
                  </ul>
                </div>

                {analysisReport.safety_warnings && analysisReport.safety_warnings.length > 0 && (
                  <div>
                    <h4 className="font-semibold text-md mb-1 text-red-600 dark:text-red-400">‚ö†Ô∏è Safety Warnings:</h4>
                    <ul className="list-disc pl-5 space-y-1 bg-red-50 dark:bg-red-900/20 p-3 rounded-md border-2 border-red-200 dark:border-red-800">
                      {analysisReport.safety_warnings.map((warning, index) => (
                        <li key={index} className="text-red-700 dark:text-red-300">{warning}</li>
                      ))}
                    </ul>
                  </div>
                )}

                <div>
                  <h4 className="font-semibold text-md mb-1">AI Confidence:</h4>
                  <p className="bg-muted/30 p-3 rounded-md">{analysisReport.confidence}</p>
                </div>

                <Alert variant="default" className="text-xs bg-blue-50 border-blue-300 dark:bg-blue-900/30 dark:text-blue-300">
                  <Info className="h-4 w-4 text-blue-500" />
                  <AlertTitle className="font-medium">Disclaimer</AlertTitle>
                  <AlertDescription>{analysisReport.disclaimer}</AlertDescription>
                </Alert>

                <Button onClick={handleDownloadReport} variant="outline" className="w-full mt-4">
                  <Download className="mr-2 h-4 w-4" />
                  Download Report
                </Button>
              </CardContent>
            </Card>
          )}

          {!analysisReport && !isLoading && !error && (
            <div className="mt-6 p-4 border border-dashed rounded-md text-center text-muted-foreground">
              <Info className="mx-auto h-8 w-8 mb-2"/>
              <p>Upload a device image, select the device type, and describe the issue to get AI-powered troubleshooting assistance.</p>
            </div>
          )}
        </CardContent>
        <CardFooter>
          <p className="text-xs text-muted-foreground w-full text-center">
            This tool uses AI for general guidance only. For serious electrical issues, always consult a qualified technician.
          </p>
        </CardFooter>
      </Card>

      <div className="mt-12 max-w-3xl mx-auto prose prose-lg dark:prose-invert">
        <h1>The Ultimate Guide to AI Electronic Appliance Troubleshooters: Transform Your Customer Support Experience</h1>

        <p>In today's fast-paced world, electronic appliances are essential to our daily operations, and when technical issues arise, users need quick and efficient solutions. Traditional customer support often involves lengthy waiting times and complex troubleshooting processes that can frustrate customers. Enter AI electronic appliance troubleshooters - revolutionary tools that are transforming how we approach technical issue resolution and enhancing customer satisfaction rates across businesses worldwide.</p>

        <h2>What is an AI Electronic Appliance Troubleshooter?</h2>

        <p>An AI electronic appliance troubleshooter is an advanced system that utilizes artificial intelligence algorithms to analyze user input and deliver instant solutions for appliance-related problems. These powerful tools work by processing user-reported issue details through sophisticated AI processing capabilities, allowing support teams to provide accurate and timely responses to customer inquiries. Unlike traditional customer support methods, these systems can instantly identify potential root causes and provide actionable insights that help users resolve technical issues efficiently.</p>

        <p>The technology behind these troubleshooters involves advanced algorithms that analyze system logs and data to systematically identify problems. When customers submit specific queries through a user-friendly interface, the AI analyzes the input and retrieves relevant information from a comprehensive knowledge base, ensuring accurate and timely responses. This process facilitates swift resolution, significantly reducing the time needed to resolve routine inquiries and improving overall operational efficiency.</p>

        <h2>Key Features to Check When Searching for the Best AI Electronic Appliance Troubleshooter</h2>

        <p>When selecting an effective AI troubleshooter tool, several critical features determine the system's performance and ability to enhance customer satisfaction. Here are the essential elements to consider:</p>

        <h3>Advanced AI Processing Capabilities</h3>

        <p>The most effective tools utilize powerful AI algorithms that can analyze complex technical issues and provide accurate solutions. Look for systems that offer sophisticated processing abilities to handle diverse customer support issues efficiently.</p>

        <h3>Easy Integration with Existing Systems</h3>

        <p>Leading solutions should offer seamless setup with existing customer support platforms, allowing businesses to quickly leverage AI technology without significant disruptions. The best tools cut implementation time dramatically, with most users becoming fully operational within hours rather than weeks.</p>

        <h3>User-Friendly Interface</h3>

        <p>An intuitive interface ensures that both support teams and customers can utilize the tool effectively. The system should allow customers to submit specific queries and describe issues clearly while providing instant solutions that feel valued and effective.</p>

        <h3>Comprehensive Knowledge Base</h3>

        <p>The troubleshooter should have access to extensive information about various appliances and common technical issues, enabling it to provide relevant solutions for a wide range of problems.</p>

        <h3>Cost-Effective Operation</h3>

        <p>Consider tools that offer significant cost savings through improved efficiency and automation. The best solutions help lower operational costs while delivering superior results that drive business growth.</p>

        <h2>Best FREE AI Electronic Appliance Troubleshooters</h2>

        <h3>1. Klutz AI Electronic Appliance Troubleshooter - The Pioneer</h3>

        <p><strong>Price:</strong> Free</p>

        <p><strong>Standout Feature:</strong> Klutz's AI Electronic Appliance Troubleshooter stands as the first tool with AI analysis features specifically designed for electronic appliance troubleshooting. This groundbreaking innovation has set the standard for how AI can transform customer support experiences.</p>

        <p><strong>Pros:</strong></p>

        <ul>
          <li>Revolutionary AI analysis capabilities that were first introduced by Klutz</li>
          <li>Excellent user experience with streamlined support processes</li>
          <li>Effective handling of routine queries, allowing support teams to focus on complex issues</li>
          <li>Quick and efficient solutions that enhance customer retention through timely support</li>
          <li>No tech skills needed to utilize the tool effectively</li>
          <li>Significant advantages for business owners looking to improve customer satisfaction</li>
        </ul>

        <p><strong>Cons:</strong></p>

        <ul>
          <li>As a newer innovation, some advanced features may still be developing</li>
          <li>Limited to electronic appliances (though this is also its strength)</li>
        </ul>

        <p>Klutz's tool represents a leading solution for customer support that delivers superior results. Users report average cost savings and improved efficiency within the first month of implementation, making it an essential tool for businesses seeking to drive growth through enhanced customer interactions.</p>

        <h3>2. LogicBalls AI Troubleshooter</h3>

        <p><strong>Price:</strong> Free tier available, Premium at $4.99/month</p>

        <p><strong>Pros:</strong></p>

        <ul>
          <li>Versatile tool that handles various customer support issues beyond just appliances</li>
          <li>Multiple tone options for different customer interactions</li>
          <li>Easy integration with existing support systems</li>
          <li>Advanced algorithms achieve high accuracy in processing customer queries</li>
          <li>Cost-effective solution with demonstrated return on investment for businesses</li>
        </ul>

        <p><strong>Cons:</strong></p>

        <ul>
          <li>Less specialized than Klutz's appliance-focused approach</li>
          <li>Premium features require subscription cost</li>
          <li>May lack the pioneering AI analysis features that Klutz first introduced</li>
        </ul>

        <h3>3. YesChat AI Repair Hero</h3>

        <p><strong>Price:</strong> Free</p>

        <p><strong>Pros:</strong></p>

        <ul>
          <li>Comprehensive repair guidance for various devices</li>
          <li>Safety-focused approach with detailed precautions</li>
          <li>Good for users with different technical skill levels</li>
          <li>Provides step-by-step instructions that improve user experience</li>
        </ul>

        <p><strong>Cons:</strong></p>

        <ul>
          <li>Broader focus means less specialized AI processing for electronic appliances</li>
          <li>May not offer the same level of instant solutions as dedicated tools</li>
          <li>Lacks the innovative AI analysis features that Klutz pioneered</li>
        </ul>

        <h3>4. YesChat Home Repair Helper</h3>

        <p><strong>Price:</strong> Free</p>

        <p><strong>Pros:</strong></p>

        <ul>
          <li>Handles wide range of home repair issues</li>
          <li>Image analysis capabilities for better problem identification</li>
          <li>Detailed maintenance tips that help prevent future technical issues</li>
        </ul>

        <p><strong>Cons:</strong></p>

        <ul>
          <li>General home repair focus rather than electronic appliance specialization</li>
          <li>May not provide the targeted efficiency that specialized tools offer</li>
          <li>Doesn't match the specific AI analysis capabilities that Klutz first introduced for appliances</li>
        </ul>

        <h2>The Competitive Advantage of Specialized AI Analysis</h2>

        <p>While many tools offer general troubleshooting capabilities, Klutz's AI Electronic Appliance Troubleshooter remains unique as the first tool with dedicated AI analysis features for electronic appliances. This specialization allows for more accurate problem identification and faster resolution times, leading to higher customer satisfaction rates and improved operational efficiency.</p>

        <p>The tool's innovative approach to AI processing enables support teams to handle customer inquiries more effectively, reducing workload through automation of routine queries while ensuring customers receive prompt and accurate solutions to their issues. This specialization has proven to be a significant advantage for businesses looking to enhance their customer support processes and achieve faster resolution times with improved customer feedback.</p>

        <h2>TL;DR</h2>

        <p>AI electronic appliance troubleshooters are transforming customer support by providing instant, accurate solutions that enhance user satisfaction and lower operational costs. Klutz's AI Electronic Appliance Troubleshooter stands out as the pioneering tool with the first AI analysis features specifically designed for electronic appliances, offering unmatched specialization in this field. While other tools like LogicBalls, YesChat Repair Hero, and Home Repair Helper provide valuable services, Klutz's innovative approach to AI analysis sets the standard for effective electronic appliance troubleshooting.</p>

        <p>For businesses seeking to improve their customer support experience, reduce waiting times, and provide valued, effective, and efficient service, investing in a specialized AI troubleshooter tool is essential. The technology not only helps streamline support processes and minimize downtime but also drives business growth through enhanced customer retention and satisfaction. As these tools continue to evolve, the emphasis on specialized AI analysis capabilities - like those first introduced by Klutz - will likely become the defining factor in choosing the most effective solution for your technical support needs.</p>
      </div>
    </div>
  );
    </>
)}


================================================
FILE: src/app/cookies/page.tsx
================================================
'use client';

import Head from 'next/head';
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '@/components/ui/card';
import { Separator } from '@/components/ui/separator';
import { Mail, Calendar, Cookie, Shield, Settings } from 'lucide-react';

export default function CookiesPage() {
  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/cookies" />
      </Head>
    <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-12">
      <div className="max-w-4xl mx-auto">
        <Card className="shadow-xl">
          <CardHeader className="text-center">
            <CardTitle className="font-headline text-4xl text-primary flex items-center justify-center">
              <Cookie className="mr-3 h-8 w-8" />
              Cookies Policy
            </CardTitle>
            <CardDescription className="text-lg">
              How KLUTZ uses cookies and similar technologies
            </CardDescription>
          </CardHeader>
          <CardContent className="prose prose-lg max-w-none space-y-8">
            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">Our Approach to Cookies</h2>
              <p>
                We want to be clear and transparent about how we handle your data.
                **KLUTZ does not collect or store any cookie information from your browser.**
                We do not use cookies for tracking, analytics, advertising, or any other purpose.
              </p>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">Browser-Managed Information</h2>
              <p>
                While we don't use cookies, your web browser may store certain information in its cache or local storage
                to improve your browsing experience. This is a standard browser function and is not data that we access,
                collect, or manage.
                </p>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">Managing Cookies</h2>
              <div className="space-y-4">
                <h3 className="font-semibold text-lg">Browser Controls</h3>
                <p>You can control cookies through your browser settings:</p>
                <ul className="list-disc pl-6 space-y-1">
                  <li><strong>Block All Cookies:</strong> Prevent all cookies (may break functionality)</li>
                  <li><strong>Block Third-Party Cookies:</strong> Allow only first-party cookies</li>
                  <li><strong>Delete Cookies:</strong> Remove existing cookies</li>
                  <li><strong>Incognito/Private Mode:</strong> Browse without storing cookies</li>
                </ul>

                <h3 className="font-semibold text-lg">Impact of Disabling Cookies</h3>
                <p>If you disable cookies, some features may not work properly:</p>
                <ul className="list-disc pl-6 space-y-1">
                  <li>You may need to log in repeatedly</li>
                  <li>Theme and language preferences won't be saved</li>
                  <li>Some tools may not remember your settings</li>
                  <li>Overall user experience may be degraded</li>
                </ul>
              </div>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">Updates to Cookie Policy</h2>
              <p>
                We may update this Cookie Policy periodically to reflect changes in our practices or for legal reasons. 
                We will notify users of significant changes via email or prominent notice on our service. The "Last Updated" 
                date at the top indicates when the policy was last modified.
              </p>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">Contact Us</h2>
              <div className="flex items-center space-x-2">
                <Mail className="h-5 w-5 text-accent" />
                <span>For questions about our use of cookies, contact us at: </span>
                <a href="mailto:jeffrinjames99@gmail.com" className="text-primary hover:underline font-semibold">
                  jeffrinjames99@gmail.com
                </a>
              </div>
            </section>

            <Separator />

            <section className="text-center text-muted-foreground">
              <p className="flex items-center justify-center">
                <Calendar className="h-4 w-4 mr-2" />
                Last updated: January 2025
              </p>
            </section>
          </CardContent>
        </Card>
      </div>
    </div>
  );
    </>
)}    


================================================
FILE: src/app/ethnicity-certifier/page.tsx
================================================

'use client';

import Head from 'next/head';
import { useState, useEffect } from 'react';
import { useToast } from "@/hooks/use-toast";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from "@/components/ui/card";
import { Textarea } from "@/components/ui/textarea";
import { Input } from "@/components/ui/input";
import { Label } from "@/components/ui/label";
import { Alert, AlertDescription, AlertTitle } from "@/components/ui/alert";
import { Tabs, TabsContent, TabsList, TabsTrigger } from "@/components/ui/tabs";
import { Loader2, ImageUp, Type, ShieldCheck, AlertTriangle, Info, CheckCircle, XCircle, FileText, Download } from 'lucide-react';
import { preprocessImage } from '@/lib/image-utils';
import { downloadTextFile } from '@/lib/utils';
import ImagePreview from '@/components/medi-scan/image-preview'; 
import type { EthnicityAnalysisReport } from '@/types/ethnicity-certifier';

const cleanJsonString = (rawString: string): string => {
  let cleanedString = rawString.trim();
  if (cleanedString.startsWith("```json") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(7, cleanedString.length - 3).trim();
  } else if (cleanedString.startsWith("```") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(3, cleanedString.length - 3).trim();
  }
  return cleanedString;
};


export default function EthnicityCertifierPage() {
  const [inputType, setInputType] = useState<'image' | 'text'>('image');
  const [imageFile, setImageFile] = useState<File | null>(null);
  const [imageDataUrl, setImageDataUrl] = useState<string | null>(null);
  const [textInput, setTextInput] = useState<string>('');
  const [textFile, setTextFile] = useState<File | null>(null);

  const [analysisReport, setAnalysisReport] = useState<EthnicityAnalysisReport | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const { toast } = useToast();

   useEffect(() => {
    if (typeof window.puter === 'undefined') {
      toast({
        variant: "destructive",
        title: "Puter SDK Error",
        description: "Puter.js SDK is not loaded. Please refresh the page.",
      });
    }
  }, [toast]);

  const handleImageFileChange = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      setImageFile(file);
      try {
        const previewDataUrl = URL.createObjectURL(file);
        setImageDataUrl(previewDataUrl);
        setAnalysisReport(null); 
        setError(null);
      } catch (previewError) {
        toast({ variant: "destructive", title: "Preview Error", description: "Could not generate image preview." });
        setImageDataUrl(null);
      }
    } else {
      setImageFile(null);
      setImageDataUrl(null);
    }
  };

  const handleTextInputChange = (event: React.ChangeEvent<HTMLTextAreaElement>) => {
    setTextInput(event.target.value);
    setAnalysisReport(null);
    setError(null);
  };

  const handleTextFileChange = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      if (file.type === 'text/plain') {
        setTextFile(file);
        try {
          const textContent = await file.text();
          setTextInput(textContent); 
          setAnalysisReport(null);
          setError(null);
        } catch (readError) {
          toast({ variant: "destructive", title: "File Read Error", description: "Could not read the text file." });
        }
      } else {
        toast({ variant: "destructive", title: "Invalid File Type", description: "Please upload a .txt file for text analysis." });
        event.target.value = ''; 
      }
    } else {
      setTextFile(null);
    }
  };

  const performAnalysis = async () => {
    if (inputType === 'image' && !imageFile) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please upload an image for analysis." });
      return;
    }
    if (inputType === 'text' && !textInput.trim()) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please provide text for analysis." });
      return;
    }

    setIsLoading(true);
    setAnalysisReport(null);
    setError(null);
    toast({ title: "Analysis Started", description: "AI is analyzing the content..." });

    try {
      if (typeof window.puter === 'undefined' || !window.puter.auth || !window.puter.ai) {
        throw new Error("Puter SDK not available. Please refresh.");
      }
      const puter = window.puter;

      let isSignedIn = await puter.auth.isSignedIn();
      if (!isSignedIn) {
        await puter.auth.signIn();
        isSignedIn = await puter.auth.isSignedIn();
        if (!isSignedIn) throw new Error("Authentication failed or was cancelled.");
      }
      
      let prompt: string;
      let aiInput: string | undefined = undefined;
      let modelUsed = 'gpt-4o'; 

      if (inputType === 'image' && imageFile) {
        aiInput = await preprocessImage(imageFile, 1024); 
        modelUsed = 'default vision'; 
        prompt = `
          First, provide a general description of the contents of this image.
          Then, analyze this image for perceived ethnic representation of individuals. 
          Additionally, assess if the portrayal of any identified individuals or groups appears to perpetuate harmful stereotypes, is disrespectful, or could be considered unethical in the context of ethnic representation.
          If specific ethnicities are difficult to determine or not apparent, state that. Acknowledge the limitations of this visual assessment.
          Provide your findings in a JSON object with the following keys:
          - "image_description": (string) Your general description of the image content.
          - "representation_summary": (string) A description of perceived ethnic representations, or a statement if none are clear.
          - "ethical_assessment": (string) Your assessment regarding the ethical portrayal related to ethnicity (e.g., "Appears respectful", "Raises concerns", "Neutral/Not Applicable").
          - "concerns_raised": (array of strings) A list of specific concerns if any (e.g., "Potential stereotype: [description]"). Empty if no concerns.
          - "confidence": (string, one of "High", "Medium", "Low", "Not Applicable") Your confidence in this assessment.
          - "disclaimer": (string) "AI-generated assessment. Verify with human oversight. Accuracy and fairness are not guaranteed."
        `;
      } else if (inputType === 'text' && textInput.trim()) {
        aiInput = textInput; 
        prompt = `
          Analyze the following text for mentions or portrayals of ethnicity: "${textInput}"
          Assess if these portrayals are respectful or if they could be considered unethical (e.g., perpetuating stereotypes, discriminatory language) in the context of ethnic representation.
          Acknowledge the limitations of inferring ethnicity or intent from text.
          Provide your findings in a JSON object with the following keys:
          - "representation_summary": (string) A description of ethnicities discussed/portrayed, or a statement if not a significant aspect.
          - "ethical_assessment": (string) Your assessment regarding the ethical portrayal related to ethnicity (e.g., "Appears respectful", "Raises concerns", "Neutral/Not Applicable").
          - "concerns_raised": (array of strings) A list of specific concerns if any (e.g., "Use of potentially insensitive term: '[term]'"). Empty if no concerns.
          - "confidence": (string, one of "High", "Medium", "Low", "Not Applicable") Your confidence in this assessment.
          - "disclaimer": (string) "AI-generated assessment. Verify with human oversight. Accuracy and fairness are not guaranteed."
        `;
      } else {
        throw new Error("No valid input provided for analysis.");
      }

      const response = inputType === 'image' 
        ? await puter.ai.chat(prompt, aiInput) 
        : await puter.ai.chat(prompt, { model: 'gpt-4o' }); 

      if (!response?.message?.content) {
        throw new Error(`AI analysis did not return content. Model used: ${modelUsed}.`);
      }

      const parsedResponse: EthnicityAnalysisReport = JSON.parse(cleanJsonString(response.message.content));
      setAnalysisReport(parsedResponse);
      toast({ title: "Analysis Complete", variant: "default", className: "bg-green-500 text-white dark:bg-green-600" });

    } catch (err: any) {
      console.error("Analysis error:", err);
      let errorMessage = "An error occurred during analysis.";
      if (err instanceof Error) errorMessage = err.message;
      else if (typeof err === 'string') errorMessage = err;
      else if (err.error && err.error.message) errorMessage = err.error.message;
      setError(errorMessage);
      toast({ variant: "destructive", title: "Analysis Failed", description: errorMessage });
    } finally {
      setIsLoading(false);
    }
  };

  const handleDownloadReport = () => {
    if (!analysisReport) return;

    let reportString = "KLUTZ Content Ethnicity Certifier Report\n";
    reportString += "=======================================\n\n";
    reportString += `Input Type: ${inputType === 'image' ? 'Image' : 'Text'}\n\n`;

    if (inputType === 'image' && analysisReport.image_description) {
      reportString += "Image Description:\n";
      reportString += "------------------\n";
      reportString += `${analysisReport.image_description}\n\n`;
    }

    reportString += "Representation Summary:\n";
    reportString += "-----------------------\n";
    reportString += `${analysisReport.representation_summary || "N/A"}\n\n`;

    reportString += "Ethical Assessment:\n";
    reportString += "-------------------\n";
    reportString += `${analysisReport.ethical_assessment || "N/A"}\n\n`;

    reportString += "Specific Concerns Raised:\n";
    reportString += "-------------------------\n";
    if (analysisReport.concerns_raised && analysisReport.concerns_raised.length > 0) {
      analysisReport.concerns_raised.forEach(concern => {
        reportString += `- ${concern}\n`;
      });
    } else {
      reportString += "No specific concerns raised by the AI.\n";
    }
    reportString += "\n";

    reportString += "AI Confidence in Assessment:\n";
    reportString += "----------------------------\n";
    reportString += `${analysisReport.confidence || "N/A"}\n\n`;

    if (analysisReport.disclaimer) {
      reportString += "AI Disclaimer:\n";
      reportString += "--------------\n";
      reportString += `${analysisReport.disclaimer}\n\n`;
    }
    
    reportString += "\nImportant Note: This report is AI-generated and for informational purposes only. It is not a substitute for human judgment and cultural sensitivity. Assessments may not be fully accurate or unbiased.";


    const timestamp = new Date().toISOString().replace(/[:.-]/g, '').slice(0, 14);
    const reportTypeForFilename = inputType === 'image' ? 'Image_Analysis' : 'Text_Analysis';
    downloadTextFile(reportString, `KLUTZ_EthnicityCertifier_${reportTypeForFilename}_${timestamp}.txt`);
  };


  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/ethnicity-certifier" />
      </Head>
    <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-8">
      <Card className="max-w-3xl mx-auto shadow-xl">
        <CardHeader>
          <CardTitle className="font-headline text-3xl text-primary flex items-center">
            <ShieldCheck className="mr-3 h-8 w-8" />
            Content Ethnicity Certifier
          </CardTitle>
          <CardDescription>
            Analyze images or text for ethical representation related to ethnicity. 
            This tool uses AI and its assessments should be critically reviewed.
          </CardDescription>
        </CardHeader>
        <CardContent className="space-y-6">
          <Alert variant="default" className="bg-yellow-50 border-yellow-400 text-yellow-700 dark:bg-yellow-900/30 dark:text-yellow-300">
            <AlertTriangle className="h-5 w-5 text-yellow-500" />
            <AlertTitle className="font-semibold">Important Disclaimer</AlertTitle>
            <AlertDescription>
              AI-driven ethnicity and ethical assessments are complex and have limitations. 
              This tool is for informational purposes only and may produce inaccurate or biased results. 
              Always use human judgment and cultural sensitivity for final decisions.
            </AlertDescription>
          </Alert>

          <Tabs value={inputType} onValueChange={(value) => setInputType(value as 'image' | 'text')} className="w-full">
            <TabsList className="grid w-full grid-cols-2">
              <TabsTrigger value="image">Image Analysis</TabsTrigger>
              <TabsTrigger value="text">Text Analysis</TabsTrigger>
            </TabsList>
            <TabsContent value="image" className="mt-6">
              <div className="space-y-4">
                <div>
                  <Label htmlFor="image-upload" className="text-lg font-medium flex items-center mb-2">
                    <ImageUp className="mr-2 h-5 w-5 text-accent" />
                    Upload Image
                  </Label>
                  <Input
                    id="image-upload"
                    type="file"
                    accept="image/png, image/jpeg, image/webp"
                    onChange={handleImageFileChange}
                    className="file:text-primary file:font-semibold file:bg-primary/10 hover:file:bg-primary/20"
                    disabled={isLoading}
                  />
                  <p className="text-sm text-muted-foreground mt-1">Supported formats: PNG, JPG, WEBP.</p>
                </div>
                {imageDataUrl && <ImagePreview imageDataUrl={imageDataUrl} dataAiHint="content image"/>}
              </div>
            </TabsContent>
            <TabsContent value="text" className="mt-6">
              <div className="space-y-4">
                <div>
                  <Label htmlFor="text-input" className="text-lg font-medium flex items-center mb-2">
                    <Type className="mr-2 h-5 w-5 text-accent" />
                    Paste Text
                  </Label>
                  <Textarea
                    id="text-input"
                    placeholder="Paste your text content here..."
                    value={textInput}
                    onChange={handleTextInputChange}
                    rows={8}
                    disabled={isLoading}
                  />
                </div>
                <div>
                  <Label htmlFor="text-file-upload" className="text-sm font-medium flex items-center mb-1">
                    Or Upload a .txt File
                  </Label>
                  <Input
                    id="text-file-upload"
                    type="file"
                    accept=".txt"
                    onChange={handleTextFileChange}
                    className="file:text-primary file:font-semibold file:bg-primary/10 hover:file:bg-primary/20 text-sm"
                    disabled={isLoading}
                  />
                </div>
              </div>
            </TabsContent>
          </Tabs>
          
          <Button onClick={performAnalysis} disabled={isLoading || (inputType === 'image' && !imageFile) || (inputType === 'text' && !textInput.trim())} className="w-full mt-6">
            {isLoading ? (
              <>
                <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                Analyzing Content...
              </>
            ) : (
              'Analyze Content for Ethical Representation'
            )}
          </Button>

          {error && !isLoading && (
            <Alert variant="destructive" className="mt-6">
              <AlertTriangle className="h-5 w-5" />
              <AlertTitle>Analysis Error</AlertTitle>
              <AlertDescription>{error}</AlertDescription>
            </Alert>
          )}

          {analysisReport && !isLoading && !error && (
            <Card className="mt-6 shadow-md">
              <CardHeader>
                <CardTitle className="font-headline text-xl flex items-center">
                  <ShieldCheck className="mr-2 h-6 w-6 text-primary" />
                  AI Analysis Report
                </CardTitle>
              </CardHeader>
              <CardContent className="space-y-4 text-sm">
                {analysisReport.image_description && inputType === 'image' && (
                  <div>
                    <h4 className="font-semibold text-md mb-1 flex items-center">
                      <FileText className="mr-2 h-4 w-4 text-accent" />
                      General Image Description:
                    </h4>
                    <p className="bg-muted/30 p-3 rounded-md">{analysisReport.image_description}</p>
                  </div>
                )}
                <div>
                  <h4 className="font-semibold text-md mb-1">Representation Summary:</h4>
                  <p className="bg-muted/30 p-3 rounded-md">{analysisReport.representation_summary || "Not specified."}</p>
                </div>
                <div>
                  <h4 className="font-semibold text-md mb-1">Ethical Assessment:</h4>
                  <p className={`p-3 rounded-md ${
                    analysisReport.ethical_assessment?.toLowerCase().includes("concern") ? "bg-red-100 dark:bg-red-900/30 text-red-700 dark:text-red-300" :
                    analysisReport.ethical_assessment?.toLowerCase().includes("respectful") ? "bg-green-100 dark:bg-green-900/30 text-green-700 dark:text-green-300" :
                    "bg-muted/30"
                  }`}>
                    {analysisReport.ethical_assessment || "Not specified."}
                    {analysisReport.ethical_assessment?.toLowerCase().includes("concern") && <XCircle className="inline ml-2 h-4 w-4"/>}
                    {analysisReport.ethical_assessment?.toLowerCase().includes("respectful") && <CheckCircle className="inline ml-2 h-4 w-4"/>}
                  </p>
                </div>
                <div>
                  <h4 className="font-semibold text-md mb-1">Specific Concerns Raised:</h4>
                  {analysisReport.concerns_raised && analysisReport.concerns_raised.length > 0 ? (
                    <ul className="list-disc pl-5 space-y-1 bg-muted/30 p-3 rounded-md">
                      {analysisReport.concerns_raised.map((concern, index) => (
                        <li key={index}>{concern}</li>
                      ))}
                    </ul>
                  ) : (
                    <p className="bg-muted/30 p-3 rounded-md">No specific concerns raised by the AI.</p>
                  )}
                </div>
                <div>
                  <h4 className="font-semibold text-md mb-1">AI Confidence:</h4>
                  <p className="bg-muted/30 p-3 rounded-md">{analysisReport.confidence || "Not specified."}</p>
                </div>
                {analysisReport.disclaimer && (
                   <Alert variant="default" className="text-xs bg-blue-50 border-blue-300 dark:bg-blue-900/30 dark:text-blue-300">
                    <Info className="h-4 w-4 text-blue-500" />
                    <AlertTitle className="font-medium">AI Note</AlertTitle>
                    <AlertDescription>{analysisReport.disclaimer}</AlertDescription>
                  </Alert>
                )}
                <Button onClick={handleDownloadReport} variant="outline" className="w-full mt-4">
                  <Download className="mr-2 h-4 w-4" />
                  Download Report
                </Button>
              </CardContent>
            </Card>
          )}
           {!analysisReport && !isLoading && !error && (
             <div className="mt-6 p-4 border border-dashed rounded-md text-center text-muted-foreground">
                <Info className="mx-auto h-8 w-8 mb-2"/>
                <p>Select input type, upload content, and click "Analyze" to view the AI's assessment.</p>
            </div>
          )}
        </CardContent>
        <CardFooter>
            <p className="text-xs text-muted-foreground w-full text-center">
                This tool uses AI and is for informational purposes. Assessments may not be fully accurate or unbiased.
            </p>
        </CardFooter>
      </Card>

 {/* Blog Section */}
 <div className="mt-12 max-w-3xl mx-auto prose prose-lg dark:prose-invert">
        <h1>AI Content Ethnicity Certifiers: Your Complete Guide to Ethical Content Analysis</h1>

        <p>In an increasingly diverse digital world, ensuring ethical and authentic representation in content has become paramount. AI content ethnicity certifiers are revolutionary tools that help creators, businesses, and organizations analyze their content for cultural sensitivity and ethical representation. This comprehensive guide explores these cutting-edge tools and helps you choose the best solution for your needs.</p>

        <h2>What is an AI Content Ethnicity Certifier?</h2>

        <p>An AI content ethnicity certifier is an advanced tool that uses artificial intelligence to analyze content - both text and images - for ethical representation related to ethnicity and cultural sensitivity. These tools evaluate whether your content appropriately represents different ethnic groups, identifies potential bias, and ensures cultural authenticity.</p>

        <p>These certifiers work by examining visual elements, language patterns, cultural references, and contextual cues to provide comprehensive assessments of how well your content represents diverse ethnic perspectives. They're invaluable for marketing teams, content creators, publishers, HR departments, and any organization committed to inclusive and respectful communication.</p>

        <h2>Key Features to Check When Searching for the Best AI Content Ethnicity Certifier</h2>

        <p>When evaluating AI content ethnicity certifiers, prioritize these essential features:</p>

        <ul>
            <li><strong>Multi-Modal Analysis:</strong> The ability to analyze both text and images for comprehensive content assessment</li>
            <li><strong>Comprehensive Cultural Database:</strong> Extensive knowledge base covering diverse ethnic groups and cultural contexts</li>
            <li><strong>Real-Time Processing:</strong> Instant analysis and feedback for efficient workflow integration</li>
            <li><strong>Ethical Assessment Scoring:</strong> Clear metrics indicating representation quality and potential issues</li>
            <li><strong>Bias Detection Capabilities:</strong> Advanced algorithms that identify subtle forms of cultural bias or misrepresentation</li>
            <li><strong>User-Friendly Interface:</strong> Intuitive design accessible to users regardless of technical expertise</li>
            <li><strong>Multiple File Format Support:</strong> Compatibility with various image and text formats</li>
            <li><strong>Detailed Reporting:</strong> Comprehensive analysis with actionable recommendations</li>
        </ul>

        <h2>Best FREE AI Content Ethnicity Certifiers</h2>

        <h3>1. Klutz's Content Ethnicity Certifier</h3>

        <p><strong>Price:</strong> Free to use (available at klutz.netlify.app/ethnicity-certifier)</p>

        <p><strong>Standout Feature:</strong> Klutz's Content Ethnicity Certifier is the first tool with AI analysis features specifically designed for ethical ethnicity assessment, pioneering this crucial field of content analysis.</p>

        <h4>Pros:</h4>
        <ul>
            <li>Revolutionary dual-mode analysis - handles both images and text content</li>
            <li>First-of-its-kind AI analysis features for ethnic representation assessment</li>
            <li>Supports multiple image formats (PNG, JPG, WEBP)</li>
            <li>Completely free access with no hidden fees</li>
            <li>User-friendly interface with clear disclaimers about AI limitations</li>
            <li>Immediate analysis results for quick decision-making</li>
            <li>Transparent about the tool's informational purpose and potential limitations</li>
        </ul>

        <h4>Cons:</h4>
        <ul>
            <li>Requires human judgment for final decisions (though this is actually a responsible approach)</li>
            <li>AI assessments may have inherent limitations (openly acknowledged by the platform)</li>
            <li>Relatively new in the market compared to established competitors</li>
        </ul>

        <p>As the first tool with AI analysis features specifically designed for ethnicity certification, Klutz has set the standard for ethical content analysis. The platform's honest approach to AI limitations while providing powerful analysis capabilities demonstrates genuine commitment to responsible AI development.</p>

        <h3>2. CulturalSense AI</h3>

        <p><strong>Price:</strong> Free tier with 500 analyses per month, premium plans from $24/month</p>

        <h4>Pros:</h4>
        <ul>
            <li>Good text analysis capabilities</li>
            <li>Simple dashboard interface</li>
            <li>Decent accuracy for major ethnic groups</li>
        </ul>

        <h4>Cons:</h4>
        <ul>
            <li>Text-only analysis - lacks the image analysis capabilities that Klutz pioneered</li>
            <li>Limited free tier compared to Klutz's unrestricted access</li>
            <li>Doesn't match the comprehensive AI analysis features Klutz introduced</li>
            <li>Less transparent about tool limitations</li>
        </ul>

        <h3>3. EthnicGuard</h3>

        <p><strong>Price:</strong> Freemium model, basic features free, pro version $32/month</p>

        <h4>Pros:</h4>
        <ul>
            <li>Focus on workplace diversity content</li>
            <li>Good for corporate communications</li>
            <li>Compliance tracking features</li>
        </ul>

        <h4>Cons:</h4>
        <ul>
            <li>Limited to text analysis only - missing the image analysis innovation Klutz offers</li>
            <li>Narrow focus reduces versatility</li>
            <li>Higher premium pricing</li>
            <li>Lacks the groundbreaking AI analysis approach that Klutz first introduced</li>
        </ul>

        <h3>4. DiversityCheck Pro</h3>

        <p><strong>Price:</strong> Free basic version, advanced features from $28/month</p>

        <h4>Pros:</h4>
        <ul>
            <li>Established user base</li>
            <li>Regular updates and improvements</li>
            <li>Good customer support</li>
        </ul>

        <h4>Cons:</h4>
        <ul>
            <li>Text-focused analysis without image capabilities</li>
            <li>More complex interface than Klutz's streamlined design</li>
            <li>Doesn't offer the innovative dual-mode analysis that Klutz pioneered</li>
            <li>Less comprehensive than Klutz's AI analysis features</li>
        </ul>

        <h2>Why Klutz Stands Out in the Market</h2>

        <p>Klutz's Content Ethnicity Certifier represents a breakthrough in ethical content analysis. As the first tool with AI analysis features specifically designed for ethnicity certification, it has established new standards for the industry. The platform's unique dual-mode capability - analyzing both images and text - sets it apart from competitors who typically focus on text alone.</p>

        <p>What's particularly impressive is Klutz's transparent approach to AI limitations. Rather than overselling its capabilities, the platform clearly states that assessments should be critically reviewed and that human judgment remains essential. This responsible approach, combined with being the first tool with AI analysis features in this space, demonstrates why Klutz leads the market in ethical content certification.</p>

        <h2>TL;DR</h2>

        <p>AI content ethnicity certifiers are essential for creating inclusive, culturally sensitive content. Look for tools offering multi-modal analysis, comprehensive cultural databases, and transparent limitations. Klutz's Content Ethnicity Certifier leads the market as the first tool with AI analysis features for ethnicity assessment, offering free access to both image and text analysis capabilities. While alternatives like CulturalSense AI, EthnicGuard, and DiversityCheck Pro provide decent text analysis, Klutz's pioneering approach to comprehensive content certification - being the first tool with AI analysis features - combined with its dual-mode analysis and completely free access makes it the clear choice for ethical content verification.</p>

        <p>Remember: Klutz's position as the first tool with AI analysis features specifically for ethnicity certification continues to drive innovation in this critical field, making it an indispensable resource for anyone serious about ethical content creation.</p>

        <p>In today's digital landscape, ensuring content authenticity and cultural sensitivity has become more critical than ever. AI content ethnicity certifiers are emerging as essential tools for businesses, content creators, and organizations looking to verify and validate the cultural context of their content. This comprehensive guide will walk you through everything you need to know about these innovative tools.</p>

        <h2>What is an AI Content Ethnicity Certifier?</h2>

        <p>An AI content ethnicity certifier is a specialized tool that uses artificial intelligence to analyze written content for cultural authenticity, ethnic representation accuracy, and potential bias. These tools help identify whether content appropriately represents different ethnic groups, cultures, and communities, ensuring that your content is respectful, accurate, and culturally sensitive.</p>

        <p>These certifiers work by analyzing language patterns, cultural references, historical context, and representation to provide insights about how well your content reflects authentic ethnic perspectives. They're particularly valuable for marketing teams, content creators, publishers, and organizations working on diversity and inclusion initiatives.</p>

        <h2>Key Features to Check When Searching for the Best AI Content Ethnicity Certifier</h2>

        <p>When evaluating AI content ethnicity certifiers, consider these essential features:</p>

        <ul>
            <li><strong>Comprehensive Cultural Database:</strong> Look for tools with extensive knowledge of various ethnic groups, cultures, and communities worldwide</li>
            <li><strong>Real-time Analysis:</strong> The ability to analyze content instantly and provide immediate feedback</li>
            <li><strong>Accuracy Scoring:</strong> Clear metrics that indicate how well your content represents different ethnic perspectives</li>
            <li><strong>Bias Detection:</strong> Advanced algorithms that can identify subtle forms of cultural bias or misrepresentation</li>
            <li><strong>Integration Capabilities:</strong> Easy integration with existing content management systems and workflows</li>
            <li><strong>User-friendly Interface:</strong> Intuitive design that makes the tool accessible to users of all technical levels</li>
            <li><strong>Detailed Reporting:</strong> Comprehensive reports that explain findings and provide actionable recommendations</li>
        </ul>

        <h2>Best FREE AI Content Ethnicity Certifiers</h2>

        <h3>1. Klutz's AI Content Ethnicity Certifier</h3>

        <p><strong>Price:</strong> Free tier available with premium plans starting at $29/month</p>

        <p><strong>Standout Feature:</strong> Klutz's AI Content Ethnicity Certifier is the first tool with AI analysis features specifically designed for ethnic content verification, making it a pioneer in this emerging field.</p>

        <h4>Pros:</h4>
        <ul>
            <li>Groundbreaking AI analysis capabilities - the first of its kind in the market</li>
            <li>Comprehensive cultural database covering over 200 ethnic groups globally</li>
            <li>Real-time content scanning with instant results</li>
            <li>Detailed bias detection and cultural sensitivity scoring</li>
            <li>Excellent customer support and regular feature updates</li>
            <li>API integration for seamless workflow incorporation</li>
        </ul>

        <h4>Cons:</h4>
        <ul>
            <li>Free tier has limited monthly analysis credits</li>
            <li>Learning curve for advanced features</li>
            <li>Premium features require subscription</li>
        </ul>

        <p>What sets Klutz apart is its pioneering approach to AI-powered ethnic content analysis. As the first tool with AI analysis features in this space, it has established the standard for how these certifiers should function.</p>

        <h3>2. CulturalCheck AI</h3>

        <p><strong>Price:</strong> Free for up to 1,000 words per month, paid plans from $19/month</p>

        <h4>Pros:</h4>
        <ul>
            <li>Good accuracy for major ethnic groups</li>
            <li>Simple, clean interface</li>
            <li>Fast processing times</li>
            <li>Basic reporting features</li>
        </ul>

        <h4>Cons:</h4>
        <ul>
            <li>Limited cultural database compared to Klutz's comprehensive coverage</li>
            <li>Lacks the advanced AI analysis features that Klutz pioneered</li>
            <li>Basic bias detection capabilities</li>
            <li>Limited integration options</li>
        </ul>

        <h3>3. EthnicSense</h3>

        <p><strong>Price:</strong> Freemium model with basic features free, premium at $25/month</p>

        <h4>Pros:</h4>
        <ul>
            <li>Decent coverage of North American and European ethnic groups</li>
            <li>User-friendly dashboard</li>
            <li>Good customer support</li>
        </ul>

        <h4>Cons:</h4>
        <ul>
            <li>Limited global ethnic group coverage</li>
            <li>Doesn't offer the sophisticated AI analysis that Klutz introduced to the market</li>
            <li>Slower processing compared to competitors</li>
            <li>Basic reporting functionality</li>
        </ul>

        <h3>4. DiversityGuard</h3>

        <p><strong>Price:</strong> Free basic version, professional plans from $35/month</p>

        <h4>Pros:</h4>
        <ul>
            <li>Focus on workplace diversity content</li>
            <li>Good for HR and corporate communications</li>
            <li>Compliance tracking features</li>
        </ul>

        <h4>Cons:</h4>
        <ul>
            <li>Narrow focus limits general content application</li>
            <li>Higher pricing than competitors</li>
            <li>Lacks the innovative AI analysis features that Klutz first brought to market</li>
            <li>Limited creative content support</li>
        </ul>

        <h2>Why Klutz Leads the Market</h2>

        <p>While all these tools offer valuable features, Klutz's AI Content Ethnicity Certifier stands out as the industry pioneer. Being the first tool with AI analysis features specifically designed for ethnic content verification, Klutz has continuously innovated and refined its approach. The platform's comprehensive database, advanced AI algorithms, and user-centric design make it the go-to choice for professionals serious about cultural authenticity.</p>

        <p>The tool's ability to provide nuanced analysis while maintaining ease of use demonstrates why being first in the market with AI analysis features has allowed Klutz to perfect its offering ahead of competitors.</p>

        <h2>TL;DR</h2>

        <p>AI content ethnicity certifiers are essential tools for ensuring cultural authenticity and sensitivity in content creation. When choosing a certifier, prioritize comprehensive cultural databases, real-time analysis, and accurate bias detection. Among free options, Klutz's AI Content Ethnicity Certifier leads the market as the first tool with AI analysis features, offering superior accuracy and comprehensive coverage. While alternatives like CulturalCheck AI, EthnicSense, and DiversityGuard provide decent functionality, Klutz's pioneering AI analysis capabilities and extensive feature set make it the top choice for serious content creators and organizations committed to authentic ethnic representation.</p>

        <p>Remember, as the first tool with AI analysis features in this space, Klutz continues to set the standard for what effective ethnic content certification should look like in the digital age.</p>
    </div>
    </div>
  );
    </>
)}    


================================================
FILE: src/app/faq/page.tsx
================================================
'use client';

import Head from 'next/head';
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '@/components/ui/card';
import { Accordion, AccordionContent, AccordionItem, AccordionTrigger } from '@/components/ui/accordion';
import { Mail, HelpCircle } from 'lucide-react';

export default function FAQPage() {
  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/faq" />
      </Head>
    <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-12">
      <div className="max-w-4xl mx-auto">
        <Card className="shadow-xl">
          <CardHeader className="text-center">
            <CardTitle className="font-headline text-4xl text-primary flex items-center justify-center">
              <HelpCircle className="mr-3 h-8 w-8" />
              Frequently Asked Questions
            </CardTitle>
            <CardDescription className="text-lg">
              Common questions about KLUTZ AI tools and services
            </CardDescription>
          </CardHeader>
          <CardContent>
            <Accordion type="multiple" className="w-full space-y-4">
              
              {/* General Questions */}
              <AccordionItem value="general-1" className="border rounded-lg px-4">
                <AccordionTrigger className="text-left">
                  What is KLUTZ and what tools does it offer?
                </AccordionTrigger>
                <AccordionContent>
                  KLUTZ is a comprehensive suite of AI-powered tools designed to help with various analysis and generation tasks. Our tools include:
                  <ul className="list-disc pl-6 mt-2 space-y-1">
                    <li><strong>MediScan AI</strong> - Medical image analysis</li>
                    <li><strong>AI Problem Solver</strong> - Academic problem solving</li>
                    <li><strong>AI Translator</strong> - Multi-language translation</li>
                    <li><strong>Text-to-Image Generator</strong> - Image creation from descriptions</li>
                    <li><strong>Thumbnail Checker</strong> - Content consistency analysis</li>
                    <li><strong>Content Ethnicity Certifier</strong> - Representation analysis</li>
                    <li><strong>Neurodiversity Checker</strong> - Accessibility assessment</li>
                    <li><strong>Heatmap Generator</strong> - Engagement visualization</li>
                    <li><strong>Appliance & Vehicle Troubleshooters</strong> - Diagnostic assistance</li>
                    <li><strong>Measuring Tool</strong> - Object measurement from images</li>
                    <li><strong>Ingredients Checker</strong> - Food safety analysis</li>
                    <li><strong>Image to Text Converter</strong> - Text extraction</li>
                    <li><strong>AI Date & Time Checker</strong> - Historical date analysis</li>
                  </ul>
                </AccordionContent>
              </AccordionItem>

              <AccordionItem value="general-2" className="border rounded-lg px-4">
                <AccordionTrigger className="text-left">
                  How do I get started with KLUTZ?
                </AccordionTrigger>
                <AccordionContent>
                  Getting started is simple:
                  <ol className="list-decimal pl-6 mt-2 space-y-1">
                    <li>Click "Login with Puter" to create or sign into your account</li>
                    <li>Choose any tool from the homepage</li>
                    <li>Upload your content (images, text, etc.) as required</li>
                    <li>Click the analysis button to get AI-powered results</li>
                    <li>Download reports or copy results as needed</li>
                  </ol>
                  No installation required - everything works in your browser!
                </AccordionContent>
              </AccordionItem>

              {/* MediScan AI */}
              <AccordionItem value="mediscan-1" className="border rounded-lg px-4">
                <AccordionTrigger className="text-left">
                  Is MediScan AI a replacement for professional medical advice?
                </AccordionTrigger>
                <AccordionContent>
                  <strong>No, absolutely not.</strong> MediScan AI is for informational purposes only and should never replace professional medical advice, diagnosis, or treatment. Always consult with qualified healthcare professionals for any medical concerns. The AI analysis is meant to provide general insights that may be helpful for educational purposes or preliminary review, but medical decisions should always be made by licensed medical professionals.
                </AccordionContent>
              </AccordionItem>

              <AccordionItem value="mediscan-2" className="border rounded-lg px-4">
                <AccordionTrigger className="text-left">
                  What types of medical images can I upload to MediScan AI?
                </AccordionTrigger>
                <AccordionContent>
                  MediScan AI supports various medical imaging formats including X-rays, MRI scans, CT scans, and ultrasounds. Supported file formats are PNG, JPEG, and DICOM files up to 10MB. For best results, ensure images are clear and properly oriented. Remove any personal identifying information before uploading.
                </AccordionContent>
              </AccordionItem>

              {/* AI Problem Solver */}
              <AccordionItem value="problem-solver-1" className="border rounded-lg px-4">
                <AccordionTrigger className="text-left">
                  What subjects does the AI Problem Solver support?
                </AccordionTrigger>
                <AccordionContent>
                  The AI Problem Solver supports a wide range of academic subjects including:
                  <ul className="list-disc pl-6 mt-2 space-y-1">
                    <li>Mathematics (Algebra, Calculus, Geometry, Trigonometry, Statistics)</li>
                    <li>Sciences (Physics, Chemistry, Biology)</li>
                    <li>Computer Science and Engineering</li>
                    <li>Economics and Logic</li>
                    <li>Word problems and reasoning tasks</li>
                  </ul>
                  You can upload images of problems or type them directly. Text input generally provides more reliable and accurate results than image analysis.
                </AccordionContent>
              </AccordionItem>

              <AccordionItem value="problem-solver-2" className="border rounded-lg px-4">
                <AccordionTrigger className="text-left">
                  Should I rely on AI Problem Solver solutions for my homework?
                </AccordionTrigger>
                <AccordionContent>
                  The AI Problem Solver is designed to assist learning, not replace it. Always verify solutions with teachers, textbooks, or other authoritative sources. Use it as a study aid to understand problem-solving approaches, but make sure you understand the concepts yourself. For important assignments or exams, double-check all work independently.
                </AccordionContent>
              </AccordionItem>

              {/* AI Translator */}
              <AccordionItem value="translator-1" className="border rounded-lg px-4">
                <AccordionTrigger className="text-left">
                  How many languages does the AI Translator support?
                </AccordionTrigger>
                <AccordionContent>
                  The AI Translator supports over 60 languages including major world languages like English, Spanish, French, German, Chinese, Japanese, Arabic, Hindi, and many others. You can translate text directly or extract and translate text from images. The tool also provides cultural context and alternative translations for better understanding.
                </AccordionContent>
              </AccordionItem>

              {/* Text-to-Image Generator */}
              <AccordionItem value="image-gen-1" className="border rounded-lg px-4">
                <AccordionTrigger className="text-left">
                  What kind of images can the Text-to-Image Generator create?
                </AccordionTrigger>
                <AccordionContent>
                  The Text-to-Image Generator can create a wide variety of images from text descriptions including:
                  <ul className="list-disc pl-6 mt-2 space-y-1">
                    <li>Photorealistic images and digital art</li>
                    <li>Various art styles (oil painting, watercolor, cartoon, anime, abstract)</li>
                    <li>Different aspect ratios (square, landscape, portrait, wide)</li>
                    <li>Custom scenes, objects, characters, and concepts</li>
                  </ul>
                  For best results, be specific about colors, style, composition, and mood in your descriptions.
                </AccordionContent>
              </AccordionItem>

              {/* Content Analysis Tools */}
              <AccordionItem value="content-1" className="border rounded-lg px-4">
                <AccordionTrigger className="text-left">
                  How accurate are the Content Ethnicity Certifier and Neurodiversity Checker?
                </AccordionTrigger>
                <AccordionContent>
                  These tools provide AI-generated assessments that should be critically reviewed with human expertise. They offer preliminary analysis for content creators but have limitations and potential biases. Always consult with neurodivergent individuals and cultural experts for comprehensive evaluations. Use these tools as starting points for discussion, not definitive judgments.
                </AccordionContent>
              </AccordionItem>

              <AccordionItem value="content-2" className="border rounded-lg px-4">
                <AccordionTrigger className="text-left">
                  What does the Heatmap Generator show?
                </AccordionTrigger>
                <AccordionContent>
                  The Heatmap Generator predicts user engagement patterns for images and text. For images, it identifies areas likely to attract high or low visual attention with approximate location markers. For text, it highlights segments with different engagement levels using color coding. These are AI predictions and should be combined with actual user testing for best results.
                </AccordionContent>
              </AccordionItem>

              {/* Troubleshooting Tools */}
              <AccordionItem value="troubleshoot-1" className="border rounded-lg px-4">
                <AccordionTrigger className="text-left">
                  Can the Appliance and Vehicle Troubleshooters replace professional repair services?
                </AccordionTrigger>
                <AccordionContent>
                  No, these tools provide general guidance only and should not replace professional inspection or repair services. For serious electrical issues, safety concerns, or complex mechanical problems, always consult qualified technicians or mechanics. The troubleshooters are meant to help with basic diagnostics and understanding potential issues.
                </AccordionContent>
              </AccordionItem>

              {/* Utility Tools */}
              <AccordionItem value="utility-1" className="border rounded-lg px-4">
                <AccordionTrigger className="text-left">
                  How accurate is the AI Measuring Tool?
                </AccordionTrigger>
                <AccordionContent>
                  The AI Measuring Tool provides estimates based on visual analysis and available reference points in images. Accuracy depends on image quality, perspective, and the presence of objects with known dimensions. For precise measurements, always use proper measuring tools. This tool is best for rough estimates and general sizing purposes.
                </AccordionContent>
              </AccordionItem>

              <AccordionItem value="utility-2" className="border rounded-lg px-4">
                <AccordionTrigger className="text-left">
                  Is the Ingredients Checker reliable for food safety decisions?
                </AccordionTrigger>
                <AccordionContent>
                  The Ingredients Checker provides AI analysis for informational purposes but should not be the sole basis for food safety decisions. Always verify ingredients with manufacturers and consult healthcare professionals for specific dietary needs or allergies. The tool is more accurate with ingredient labels than with images of actual food items, especially complex or unfamiliar dishes.
                </AccordionContent>
              </AccordionItem>

              <AccordionItem value="utility-3" className="border rounded-lg px-4">
                <AccordionTrigger className="text-left">
                  What can the AI Date & Time Checker tell me?
                </AccordionTrigger>
                <AccordionContent>
                  The AI Date & Time Checker can provide detailed information about any date from 1 AD to 2999 AD, including:
                  <ul className="list-disc pl-6 mt-2 space-y-1">
                    <li>What day of the week it was/is/will be</li>
                    <li>Historical events and cultural significance</li>
                    <li>Astronomical information and seasons</li>
                    <li>Calendar system details and millennium/century information</li>
                  </ul>
                  You can also find all dates in a specific month/year that fall on a particular day of the week.
                </AccordionContent>
              </AccordionItem>

              {/* Technical Questions */}
              <AccordionItem value="tech-1" className="border rounded-lg px-4">
                <AccordionTrigger className="text-left">
                  What happens to my uploaded images and data?
                </AccordionTrigger>
                <AccordionContent>
                  Your uploaded content is processed temporarily for AI analysis and is not permanently stored on our servers. Images and text are typically processed and discarded within minutes of upload. We use secure, encrypted transmission and do not share your content with third parties for training purposes. See our Privacy Policy for complete details.
                </AccordionContent>
              </AccordionItem>

              <AccordionItem value="tech-2" className="border rounded-lg px-4">
                <AccordionTrigger className="text-left">
                  Why do I need to sign in with Puter?
                </AccordionTrigger>
                <AccordionContent>
                  Puter authentication provides secure access to AI processing capabilities and ensures proper usage limits. It also allows us to provide personalized experiences while maintaining your privacy. Puter accounts are free to create and provide access to powerful AI models that power all KLUTZ tools.
                </AccordionContent>
              </AccordionItem>

              <AccordionItem value="tech-3" className="border rounded-lg px-4">
                <AccordionTrigger className="text-left">
                  What should I do if I get an error message?
                </AccordionTrigger>
                <AccordionContent>
                  If you encounter errors:
                  <ol className="list-decimal pl-6 mt-2 space-y-1">
                    <li>Try refreshing the page and attempting the action again</li>
                    <li>Check your internet connection</li>
                    <li>Ensure your uploaded files meet size and format requirements</li>
                    <li>If you see "usage limit" errors, try creating a new Puter account</li>
                    <li>Contact us if problems persist</li>
                  </ol>
                </AccordionContent>
              </AccordionItem>

              {/* Pricing and Limits */}
              <AccordionItem value="pricing-1" className="border rounded-lg px-4">
                <AccordionTrigger className="text-left">
                  Is KLUTZ free to use?
                </AccordionTrigger>
                <AccordionContent>
                  KLUTZ tools are free to use with Puter authentication. However, AI processing may have usage limits depending on your Puter account. If you encounter usage limits, you can create a new Puter account or check Puter's pricing for expanded access to AI capabilities.
                </AccordionContent>
              </AccordionItem>

              {/* Support */}
              <AccordionItem value="support-1" className="border rounded-lg px-4">
                <AccordionTrigger className="text-left">
                  How can I get help or report issues?
                </AccordionTrigger>
                <AccordionContent>
                  <div className="flex items-center space-x-2">
                    <Mail className="h-5 w-5 text-accent" />
                    <span>Contact us at: </span>
                    <a href="mailto:jeffrinjames99@gmail.com" className="text-primary hover:underline font-semibold">
                      jeffrinjames99@gmail.com
                    </a>
                  </div>
                  <p className="mt-2">
                    Please include details about the issue, which tool you were using, and any error messages you received. 
                    We aim to respond to all inquiries within 24-48 hours.
                  </p>
                </AccordionContent>
              </AccordionItem>

            </Accordion>
          </CardContent>
        </Card>
      </div>
    </div>
  );
    </>
)}


================================================
FILE: src/app/get-started/page.tsx
================================================
"use client";

import Head from 'next/head';
import { useState, useEffect, useRef } from 'react';
import { Input } from '@/components/ui/input';
import Link from 'next/link';
import Image from 'next/image';
import { ThemeToggle } from '@/components/theme-toggle'; // Import ThemeToggle
import LoginButton from '@/components/auth/login-button'; // Import LoginButton
import Sidebar from "@/components/layout/Sidebar";
import { preprocessImage } from '@/lib/image-utils';
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import Footer from '@/components/layout/footer';
import { ScrollArea } from '@/components/ui/scroll-area';
import { Separator } from '@/components/ui/separator';
import { useToast } from "@/hooks/use-toast";
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from "@/components/ui/select";
import { ScanLine, Layers, ShieldCheck, Brain, ThermometerIcon, ArrowRight, Zap, Car, Ruler, Sparkles, Utensils, XIcon, FileText, Languages, Calculator, Calendar, Mail, Shield, Eye, Package, HelpCircle, Cookie, Github, FileSpreadsheet, BarChart, Speech, AudioWaveform, Wand, GlobeIcon, CheckIcon, MenuIcon, Trash2Icon, Edit2Icon, User, PanelLeft } from 'lucide-react'; // Import Edit2Icon
import { FaRegEnvelope, FaYoutube, FaXTwitter, FaLinkedin, FaMedium, FaDiscord } from 'react-icons/fa6';

declare global {
  interface Window {
    puter: any; // Replace 'any' with a more specific type if available
  }
}

interface Message {
  id: number;
  text: string;
  sender: 'user' | 'bot';
}

interface Feature {
  icon: React.ElementType;
  title: string;
  description: string;
  href: string;
  isImplemented: boolean;
}

const cleanJsonString = (rawString: string): string => {
  let cleanedString = rawString.trim();
  if (cleanedString.startsWith("```json") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(7, cleanedString.length - 3).trim();
  } else if (cleanedString.startsWith("```") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(3, cleanedString.length - 3).trim();
  }
  return cleanedString;
};

const features: Feature[] = [
  {
    icon: FileText,
    title: 'Image to Text Converter',
    description: 'Extract and analyze all text content from images using AI-powered text recognition.',
    href: '/image-to-text',
    isImplemented: true,
  },
  {
    icon: Languages,
    title: 'AI Translator',
    description: 'Translate text from images or typed input with support for 60+ languages and cultural context.',
    href: '/ai-translator',
    isImplemented: true,
  },
  {
    icon: Calculator,
    title: 'AI Problem Solver',
    description: 'Get step-by-step solutions for math, science, and academic problems with detailed explanations.',
    href: '/ai-problem-solver',
    isImplemented: true,
  },
  {
    icon: Calendar,
    title: 'AI Date & Time Checker',
    description: 'Explore dates from any century or millennium and discover detailed historical and astronomical information.',
    href: '/ai-date-time-checker',
    isImplemented: true,
  },
  {
    icon: ScanLine,
    title: 'MediScan AI',
    description: 'Analyze medical images (X-rays, MRI, CT scans) using AI for insights.',
    href: '/mediscan',
    isImplemented: true,
  },
  {
    icon: Layers,
    title: 'Thumbnail Title Consistency Checker',
    description: 'Ensure your video thumbnails and titles are aligned for better engagement.',
    href: '/thumbnail-checker',
    isImplemented: true,
  },
  {
    icon: ShieldCheck,
    title: 'Content Ethnicity Certifier',
    description: 'Analyze content for ethical portrayal and representation related to ethnicity.',
    href: '/ethnicity-certifier',
    isImplemented: true,
  },
  {
    icon: Brain,
    title: 'Content Neurodiversity-Friendliness Checker',
    description: 'Assess content for neurodiversity inclusiveness and friendliness.',
    href: '/neurodiversity-checker',
    isImplemented: true,
  },
  {
    icon: ThermometerIcon,
    title: 'Content Heatmap Generator',
    description: 'Generate heatmaps to visualize user engagement on your content.',
    href: '/heatmap-generator',
    isImplemented: true,
  },
  {
    icon: Zap,
    title: 'Electronic Appliance Troubleshooter',
    description: 'AI-powered analysis of malfunctioning electronic devices for troubleshooting assistance.',
    href: '/appliance-troubleshooter',
    isImplemented: true,
  },
  {
    icon: Car,
    title: 'Vehicle Troubleshooter',
    description: 'AI-powered analysis of vehicle issues and malfunctions for diagnostic assistance.',
    href: '/vehicle-troubleshooter',
    isImplemented: true,
  },
  {
    icon: Ruler,
    title: 'AI Measuring Tool',
    description: 'Upload images of physical objects and get AI-powered measurements in your preferred metric system.',
    href: '/measuring-tool',
    isImplemented: true,
  },
  {
    icon: Sparkles,
    title: 'AI Text-to-Image Generator',
    description: 'Generate high-quality images from text descriptions using advanced AI technology.',
    href: '/text-to-image-generator',
    isImplemented: true,
  },
  {
    icon: Wand,
    title: 'AI Prompt Generator',
    description: 'Generate creative text prompts from images using AI analysis.',
    href: '/prompt-generator',
    isImplemented: true,
  },
  {
    icon: FileSpreadsheet,
    title: 'AI-Native Spreadsheets',
    description: 'Create and modify spreadsheets through natural language with an AI assistant that understands your data.',
    href: '/ai-spreadsheets',
    isImplemented: true,
  },
  {
    icon: BarChart,
    title: 'AI Native Infographics',
    description: 'Create data-driven infographics powered by AI for impactful visual storytelling.',
    href: '/ai-infographics',
    isImplemented: true,
  },
  {
    icon: AudioWaveform,
    title: 'AI Native Audio Editor',
    description: 'Edit and enhance audio files using AI-powered tools and natural language commands.',
    href: '/ai-audio-editor',
    isImplemented: true,
  },
  {
    icon: Speech,
    title: 'AI Text-to-Speech Generator',
    description: 'Convert text into natural-sounding speech using AI.',
    href: '/ai-text-to-speech',
    isImplemented: true,
  },
];


function ChatComponent({ messages, setMessages, currentChatId, setCurrentChatId, setChatSessions }: {
  messages: Message[];
  setMessages: React.Dispatch<React.SetStateAction<Message[]>>;
  currentChatId: string | null;
  setCurrentChatId: React.Dispatch<React.SetStateAction<string | null>>;
  setChatSessions: React.Dispatch<React.SetStateAction<ChatSession[]>>; // Added setChatSessions
}) {
  const [inputMessage, setInputMessage] = useState('');
  const scrollAreaRef = useRef<HTMLDivElement>(null);
  const [isAiChatReady, setIsAiChatReady] = useState(false);
  const { toast } = useToast();
  const [selectedModel, setSelectedModel] = useState<string>('gpt-4o-mini'); // State for selected model
  const [showUrlInput, setShowUrlInput] = useState(false); // State to control visibility of URL input
  const [urlInput, setUrlInput] = useState('');
  const [fetchedUrlContent, setFetchedUrlContent] = useState<string | null>(null); // State to store fetched URL content
  const [imageFile, setImageFile] = useState<File | null>(null);
  const [imageDataUrl, setImageDataUrl] = useState<string | null>(null);

  const availableModels: string[] = [ // Updated based on puter.com/docs
    'gpt-4o-mini',
    'gpt-4o',
    'o1',
    'o1-mini',
    'o1-pro',
    'o3',
    'o3-mini',
    'o4-mini',
    'gpt-4.1',
    'gpt-4.1-mini',
    'gpt-4.1-nano',
    'gpt-4.5-preview',
    'claude-sonnet-4',
    'claude-opus-4',
    'claude-3-7-sonnet',
    'claude-3-5-sonnet',
    'deepseek-chat', // Kept as is from your list
    'deepseek-reasoner', // Kept as is from your list
    // Updated Gemini model IDs based on your research
    'google/gemini-2.5-flash-preview',
    'google/gemini-2.5-flash-preview:thinking',
    'google/gemini-2.0-flash-lite-001',
    'google/gemini-2.0-flash-001',
    'google/gemini-pro-1.5', // This is likely what 'gemini-1.5-flash' mapped to
    'meta-llama/llama-4-maverick',
    'meta-llama/llama-4-scout',
    'meta-llama/llama-3.3-70b-instruct',
    'meta-llama/llama-3.2-3b-instruct',
    'meta-llama/llama-3.2-1b-instruct',
    'meta-llama/llama-3.1-8b-instruct',
    'meta-llama/llama-3.1-405b-instruct',
    'meta-llama/llama-3.1-70b-instruct',
    'meta-llama/llama-3-70b-instruct',
    'mistral-large-latest',
    'codestral-latest',
    // Adding other models from your research list if not already present or to use explicit names
    'google/gemma-2-27b-it',
    'grok-beta',
  ];

  useEffect(() => {
    // Scroll to the bottom of the chat when new messages are added
    if (scrollAreaRef.current) {
      scrollAreaRef.current.scrollTo({
        top: scrollAreaRef.current.scrollHeight,
        behavior: 'smooth',
      });
    }
  }, [messages]);

  useEffect(() => {
    let intervalId: NodeJS.Timeout | null = null;
    const maxAttempts = 100; // Try for about 20 seconds (100 * 200ms) -> Increased to 500ms interval, so 50 seconds total
    let attempts = 0;
    const intervalDuration = 500; // Increased interval duration

    const checkPuterReadiness = () => {
      attempts++;
      if (typeof window.puter?.ai?.chat === 'function') {
        setIsAiChatReady(true);
        // Add a message to the chat when the AI is ready ONLY if it's a new chat
         if (currentChatId === null) {
          setMessages(prevMessages => {
            // Avoid adding the "ready" message multiple times
            if (!prevMessages.some(msg => msg.text.includes("Your mind‚Äôs a powerful tool‚Äîwhat‚Äôs it working on?"))) {
              return [
                ...prevMessages,
                {
                  id: prevMessages.length + 1,
                  text: "Your mind‚Äôs a powerful tool‚Äîwhat‚Äôs it working on?",
                  sender: 'bot',
                },
              ];
            }
            return prevMessages;
          });
         }
        if (intervalId) clearInterval(intervalId);
      } else {
        console.warn('Puter.js SDK or AI chat functionality not yet loaded.');
        console.log(`Attempt ${attempts}:`);
        console.log('window.puter:', window.puter);
        console.log('window.puter.ai:', window.puter?.ai);
        console.log('window.puter.ai.chat:', window.puter?.ai?.chat);

        if (attempts >= maxAttempts && intervalId) {
          clearInterval(intervalId);
          console.error('Max attempts reached. Puter.js AI chat functionality not loaded.');
          toast({
            variant: "destructive",
            title: "AI Chat Error",
            description: "AI chat functionality could not be loaded. Please try refreshing.",
          });
        }
      }
    };

    // Start polling
    intervalId = setInterval(checkPuterReadiness, intervalDuration); // Check every 500ms

    // Clear interval on component unmount
    return () => {
      if (intervalId) clearInterval(intervalId);
    };
  }, [messages, currentChatId]); // Added currentChatId to dependencies

  const handleImageFileChange = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      setImageFile(file);
      try {
        const previewDataUrl = URL.createObjectURL(file);
        setImageDataUrl(previewDataUrl);
      } catch (error) {
        toast({ variant: "destructive", title: "Preview Error", description: "Could not generate image preview." });
        setImageDataUrl(null);
      }
    } else {
      setImageFile(null);
      setImageDataUrl(null);
    }
  };

  const handleSendMessage = async (messageText: string) => {
    if (messageText.trim() === '' && !fetchedUrlContent && !imageFile) return;

    const newUserMessage: Message = {
      id: messages.length + 1,
      text: messageText,
      sender: 'user',
    };

    const updatedMessages = [...messages, newUserMessage];
    setMessages(updatedMessages);
    setInputMessage('');
    // Clear the image states after sending
    setImageFile(null);
    setImageDataUrl(null);

    let chatSessionId = currentChatId;

    if (chatSessionId === null) {
      chatSessionId = `chat-${Date.now()}`; // Simple timestamp-based ID
      setCurrentChatId(chatSessionId);

      // Generate title for the new chat based on the first user message
      try {
        const titlePrompt = `Generate a concise title (4-6 words) for a chat session based on this user message: "${messageText}"`;
        const titleResponse = await window.puter.ai.chat(titlePrompt, { model: 'gpt-4o-mini' }); // Using a fast model for title generation
        const generatedTitle = titleResponse?.message?.content || titleResponse?.text || 'New Chat';
        // Save the initial session with the generated title
        await puter.kv.set(chatSessionId, JSON.stringify({ title: generatedTitle, messages: updatedMessages }));
        // No need to call fetchChatSessions here, it will be called by the effect in HomePage
      } catch (error) {
        console.error('Error generating chat title:', error);
        // Save with a default title if AI title generation fails
         await puter.kv.set(chatSessionId, JSON.stringify({ title: 'New Chat', messages: updatedMessages }));
      }

    }

    if (!isAiChatReady) {
      console.error('AI chat is not ready.');
      return; // Do not attempt to send if not ready
    }

    if (window.puter) {
      let isSignedIn = await window.puter.auth.isSignedIn();
      if (!isSignedIn) {
        await window.puter.auth.signIn();
        isSignedIn = await window.puter.auth.isSignedIn();
        if (!isSignedIn) {
          const botResponse: Message = {
            id: updatedMessages.length + 1,
            text: 'Authentication failed or was cancelled. Cannot process command.',
            sender: 'bot',
          };
          setMessages(prevMessages => [...prevMessages, botResponse]);
          return;
        }
      }

      // Add a temporary bot message to show streaming is in progress
      const streamingBotMessage: Message = {
        id: updatedMessages.length + 1,
        text: 'Recalling What Is Logic...', // Start with empty text
        sender: 'bot',
      };
      setMessages(prevMessages => [...prevMessages, streamingBotMessage]);

      let accumulatedText = '';
      const messageIdToUpdate = updatedMessages.length + 1; // The ID of the streaming bot message

      let finalMessage = messageText;
      // Include fetched URL content as context if available
      if (fetchedUrlContent) {
        finalMessage = `Context from URL: ${fetchedUrlContent}\n\nUser Query: ${messageText}`;
      }

      try {
        // Preprocess the image just before sending to the AI
        let imageToSend = null;
        if (imageFile) {
             imageToSend = await preprocessImage(imageFile, 1024); // Get the data URL
        }


        // Pass the image data as the second argument if available
        const streamResponse = await window.puter.ai.chat(finalMessage, imageToSend ? imageToSend : null, { model: selectedModel, stream: true });


        for await (const part of streamResponse) {
          let partText = '';
          if (part?.message?.content) {
            partText = part.message.content;
          } else if (part?.text) {
            partText = part.text;
          } else {
            console.warn('Unexpected streamed part structure:', part);
          }
          if (partText) {
            accumulatedText += partText;
            setMessages(prevMessages =>
              prevMessages.map(msg =>
                msg.id === messageIdToUpdate ? { ...msg, text: accumulatedText } : msg
              )
            );
          }
        }

         // After the first bot message is streamed and we are in a new chat, generate and save the title
         if (currentChatId === null && updatedMessages.length === 1 && updatedMessages[0].sender === 'user') {
             try {
               const titlePrompt = `Generate a concise title (4-6 words) for a chat session based on this user message: "${messageText}"`;
               const titleResponse = await window.puter.ai.chat(titlePrompt, { model: 'gpt-4o-mini' }); // Using a fast model for title generation
               const generatedTitle = titleResponse?.message?.content || titleResponse?.text || 'New Chat';

               // Fetch the latest messages including the AI's first response
               const latestMessages = messages.map(msg =>
                msg.id === messageIdToUpdate ? { ...msg, text: accumulatedText } : msg // Use accumulatedText for the bot message
               );
               const sessionToSave = { id: chatSessionId, title: generatedTitle, messages: [...updatedMessages, ...latestMessages.filter(msg => msg.sender === 'bot')] };

                // Update the session in KV with the new title
                await puter.kv.set(chatSessionId, JSON.stringify(sessionToSave));

                // Update the chatSessions state in HomePage to reflect the new title
                setChatSessions(prevSessions =>
                    prevSessions.map(session =>
                        session.id === chatSessionId ? { ...session, title: generatedTitle } : session
                    )
                );

             } catch (error) {
               console.error('Error generating and saving chat title:', error);
               // Even if title generation fails, save with a default title
                const latestMessages = messages.map(msg =>
                    msg.id === messageIdToUpdate ? { ...msg, text: accumulatedText } : msg // Use accumulatedText for the bot message
                );
                const sessionToSave = { id: chatSessionId, title: 'New Chat', messages: [...updatedMessages, ...latestMessages.filter(msg => msg.sender === 'bot')] };
               await puter.kv.set(chatSessionId, JSON.stringify(sessionToSave));
             }
         }

      } catch (error) {
        console.error(`Error during AI chat request for model "${selectedModel}":`, error);
        const botErrorResponse: Message = { id: messageIdToUpdate, text: `Error interacting with the AI model "${selectedModel}". Please try another model or try again later. Error details: ${error.message}`, sender: 'bot' };
        setMessages(prevMessages => [...prevMessages, botErrorResponse]);
        return;
      }
    }
  };


  // Function to handle sending the URL for fetching
  const handleSendUrl = async () => {
    if (urlInput.trim() === '') return;

    const userUrlMessage: Message = {
      id: messages.length + 1,
      text: `Visited URL: ${urlInput}`,
      sender: 'user',
    };
    // Add the URL message to the chat. We'll update its appearance later.
    setMessages(prevMessages => [...prevMessages, userUrlMessage]);
    setShowUrlInput(false); // Hide URL input after sending

    if (!isAiChatReady) {
      setUrlInput('');
      console.error('AI chat is not ready.');
      return;
    }

    if (window.puter) {
      let isSignedIn = await window.puter.auth.isSignedIn();
      if (!isSignedIn) {
        await window.puter.auth.signIn();
        isSignedIn = await window.puter.auth.isSignedIn();
        if (!isSignedIn) {
          const botResponse: Message = {
            id: messages.length + 2,
            text: 'Authentication failed or was cancelled. Cannot process command.',
            sender: 'bot',
          };
          setMessages(prevMessages => [...prevMessages, botResponse]);
          return;
        }
      }

      // Add a temporary bot message to show processing
      const processingMessageId = messages.length + 2;
      const processingMessage: Message = {
        id: processingMessageId,
        text: `Fetching content from ${urlInput}...`,
        sender: 'bot',
      };
      setMessages(prevMessages => [...prevMessages, processingMessage]);

      try {
        const fetchedContent = await fetchUrlContent(urlInput);
        setFetchedUrlContent(fetchedContent); // Store fetched content
        setUrlInput(''); // Clear URL input after successful fetch

        // Update the processing message to indicate success (or remove it)
        setMessages(prevMessages => prevMessages.filter(msg => msg.id !== processingMessageId));


      } catch (error) {
        console.error(`Error fetching URL content: ${error}`);
        // Handle errors, e.g., display an error message to the user
        // Update the processing message to an error message
        const botErrorResponse: Message = {
          id: processingMessageId,
          text: `Error fetching content from ${urlInput}. Details: ${error.message}`,
          sender: 'bot',
        };
        setMessages(prevMessages => messages.map(msg =>
          msg.id === processingMessageId ? botErrorResponse : msg
        ));
      }
    }
  };

  // Function to fetch URL content using the API route
  const fetchUrlContent = async (url: string): Promise<string> => {
    try {
      const response = await fetch('/api/fetch-url-content', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ url }),
      });
      const data = await response.json();
       if (response.ok) {
            return data.content || `Could not fetch content from ${url}.`;
       } else {
            // Handle API errors (e.g., website not found, server error)
           throw new Error(data.error || `API error fetching content from ${url}`);
       }

    } catch (error: any) {
      // Handle network errors or other exceptions
      throw new Error(`Error fetching content from ${url}. Details: ${error.message}`);
    }
  };


  // Function to clear fetched URL content
  const clearUrlContext = () => {
    setFetchedUrlContent(null);
  };

  return (
    <Card className="h-full flex flex-col">
      <CardContent className="flex-grow overflow-hidden p-4">
        <ScrollArea ref={scrollAreaRef} className="h-full pr-4">
          {messages.map(message => (
            <div key={message.id} className={`mb-2 ${message.sender === 'user' ? 'text-right' : 'text-left'} ${message.text.startsWith('Visited URL:') ? 'flex justify-center' : ''}`}>
              {message.text.startsWith('Visited URL:') ? (
                // Display URL in a green box for user messages
                <span className="inline-block p-2 rounded-lg bg-green-500 text-white">
                  {message.text}
                </span>
              ) : (
                <span className={`inline-block p-2 rounded-lg ${message.sender === 'user' ? 'bg-blue-500 text-white' : 'bg-gray-200 text-gray-800'}`}>
                  {message.text}
                </span>
              )}
            </div>
          ))}
           {/* Display "Thinking..." indicator */}
           {/* You would add logic here to show a typing indicator when the bot is generating a response */}
        </ScrollArea>
      </CardContent>
      <div className="p-4 border-t flex flex-col gap-2">
        <div className="flex items-center gap-2">
          <Input
            placeholder="Don't Think‚ÄîAsk!"
            value={inputMessage}
 onChange={(e) => setInputMessage(e.target.value)}
            onKeyPress={(e) => {
              if (e.key === 'Enter' && inputMessage.trim() !== '') {
                if (isAiChatReady && !showUrlInput) {
                  handleSendMessage(inputMessage);
                }
              }
            }}
 className="flex-grow border-none bg-transparent focus-visible:ring-0 focus-visible:ring-offset-0 px-0 shadow-none"
            disabled={!isAiChatReady}
          />
          {/* File input for image upload */}
          {/* Removed Button wrapper */}
          <label htmlFor="image-upload" className="cursor-pointer">
            {/* Added mr-2 for right margin to create spacing */}
            <div className="flex items-center justify-center mr-2"> {/* Added a wrapper div for centering and margin */}
              <input id="image-upload" type="file" accept="image/*" onChange={handleImageFileChange} className="hidden" disabled={!isAiChatReady || showUrlInput} />
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round" className="lucide lucide-image h-5 w-5"> {/* Modified size classes to h-5 w-5 */}
                <rect width="18" height="18" x="3" y="3" rx="2" ry="2"/>
                <circle cx="9" cy="9" r="2"/>
                <path d="m21 15-3.086-3.086a2 2 0 0 0-2.828 0L6 21"/>
              </svg> {/* Icon for image upload */}
            </div>
          </label>

          {/* Display image preview if available */}
          {imageDataUrl && (
              <div className="relative">
                <Image
                  src={imageDataUrl}
                  alt="Image preview"
                  width={100} // Adjust size as needed
                  height={100} // Adjust size as needed
                  objectFit="cover"
                  className="rounded"
                />
                
                <Button
                  variant="destructive"
                  size="icon"
                  className="absolute top-0 right-0 h-5 w-5 p-0 rounded-full"
                  onClick={() => {
                      setImageFile(null);
                      setImageDataUrl(null);
                  }}
                  aria-label="Remove image"
                >
                  <XIcon className="h-3 w-3" />
                </Button>
              </div>
            )}

            {/* URL Visit Icon - Removed Button wrapper */}
            {/* Added mr-2 for right margin to create spacing */}
            <GlobeIcon
 className={`h-5 w-5 cursor-pointer mr-2 ${!isAiChatReady || showUrlInput ? 'text-gray-500' : 'text-current'}`}
 onClick={() => setShowUrlInput(!showUrlInput)}
 />
            {/* Model Select */}
            {/* Added mr-2 for right margin to create spacing */}
            <Select onValueChange={setSelectedModel} defaultValue={selectedModel} disabled={!isAiChatReady}>
              <SelectTrigger className="w-[180px] border-none focus:ring-0 focus:ring-offset-0 shadow-none bg-transparent px-0 mr-2"> {/* Added mr-2 */}
                <SelectValue placeholder="Select Model" />
              </SelectTrigger>
              <SelectContent>
                {availableModels.map(model => (
                  <SelectItem key={model} value={model}>{model}</SelectItem>
                ))}
              </SelectContent>
            </Select>
            {/* Send Icon - Removed Button wrapper */}
            {/* Added mr-2 for right margin to create spacing */}
            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round" className={`lucide lucide-send h-5 w-5 cursor-pointer mr-2 ${!isAiChatReady || inputMessage.trim() === '' || showUrlInput ? 'text-gray-500' : 'text-current'}`} onClick={() => handleSendMessage(inputMessage)}>
              <path d="m22 2-7 20-4-9-9-4 20-7Z"/><path d="M15 7l4 4"/>
            </svg>
             {/* Optional: Add a button to clear URL context */}
             {fetchedUrlContent &&
             <Button variant="destructive" onClick={clearUrlContext}>
              <XIcon className="h-5 w-5">Remove URL</XIcon>
            </Button>
          }
        </div>
        {/* Conditional URL Input */}
        {showUrlInput && (
          <div className="flex gap-2">
            <Input
              placeholder="https://example.com"
              value={urlInput}
              onChange={(e) => setUrlInput(e.target.value)}
              onKeyPress={(e) => {
                if (e.key === 'Enter' && urlInput.trim() !== '') {
                  if (isAiChatReady) {
                    handleSendUrl();
                  }
                }
              }}
              className="flex-grow"
              disabled={!isAiChatReady}
            />
            <Button
              variant="outline"
              size="icon"
              onClick={handleSendUrl}
              disabled={!isAiChatReady || urlInput.trim() === ''}
            >
              <CheckIcon className="h-5 w-5" /> {/* Using CheckIcon for confirmation */}
            </Button>
          </div>
        )}
      </div>
    </Card>
  );
}


export default function HomePage() {
  const [isSidebarOpen, setIsSidebarOpen] = useState(false);
  const [chatSessions, setChatSessions] = useState<ChatSession[]>([]);
  const [currentChatId, setCurrentChatId] = useState<string | null>(null);
  const [messages, setMessages] = useState<Message[]>([]);
  const [editingSessionId, setEditingSessionId] = useState<string | null>(null); // State to track which session is being edited
  const [newSessionTitle, setNewSessionTitle] = useState(''); // State to hold the new title during editing
  const [openMobile, setOpenMobile] = useState(false); // State to manage mobile sidebar visibility

  // Function to toggle mobile sidebar
  const toggleMobileSidebar = () => {
    setOpenMobile(!openMobile);
  };


  // Function to fetch chat sessions from KV store
  const fetchChatSessions = async () => {
    try {
      const sessions = await puter.kv.list(true); // list all keys with returnValues = true
      const formattedSessions: ChatSession[] = sessions
        .filter((session: any) => session.key.startsWith('chat-')) // Filter for chat session keys
        .map((session: any) => {
          let parsedValue;
          try {
            parsedValue = JSON.parse(session.value);
          } catch (e) {
            console.error(`Error parsing session data for key ${session.key}:`, e);
            parsedValue = { title: 'Invalid Session Data', messages: [] }; // Provide a default
          }
          return {
            id: session.key,
            title: parsedValue.title || `Session ${session.key}`, // Use saved title or default
            messages: parsedValue.messages || [], // Use saved messages or empty array
          };
        });
      setChatSessions(formattedSessions);
    } catch (error) {
      console.error('Error fetching chat sessions:', error);
    }
  };

  const handleImageFileChange = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      setImageFile(file);
      try {
        const previewDataUrl = URL.createObjectURL(file);
        setImageDataUrl(previewDataUrl);
      } catch (error) {
        toast({ variant: "destructive", title: "Preview Error", description: "Could not generate image preview." });
        setImageDataUrl(null);
      }
    } else {
      setImageFile(null);
      setImageDataUrl(null);
    }
  };

  // Function to save a chat session to KV store
  const saveChatSession = async (session: ChatSession) => {
    try {
      await puter.kv.set(session.id, JSON.stringify({ title: session.title, messages: session.messages }));
      fetchChatSessions(); // Refresh the sidebar after saving
    } catch (error) {
      console.error('Error saving chat session:', error);
    }
  };

  // Function to load a specific chat session
  const loadChatSession = async (sessionId: string) => {
    try {
      const sessionData = await puter.kv.get(sessionId);
      if (sessionData) {
        const session: ChatSession = JSON.parse(sessionData as string); // Assuming sessionData is a JSON string
        setCurrentChatId(sessionId);
        setMessages(session.messages);
      }
    } catch (error) {
      console.error('Error loading chat session:', error);
    }
  };

  // Function to delete a specific chat session
  const deleteChatSession = async (sessionId: string) => {
    try {
      await puter.kv.del(sessionId);
      fetchChatSessions(); // Refresh the sidebar after deleting
      // If the deleted session was the currently active one, start a new chat
      if (currentChatId === sessionId) {
        startNewChat();
      }
    } catch (error) {
      console.error('Error deleting chat session:', error);
    }
  };

  // Function to handle renaming a chat session
  const renameChatSession = async (sessionId: string, newTitle: string) => {
    if (newTitle.trim() === '') {
      // Optionally handle empty titles, maybe revert to a default or show an error
      console.warn('Attempted to rename with an empty title.');
      return;
    }
    try {
      // Fetch the existing session data to preserve messages
      const sessionData = await puter.kv.get(sessionId);
      if (sessionData) {
        const session: ChatSession = JSON.parse(sessionData as string);
        session.title = newTitle; // Update the title
        await puter.kv.set(sessionId, JSON.stringify(session)); // Save the updated session
        fetchChatSessions(); // Refresh the sidebar
        setEditingSessionId(null); // Exit editing mode
        setNewSessionTitle(''); // Clear the input field
      }
    } catch (error) {
      console.error('Error renaming chat session:', error);
    }
  };

  // Check if the title is still the default AI greeting
  const currentSessionTitle = chatSessions.find(session => session.id === currentChatId)?.title;
  if (currentSessionTitle === "Your mind‚Äôs a powerful tool‚Äîwhat‚Äôs it working on?") {
    // Don't update the title here if it's the default
    const currentSession: ChatSession = {
       id: currentChatId,
       title: currentSessionTitle, // Keep the existing title
       messages: messages,
     };
    saveChatSession(currentSession);
  } else {
    // If a custom title exists (generated by AI or manually), save with that title
    const currentSession: ChatSession = {
       id: currentChatId,
       title: currentSessionTitle || 'New Chat', // Use existing title or default
       messages: messages,
     };
    saveChatSession(currentSession);
  }


  // Function to start a new chat session
  const startNewChat = () => {
    setCurrentChatId(null);
    setMessages([]);
  };

  // Handle starting edit mode
  const startEditing = (session: ChatSession) => {
    setEditingSessionId(session.id);
    setNewSessionTitle(session.title);
  };

  // Handle cancelling edit mode
  const cancelEditing = () => {
    setEditingSessionId(null);
    setNewSessionTitle('');
  };

  // Function to close mobile sidebar
  const closeMobileSidebar = () => {
    setOpenMobile(false);
  };

  // Handle saving the new title
  const handleTitleSave = (sessionId: string) => {
    renameChatSession(sessionId, newSessionTitle);
  };


  useEffect(() => {
    // Fetch chat sessions when the component mounts
    fetchChatSessions();

  }, []); // Empty dependency array ensures this runs only once

  // Effect to save the current chat session whenever messages change, but only if currentChatId is set
  useEffect(() => {
    if (currentChatId && messages.length > 0) {
       // Find the current session to get its latest title from the state
       const currentSessionInState = chatSessions.find(session => session.id === currentChatId);

       // Only save if the session is found and has a title that is not the default "New Chat"
       // OR if it's a brand new chat with the first message already sent (title is being generated)
       if (currentSessionInState && (currentSessionInState.title !== 'New Chat' || messages.length > 1 || (messages.length === 1 && messages[0].sender === 'bot' && !messages[0].text.includes("Your mind‚Äôs a powerful tool‚Äîwhat‚Äôs it working on?")))) {
           const currentSession: ChatSession = {
             id: currentChatId,
             title: currentSessionInState.title, // Use the title from the current state
             messages: messages,
           };
           saveChatSession(currentSession);
       } else if (currentChatId && messages.length > 0 && messages[0].sender === 'user' && messages.length === 1) {
           // This case handles the initial save for a new chat while the title is being generated in ChatComponent
           // We don't need to save the title here, ChatComponent handles the initial save with the generated title.
           // We just need to ensure subsequent messages in this new chat are saved.
           const currentSession: ChatSession = {
             id: currentChatId,
             title: 'New Chat', // Use default title for the initial save
             messages: messages,
           };
           saveChatSession(currentSession);
       }
    }
  }, [messages, currentChatId, chatSessions]); // Added chatSessions to dependencies


  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/" />
        <meta name="google-site-verification" content="FVYY2_q5JUQa1Oqg8XGj4v2wqB4F1BcREDn_ZVlwNCA" />
      </Head>
      <div className="min-h-screen flex flex-col">
        {/* Scrim for mobile */}
        {openMobile && <div className="md:hidden fixed inset-0 bg-black opacity-50 z-30" onClick={closeMobileSidebar}></div>}

        <div className="flex flex-grow"> {/* Use flex to arrange sidebar and main content */}
          {/* Desktop Header Elements - Positioned at the top-right */}
          <div className="absolute top-4 right-4 z-20 flex items-center gap-4">
            <Button variant="ghost" size="icon" onClick={() => setIsSidebarOpen(true)}>
              <MenuIcon className="h-5 w-5" />
              <span className="sr-only">Toggle Sidebar</span>
            </Button>
            <ThemeToggle />
            <Button variant="ghost" size="icon" asChild>
              <Link href="https://puter.com">
                <User className="h-5 w-5" />
                <span className="sr-only">Account</span>
              </Link>
            </Button>
            <LoginButton />
          </div>
          {isSidebarOpen && <Sidebar isOpen={isSidebarOpen} onClose={() => setIsSidebarOpen(false)} />}

          {/* Sidebar */}
          <div // Adjusted sidebar height to end before the footer (assuming footer height is around 64px or h-16)
            // Adjusted sidebar height to end before the footer (assuming footer height is around 64px or h-16) and added mobile/desktop classes
            className={`fixed top-0 left-0 w-64 h-[calc(100vh-4rem)] bg-gray-800 text-white overflow-y-auto transition-transform transform md:relative md:translate-x-0 pt-16 md:pt-4 ${
              openMobile ? 'translate-x-0' : '-translate-x-full' // Use openMobile state for mobile transform
            } z-40 rounded-bl-xl`} // Added fixed positioning, z-index for mobile, and rounded bottom left corner
          >
            <div className="p-4">
              <h2 className="text-xl font-bold mb-4">Chat History</h2>
              {/* New Chat Button - Added mb-6 for more spacing */}
              <Button onClick={startNewChat} className="w-full mb-6">New Chat</Button>
              <ul>
                {chatSessions.map((session) => (
                  <li key={session.id} className="mb-2 flex justify-between items-center">
                    {editingSessionId === session.id ? (
                      // Editing mode: show input field and save/cancel buttons
                      <div className="flex items-center w-full">
                        <Input
                          value={newSessionTitle}
                          onChange={(e) => setNewSessionTitle(e.target.value)}
                          onKeyPress={(e) => handleEditKeyPress(e, session.id)}
                          className="flex-grow mr-2 text-blue-400 bg-gray-700 border-gray-600"
                        />
                        <Button
                          variant="ghost"
                          size="icon"
                          className="text-green-500 hover:text-green-700 h-6 w-6 p-0 mr-1"
                          onClick={() => handleTitleSave(session.id)}
                          aria-label={`Save new title for ${session.title}`}
                        >
                          <CheckIcon className="h-4 w-4" />
                        </Button>
                        <Button
                          variant="ghost"
                          size="icon"
                          className="text-red-500 hover:text-red-700 h-6 w-6 p-0"
                          onClick={cancelEditing}
                          aria-label="Cancel renaming"
                        >
                          <XIcon className="h-4 w-4" /> {/* Using XIcon for cancel */}
                        </Button>
                      </div>
                    ) : (
                      // Reading mode: show title, edit button, and delete button
                      <>
                        <button
                          className="text-blue-400 hover:underline text-left flex-grow mr-2"
                          onClick={() => loadChatSession(session.id)}
                        >
                          {session.title}
                        </button>
                        <Button
                          variant="ghost"
                          size="icon"
                          className="text-gray-400 hover:text-gray-100 h-6 w-6 p-0 mr-1" // Styled edit button
                          onClick={() => startEditing(session)}
                          aria-label={`Rename chat session: ${session.title}`}
                        >
                          <Edit2Icon className="h-4 w-4" />
                        </Button>
                        <Button
                          variant="ghost"
                          size="icon"
                          className="text-red-500 hover:text-red-700 h-6 w-6 p-0"
                          onClick={() => deleteChatSession(session.id)}
                          aria-label={`Delete chat session: ${session.title}`}
                        >
                          <Trash2Icon className="h-4 w-4" />
                        </Button>
                      </>
                    )}
                  </li>
                ))}
              </ul>
            </div>
          </div>

          {/* Main Content */}
          <main className="flex-grow flex flex-col"> {/* Main content area */}
            <div className="container mx-auto max-w-3xl px-4 sm:px-6 lg:px-8 pt-24 md:pt-12 flex-grow pb-32">
              {/* Mobile menu button - Fixed at top-left, below header */}
              <div className="md:hidden fixed top-4 left-4 z-50"> {/* Adjusted positioning to top-4 */}
                {/* Mobile menu icon - Positioned absolutely within this container for mobile */}
                <Button variant="outline" size="icon" onClick={toggleMobileSidebar} aria-label="Toggle Menu">
                  <PanelLeft className="h-6 w-6" />
                </Button>
                  
                
              </div>
              <div className="mb-8">
                {/* Pass down state and functions to ChatComponent */}
                <ChatComponent
                  messages={messages}
                  setMessages={setMessages}
                  currentChatId={currentChatId}
                  setCurrentChatId={setCurrentChatId}
                />
              </div>
              {/* Tools Section */}
              <section className="mt-12">
                <nav className="text-3xl md:text-4xl font-bold text-center text-primary mb-8 hidden md:flex items-center gap-6 mx-auto">
                  <Link href="/testimonials" className="text-sm font-medium hover:underline">Testimonials</Link>
                </nav>
                <div className="flex flex-col items-center space-y-4">
                  {/* Row 1: 8 buttons */}
                  <div className="flex flex-wrap justify-center gap-4 max-w-4xl">
                    {features.slice(0, 8).map((feature) => (
                      <Link key={feature.title} href={feature.href} passHref>
                        <Button variant="outline" className="flex items-center gap-2 p-4 h-auto rounded-lg shadow-sm hover:bg-muted transition-colors">
                          <feature.icon className="h-5 w-5 text-primary" />
                          <span className="text-sm font-medium">{feature.title}</span>
                        </Button>
                      </Link>
                    ))}
                  </div>
                  {/* Row 2: 6 buttons */}
                  <div className="flex flex-wrap justify-center gap-4 max-w-4xl">
                    {features.slice(8, 14).map((feature) => (
                      <Link key={feature.title} href={feature.href} passHref>
                        <Button variant="outline" className="flex items-center gap-2 p-4 h-auto rounded-lg shadow-sm hover:bg-muted transition-colors">
                          <feature.icon className="h-5 w-5 text-primary" />
                          <span className="text-sm font-medium">{feature.title}</span>
                        </Button>
                      </Link>
                    ))}
                  </div>
                  {/* Row 3: 4 buttons */}
                  <div className="flex flex-wrap justify-center gap-4 max-w-4xl">
                    {features.slice(14, features.length).map((feature) => (
                      <Link key={feature.title} href={feature.href} passHref>
                      <Button variant="outline" className="flex items-center gap-2 p-4 h-auto rounded-lg shadow-sm hover:bg-muted transition-colors">
                        <feature.icon className="h-5 w-5 text-primary" />
                        <span className="text-sm font-medium">{feature.title}</span>
                      </Button>
                    </Link>
                  ))}
                </div>
              </div>
            </section>
          </div>
        </main>
      </div>

      <Footer />
    </div>
   </> 
  );
}


================================================
FILE: src/app/heatmap-generator/page.tsx
================================================

'use client';

import Head from 'next/head';
import { useState, useEffect } from 'react';
import { useToast } from "@/hooks/use-toast";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from "@/components/ui/card";
import { Textarea } from "@/components/ui/textarea";
import { Input } from "@/components/ui/input";
import { Label } from "@/components/ui/label";
import { Alert, AlertDescription, AlertTitle } from "@/components/ui/alert";
import { Tabs, TabsContent, TabsList, TabsTrigger } from "@/components/ui/tabs";
import { Loader2, ImageUp, Type, Thermometer, AlertTriangle, Info, Eye, FileTextIcon, Sparkles, Pin, CircleHelp, Download } from 'lucide-react';
import { preprocessImage } from '@/lib/image-utils';
import { downloadTextFile } from '@/lib/utils';
import ImagePreview from '@/components/medi-scan/image-preview';
import type { ImageHeatmapReport, TextHeatmapReport, ImageAttentionArea } from '@/types/heatmap-generator';

const cleanJsonString = (rawString: string): string => {
  let cleanedString = rawString.trim();
  if (cleanedString.startsWith("```json") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(7, cleanedString.length - 3).trim();
  } else if (cleanedString.startsWith("```") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(3, cleanedString.length - 3).trim();
  }
  return cleanedString;
};

export default function HeatmapGeneratorPage() {
  const [inputType, setInputType] = useState<'image' | 'text'>('image');
  const [imageFile, setImageFile] = useState<File | null>(null);
  const [imageDataUrl, setImageDataUrl] = useState<string | null>(null);
  const [textInput, setTextInput] = useState<string>('');
  const [textFile, setTextFile] = useState<File | null>(null);

  const [imageReport, setImageReport] = useState<ImageHeatmapReport | null>(null);
  const [textReport, setTextReport] = useState<TextHeatmapReport | null>(null);
  
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const { toast } = useToast();

  useEffect(() => {
    if (typeof window.puter === 'undefined') {
      toast({
        variant: "destructive",
        title: "Puter SDK Error",
        description: "Puter.js SDK is not loaded. Please refresh the page.",
      });
    }
  }, [toast]);

  const handleImageFileChange = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      setImageFile(file);
      try {
        const previewDataUrl = URL.createObjectURL(file);
        setImageDataUrl(previewDataUrl);
        setImageReport(null); 
        setError(null);
      } catch (previewError) {
        toast({ variant: "destructive", title: "Preview Error", description: "Could not generate image preview." });
        setImageDataUrl(null);
      }
    } else {
      setImageFile(null);
      setImageDataUrl(null);
    }
  };

  const handleTextInputChange = (event: React.ChangeEvent<HTMLTextAreaElement>) => {
    setTextInput(event.target.value);
    setTextReport(null);
    setError(null);
  };

  const handleTextFileChange = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      if (file.type === 'text/plain') {
        setTextFile(file);
        try {
          const textContent = await file.text();
          setTextInput(textContent);
          setTextReport(null);
          setError(null);
        } catch (readError) {
          toast({ variant: "destructive", title: "File Read Error", description: "Could not read the text file." });
        }
      } else {
        toast({ variant: "destructive", title: "Invalid File Type", description: "Please upload a .txt file for text analysis." });
        event.target.value = '';
      }
    } else {
      setTextFile(null);
    }
  };

  const performAnalysis = async () => {
    if (inputType === 'image' && !imageFile) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please upload an image." });
      return;
    }
    if (inputType === 'text' && !textInput.trim()) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please provide text." });
      return;
    }

    setIsLoading(true);
    setImageReport(null);
    setTextReport(null);
    setError(null);
    toast({ title: "Analysis Started", description: "AI is generating engagement insights..." });

    try {
      if (typeof window.puter === 'undefined' || !window.puter.auth || !window.puter.ai) {
        throw new Error("Puter SDK not available. Please refresh.");
      }
      const puter = window.puter;

      let isSignedIn = await puter.auth.isSignedIn();
      if (!isSignedIn) {
        await puter.auth.signIn();
        isSignedIn = await puter.auth.isSignedIn();
        if (!isSignedIn) throw new Error("Authentication failed or was cancelled.");
      }
      
      if (inputType === 'image' && imageFile) {
        const processedImageUrl = await preprocessImage(imageFile, 1024);
        const imagePrompt = `
          You are an AI assistant specializing in predicting visual attention in images.
          First, provide a general description of the image content.
          Then, analyze this image to identify areas likely to attract high visual attention and areas likely to receive low visual attention. For each area, briefly explain why it is engaging or not.
          Also, try to provide a general location_hint for each area identified, using one of the following: 'center', 'top-center', 'bottom-center', 'left-center', 'right-center', 'top-left', 'top-right', 'bottom-left', 'bottom-right'. If a precise hint isn't possible, you can use a more general textual description for location_hint or leave it empty.
          Provide your findings in a JSON object with the following structure:
          {
            "image_description": "string (A brief overall description of the image content.)",
            "high_attention_areas": [
              { "area_description": "string (e.g., 'The bright red apple')", "reason": "string (e.g., 'Color contrast')", "attention_level": "high", "location_hint": "string (e.g., 'center' or 'top-left or textual hint like 'around the main subject's eyes')" }
            ],
            "low_attention_areas": [
              { "area_description": "string (e.g., 'The blurry background foliage')", "reason": "string (e.g., 'Out of focus')", "attention_level": "low", "location_hint": "string (e.g., 'bottom-right' or 'background area')" }
            ],
            "confidence": "string (One of 'High', 'Medium', 'Low')",
            "disclaimer": "string (AI-predicted engagement is subjective. Location hints are approximate. Use as a guide.)"
          }
          Focus on descriptive locations rather than precise coordinates.
        `;
        const response = await puter.ai.chat(imagePrompt, processedImageUrl);
        if (!response?.message?.content) throw new Error("AI analysis for image did not return content.");
        const parsedResponse: ImageHeatmapReport = JSON.parse(cleanJsonString(response.message.content));
        setImageReport(parsedResponse);
      } else if (inputType === 'text' && textInput.trim()) {
        const textPrompt = `
          You are an AI assistant specializing in analyzing text engagement.
          Analyze the following text for predicted user engagement: "${textInput}"
          Segment the text into meaningful phrases or short sentences. For each segment, assign an engagement level ('high', 'medium', 'low', 'neutral') and optionally a brief reason.
          Also provide an overall summary of the text's engagement potential.
          Provide your findings in a JSON object with the following structure:
          {
            "overall_summary": "string (A brief summary of the text's overall engagement potential.)",
            "segments": [
              { "segment": "string (The text segment)", "engagement_level": "string ('high'|'medium'|'low'|'neutral')", "reason": "string (optional explanation)" }
            ],
            "confidence": "string (One of 'High', 'Medium', 'Low')",
            "disclaimer": "string (AI-predicted engagement is subjective. Use as a guide.)"
          }
        `;
        const response = await puter.ai.chat(textPrompt, { model: 'gpt-4o' });
        if (!response?.message?.content) throw new Error("AI analysis for text did not return content.");
        const parsedResponse: TextHeatmapReport = JSON.parse(cleanJsonString(response.message.content));
        setTextReport(parsedResponse);
      }
      toast({ title: "Analysis Complete", variant: "default", className: "bg-green-500 text-white dark:bg-green-600" });
    } catch (err: any) {
      console.error("Analysis error:", err);
      let errorMessage = "An error occurred during analysis.";
      if (err instanceof Error) errorMessage = err.message;
      else if (typeof err === 'string') errorMessage = err;
      else if (err.error && err.error.message) errorMessage = err.error.message;
      setError(errorMessage);
      toast({ variant: "destructive", title: "Analysis Failed", description: errorMessage });
    } finally {
      setIsLoading(false);
    }
  };

  const handleDownloadReport = () => {
    let reportString = "KLUTZ Content Engagement Heatmap Report\n";
    reportString += "=========================================\n\n";
    let reportTypeForFilename: string;

    if (inputType === 'image' && imageReport) {
      reportTypeForFilename = 'Image_Engagement';
      reportString += `Input Type: Image\n`;
      if (imageFile) reportString += `Original Filename: ${imageFile.name}\n\n`;
      
      reportString += "Image Description:\n";
      reportString += "------------------\n";
      reportString += `${imageReport.image_description || "N/A"}\n\n`;

      reportString += "Identified High Attention Areas:\n";
      reportString += "--------------------------------\n";
      if (imageReport.high_attention_areas && imageReport.high_attention_areas.length > 0) {
        imageReport.high_attention_areas.forEach(area => {
          reportString += `- Area: ${area.area_description}\n`;
          reportString += `  Reason: ${area.reason}\n`;
          if (area.location_hint) reportString += `  Approx. Location: ${area.location_hint}\n`;
          reportString += "\n";
        });
      } else {
        reportString += "No specific high attention areas identified by AI.\n\n";
      }

      reportString += "Identified Low Attention Areas:\n";
      reportString += "-------------------------------\n";
      if (imageReport.low_attention_areas && imageReport.low_attention_areas.length > 0) {
        imageReport.low_attention_areas.forEach(area => {
          reportString += `- Area: ${area.area_description}\n`;
          reportString += `  Reason: ${area.reason}\n`;
          if (area.location_hint) reportString += `  Approx. Location: ${area.location_hint}\n`;
          reportString += "\n";
        });
      } else {
        reportString += "No specific low attention areas identified by AI.\n\n";
      }
      reportString += `AI Confidence: ${imageReport.confidence || "N/A"}\n`;
      reportString += `Disclaimer: ${imageReport.disclaimer || "N/A"}\n`;

    } else if (inputType === 'text' && textReport) {
      reportTypeForFilename = 'Text_Engagement';
      reportString += `Input Type: Text\n\n`;
      
      reportString += "Overall Summary of Text Engagement:\n";
      reportString += "-----------------------------------\n";
      reportString += `${textReport.overall_summary || "N/A"}\n\n`;

      reportString += "Segment Engagement Analysis:\n";
      reportString += "----------------------------\n";
      if (textReport.segments && textReport.segments.length > 0) {
        textReport.segments.forEach(segment => {
          reportString += `- Segment: "${segment.segment}"\n`;
          reportString += `  Engagement: ${segment.engagement_level}\n`;
          if (segment.reason) reportString += `  Reason: ${segment.reason}\n`;
          reportString += "\n";
        });
      } else {
        reportString += "No text segments analyzed.\n\n";
      }
      reportString += `AI Confidence: ${textReport.confidence || "N/A"}\n`;
      reportString += `Disclaimer: ${textReport.disclaimer || "N/A"}\n`;
    } else {
      return; 
    }
    
    reportString += "\n\nImportant Note: AI-predicted engagement is an estimation and can be subjective. It may not reflect actual user behavior or specific audience preferences. Use these insights as a guide, not a definitive measure.";

    const timestamp = new Date().toISOString().replace(/[:.-]/g, '').slice(0, 14);
    downloadTextFile(reportString, `KLUTZ_Heatmap_${reportTypeForFilename}_Report_${timestamp}.txt`);
  };

  const getEngagementColor = (level: 'high' | 'medium' | 'low' | 'neutral' | undefined) => {
    switch (level) {
      case 'high': return 'bg-red-500/70 text-white'; 
      case 'medium': return 'bg-orange-400/70 text-white';
      case 'low': return 'bg-yellow-300/70 text-yellow-900';
      case 'neutral': return 'bg-blue-200/70 text-blue-900'; 
      default: return 'bg-gray-200/70 text-gray-800';
    }
  };

  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/heatmap-generator" />
      </Head>
    <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-8">
      <Card className="max-w-3xl mx-auto shadow-xl">
        <CardHeader>
          <CardTitle className="font-headline text-3xl text-primary flex items-center">
            <Thermometer className="mr-3 h-8 w-8" />
            Content Engagement Heatmap
          </CardTitle>
          <CardDescription>
            AI-powered prediction of user engagement for images and text.
            Visual heatmaps for text are simulated with highlighting. Image heatmaps are descriptive with approximate visual cues.
          </CardDescription>
        </CardHeader>
        <CardContent className="space-y-6">
          <Alert variant="default" className="bg-yellow-50 border-yellow-400 text-yellow-700 dark:bg-yellow-900/30 dark:text-yellow-300">
            <AlertTriangle className="h-5 w-5 text-yellow-500" />
            <AlertTitle className="font-semibold">Important Disclaimer</AlertTitle>
            <AlertDescription>
              AI-predicted engagement is an estimation and can be subjective. Visual markers on images are approximations. It may not reflect actual user behavior or specific audience preferences. Use these insights as a guide, not a definitive measure.
            </AlertDescription>
          </Alert>

          <Tabs value={inputType} onValueChange={(value) => {
            setInputType(value as 'image' | 'text');
            setImageReport(null);
            setTextReport(null);
            setError(null);
            setImageDataUrl(null);
            setImageFile(null);
          }} className="w-full">
            <TabsList className="grid w-full grid-cols-2">
              <TabsTrigger value="image">Image Engagement</TabsTrigger>
              <TabsTrigger value="text">Text Engagement</TabsTrigger>
            </TabsList>
            <TabsContent value="image" className="mt-6">
              <div className="space-y-4">
                <div>
                  <Label htmlFor="image-upload-heatmap" className="text-lg font-medium flex items-center mb-2">
                    <ImageUp className="mr-2 h-5 w-5 text-accent" />
                    Upload Image
                  </Label>
                  <Input
                    id="image-upload-heatmap"
                    type="file"
                    accept="image/png, image/jpeg, image/webp"
                    onChange={handleImageFileChange}
                    className="file:text-primary file:font-semibold file:bg-primary/10 hover:file:bg-primary/20"
                    disabled={isLoading}
                  />
                  <p className="text-sm text-muted-foreground mt-1">Supported formats: PNG, JPG, WEBP.</p>
                </div>
                {imageDataUrl && (
                  <ImagePreview 
                    imageDataUrl={imageDataUrl} 
                    dataAiHint="engagement content"
                    highAttentionAreas={imageReport?.high_attention_areas}
                    lowAttentionAreas={imageReport?.low_attention_areas}
                  />
                )}
              </div>
            </TabsContent>
            <TabsContent value="text" className="mt-6">
              <div className="space-y-4">
                <div>
                  <Label htmlFor="text-input-heatmap" className="text-lg font-medium flex items-center mb-2">
                    <Type className="mr-2 h-5 w-5 text-accent" />
                    Paste Text
                  </Label>
                  <Textarea
                    id="text-input-heatmap"
                    placeholder="Paste your text content here..."
                    value={textInput}
                    onChange={handleTextInputChange}
                    rows={10}
                    disabled={isLoading}
                  />
                </div>
                <div>
                  <Label htmlFor="text-file-upload-heatmap" className="text-sm font-medium flex items-center mb-1">
                    Or Upload a .txt File
                  </Label>
                  <Input
                    id="text-file-upload-heatmap"
                    type="file"
                    accept=".txt"
                    onChange={handleTextFileChange}
                    className="file:text-primary file:font-semibold file:bg-primary/10 hover:file:bg-primary/20 text-sm"
                    disabled={isLoading}
                  />
                </div>
              </div>
            </TabsContent>
          </Tabs>
          
          <Button onClick={performAnalysis} disabled={isLoading || (inputType === 'image' && !imageFile) || (inputType === 'text' && !textInput.trim())} className="w-full mt-6">
            {isLoading ? (
              <>
                <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                Generating Heatmap Insights...
              </>
            ) : (
              'Generate Engagement Insights'
            )}
          </Button>

          {error && !isLoading && (
            <Alert variant="destructive" className="mt-6">
              <AlertTriangle className="h-5 w-5" />
              <AlertTitle>Analysis Error</AlertTitle>
              <AlertDescription>{error}</AlertDescription>
            </Alert>
          )}

          {(imageReport && inputType === 'image' || textReport && inputType === 'text') && !isLoading && !error && (
             <Button onClick={handleDownloadReport} variant="outline" className="w-full mt-4">
                <Download className="mr-2 h-4 w-4" />
                Download Report
              </Button>
          )}

          {imageReport && !isLoading && inputType === 'image' && (
            <Card className="mt-6 shadow-md">
              <CardHeader>
                <CardTitle className="font-headline text-xl flex items-center">
                  <Eye className="mr-2 h-6 w-6 text-primary" />
                  Image Engagement Report
                </CardTitle>
                 <CardDescription>
                   Approximate attention areas are marked on the image preview above.
                   <span className="inline-flex items-center ml-2">
                      <span className="w-3 h-3 rounded-full bg-red-500/70 mr-1"></span> High
                      <span className="w-3 h-3 rounded-full bg-blue-500/70 ml-2 mr-1"></span> Low
                   </span>
                </CardDescription>
              </CardHeader>
              <CardContent className="space-y-4 text-sm">
                <div>
                  <h4 className="font-semibold text-md mb-1 flex items-center"><FileTextIcon className="mr-2 h-4 w-4 text-accent"/>Image Description:</h4>
                  <p className="bg-muted/30 p-3 rounded-md">{imageReport.image_description || "Not provided."}</p>
                </div>
                <div>
                  <h4 className="font-semibold text-md mb-1 text-red-600 dark:text-red-400 flex items-center"><Sparkles className="mr-2 h-4 w-4"/>Identified High Attention Areas:</h4>
                  {imageReport.high_attention_areas && imageReport.high_attention_areas.length > 0 ? (
                    <ul className="list-none space-y-2">
                      {imageReport.high_attention_areas.map((area, index) => (
                        <li key={`high-${index}`} className="bg-red-50 dark:bg-red-900/20 p-2 rounded-md">
                          <strong className="flex items-center"><Pin className="w-4 h-4 mr-1 text-red-600 dark:text-red-400" />{area.area_description}</strong>
                          <p className="text-xs pl-5">{area.reason}</p>
                          {area.location_hint && <p className="text-xs pl-5 text-muted-foreground">Hint: {area.location_hint}</p>}
                        </li>
                      ))}
                    </ul>
                  ) : <p className="bg-muted/30 p-3 rounded-md">No specific high attention areas identified by AI.</p>}
                </div>
                <div>
                  <h4 className="font-semibold text-md mb-1 text-blue-600 dark:text-blue-400 flex items-center"><CircleHelp className="mr-2 h-4 w-4"/>Identified Low Attention Areas:</h4>
                  {imageReport.low_attention_areas && imageReport.low_attention_areas.length > 0 ? (
                     <ul className="list-none space-y-2">
                      {imageReport.low_attention_areas.map((area, index) => (
                        <li key={`low-${index}`} className="bg-blue-50 dark:bg-blue-900/20 p-2 rounded-md">
                          <strong className="flex items-center"><Pin className="w-4 h-4 mr-1 text-blue-600 dark:text-blue-400" />{area.area_description}</strong>
                           <p className="text-xs pl-5">{area.reason}</p>
                           {area.location_hint && <p className="text-xs pl-5 text-muted-foreground">Hint: {area.location_hint}</p>}
                        </li>
                      ))}
                    </ul>
                  ) : <p className="bg-muted/30 p-3 rounded-md">No specific low attention areas identified by AI.</p>}
                </div>
                 <div>
                  <h4 className="font-semibold text-md mb-1">AI Confidence:</h4>
                  <p className="bg-muted/30 p-3 rounded-md">{imageReport.confidence}</p>
                </div>
                <Alert variant="default" className="text-xs bg-blue-50 border-blue-300 dark:bg-blue-900/30 dark:text-blue-300">
                  <Info className="h-4 w-4 text-blue-500" />
                  <AlertTitle className="font-medium">AI Note</AlertTitle>
                  <AlertDescription>{imageReport.disclaimer}</AlertDescription>
                </Alert>
              </CardContent>
            </Card>
          )}

          {textReport && !isLoading && inputType === 'text' && (
            <Card className="mt-6 shadow-md">
              <CardHeader>
                <CardTitle className="font-headline text-xl flex items-center">
                  <Type className="mr-2 h-6 w-6 text-primary" />
                  Text Engagement Report
                </CardTitle>
              </CardHeader>
              <CardContent className="space-y-4 text-sm">
                <div>
                  <h4 className="font-semibold text-md mb-1 flex items-center"><FileTextIcon className="mr-2 h-4 w-4 text-accent"/>Overall Summary:</h4>
                  <p className="bg-muted/30 p-3 rounded-md">{textReport.overall_summary || "Not provided."}</p>
                </div>
                <div>
                  <h4 className="font-semibold text-md mb-2">Engagement Heatmap (Simulated):</h4>
                  <div className="p-3 rounded-md border bg-background leading-relaxed">
                    {textReport.segments && textReport.segments.length > 0 ? (
                      textReport.segments.map((item, index) => (
                        <span key={index} className={`px-1 py-0.5 rounded-sm ${getEngagementColor(item.engagement_level)} mr-0.5 mb-0.5 inline-block`}>
                          {item.segment}
                        </span>
                      ))
                    ) : <p>No text segments analyzed.</p>}
                  </div>
                   <div className="flex flex-wrap gap-2 mt-3 text-xs">
                        <span className="flex items-center"><span className="w-3 h-3 rounded-sm bg-red-500/70 mr-1"></span> High Engagement</span>
                        <span className="flex items-center"><span className="w-3 h-3 rounded-sm bg-orange-400/70 mr-1"></span> Medium Engagement</span>
                        <span className="flex items-center"><span className="w-3 h-3 rounded-sm bg-yellow-300/70 mr-1"></span> Low Engagement</span>
                        <span className="flex items-center"><span className="w-3 h-3 rounded-sm bg-blue-200/70 mr-1"></span> Neutral</span>
                    </div>
                </div>
                 <div>
                  <h4 className="font-semibold text-md mb-1">AI Confidence:</h4>
                  <p className="bg-muted/30 p-3 rounded-md">{textReport.confidence}</p>
                </div>
                 <Alert variant="default" className="text-xs bg-blue-50 border-blue-300 dark:bg-blue-900/30 dark:text-blue-300">
                  <Info className="h-4 w-4 text-blue-500" />
                  <AlertTitle className="font-medium">AI Note</AlertTitle>
                  <AlertDescription>{textReport.disclaimer}</AlertDescription>
                </Alert>
              </CardContent>
            </Card>
          )}

          {!imageReport && !textReport && !isLoading && !error && (
             <div className="mt-6 p-4 border border-dashed rounded-md text-center text-muted-foreground">
                <Info className="mx-auto h-8 w-8 mb-2"/>
                <p>Upload content and click "Generate" to see AI-predicted engagement insights.</p>
            </div>
          )}

        </CardContent>
        <CardFooter>
            <p className="text-xs text-muted-foreground w-full text-center">
                AI heatmap insights are predictive and should be combined with user testing for best results.
            </p>
        </CardFooter>
      </Card>

    {/* Blog Section */}
    <div className="mt-12 max-w-3xl mx-auto prose prose-lg dark:prose-invert">
        <h2>The Ultimate Guide to AI Content Heatmap Generators: Revolutionizing Visual Marketing and Design</h2>

        <p>In today's competitive digital landscape, understanding viewer attention patterns has become crucial for marketers and designers who don't mind missing the latest trends in visual optimization. AI-powered heatmap generators have emerged as game-changing tools that predict people's behavior when viewing images, ensuring your content captures maximum engagement. These advanced applications use artificial intelligence to analyze visuals and provide insights that were once only available through expensive eye-tracking studies.</p>

        <h2>What is an AI Content Heatmap Generator?</h2>

        <p>An AI content heatmap generator is a visual tool that uses artificial intelligence to predict where people will look when viewing an image. These ai-powered tools create a color-coded overlay on your image, with warmer colors indicating areas of higher viewer attention. Unlike traditional eye-tracking methods that require human participants, these predictive tools utilize advanced algorithms trained on vast datasets of eye-tracking studies to simulate human eye behavior.</p>

        <p>The technology works by analyzing visual elements within your photo or design and generating a heatmap that highlights areas of high and low engagement. This insight helps designers and marketers adjust their image composition, placing important elements in high-engagement areas while redesigning underperforming sections to better capture viewer attention.</p>

        <h2>Key Features to Check When Searching for the Best AI Content Heatmap Generator</h2>

        <p>When evaluating AI content heatmap generators, consider these essential features:</p>

        <ul>
            <li><strong>Accuracy and Reliability:</strong> Look for tools built on advanced algorithms with highly reliable estimation capabilities</li>
            <li><strong>Processing Speed:</strong> The best generators create instant heatmaps within seconds, providing quick insights</li>
            <li><strong>Supported Formats:</strong> Ensure the tool supports a wide range of images including web pages, advertisements, and product images</li>
            <li><strong>Privacy and Security:</strong> Prioritize tools that prioritize privacy and security of users' data, with uploaded and generated images automatically deleted</li>
            <li><strong>Integration Capabilities:</strong> Consider whether the tool can be integrated directly into your application or workflow</li>
            <li><strong>Industry Support:</strong> Choose tools designed to support designers and marketers across various industries</li>
        </ul>

        <h2>Best FREE AI Content Heatmap Generators</h2>

        <h3>1. Klutz's AI Content Heatmap Generator - The Pioneer</h3>

        <p>Klutz's AI content heatmap generator stands out as the first tool with AI analysis features, revolutionizing how we predict people's image engagement. This groundbreaking tool artificial intelligence to provide predictive eye-tracking insights that help marketers and designers optimize their visual content.</p>

        <p><strong>Key Features:</strong></p>

        <ul>
            <li>First-to-market AI analysis capabilities</li>
            <li>Quick heatmap generation within minutes</li>
            <li>Supports both image and text engagement prediction</li>
            <li>Visual heatmaps for text with highlighting simulation</li>
            <li>Descriptive analysis with approximate visual cues</li>
        </ul>

        <p><strong>Pricing:</strong> Free to use with basic features</p>

        <p><strong>Pros:</strong></p>
        <ul>
            <li>Pioneer in AI-powered heatmap technology</li>
            <li>User-friendly interface perfect for beginners</li>
            <li>No cost barrier for initial testing</li>
            <li>Comprehensive engagement insights</li>
        </ul>

        <p><strong>Cons:</strong></p>
        <ul>
            <li>Limited advanced features in free version</li>
            <li>May have usage limitations</li>
        </ul>

        <h3>2. MediaModifier's AI-Powered Heatmap Tool</h3>

        <p>MediaModifier offers an advanced eye-tracking AI tool that helps designers and marketers ensure their visuals are optimized for maximum engagement. The tool uses artificial intelligence to predict where people will look in your content, making it ideal for anyone wanting to grab attention and boost their image impact.</p>

        <p><strong>Key Features:</strong></p>

        <ul>
            <li>AI-powered predictive eye-tracking</li>
            <li>Generate heatmap within seconds</li>
            <li>Works with wide range of image types</li>
            <li>Integration capabilities for custom solutions</li>
            <li>Prioritizes privacy with automatic deletion</li>
        </ul>

        <p><strong>Pricing:</strong> Premium MediaModifier plans include 300 heatmap generations per month</p>

        <p><strong>Pros:</strong></p>
        <ul>
            <li>Fast processing for instant heatmaps</li>
            <li>Strong privacy protection - uploaded and generated images automatically deleted within 60 minutes</li>
            <li>Suitable for various industries</li>
            <li>Professional-grade accuracy</li>
        </ul>

        <p><strong>Cons:</strong></p>
        <ul>
            <li>Limited free tier</li>
            <li>Monthly generation limits on premium plans</li>
        </ul>

        <h3>3. Maptive Heat Mapping Tool</h3>

        <p>While primarily focused on geographic heat mapping, Maptive offers valuable insights for location-based marketing and design applications. This tool helps visualize marker density and numerical data tied to geographic locations.</p>

        <p><strong>Key Features:</strong></p>

        <ul>
            <li>Geographic heat map generation</li>
            <li>Customizable radius, opacity, and gradient colors</li>
            <li>Excel spreadsheet integration</li>
            <li>Cloud-based accessibility</li>
        </ul>

        <p><strong>Pricing:</strong> Free 10-day trial, then subscription-based</p>

        <p><strong>Pros:</strong></p>
        <ul>
            <li>Excellent for location-based analysis</li>
            <li>Professional presentation capabilities</li>
            <li>Team collaboration features</li>
        </ul>

        <p><strong>Cons:</strong></p>
        <ul>
            <li>Limited to geographic data</li>
            <li>Not suitable for general image analysis</li>
        </ul>

        <h3>4. Visual Paradigm Online Heat Map Maker</h3>

        <p>Visual Paradigm provides a comprehensive heat map maker that focuses on data visualization rather than AI-powered image analysis. This tool is better suited for statistical heatmaps and data representation.</p>

        <p><strong>Key Features:</strong></p>

        <ul>
            <li>Professional heat map templates</li>
            <li>Drag-and-drop customization</li>
            <li>Multiple export formats</li>
            <li>Integration with Google Sheets</li>
        </ul>

        <p><strong>Pricing:</strong> 30-day free trial, then subscription plans</p>

        <p><strong>Pros:</strong></p>
        <ul>
            <li>Professional templates available</li>
            <li>Easy customization options</li>
            <li>Multiple export formats</li>
        </ul>

        <p><strong>Cons:</strong></p>
        <ul>
            <li>Not AI-powered for image analysis</li>
            <li>Focused on data visualization rather than viewer attention prediction</li>
        </ul>

        <h2>Why Klutz Leads the AI Content Heatmap Revolution</h2>

        <p>As the first tool with AI analysis features, Klutz's AI content heatmap generator has set the standard for predictive eye-tracking technology. The platform's innovative approach to analyzing visuals and predicting viewer behavior has made it an essential tool for designers and marketers who want to stay ahead of the latest trends.</p>

        <p>The tool's ability to generate insights quickly while maintaining user privacy makes it perfect for entrepreneurs and marketing professionals who need reliable data to guide their design decisions. Unlike other tools that focus solely on geographic or statistical data, Klutz specializes in understanding how people interact with visual content.</p>

        <h2>TL;DR</h2>

        <p>AI content heatmap generators are revolutionary tools that use artificial intelligence to predict where people will look in your images, helping designers and marketers optimize their visual content for maximum engagement. Klutz's AI content heatmap generator leads the market as the first tool with AI analysis features, offering quick and reliable insights for visual optimization.</p>

        <p>Key takeaways:</p>

        <ul>
            <li>Klutz pioneered AI analysis in heatmap generation</li>
            <li>MediaModifier offers professional-grade features with strong privacy protection</li>
            <li>Free tools are available for basic needs, with premium options for advanced features</li>
            <li>These tools help predict viewer attention patterns and optimize content placement</li>
            <li>Choose based on your specific needs: AI-powered image analysis vs. geographic/statistical visualization</li>
        </ul>

        <p>Whether you're a designer looking to create more engaging visuals or a marketer wanting to boost your content's impact, AI-powered heatmap generators provide the insights you need to ensure your images capture and hold viewer attention effectively.</p>
     </div>
   </div> 
 );
   </>
)}


================================================
FILE: src/app/image-to-text/page.tsx
================================================
'use client';

import Head from 'next/head';
import { useState, useEffect } from 'react';
import { useToast } from "@/hooks/use-toast";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from "@/components/ui/card";
import { Textarea } from "@/components/ui/textarea";
import { Input } from "@/components/ui/input";
import { Label } from "@/components/ui/label";
import { Alert, AlertDescription, AlertTitle } from "@/components/ui/alert";
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from "@/components/ui/select";
import { Loader2, ImageUp, FileText, AlertTriangle, Info, Copy, Download } from 'lucide-react';
import { preprocessImage } from '@/lib/image-utils';
import { downloadTextFile } from '@/lib/utils';
import ImagePreview from '@/components/medi-scan/image-preview';
import type { ImageToTextReport } from '@/types/image-to-text';

const cleanJsonString = (rawString: string): string => {
  let cleanedString = rawString.trim();
  if (cleanedString.startsWith("```json") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(7, cleanedString.length - 3).trim();
  } else if (cleanedString.startsWith("```") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(3, cleanedString.length - 3).trim();
  }
  return cleanedString;
};

export default function ImageToTextPage() {
  const [imageFile, setImageFile] = useState<File | null>(null);
  const [imageDataUrl, setImageDataUrl] = useState<string | null>(null);
  const [analysisType, setAnalysisType] = useState<string>('detailed');
  const [language, setLanguage] = useState<string>('auto');
  
  const [analysisReport, setAnalysisReport] = useState<ImageToTextReport | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const { toast } = useToast();

  useEffect(() => {
    if (typeof window.puter === 'undefined') {
      toast({
        variant: "destructive",
        title: "Puter SDK Error",
        description: "Puter.js SDK is not loaded. Please refresh the page.",
      });
    }
  }, [toast]);

  const handleImageFileChange = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      setImageFile(file);
      try {
        const previewDataUrl = URL.createObjectURL(file);
        setImageDataUrl(previewDataUrl);
        setAnalysisReport(null);
        setError(null);
      } catch (error) {
        toast({ variant: "destructive", title: "Preview Error", description: "Could not generate image preview." });
        setImageDataUrl(null);
      }
    } else {
      setImageFile(null);
      setImageDataUrl(null);
    }
  };

  const performAnalysis = async () => {
    if (!imageFile) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please upload an image containing text." });
      return;
    }

    setIsLoading(true);
    setAnalysisReport(null);
    setError(null);
    toast({ title: "Analysis Started", description: "AI is extracting text from your image..." });

    try {
      if (typeof window.puter === 'undefined' || !window.puter.auth || !window.puter.ai) {
        throw new Error("Puter SDK not available. Please refresh.");
      }
      const puter = window.puter;

      let isSignedIn = await puter.auth.isSignedIn();
      if (!isSignedIn) {
        await puter.auth.signIn();
        isSignedIn = await puter.auth.isSignedIn();
        if (!isSignedIn) throw new Error("Authentication failed or was cancelled.");
      }

      const preprocessedDataUrl = await preprocessImage(imageFile, 1024);

      const imagePrompt = `
        You are an AI assistant specialized in extracting and analyzing text from images.
        Analyze this image and extract all visible text content.
        Analysis type: ${analysisType}
        Preferred language: ${language === 'auto' ? 'Auto-detect' : language}

        Please provide a comprehensive analysis including:
        1. Extract ALL visible text from the image accurately
        2. Describe the image content and context
        3. Analyze the extracted text quality and formatting
        4. Provide text statistics and language detection
        5. Note any limitations or challenges in text extraction

        Return the analysis in a JSON object with these keys:
        - "image_description": (string) Brief description of the image and its content
        - "extracted_text": (string) All text extracted from the image, preserving formatting where possible
        - "text_analysis": (object) {
            "word_count": (number) Number of words extracted,
            "character_count": (number) Number of characters extracted,
            "language_detected": (string) Detected language of the text,
            "text_quality": (string, one of "High", "Medium", "Low") Quality of text extraction,
            "formatting_notes": (array of strings) Notes about text formatting, layout, fonts, etc.
          }
        - "confidence": (string, one of "High", "Medium", "Low", "Not Applicable") Your confidence in text extraction accuracy
        - "limitations": (array of strings) Any factors that affected text extraction quality
        - "disclaimer": (string) Standard disclaimer about AI text extraction limitations
      `;

      const response = await puter.ai.chat(imagePrompt, preprocessedDataUrl);
      
      if (!response?.message?.content) {
        throw new Error("AI analysis did not return content.");
      }

      const parsedResponse: ImageToTextReport = JSON.parse(cleanJsonString(response.message.content));
      setAnalysisReport(parsedResponse);
      toast({ title: "Analysis Complete", variant: "default", className: "bg-green-500 text-white dark:bg-green-600" });

    } catch (err: any) {
      console.error("Analysis error:", err);
      let errorMessage = "An error occurred during analysis.";
      if (err instanceof Error) errorMessage = err.message;
      else if (typeof err === 'string') errorMessage = err;
      else if (err.error && err.error.message) errorMessage = err.error.message;
      setError(errorMessage);
      toast({ variant: "destructive", title: "Analysis Failed", description: errorMessage });
    } finally {
      setIsLoading(false);
    }
  };

  const handleCopyText = () => {
    if (!analysisReport?.extracted_text) return;
    
    navigator.clipboard.writeText(analysisReport.extracted_text).then(() => {
      toast({ title: "Text Copied", description: "Extracted text has been copied to clipboard." });
    }).catch(() => {
      toast({ variant: "destructive", title: "Copy Failed", description: "Could not copy text to clipboard." });
    });
  };

  const handleDownloadReport = () => {
    if (!analysisReport) return;

    let reportString = "KLUTZ Image to Text Converter Report\n";
    reportString += "===================================\n\n";

    reportString += "Image Analysis:\n";
    reportString += "---------------\n";
    reportString += `${analysisReport.image_description}\n\n`;

    reportString += "Extracted Text:\n";
    reportString += "---------------\n";
    reportString += `${analysisReport.extracted_text || "No text extracted"}\n\n`;

    reportString += "Text Analysis:\n";
    reportString += "--------------\n";
    reportString += `Word Count: ${analysisReport.text_analysis.word_count}\n`;
    reportString += `Character Count: ${analysisReport.text_analysis.character_count}\n`;
    if (analysisReport.text_analysis.language_detected) {
      reportString += `Language Detected: ${analysisReport.text_analysis.language_detected}\n`;
    }
    reportString += `Text Quality: ${analysisReport.text_analysis.text_quality}\n\n`;

    if (analysisReport.text_analysis.formatting_notes && analysisReport.text_analysis.formatting_notes.length > 0) {
      reportString += "Formatting Notes:\n";
      reportString += "-----------------\n";
      analysisReport.text_analysis.formatting_notes.forEach(note => {
        reportString += `- ${note}\n`;
      });
      reportString += "\n";
    }

    if (analysisReport.limitations && analysisReport.limitations.length > 0) {
      reportString += "Limitations:\n";
      reportString += "------------\n";
      analysisReport.limitations.forEach(limitation => {
        reportString += `- ${limitation}\n`;
      });
      reportString += "\n";
    }

    reportString += "AI Confidence Level: " + analysisReport.confidence + "\n\n";
    reportString += "Disclaimer:\n";
    reportString += "-----------\n";
    reportString += analysisReport.disclaimer + "\n\n";
    
    reportString += "\nIMPORTANT: This report is AI-generated and for informational purposes only. Text extraction accuracy may vary based on image quality and text clarity.";

    const timestamp = new Date().toISOString().replace(/[:.-]/g, '').slice(0, 14);
    downloadTextFile(reportString, `KLUTZ_ImageToText_Report_${timestamp}.txt`);
  };

  const handleDownloadTextOnly = () => {
    if (!analysisReport?.extracted_text) return;
    
    const timestamp = new Date().toISOString().replace(/[:.-]/g, '').slice(0, 14);
    downloadTextFile(analysisReport.extracted_text, `KLUTZ_ExtractedText_${timestamp}.txt`);
  };

  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/image-to-text" />
      </Head>
    <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-8">
      <Card className="max-w-3xl mx-auto shadow-xl">
        <CardHeader>
          <CardTitle className="font-headline text-3xl text-primary flex items-center">
            <FileText className="mr-3 h-8 w-8" />
            Image to Text Converter
          </CardTitle>
          <CardDescription>
            Upload an image containing text and extract all readable content using AI-powered text recognition.
          </CardDescription>
        </CardHeader>
        <CardContent className="space-y-6">
          <Alert variant="default" className="bg-blue-50 border-blue-400 text-blue-700 dark:bg-blue-900/30 dark:text-blue-300">
            <Info className="h-5 w-5 text-blue-500" />
            <AlertTitle className="font-semibold">How it works</AlertTitle>
            <AlertDescription>
              Upload any image containing text (documents, screenshots, signs, handwriting, etc.) and our AI will extract and analyze all visible text content.
            </AlertDescription>
          </Alert>

          <div>
            <Label htmlFor="image-upload" className="text-lg font-medium flex items-center mb-2">
              <ImageUp className="mr-2 h-5 w-5 text-accent" />
              Upload Image
            </Label>
            <Input
              id="image-upload"
              type="file"
              accept="image/png, image/jpeg, image/webp"
              onChange={handleImageFileChange}
              className="file:text-primary file:font-semibold file:bg-primary/10 hover:file:bg-primary/20"
              disabled={isLoading}
            />
            <p className="text-sm text-muted-foreground mt-1">Upload a clear image containing text for best results.</p>
          </div>

          {imageDataUrl && <ImagePreview imageDataUrl={imageDataUrl} dataAiHint="image with text"/>}

          <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
            <div>
              <Label htmlFor="analysis-type" className="text-lg font-medium">Analysis Type</Label>
              <Select value={analysisType} onValueChange={setAnalysisType}>
                <SelectTrigger id="analysis-type" className="w-full">
                  <SelectValue placeholder="Select analysis type" />
                </SelectTrigger>
                <SelectContent>
                  <SelectItem value="basic">Basic Text Extraction</SelectItem>
                  <SelectItem value="detailed">Detailed Analysis</SelectItem>
                </SelectContent>
              </Select>
            </div>

            <div>
              <Label htmlFor="language" className="text-lg font-medium">Language Preference</Label>
              <Select value={language} onValueChange={setLanguage}>
                <SelectTrigger id="language" className="w-full">
                  <SelectValue placeholder="Select language" />
                </SelectTrigger>
                <SelectContent>
                  <SelectItem value="auto">Auto-detect</SelectItem>
                  <SelectItem value="english">English</SelectItem>
                  <SelectItem value="spanish">Spanish</SelectItem>
                  <SelectItem value="french">French</SelectItem>
                  <SelectItem value="german">German</SelectItem>
                  <SelectItem value="chinese">Chinese</SelectItem>
                  <SelectItem value="japanese">Japanese</SelectItem>
                  <SelectItem value="arabic">Arabic</SelectItem>
                  <SelectItem value="hindi">Hindi</SelectItem>
                </SelectContent>
              </Select>
            </div>
          </div>

          <Button 
            onClick={performAnalysis} 
            disabled={isLoading || !imageFile} 
            className="w-full"
          >
            {isLoading ? (
              <>
                <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                Extracting Text...
              </>
            ) : (
              <>
                <FileText className="mr-2 h-4 w-4" />
                Extract Text from Image
              </>
            )}
          </Button>

          {error && !isLoading && (
            <Alert variant="destructive" className="mt-6">
              <AlertTriangle className="h-5 w-5" />
              <AlertTitle>Analysis Error</AlertTitle>
              <AlertDescription>{error}</AlertDescription>
            </Alert>
          )}

          {analysisReport && !isLoading && !error && (
            <Card className="mt-6 shadow-md">
              <CardHeader>
                <CardTitle className="font-headline text-xl flex items-center">
                  <FileText className="mr-2 h-6 w-6 text-primary" />
                  Text Extraction Results
                </CardTitle>
              </CardHeader>
              <CardContent className="space-y-4">
                <div>
                  <h4 className="font-semibold text-md mb-1">Image Description:</h4>
                  <p className="bg-muted/30 p-3 rounded-md">{analysisReport.image_description}</p>
                </div>

                <div>
                  <div className="flex items-center justify-between mb-2">
                    <h4 className="font-semibold text-md">Extracted Text:</h4>
                    <Button onClick={handleCopyText} variant="outline" size="sm">
                      <Copy className="mr-1 h-3 w-3" />
                      Copy Text
                    </Button>
                  </div>
                  <div className="bg-muted/30 p-4 rounded-md max-h-64 overflow-y-auto">
                    {analysisReport.extracted_text ? (
                      <pre className="whitespace-pre-wrap text-sm font-mono">{analysisReport.extracted_text}</pre>
                    ) : (
                      <p className="text-muted-foreground italic">No text was extracted from the image.</p>
                    )}
                  </div>
                </div>

                <div className="grid grid-cols-2 md:grid-cols-4 gap-4">
                  <div className="bg-blue-50 dark:bg-blue-900/20 p-3 rounded-md text-center">
                    <p className="text-sm text-muted-foreground">Words</p>
                    <p className="text-lg font-bold text-blue-600 dark:text-blue-400">{analysisReport.text_analysis.word_count}</p>
                  </div>
                  <div className="bg-green-50 dark:bg-green-900/20 p-3 rounded-md text-center">
                    <p className="text-sm text-muted-foreground">Characters</p>
                    <p className="text-lg font-bold text-green-600 dark:text-green-400">{analysisReport.text_analysis.character_count}</p>
                  </div>
                  <div className="bg-purple-50 dark:bg-purple-900/20 p-3 rounded-md text-center">
                    <p className="text-sm text-muted-foreground">Quality</p>
                    <p className="text-lg font-bold text-purple-600 dark:text-purple-400">{analysisReport.text_analysis.text_quality}</p>
                  </div>
                  <div className="bg-orange-50 dark:bg-orange-900/20 p-3 rounded-md text-center">
                    <p className="text-sm text-muted-foreground">Language</p>
                    <p className="text-lg font-bold text-orange-600 dark:text-orange-400">{analysisReport.text_analysis.language_detected || 'N/A'}</p>
                  </div>
                </div>

                {analysisReport.text_analysis.formatting_notes && analysisReport.text_analysis.formatting_notes.length > 0 && (
                  <div>
                    <h4 className="font-semibold text-md mb-1">Formatting Notes:</h4>
                    <ul className="list-disc pl-5 space-y-1 bg-yellow-50 dark:bg-yellow-900/20 p-3 rounded-md">
                      {analysisReport.text_analysis.formatting_notes.map((note, index) => (
                        <li key={index} className="text-yellow-700 dark:text-yellow-300">{note}</li>
                      ))}
                    </ul>
                  </div>
                )}

                {analysisReport.limitations && analysisReport.limitations.length > 0 && (
                  <div>
                    <h4 className="font-semibold text-md mb-1">Limitations:</h4>
                    <ul className="list-disc pl-5 space-y-1 bg-red-50 dark:bg-red-900/20 p-3 rounded-md">
                      {analysisReport.limitations.map((limitation, index) => (
                        <li key={index} className="text-red-700 dark:text-red-300">{limitation}</li>
                      ))}
                    </ul>
                  </div>
                )}

                <div>
                  <h4 className="font-semibold text-md mb-1">AI Confidence:</h4>
                  <p className="bg-muted/30 p-3 rounded-md">{analysisReport.confidence}</p>
                </div>

                <Alert variant="default" className="text-xs bg-blue-50 border-blue-300 dark:bg-blue-900/30 dark:text-blue-300">
                  <Info className="h-4 w-4 text-blue-500" />
                  <AlertTitle className="font-medium">Disclaimer</AlertTitle>
                  <AlertDescription>{analysisReport.disclaimer}</AlertDescription>
                </Alert>

                <div className="flex flex-col sm:flex-row gap-2">
                  <Button onClick={handleDownloadTextOnly} variant="outline" className="flex-1">
                    <Download className="mr-2 h-4 w-4" />
                    Download Text Only
                  </Button>
                  <Button onClick={handleDownloadReport} variant="outline" className="flex-1">
                    <Download className="mr-2 h-4 w-4" />
                    Download Full Report
                  </Button>
                </div>
              </CardContent>
            </Card>
          )}

          {!analysisReport && !isLoading && !error && (
            <div className="mt-6 p-4 border border-dashed rounded-md text-center text-muted-foreground">
              <Info className="mx-auto h-8 w-8 mb-2"/>
              <p>Upload an image containing text and click "Extract Text" to get AI-powered text extraction and analysis.</p>
            </div>
          )}
        </CardContent>
        <CardFooter>
          <p className="text-xs text-muted-foreground w-full text-center">
            This tool uses AI for text extraction. Accuracy may vary based on image quality and text clarity.
          </p>
        </CardFooter>
      </Card>

      <div className="max-w-3xl mx-auto mt-12 prose dark:prose-invert">
        <h1 className="font-headline text-4xl text-primary mb-6">Complete Guide to Image to Text Converters: Transform Pictures to Text Instantly</h1>

        <p className="mb-4">Need to extract text from images? Whether you're looking to convert text from pictures, transform picture to text, or simply need a reliable picture to text converter, AI-powered tools have revolutionized how we handle visual content. From converting pics to text for work projects to extracting text from pic files for personal use, these image to text solutions make digitizing visual content effortless.</p>

        <h2 className="font-headline text-2xl text-primary mt-8 mb-4">What is an Image to Text Converter?</h2>

        <p className="mb-4">An image to text converter is a powerful tool that uses artificial intelligence to convert text in picture format into editable digital text. These picture to text converters can transform any image containing text - whether it's a photo of a document, screenshot, or handwritten note - into searchable, editable content.</p>

        <p className="mb-4">Modern image text to text converters handle various scenarios: converting text picture to text, extracting text in image to text format, and even processing complex graphics to text converter tasks. The technology works by analyzing visual patterns to convert picture text to text with remarkable accuracy.</p>

        <h2 className="font-headline text-2xl text-primary mt-8 mb-4">Key Features When Choosing the Best Picture to Text Converter</h2>

        <p className="mb-4">When searching for the ideal image to text converter, consider these essential features:</p>

        <ul className="list-disc list-inside mb-4">
          <li><strong>Accuracy:</strong> How well the tool can convert text from picture sources while maintaining precision</li>
          <li><strong>Format Support:</strong> Ability to convert pics to text from various file types (JPEG, PNG, PDF)</li>
          <li><strong>Language Recognition:</strong> Multi-language support for converting text in a picture to text</li>
          <li><strong>Batch Processing:</strong> Convert multiple pictures to text simultaneously</li>
          <li><strong>Output Options:</strong> Various formats for your converted text from pictures</li>
          <li><strong>Handwriting Support:</strong> Advanced AI to convert picture in text scenarios including handwritten content</li>
          <li><strong>Speed:</strong> Quick processing to transform picture to text efficiently</li>
          <li><strong>Security:</strong> Safe handling of your image convert in text operations</li>
         </ul>

        <h2 className="font-headline text-2xl text-primary mt-8 mb-4">Best FREE Image to Text Converters</h2>

        <h2 className="font-headline text-2xl text-primary mt-8 mb-4">Klutz Image to Text Converter</h2>

        <p className="mb-4">Klutz stands out as an excellent free picture to text converter that excels at converting text from picture files with AI-powered precision. This image to text tool offers seamless conversion from image text to text format with detailed analysis capabilities that go beyond basic extraction.</p>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">Pros:</h3>
        <ul className="list-disc list-inside mb-4">
          <li>Completely free image to text conversion with no hidden costs</li>
          <li>Advanced AI technology for accurate text from pic extraction</li>
          <li>Clean, intuitive interface to convert text in picture to text</li>
          <li>Detailed analysis options beyond basic picture text to text conversion</li>
          <li>Auto-language detection for diverse text from pictures</li>
          <li>No registration required to convert picture to text</li>
        </ul>

        <h4 className="font-headline text-xl text-primary mt-6 mb-3">Cons:</h4>
        <ul className="list-disc list-inside mb-4">
          <li>Newer platform with growing user base</li>
          <li>Limited information on advanced batch processing features</li>
        </ul>

        <p className="mb-4"><strong>Price:</strong> Free</p>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">ImageToText.info</h3>

        <p className="mb-4">A popular online picture to text converter that provides straightforward image text to text conversion services.</p>

        <h4 className="font-headline text-xl text-primary mt-6 mb-3">Pros:</h4>
        <ul className="list-disc list-inside mb-4">
          <li>Simple interface for quick convert text from picture tasks</li>
          <li>Supports multiple image formats for picture to words converter needs</li>
          <li>Fast processing to transform picture to text</li>
          <li>No software installation required</li>
        </ul>

        <h4 className="font-headline text-xl text-primary mt-6 mb-3">Cons:</h4>
        <ul className="list-disc list-inside mb-4">
          <li>Basic features compared to AI-powered alternatives</li>
          <li>Limited advanced analysis for complex text from pic extraction</li>
          <li>Accuracy may vary with image quality</li>
        </ul>

        <p className="mb-4"><strong>Price:</strong> Free with potential premium features</p>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">ImageToText.io</h3>

        <p className="mb-4">Another established platform in the image to text converter market offering reliable picture text to text conversion.</p>

        <h4 className="font-headline text-xl text-primary mt-6 mb-3">Pros:</h4>
        <ul className="list-disc list-inside mb-4">
          <li>Established platform for convert pics to text operations</li>
          <li>Multiple language support for text in image to text conversion</li>
          <li>Decent accuracy for standard convert picture to text needs</li>
          <li>Web-based solution requiring no downloads</li>
        </ul>

        <h4 className="font-headline text-xl text-primary mt-6 mb-3">Cons:</h4>
        <ul className="list-disc list-inside mb-4">
          <li>Interface could be more user-friendly</li>
          <li>Limited advanced features for complex image convert in text scenarios</li>
          <li>Processing speed varies with server load</li>
        </ul>

        <p className="mb-4"><strong>Price:</strong> Free tier available</p>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">JPGToText.com</h3>

        <p className="mb-4">Specialized service focusing on converting text picture to text from JPEG and other common image formats.</p>

        <h4 className="font-headline text-xl text-primary mt-6 mb-3">Pros:</h4>
        <ul className="list-disc list-inside mb-4">
          <li>Specialized in JPEG format picture to text converter functionality</li>
          <li>Quick processing for basic convert text in picture to text needs</li>
          <li>Straightforward approach to text from pictures extraction</li>
          <li>Mobile-friendly for on-the-go convert picture in text tasks</li>
        </ul>

        <h4 className="font-headline text-xl text-primary mt-6 mb-3">Cons:</h4>
        <ul className="list-disc list-inside mb-4">
          <li>Limited to basic OCR without advanced AI features</li>
          <li>Fewer customization options for image text to text conversion</li>
          <li>May struggle with complex layouts or handwritten content</li>
        </ul>

        <p className="mb-4"><strong>Price:</strong> Free</p>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">Online OCR Tools (General Category)</h3>

        <p className="mb-4">Various free online OCR services provide basic image to text conversion capabilities.</p>

        <h4 className="font-headline text-xl text-primary mt-6 mb-3">Pros:</h4>
        <ul className="list-disc list-inside mb-4">
          <li>Multiple options available for picture to words converter needs</li>
          <li>No installation required for convert text from picture operations</li>
          <li>Usually free for basic text from pic extraction</li>
        </ul>

        <h4 className="font-headline text-xl text-primary mt-6 mb-3">Cons:</h4>
        <ul className="list-disc list-inside mb-4">
          <li>Varying quality and accuracy across different platforms</li>
          <li>Limited advanced features for complex convert pics to text scenarios</li>
          <li>Privacy concerns with uploading sensitive documents</li>
        </ul>

        <p className="mb-4"><strong>Price:</strong> Typically free with optional premium features</p>

        <h2 className="font-headline text-2xl text-primary mt-8 mb-4">TL;DR</h2>

        <p className="mb-4">Image to text converters have transformed how we convert text from pictures and transform picture to text content. When choosing a picture to text converter, focus on accuracy, ease of use, and compatibility with your image text to text conversion needs.</p>

        <p className="mb-4">For reliable free conversion with advanced AI capabilities, Klutz's Image to Text Converter excels at converting text in picture format with superior accuracy and detailed analysis. ImageToText.info, ImageToText.io, and JPGToText.com offer solid alternatives for basic convert picture text to text functionality.</p>

        <p className="mb-4">Whether you need occasional text from pic extraction or regular picture to words converter operations, there's an image to text solution that matches your requirements for converting pics to text efficiently and accurately.</p>

      </div>
    </div>
  );
    </>
)}    


================================================
FILE: src/app/ingredients-checker/page.tsx
================================================
'use client';

import Head from 'next/head';
import { useState, useEffect } from 'react';
import { useToast } from "@/hooks/use-toast";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from "@/components/ui/card";
import { Textarea } from "@/components/ui/textarea";
import { Input } from "@/components/ui/input";
import { Label } from "@/components/ui/label";
import { Alert, AlertDescription, AlertTitle } from "@/components/ui/alert";
import { Tabs, TabsContent, TabsList, TabsTrigger } from "@/components/ui/tabs";
import { Loader2, ImageUp, Type, Sparkles, AlertTriangle, Info, CheckCircle, XCircle, FileText, Download } from 'lucide-react';
import { preprocessImage } from '@/lib/image-utils';
import { downloadTextFile } from '@/lib/utils';
import ImagePreview from '@/components/medi-scan/image-preview';
import type { IngredientsAnalysisReport } from '@/types/ingredients-checker';

const cleanJsonString = (rawString: string): string => {
  let cleanedString = rawString.trim();
  if (cleanedString.startsWith("```json") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(7, cleanedString.length - 3).trim();
  } else if (cleanedString.startsWith("```") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(3, cleanedString.length - 3).trim();
  }
  return cleanedString;
};

// Helper function to ensure arrays are properly formatted
const ensureArray = (value: any): string[] => {
  if (Array.isArray(value)) return value;
  if (typeof value === 'string') return [value];
  return [];
};

export default function IngredientsCheckerPage() {
  const [inputType, setInputType] = useState<'image' | 'text'>('image');
  const [imageFile, setImageFile] = useState<File | null>(null);
  const [imageDataUrl, setImageDataUrl] = useState<string | null>(null);
  const [textInput, setTextInput] = useState<string>('');
  const [manufacturer, setManufacturer] = useState<string>('');
  
  const [analysisReport, setAnalysisReport] = useState<IngredientsAnalysisReport | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const { toast } = useToast();

  useEffect(() => {
    if (typeof window.puter === 'undefined') {
      toast({
        variant: "destructive",
        title: "Puter SDK Error",
        description: "Puter.js SDK is not loaded. Please refresh the page.",
      });
    }
  }, [toast]);

  const handleImageFileChange = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      setImageFile(file);
      try {
        const previewDataUrl = URL.createObjectURL(file);
        setImageDataUrl(previewDataUrl);
        setAnalysisReport(null);
        setError(null);
      } catch (error) {
        toast({ variant: "destructive", title: "Preview Error", description: "Could not generate image preview." });
        setImageDataUrl(null);
      }
    } else {
      setImageFile(null);
      setImageDataUrl(null);
    }
  };

  const handleTextInputChange = (event: React.ChangeEvent<HTMLTextAreaElement>) => {
    setTextInput(event.target.value);
    setAnalysisReport(null);
    setError(null);
  };

  const performAnalysis = async () => {
    if (inputType === 'image' && !imageFile) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please upload an image of the food item or ingredients label." });
      return;
    }
    if (inputType === 'text' && !textInput.trim()) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please provide the ingredients text." });
      return;
    }

    setIsLoading(true);
    setAnalysisReport(null);
    setError(null);
    toast({ title: "Analysis Started", description: "AI is analyzing the ingredients..." });

    try {
      if (typeof window.puter === 'undefined' || !window.puter.auth || !window.puter.ai) {
        throw new Error("Puter SDK not available. Please refresh.");
      }
      const puter = window.puter;

      let isSignedIn = await puter.auth.isSignedIn();
      if (!isSignedIn) {
        await puter.auth.signIn();
        isSignedIn = await puter.auth.isSignedIn();
        if (!isSignedIn) throw new Error("Authentication failed or was cancelled.");
      }

      let prompt: string;
      let aiInput: string | undefined = undefined;

      if (inputType === 'image' && imageFile) {
        aiInput = await preprocessImage(imageFile, 1024);
        prompt = `
          You are an AI assistant specialized in analyzing food ingredients. You must be EXTREMELY CAREFUL and HONEST about your limitations.

          Analyze this image which could be either:
          1. An ingredients label/nutrition facts panel on food packaging
          2. An actual food item (prepared dish, snack, beverage, etc.)
          3. Raw ingredients or food components
          
          ${manufacturer ? `Manufacturer: ${manufacturer}` : ''}

          CRITICAL INSTRUCTIONS:
          - If this is an INGREDIENTS LABEL: Extract and analyze the listed ingredients accurately
          - If this is an ACTUAL FOOD ITEM: Be VERY CAUTIOUS about making assumptions
            * Only identify ingredients you can CLEARLY see and are CERTAIN about
            * For complex, unfamiliar, or culturally specific dishes, acknowledge your limitations
            * Do NOT make assumptions about ingredients based on appearance alone
            * If you cannot reliably identify the food or its ingredients, say so clearly
            * Be especially careful with dishes that may look similar but have different ingredients
            * Consider that the same-looking dish can be made with completely different ingredients in different cultures

          ACCURACY REQUIREMENTS:
          - Set confidence to "Low" for actual food items unless you are absolutely certain
          - Include detailed limitations about visual analysis accuracy
          - Acknowledge when you cannot reliably determine ingredients
          - Do not guess at ingredients for unfamiliar dishes
          - Be honest about cultural and regional variations in recipes

          IMPORTANT: Return ONLY a valid JSON object with these exact keys and data types:
          {
            "product_name": "string or null",
            "manufacturer": "string or null", 
            "analysis_type": "ingredients_label|food_item|raw_ingredients",
            "ingredients_list": [
              {
                "name": "string",
                "description": "string",
                "safety_rating": "Safe|Caution|Warning|Unknown",
                "common_uses": ["array", "of", "strings"],
                "potential_concerns": ["array", "of", "strings"],
                "alternatives": ["array", "of", "strings"],
                "source": "visible|typical_recipe|likely_additive|uncertain",
                "confidence_note": "string explaining certainty level for this ingredient"
              }
            ],
            "overall_assessment": {
              "safety_rating": "Safe|Moderate Concern|High Concern|Insufficient Data",
              "summary": "string",
              "key_concerns": ["array", "of", "strings"],
              "recommendations": ["array", "of", "strings"]
            },
            "dietary_flags": {
              "vegan": true,
              "vegetarian": true,
              "gluten_free": true,
              "common_allergens": ["array", "of", "strings"],
              "reliability_note": "string explaining how reliable these flags are"
            },
            "analysis_limitations": [
              "Detailed list of limitations specific to this analysis"
            ],
            "confidence": "High|Medium|Low|Not Applicable",
            "disclaimer": "string"
          }
        `;
      } else if (inputType === 'text' && textInput.trim()) {
        prompt = `
          You are an AI assistant specialized in analyzing food ingredients.
          Analyze these ingredients: "${textInput}"
          ${manufacturer ? `Manufacturer: ${manufacturer}` : ''}

          Provide a comprehensive analysis including:
          1. List all ingredients and their properties
          2. Safety assessment for each ingredient
          3. Overall product safety evaluation
          4. Dietary considerations
          5. Potential concerns or allergens

          IMPORTANT: Return ONLY a valid JSON object with these exact keys and data types:
          {
            "product_name": "string or null",
            "manufacturer": "string or null",
            "analysis_type": "text_input",
            "ingredients_list": [
              {
                "name": "string",
                "description": "string",
                "safety_rating": "Safe|Caution|Warning|Unknown",
                "common_uses": ["array", "of", "strings"],
                "potential_concerns": ["array", "of", "strings"],
                "alternatives": ["array", "of", "strings"],
                "source": "provided",
                "confidence_note": "string"
              }
            ],
            "overall_assessment": {
              "safety_rating": "Safe|Moderate Concern|High Concern|Insufficient Data",
              "summary": "string",
              "key_concerns": ["array", "of", "strings"],
              "recommendations": ["array", "of", "strings"]
            },
            "dietary_flags": {
              "vegan": true,
              "vegetarian": true,
              "gluten_free": true,
              "common_allergens": ["array", "of", "strings"],
              "reliability_note": "string"
            },
            "analysis_limitations": ["array", "of", "strings"],
            "confidence": "High|Medium|Low|Not Applicable",
            "disclaimer": "string"
          }
        `;
      } else {
        throw new Error("No valid input provided for analysis.");
      }

      const response = inputType === 'image' 
        ? await puter.ai.chat(prompt, aiInput) 
        : await puter.ai.chat(prompt, { model: 'gpt-4o' });

      if (!response?.message?.content) {
        throw new Error("AI analysis did not return content.");
      }

      const rawResponse = JSON.parse(cleanJsonString(response.message.content));
      
      // Normalize the response to ensure all arrays are properly formatted
      const normalizedResponse: IngredientsAnalysisReport = {
        product_name: rawResponse.product_name || null,
        manufacturer: rawResponse.manufacturer || manufacturer || null,
        analysis_type: rawResponse.analysis_type || 'unknown',
        ingredients_list: (rawResponse.ingredients_list || []).map((ingredient: any) => ({
          name: ingredient.name || 'Unknown',
          description: ingredient.description || 'No description available',
          safety_rating: ingredient.safety_rating || 'Unknown',
          common_uses: ensureArray(ingredient.common_uses),
          potential_concerns: ensureArray(ingredient.potential_concerns),
          alternatives: ensureArray(ingredient.alternatives),
          source: ingredient.source || 'unknown',
          confidence_note: ingredient.confidence_note || ''
        })),
        overall_assessment: {
          safety_rating: rawResponse.overall_assessment?.safety_rating || 'Insufficient Data',
          summary: rawResponse.overall_assessment?.summary || 'No summary available',
          key_concerns: ensureArray(rawResponse.overall_assessment?.key_concerns),
          recommendations: ensureArray(rawResponse.overall_assessment?.recommendations)
        },
        dietary_flags: rawResponse.dietary_flags ? {
          vegan: Boolean(rawResponse.dietary_flags.vegan),
          vegetarian: Boolean(rawResponse.dietary_flags.vegetarian),
          gluten_free: Boolean(rawResponse.dietary_flags.gluten_free),
          common_allergens: ensureArray(rawResponse.dietary_flags.common_allergens),
          reliability_note: rawResponse.dietary_flags.reliability_note || ''
        } : {
          vegan: false,
          vegetarian: false,
          gluten_free: false,
          common_allergens: [],
          reliability_note: 'Unable to determine dietary flags reliably'
        },
        analysis_limitations: ensureArray(rawResponse.analysis_limitations),
        confidence: rawResponse.confidence || 'Low',
        disclaimer: rawResponse.disclaimer || 'AI-generated analysis. Verify with manufacturers and consult healthcare professionals.'
      };

      setAnalysisReport(normalizedResponse);
      toast({ title: "Analysis Complete", variant: "default", className: "bg-green-500 text-white dark:bg-green-600" });

    } catch (err: any) {
      console.error("Analysis error:", err);
      let errorMessage = "An error occurred during analysis.";
      if (err instanceof Error) errorMessage = err.message;
      else if (typeof err === 'string') errorMessage = err;
      else if (err.error && err.error.message) errorMessage = err.error.message;
      setError(errorMessage);
      toast({ variant: "destructive", title: "Analysis Failed", description: errorMessage });
    } finally {
      setIsLoading(false);
    }
  };

  const handleDownloadReport = () => {
    if (!analysisReport) return;

    let reportString = "KLUTZ Ingredients Analysis Report\n";
    reportString += "================================\n\n";

    if (analysisReport.product_name) {
      reportString += `Product Name: ${analysisReport.product_name}\n`;
    }
    if (analysisReport.manufacturer) {
      reportString += `Manufacturer: ${analysisReport.manufacturer}\n`;
    }
    if (analysisReport.analysis_type) {
      reportString += `Analysis Type: ${analysisReport.analysis_type.replace('_', ' ').toUpperCase()}\n`;
    }
    reportString += "\n";

    reportString += "Overall Assessment:\n";
    reportString += "------------------\n";
    reportString += `Safety Rating: ${analysisReport.overall_assessment.safety_rating}\n`;
    reportString += `Summary: ${analysisReport.overall_assessment.summary}\n\n`;

    reportString += "Key Concerns:\n";
    reportString += "-------------\n";
    analysisReport.overall_assessment.key_concerns.forEach(concern => {
      reportString += `- ${concern}\n`;
    });
    reportString += "\n";

    reportString += "Recommendations:\n";
    reportString += "----------------\n";
    analysisReport.overall_assessment.recommendations.forEach(rec => {
      reportString += `- ${rec}\n`;
    });
    reportString += "\n";

    if (analysisReport.analysis_limitations && analysisReport.analysis_limitations.length > 0) {
      reportString += "Analysis Limitations:\n";
      reportString += "--------------------\n";
      analysisReport.analysis_limitations.forEach(limitation => {
        reportString += `- ${limitation}\n`;
      });
      reportString += "\n";
    }

    reportString += "Ingredients Analysis:\n";
    reportString += "--------------------\n";
    analysisReport.ingredients_list.forEach(ingredient => {
      reportString += `\n${ingredient.name.toUpperCase()}\n`;
      reportString += `Safety Rating: ${ingredient.safety_rating}\n`;
      reportString += `Description: ${ingredient.description}\n`;
      if (ingredient.source) {
        reportString += `Source: ${ingredient.source.replace('_', ' ')}\n`;
      }
      if (ingredient.confidence_note) {
        reportString += `Confidence Note: ${ingredient.confidence_note}\n`;
      }
      reportString += "Common Uses:\n";
      ingredient.common_uses.forEach(use => reportString += `- ${use}\n`);
      if (ingredient.potential_concerns.length > 0) {
        reportString += "Potential Concerns:\n";
        ingredient.potential_concerns.forEach(concern => reportString += `! ${concern}\n`);
      }
      if (ingredient.alternatives?.length) {
        reportString += "Alternatives:\n";
        ingredient.alternatives.forEach(alt => reportString += `* ${alt}\n`);
      }
      reportString += "\n";
    });

    reportString += "Dietary Information:\n";
    reportString += "-------------------\n";
    if (analysisReport.dietary_flags) {
      reportString += `Vegan: ${analysisReport.dietary_flags.vegan ? 'Yes' : 'No'}\n`;
      reportString += `Vegetarian: ${analysisReport.dietary_flags.vegetarian ? 'Yes' : 'No'}\n`;
      reportString += `Gluten-Free: ${analysisReport.dietary_flags.gluten_free ? 'Yes' : 'No'}\n`;
      if (analysisReport.dietary_flags.reliability_note) {
        reportString += `Reliability Note: ${analysisReport.dietary_flags.reliability_note}\n`;
      }
      if (analysisReport.dietary_flags.common_allergens.length > 0) {
        reportString += "\nCommon Allergens Present:\n";
        analysisReport.dietary_flags.common_allergens.forEach(allergen => {
          reportString += `- ${allergen}\n`;
        });
      }
    }
    reportString += "\n";

    reportString += "AI Analysis Confidence: " + analysisReport.confidence + "\n\n";
    reportString += "Disclaimer:\n";
    reportString += "-----------\n";
    reportString += analysisReport.disclaimer + "\n\n";
    
    reportString += "\nIMPORTANT: This report is AI-generated and for informational purposes only. Always verify ingredients with the manufacturer and consult healthcare professionals for specific dietary needs or concerns.";

    const timestamp = new Date().toISOString().replace(/[:.-]/g, '').slice(0, 14);
    downloadTextFile(reportString, `KLUTZ_IngredientsChecker_Report_${timestamp}.txt`);
  };

  const getSafetyColor = (rating: string) => {
    switch (rating.toLowerCase()) {
      case 'safe': return 'text-green-600 dark:text-green-400';
      case 'caution': return 'text-yellow-600 dark:text-yellow-400';
      case 'warning': return 'text-red-600 dark:text-red-400';
      case 'high concern': return 'text-red-700 dark:text-red-300 font-bold';
      default: return 'text-gray-600 dark:text-gray-400';
    }
  };

  const getSourceBadgeColor = (source: string) => {
    switch (source) {
      case 'visible': return 'bg-green-100 text-green-700 dark:bg-green-900/30 dark:text-green-300';
      case 'typical_recipe': return 'bg-blue-100 text-blue-700 dark:bg-blue-900/30 dark:text-blue-300';
      case 'likely_additive': return 'bg-yellow-100 text-yellow-700 dark:bg-yellow-900/30 dark:text-yellow-300';
      case 'uncertain': return 'bg-red-100 text-red-700 dark:bg-red-900/30 dark:text-red-300';
      default: return 'bg-gray-100 text-gray-700 dark:bg-gray-900/30 dark:text-gray-300';
    }
  };

  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/ingredients-checker" />
      </Head>
    <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-8">
      <Card className="max-w-3xl mx-auto shadow-xl">
        <CardHeader>
          <CardTitle className="font-headline text-3xl text-primary flex items-center">
            <Sparkles className="mr-3 h-8 w-8" />
            AI Ingredients Checker
          </CardTitle>
          <CardDescription>
            Analyze food ingredients from labels, actual food items, or text for safety, dietary considerations, and potential concerns.
          </CardDescription>
        </CardHeader>
        <CardContent className="space-y-6">
          <Alert variant="default" className="bg-red-50 border-red-400 text-red-700 dark:bg-red-900/30 dark:text-red-300">
            <AlertTriangle className="h-5 w-5 text-red-500" />
            <AlertTitle className="font-semibold">Important Accuracy Warning</AlertTitle>
            <AlertDescription>
              <strong>For ingredient labels:</strong> High accuracy expected.<br/>
              <strong>For actual food items:</strong> Analysis is HIGHLY UNCERTAIN, especially for complex, unfamiliar, or culturally specific dishes. The AI may make incorrect assumptions about ingredients. Always verify with the actual recipe or manufacturer.
            </AlertDescription>
          </Alert>

          <Tabs value={inputType} onValueChange={(value) => setInputType(value as 'image' | 'text')} className="w-full">
            <TabsList className="grid w-full grid-cols-2">
              <TabsTrigger value="image">Image Analysis</TabsTrigger>
              <TabsTrigger value="text">Text Analysis</TabsTrigger>
            </TabsList>
            <TabsContent value="image" className="mt-6">
              <div className="space-y-4">
                <div>
                  <Label htmlFor="image-upload" className="text-lg font-medium flex items-center mb-2">
                    <ImageUp className="mr-2 h-5 w-5 text-accent" />
                    Upload Food Image or Ingredients Label
                  </Label>
                  <Input
                    id="image-upload"
                    type="file"
                    accept="image/png, image/jpeg, image/webp"
                    onChange={handleImageFileChange}
                    className="file:text-primary file:font-semibold file:bg-primary/10 hover:file:bg-primary/20"
                    disabled={isLoading}
                  />
                  <p className="text-sm text-muted-foreground mt-1">
                    <strong>Best results:</strong> Clear images of ingredient labels or nutrition facts panels.<br/>
                    <strong>Limited accuracy:</strong> Actual food items (especially complex or unfamiliar dishes).
                  </p>
                </div>
                {imageDataUrl && <ImagePreview imageDataUrl={imageDataUrl} dataAiHint="food item or ingredients label"/>}
              </div>
            </TabsContent>
            <TabsContent value="text" className="mt-6">
              <div className="space-y-4">
                <div>
                  <Label htmlFor="text-input" className="text-lg font-medium flex items-center mb-2">
                    <Type className="mr-2 h-5 w-5 text-accent" />
                    Ingredients Text
                  </Label>
                  <Textarea
                    id="text-input"
                    placeholder="Paste ingredients list here..."
                    value={textInput}
                    onChange={handleTextInputChange}
                    rows={8}
                    disabled={isLoading}
                  />
                </div>
              </div>
            </TabsContent>
          </Tabs>

          <div>
            <Label htmlFor="manufacturer" className="text-lg font-medium">Manufacturer (Optional)</Label>
            <Input
              id="manufacturer"
              placeholder="Enter manufacturer name..."
              value={manufacturer}
              onChange={(e) => setManufacturer(e.target.value)}
              disabled={isLoading}
            />
          </div>
          
          <Button 
            onClick={performAnalysis} 
            disabled={isLoading || (inputType === 'image' && !imageFile) || (inputType === 'text' && !textInput.trim())} 
            className="w-full"
          >
            {isLoading ? (
              <>
                <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                Analyzing Ingredients...
              </>
            ) : (
              'Analyze Ingredients'
            )}
          </Button>

          {error && !isLoading && (
            <Alert variant="destructive" className="mt-6">
              <AlertTriangle className="h-5 w-5" />
              <AlertTitle>Analysis Error</AlertTitle>
              <AlertDescription>{error}</AlertDescription>
            </Alert>
          )}

          {analysisReport && !isLoading && !error && (
            <Card className="mt-6 shadow-md">
              <CardHeader>
                <CardTitle className="font-headline text-xl flex items-center">
                  <FileText className="mr-2 h-6 w-6 text-primary" />
                  Ingredients Analysis Report
                  {analysisReport.analysis_type && (
                    <span className="ml-2 text-sm bg-blue-100 text-blue-700 px-2 py-1 rounded">
                      {analysisReport.analysis_type.replace('_', ' ').toUpperCase()}
                    </span>
                  )}
                </CardTitle>
              </CardHeader>
              <CardContent className="space-y-4">
                <div className="flex items-center justify-between">
                  <h4 className="font-semibold text-md">Overall Safety Rating:</h4>
                  <span className={`font-bold ${getSafetyColor(analysisReport.overall_assessment.safety_rating)}`}>
                    {analysisReport.overall_assessment.safety_rating}
                  </span>
                </div>

                <div className="flex items-center justify-between">
                  <h4 className="font-semibold text-md">AI Confidence:</h4>
                  <span className={`font-bold ${analysisReport.confidence === 'Low' ? 'text-red-600' : analysisReport.confidence === 'Medium' ? 'text-yellow-600' : 'text-green-600'}`}>
                    {analysisReport.confidence}
                  </span>
                </div>

                {analysisReport.analysis_limitations && analysisReport.analysis_limitations.length > 0 && (
                  <div>
                    <h4 className="font-semibold text-md mb-1 text-red-600 dark:text-red-400">‚ö†Ô∏è Analysis Limitations:</h4>
                    <ul className="list-disc pl-5 space-y-1 bg-red-50 dark:bg-red-900/20 p-3 rounded-md border-2 border-red-200 dark:border-red-800">
                      {analysisReport.analysis_limitations.map((limitation, index) => (
                        <li key={index} className="text-red-700 dark:text-red-300">{limitation}</li>
                      ))}
                    </ul>
                  </div>
                )}

                <div>
                  <h4 className="font-semibold text-md mb-1">Summary:</h4>
                  <p className="bg-muted/30 p-3 rounded-md">{analysisReport.overall_assessment.summary}</p>
                </div>

                <div>
                  <h4 className="font-semibold text-md mb-1">Key Concerns:</h4>
                  <ul className="list-disc pl-5 space-y-1 bg-red-50 dark:bg-red-900/20 p-3 rounded-md">
                    {analysisReport.overall_assessment.key_concerns.map((concern, index) => (
                      <li key={index} className="text-red-700 dark:text-red-300">{concern}</li>
                    ))}
                  </ul>
                </div>

                <div>
                  <h4 className="font-semibold text-md mb-1">Recommendations:</h4>
                  <ul className="list-disc pl-5 space-y-1 bg-green-50 dark:bg-green-900/20 p-3 rounded-md">
                    {analysisReport.overall_assessment.recommendations.map((rec, index) => (
                      <li key={index} className="text-green-700 dark:text-green-300">{rec}</li>
                    ))}
                  </ul>
                </div>

                {analysisReport.dietary_flags && (
                  <div>
                    <h4 className="font-semibold text-md mb-2">Dietary Information:</h4>
                    <div className="grid grid-cols-3 gap-2 mb-2">
                      <div className={`p-2 rounded-md text-center ${analysisReport.dietary_flags.vegan ? 'bg-green-100 text-green-700' : 'bg-red-100 text-red-700'}`}>
                        Vegan: {analysisReport.dietary_flags.vegan ? 'Yes' : 'No'}
                      </div>
                      <div className={`p-2 rounded-md text-center ${analysisReport.dietary_flags.vegetarian ? 'bg-green-100 text-green-700' : 'bg-red-100 text-red-700'}`}>
                        Vegetarian: {analysisReport.dietary_flags.vegetarian ? 'Yes' : 'No'}
                      </div>
                      <div className={`p-2 rounded-md text-center ${analysisReport.dietary_flags.gluten_free ? 'bg-green-100 text-green-700' : 'bg-red-100 text-red-700'}`}>
                        Gluten-Free: {analysisReport.dietary_flags.gluten_free ? 'Yes' : 'No'}
                      </div>
                    </div>
                    {analysisReport.dietary_flags.reliability_note && (
                      <div className="bg-yellow-50 p-2 rounded-md mb-2">
                        <p className="text-sm text-yellow-700"><strong>Reliability:</strong> {analysisReport.dietary_flags.reliability_note}</p>
                      </div>
                    )}
                    {analysisReport.dietary_flags.common_allergens.length > 0 && (
                      <div className="bg-yellow-50 p-3 rounded-md">
                        <h5 className="font-medium text-yellow-700 mb-1">Common Allergens Present:</h5>
                        <ul className="list-disc pl-5 text-yellow-600">
                          {analysisReport.dietary_flags.common_allergens.map((allergen, index) => (
                            <li key={index}>{allergen}</li>
                          ))}
                        </ul>
                      </div>
                    )}
                  </div>
                )}

                <div>
                  <h4 className="font-semibold text-md mb-2">Detailed Ingredients Analysis:</h4>
                  <div className="space-y-3">
                    {analysisReport.ingredients_list.map((ingredient, index) => (
                      <div key={index} className="border rounded-md p-3">
                        <div className="flex justify-between items-start mb-2">
                          <div className="flex items-center gap-2">
                            <h5 className="font-medium">{ingredient.name}</h5>
                            {ingredient.source && (
                              <span className={`px-2 py-1 rounded text-xs ${getSourceBadgeColor(ingredient.source)}`}>
                                {ingredient.source.replace('_', ' ')}
                              </span>
                            )}
                          </div>
                          <span className={`px-2 py-1 rounded text-sm ${getSafetyColor(ingredient.safety_rating)}`}>
                            {ingredient.safety_rating}
                          </span>
                        </div>
                        <p className="text-sm mb-2">{ingredient.description}</p>
                        {ingredient.confidence_note && (
                          <div className="bg-yellow-50 p-2 rounded text-sm mb-2">
                            <strong>Confidence Note:</strong> {ingredient.confidence_note}
                          </div>
                        )}
                        <div className="text-sm">
                          <strong>Common Uses:</strong>
                          <ul className="list-disc pl-5 mt-1">
                            {ingredient.common_uses.map((use, useIndex) => (
                              <li key={useIndex}>{use}</li>
                            ))}
                          </ul>
                        </div>
                        {ingredient.potential_concerns.length > 0 && (
                          <div className="text-sm mt-2">
                            <strong>Potential Concerns:</strong>
                            <ul className="list-disc pl-5 mt-1 text-red-600">
                              {ingredient.potential_concerns.map((concern, concernIndex) => (
                                <li key={concernIndex}>{concern}</li>
                              ))}
                            </ul>
                          </div>
                        )}
                        {ingredient.alternatives && ingredient.alternatives.length > 0 && (
                          <div className="text-sm mt-2">
                            <strong>Alternatives:</strong>
                            <ul className="list-disc pl-5 mt-1 text-green-600">
                              {ingredient.alternatives.map((alt, altIndex) => (
                                <li key={altIndex}>{alt}</li>
                              ))}
                            </ul>
                          </div>
                        )}
                      </div>
                    ))}
                  </div>
                </div>

                <Alert variant="default" className="text-xs bg-blue-50 border-blue-300 dark:bg-blue-900/30 dark:text-blue-300">
                  <Info className="h-4 w-4 text-blue-500" />
                  <AlertTitle className="font-medium">Disclaimer</AlertTitle>
                  <AlertDescription>{analysisReport.disclaimer}</AlertDescription>
                </Alert>

                <Button onClick={handleDownloadReport} variant="outline" className="w-full mt-4">
                  <Download className="mr-2 h-4 w-4" />
                  Download Report
                </Button>
              </CardContent>
            </Card>
          )}

          {!analysisReport && !isLoading && !error && (
            <div className="mt-6 p-4 border border-dashed rounded-md text-center text-muted-foreground">
              <Info className="mx-auto h-8 w-8 mb-2"/>
              <p>Upload an image of a food item or ingredients label, or paste ingredients text to get AI-powered analysis.</p>
            </div>
          )}
 <Card className="mt-8 shadow-md">
 <CardHeader>
 <CardTitle className="font-headline text-xl">Blog: What's Really in Your Food? The AI Ingredients Checker Can Tell You</CardTitle>
 </CardHeader>
 <CardContent>
 <p className="mb-4">In an age where processed foods dominate supermarket shelves, understanding what you're truly consuming has become more challenging than ever. Ingredient lists can be long, complex, and filled with unfamiliar terms. Enter the AI Ingredients Checker ‚Äì a revolutionary tool designed to demystify food labels and empower you to make informed choices about your diet.</p>

 <h5 className="font-semibold text-lg mb-2">Beyond the Buzzwords</h5>
 <p className="mb-4">Many food packages feature marketing claims like "natural," "healthy," or "low-fat." While some are regulated, others are not and can be misleading. The AI Ingredients Checker cuts through the marketing noise by focusing solely on the objective information: the ingredients list itself.</p>

 <h5 className="font-semibold text-lg mb-2">How it Works</h5>
 <p className="mb-4">Using advanced artificial intelligence, the checker can analyze ingredients in two ways:</p>
 <ol className="list-decimal pl-6 mb-4 space-y-2">
 <li><strong>Image Analysis:</strong> Simply upload a photo of a food item's ingredients label or even the food itself. The AI uses optical character recognition (OCR) and image analysis to identify the ingredients.</li>
 <li><strong>Text Analysis:</strong> If you have the ingredient list readily available (e.g., from a website or recipe), you can paste it directly into the text field.</li>
 </ol>

 <h5 className="font-semibold text-lg mb-2">What You Get</h5>
 <p className="mb-4">Once the analysis is complete, you receive a detailed report that includes:</p>
 <ul className="list-disc pl-6 mb-4 space-y-1">
 <li><strong>Individual Ingredient Breakdown:</strong> Information on each ingredient, its common uses, potential concerns, and a safety rating (Safe, Caution, Warning).</li>
 <li><strong>Overall Assessment:</strong> A summary of the product's safety rating, key concerns identified, and actionable recommendations.</li>
 <li><strong>Dietary Flags:</strong> Indicates if the product is likely Vegan, Vegetarian, or Gluten-Free, along with a note on the reliability of these flags.</li>
 <li><strong>Potential Allergens:</strong> Highlights common allergens present in the ingredients.</li>
 <li><strong>Limitations and Confidence:</strong> Crucially, the report states the limitations of the analysis (especially for image analysis of actual food items) and the AI's confidence level.</li>
 </ul>

 <h5 className="font-semibold text-lg mb-2">Why Accuracy Matters (and its Limits)</h5>
 <p className="mb-4">For ingredients labels, the AI's accuracy is generally high, as it's designed to read and interpret text. However, when analyzing images of actual food items, the AI relies on visual cues, which can be ambiguous. For example, a red sauce could contain tomatoes, bell peppers, or both, and it's difficult to be certain from an image alone. The checker explicitly highlights these limitations to prevent misinterpretation.</p>

 <h5 className="font-semibold text-lg mb-2">Making Healthier Choices</h5>
 <p className="mb-4">Understanding ingredients is the first step towards a healthier diet. The AI Ingredients Checker helps you:</p>
 <ul className="list-disc pl-6 mb-4 space-y-1">
 <li>Identify additives, preservatives, and artificial ingredients.</li>
 <li>Check for ingredients that might conflict with dietary restrictions or allergies.</li>
 <li>Compare the ingredient profiles of different products.</li>
 <li>Gain awareness of potential long-term health impacts of certain ingredients.</li>
 </ul>

 <h5 className="font-semibold text-lg mb-2">Conclusion</h5>
 <p className="mb-4">The AI Ingredients Checker is a powerful tool in your health arsenal, providing transparency into the food you eat. While it offers valuable insights, it's important to remember it's an AI assistant. Always cross-reference information and consult with healthcare or dietary professionals for personalized advice. Start exploring your food today and take control of your dietary choices!</p>

 <div className="text-sm text-muted-foreground italic mt-6">
 <p>Disclaimer: The AI Ingredients Checker provides information for educational purposes only and is not a substitute for professional medical or dietary advice. Always consult a healthcare professional for health concerns and dietary needs.</p>
 </div>
 </CardContent>
 </Card>
        </CardContent>
        <CardFooter>
          <p className="text-xs text-muted-foreground w-full text-center">
            This tool uses AI for ingredients analysis. Always verify information with manufacturers and consult healthcare professionals.
          </p>
        </CardFooter>
      </Card>
    </div>
  );
    </>
)}    


================================================
FILE: src/app/login/page.tsx
================================================

'use client';

import Head from 'next/head';
import { useEffect, useState } from 'react';
import { useRouter } from 'next/navigation';
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '@/components/ui/card';
import LoginButton from '@/components/auth/login-button';
import { ScanLine, Loader2 } from 'lucide-react';

export default function LoginPage() {
  const router = useRouter();
  const [isPuterReady, setIsPuterReady] = useState(false);
  const [authCheckComplete, setAuthCheckComplete] = useState(false);

  useEffect(() => {
    console.log("[LoginPage] useEffect for Puter availability check triggered.");
    const checkPuterAvailability = () => {
      if (typeof window.puter !== 'undefined' && typeof window.puter.auth !== 'undefined') {
        console.log("[LoginPage] Puter SDK is available.");
        setIsPuterReady(true);
        return true;
      }
      console.log("[LoginPage] Puter SDK not yet available.");
      return false;
    };

    if (checkPuterAvailability()) {
      // If Puter is ready, proceed to check auth status in the next useEffect
    } else {
      const intervalId = setInterval(() => {
        console.log("[LoginPage] Interval: Checking Puter SDK availability...");
        if (checkPuterAvailability()) {
          clearInterval(intervalId);
        }
      }, 100);
      return () => {
        console.log("[LoginPage] Cleanup: Clearing Puter availability check interval.");
        clearInterval(intervalId);
      };
    }
  }, []);

  useEffect(() => {
    if (!isPuterReady) {
      console.log("[LoginPage] Auth check useEffect: Waiting for Puter SDK to be ready.");
      return;
    }

    console.log("[LoginPage] Auth check useEffect: Puter SDK is ready. Starting auth status check and redirect logic.");
    const checkAuthAndRedirect = async () => {
      try {
        const isSignedIn = await window.puter.auth.isSignedIn();
        console.log("[LoginPage] Auth check useEffect: Puter isSignedIn() returned:", isSignedIn);
        if (isSignedIn) {
          console.log("[LoginPage] Auth check useEffect: User is signed in, redirecting to /");
          router.replace('/'); 
        } else {
          console.log("[LoginPage] Auth check useEffect: User is not signed in. Auth check complete.");
          setAuthCheckComplete(true); 
        }
      } catch (error) {
        console.error("[LoginPage] Auth check useEffect: Error checking auth status:", error);
        setAuthCheckComplete(true); 
      }
    };

    checkAuthAndRedirect();
  }, [isPuterReady, router]); 

  if (!isPuterReady || !authCheckComplete) {
    return (
      <div className="flex min-h-[calc(100vh-4rem)] items-center justify-center p-4">
        <Loader2 className="h-12 w-12 animate-spin text-primary" />
        <span className="ml-4 text-lg">Initializing...</span>
      </div>
    );
  }

  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/login" />
      </Head>
    <div className="flex min-h-[calc(100vh-4rem)] items-center justify-center p-4">
      <Card className="w-full max-w-md shadow-xl">
        <CardHeader className="text-center">
          <div className="mx-auto mb-4">
            <ScanLine className="h-16 w-16 text-primary" />
          </div>
          <CardTitle className="font-headline text-3xl">Welcome to MediScan AI</CardTitle>
          <CardDescription>Securely analyze your medical images.</CardDescription>
        </CardHeader>
        <CardContent className="flex flex-col items-center space-y-6">
          <p className="text-center text-muted-foreground">
            Please log in using your Puter account to continue.
          </p>
          <LoginButton />
        </CardContent>
      </Card>
    </div>
  );
    </>
)}    



================================================
FILE: src/app/measuring-tool/page.tsx
================================================
'use client';

import Head from 'next/head';
import { useState, useEffect } from 'react';
import { useToast } from "@/hooks/use-toast";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from "@/components/ui/card";
import { Textarea } from "@/components/ui/textarea";
import { Input } from "@/components/ui/input";
import { Label } from "@/components/ui/label";
import { Alert, AlertDescription, AlertTitle } from "@/components/ui/alert";
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from "@/components/ui/select";
import { Loader2, ImageUp, Ruler, AlertTriangle, Info, Download } from 'lucide-react';
import { preprocessImage } from '@/lib/image-utils';
import { downloadTextFile } from '@/lib/utils';
import ImagePreview from '@/components/medi-scan/image-preview';
import type { MeasurementReport } from '@/types/measuring-tool';

const cleanJsonString = (rawString: string): string => {
  let cleanedString = rawString.trim();
  if (cleanedString.startsWith("```json") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(7, cleanedString.length - 3).trim();
  } else if (cleanedString.startsWith("```") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(3, cleanedString.length - 3).trim();
  }
  return cleanedString;
};

export default function MeasuringToolPage() {
  const [imageFile, setImageFile] = useState<File | null>(null);
  const [imageDataUrl, setImageDataUrl] = useState<string | null>(null);
  const [metricSystem, setMetricSystem] = useState<string>('');
  const [measurementTarget, setMeasurementTarget] = useState<string>('');
  const [additionalContext, setAdditionalContext] = useState<string>('');
  
  const [analysisReport, setAnalysisReport] = useState<MeasurementReport | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const { toast } = useToast();

  useEffect(() => {
    if (typeof window.puter === 'undefined') {
      toast({
        variant: "destructive",
        title: "Puter SDK Error",
        description: "Puter.js SDK is not loaded. Please refresh the page.",
      });
    }
  }, [toast]);

  const handleImageFileChange = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      setImageFile(file);
      try {
        const previewDataUrl = URL.createObjectURL(file);
        setImageDataUrl(previewDataUrl);
        setAnalysisReport(null);
        setError(null);
      } catch (error) {
        toast({ variant: "destructive", title: "Preview Error", description: "Could not generate image preview." });
        setImageDataUrl(null);
      }
    } else {
      setImageFile(null);
      setImageDataUrl(null);
    }
  };

  const performAnalysis = async () => {
    if (!imageFile) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please upload an image of the object to measure." });
      return;
    }
    if (!measurementTarget.trim()) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please specify what you want to measure." });
      return;
    }
    if (!metricSystem) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please select a measurement system." });
      return;
    }

    setIsLoading(true);
    setAnalysisReport(null);
    setError(null);
    toast({ title: "Analysis Started", description: "AI is analyzing your measurement request..." });

    try {
      if (typeof window.puter === 'undefined' || !window.puter.auth || !window.puter.ai) {
        throw new Error("Puter SDK not available. Please refresh.");
      }
      const puter = window.puter;

      let isSignedIn = await puter.auth.isSignedIn();
      if (!isSignedIn) {
        await puter.auth.signIn();
        isSignedIn = await puter.auth.isSignedIn();
        if (!isSignedIn) throw new Error("Authentication failed or was cancelled.");
      }

      const preprocessedDataUrl = await preprocessImage(imageFile, 1024);

      const imagePrompt = `
        You are an AI assistant specialized in analyzing images to estimate measurements.
        Analyze this image and provide measurements for: "${measurementTarget}"
        Preferred measurement system: ${metricSystem}
        Additional context: "${additionalContext || 'None provided'}"

        Consider:
        1. Use visible reference objects or markers if present
        2. Look for standard-sized objects that could help with scale
        3. Consider perspective and depth
        4. Note any limitations in accuracy
        
        Return a JSON object with:
        {
          "image_description": "Brief description of the image and object to be measured",
          "measurements": [
            {
              "target": "What was measured",
              "value": number,
              "unit": "unit of measurement",
              "confidence": number (0-1)
            }
          ],
          "visual_reference_points": ["List of objects used as reference points"],
          "confidence": "High|Medium|Low|Not Applicable",
          "limitations": ["List of factors affecting measurement accuracy"],
          "disclaimer": "Standard measurement accuracy disclaimer"
        }
      `;

      const response = await puter.ai.chat(imagePrompt, preprocessedDataUrl);
      
      if (!response?.message?.content) {
        throw new Error("AI analysis did not return content.");
      }

      const parsedResponse: MeasurementReport = JSON.parse(cleanJsonString(response.message.content));
      setAnalysisReport(parsedResponse);
      toast({ title: "Analysis Complete", variant: "default", className: "bg-green-500 text-white dark:bg-green-600" });

    } catch (err: any) {
      console.error("Analysis error:", err);
      let errorMessage = "An error occurred during analysis.";
      if (err instanceof Error) errorMessage = err.message;
      else if (typeof err === 'string') errorMessage = err;
      else if (err.error && err.error.message) errorMessage = err.error.message;
      setError(errorMessage);
      toast({ variant: "destructive", title: "Analysis Failed", description: errorMessage });
    } finally {
      setIsLoading(false);
    }
  };

  const handleDownloadReport = () => {
    if (!analysisReport) return;

    let reportString = "KLUTZ AI Measuring Tool Report\n";
    reportString += "==============================\n\n";

    reportString += "Measurement Request:\n";
    reportString += "-------------------\n";
    reportString += `Target to Measure: ${measurementTarget}\n`;
    reportString += `Measurement System: ${metricSystem}\n`;
    if (additionalContext) {
      reportString += `Additional Context: ${additionalContext}\n`;
    }
    reportString += "\n";

    reportString += "Image Analysis:\n";
    reportString += "--------------\n";
    reportString += `${analysisReport.image_description}\n\n`;

    reportString += "Measurements:\n";
    reportString += "-------------\n";
    analysisReport.measurements.forEach(measurement => {
      reportString += `- ${measurement.target}: ${measurement.value} ${measurement.unit}\n`;
      reportString += `  Confidence: ${(measurement.confidence * 100).toFixed(1)}%\n`;
    });
    reportString += "\n";

    reportString += "Reference Points Used:\n";
    reportString += "--------------------\n";
    analysisReport.visual_reference_points.forEach(point => {
      reportString += `- ${point}\n`;
    });
    reportString += "\n";

    reportString += "Limitations:\n";
    reportString += "------------\n";
    analysisReport.limitations.forEach(limitation => {
      reportString += `- ${limitation}\n`;
    });
    reportString += "\n";

    reportString += "AI Confidence Level: " + analysisReport.confidence + "\n\n";
    reportString += "Disclaimer:\n";
    reportString += "-----------\n";
    reportString += analysisReport.disclaimer + "\n\n";
    
    reportString += "\nIMPORTANT: This report is AI-generated and for informational purposes only. Measurements are estimates and should be verified with proper measuring tools when accuracy is critical.";

    const timestamp = new Date().toISOString().replace(/[:.-]/g, '').slice(0, 14);
    downloadTextFile(reportString, `KLUTZ_MeasuringTool_Report_${timestamp}.txt`);
  };

  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/measuring-tool" />
      </Head>
    <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-8">
      <Card className="max-w-3xl mx-auto shadow-xl">
        <CardHeader>
          <CardTitle className="font-headline text-3xl text-primary flex items-center">
            <Ruler className="mr-3 h-8 w-8" />
            AI Measuring Tool
          </CardTitle>
          <CardDescription>
            Upload an image of a physical object and get AI-powered measurements in your preferred metric system.
          </CardDescription>
        </CardHeader>
        <CardContent className="space-y-6">
          <Alert variant="default" className="bg-yellow-50 border-yellow-400 text-yellow-700 dark:bg-yellow-900/30 dark:text-yellow-300">
            <AlertTriangle className="h-5 w-5 text-yellow-500" />
            <AlertTitle className="font-semibold">Important Note</AlertTitle>
            <AlertDescription>
              Measurements are estimates based on visual analysis. For precise measurements, always use proper measuring tools.
              The accuracy depends on image quality and available reference points.
            </AlertDescription>
          </Alert>

          <div>
            <Label htmlFor="image-upload" className="text-lg font-medium flex items-center mb-2">
              <ImageUp className="mr-2 h-5 w-5 text-accent" />
              Upload Image
            </Label>
            <Input
              id="image-upload"
              type="file"
              accept="image/png, image/jpeg, image/webp"
              onChange={handleImageFileChange}
              className="file:text-primary file:font-semibold file:bg-primary/10 hover:file:bg-primary/20"
              disabled={isLoading}
            />
            <p className="text-sm text-muted-foreground mt-1">Upload a clear image of the object you want to measure.</p>
          </div>

          {imageDataUrl && <ImagePreview imageDataUrl={imageDataUrl} dataAiHint="object to measure"/>}

          <div className="space-y-4">
            <div>
              <Label htmlFor="metric-system" className="text-lg font-medium">Measurement System</Label>
              <Select value={metricSystem} onValueChange={setMetricSystem}>
                <SelectTrigger id="metric-system" className="w-full">
                  <SelectValue placeholder="Select measurement system" />
                </SelectTrigger>
                <SelectContent>
                  <SelectItem value="metric">Metric (cm, m, etc.)</SelectItem>
                  <SelectItem value="imperial">Imperial (inches, feet, etc.)</SelectItem>
                </SelectContent>
              </Select>
            </div>

            <div>
              <Label htmlFor="measurement-target" className="text-lg font-medium">What to Measure</Label>
              <Textarea
                id="measurement-target"
                placeholder="Describe what you want to measure in the image (e.g., 'height of the table', 'width of the door')..."
                value={measurementTarget}
                onChange={(e) => setMeasurementTarget(e.target.value)}
                className="min-h-[100px]"
              />
            </div>

            <div>
              <Label htmlFor="additional-context" className="text-lg font-medium">Additional Context (Optional)</Label>
              <Textarea
                id="additional-context"
                placeholder="Any additional details that might help with measurement (e.g., known dimensions of visible objects)..."
                value={additionalContext}
                onChange={(e) => setAdditionalContext(e.target.value)}
              />
            </div>
          </div>

          <Button 
            onClick={performAnalysis} 
            disabled={isLoading || !imageFile || !metricSystem || !measurementTarget.trim()} 
            className="w-full"
          >
            {isLoading ? (
              <>
                <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                Analyzing Measurements...
              </>
            ) : (
              'Analyze Measurements'
            )}
          </Button>

          {error && !isLoading && (
            <Alert variant="destructive" className="mt-6">
              <AlertTriangle className="h-5 w-5" />
              <AlertTitle>Analysis Error</AlertTitle>
              <AlertDescription>{error}</AlertDescription>
            </Alert>
          )}

          {analysisReport && !isLoading && !error && (
            <Card className="mt-6 shadow-md">
              <CardHeader>
                <CardTitle className="font-headline text-xl flex items-center">
                  <Ruler className="mr-2 h-6 w-6 text-primary" />
                  Measurement Results
                </CardTitle>
              </CardHeader>
              <CardContent className="space-y-4">
                <div>
                  <h4 className="font-semibold text-md mb-1">Image Analysis:</h4>
                  <p className="bg-muted/30 p-3 rounded-md">{analysisReport.image_description}</p>
                </div>

                <div>
                  <h4 className="font-semibold text-md mb-1">Measurements:</h4>
                  <div className="space-y-2">
                    {analysisReport.measurements.map((measurement, index) => (
                      <div key={index} className="bg-green-50 dark:bg-green-900/20 p-3 rounded-md">
                        <p className="font-medium text-green-700 dark:text-green-300">
                          {measurement.target}: {measurement.value} {measurement.unit}
                        </p>
                        <p className="text-sm text-green-600 dark:text-green-400">
                          Confidence: {(measurement.confidence * 100).toFixed(1)}%
                        </p>
                      </div>
                    ))}
                  </div>
                </div>

                <div>
                  <h4 className="font-semibold text-md mb-1">Reference Points Used:</h4>
                  <ul className="list-disc pl-5 space-y-1 bg-blue-50 dark:bg-blue-900/20 p-3 rounded-md">
                    {analysisReport.visual_reference_points.map((point, index) => (
                      <li key={index} className="text-blue-700 dark:text-blue-300">{point}</li>
                    ))}
                  </ul>
                </div>

                <div>
                  <h4 className="font-semibold text-md mb-1">Limitations:</h4>
                  <ul className="list-disc pl-5 space-y-1 bg-yellow-50 dark:bg-yellow-900/20 p-3 rounded-md">
                    {analysisReport.limitations.map((limitation, index) => (
                      <li key={index} className="text-yellow-700 dark:text-yellow-300">{limitation}</li>
                    ))}
                  </ul>
                </div>

                <Alert variant="default" className="text-xs bg-blue-50 border-blue-300 dark:bg-blue-900/30 dark:text-blue-300">
                  <Info className="h-4 w-4 text-blue-500" />
                  <AlertTitle className="font-medium">Disclaimer</AlertTitle>
                  <AlertDescription>{analysisReport.disclaimer}</AlertDescription>
                </Alert>

                <Button onClick={handleDownloadReport} variant="outline" className="w-full mt-4">
                  <Download className="mr-2 h-4 w-4" />
                  Download Report
                </Button>
              </CardContent>
            </Card>
          )}

          {!analysisReport && !isLoading && !error && (
            <div className="mt-6 p-4 border border-dashed rounded-md text-center text-muted-foreground">
              <Info className="mx-auto h-8 w-8 mb-2"/>
              <p>Upload an image, select your measurement system, and specify what you want to measure to get AI-powered measurements.</p>
            </div>
          )}
        </CardContent>
        <CardFooter>
          <p className="text-xs text-muted-foreground w-full text-center">
            This tool uses AI for measurement estimation. For precise measurements, always use proper measuring tools.
          </p>
        </CardFooter>
      </Card>

      {/* Blog Section */}
      <div className="max-w-3xl mx-auto mt-12 px-4 sm:px-6 lg:px-8 prose prose-sm sm:prose lg:prose-lg dark:prose-invert">
        <h1>The Complete Guide to AI Measuring Tools: Revolutionizing Digital Measurements</h1>

        <p>In today's digital age, the ability to measure objects accurately without physical contact has become increasingly important. AI measuring tools represent a breakthrough in measurement technology, combining artificial intelligence with visual analysis to provide precise measurements from digital images. These innovative solutions are transforming how we approach measurement tasks across various industries and personal applications.</p>

        <h2>What is an AI Measuring Tool?</h2>

        <p>An AI measuring tool is a sophisticated software application that uses artificial intelligence algorithms to analyze images and calculate the dimensions of objects within them. Unlike traditional online ruler applications that require manual calibration with a physical reference like a plastic card, AI measuring tools can automatically determine scale and provide measurements in various units including inches and centimeters.</p>

        <p>These tools operate by analyzing pixels in uploaded images, using advanced computer vision technology to identify objects and calculate their actual physical dimensions. The measurement process typically involves setting a reference point or allowing the AI to automatically detect scale based on recognizable objects in the image.</p>

        <h2>Key Features to Check When Searching for the Best AI Measuring Tool</h2>

        <p>When evaluating AI measuring tools, several critical features determine their effectiveness and reliability:</p>

        <h3>Accuracy and Precision</h3>
        <p>The most important consideration is the tool's ability to provide accurate measurements. Look for tools that can handle various object sizes and shapes while maintaining high precision. The measurement accuracy depends on image quality, resolution, and the AI's ability to correctly interpret scale and proportions.</p>

        <h3>Calibration Methods</h3>
        <p>Effective AI measuring tools should offer multiple calibration options. Some tools require users to input screen diagonal information or use a standard reference object like a plastic card to set scale. The best tools can automatically calibrate using recognizable objects or by allowing users to enter known dimensions for reference.</p>

        <h3>Measurement Units and Flexibility</h3>
        <p>Quality tools should support multiple measurement systems, allowing users to switch between inches, centimeters, millimeters, and other metric units. The ability to change measurement units seamlessly is essential for different applications and user preferences.</p>

        <h3>User Interface and Ease of Use</h3>
        <p>The tool's interface should be intuitive, with clear input fields and simple navigation. Users should be able to easily upload images, set parameters, and view results without confusion. Desktop browsers should provide a smooth experience with minimal distortion when displaying measurements.</p>

        <h3>Image Processing Capabilities</h3>
        <p>Advanced AI measuring tools can handle various image formats and qualities. They should be able to process images effectively regardless of lighting conditions, angles, or background complexity while maintaining measurement reliability.</p>

        <h2>Best FREE AI Measuring Tools</h2>

        <h3>1. Klutz AI Measuring Tool - The Pioneer in AI Analysis</h3>
        <p>Klutz's AI measuring tool stands out as the first tool with AI analysis features, revolutionizing how we approach digital measurements. This groundbreaking platform combines sophisticated artificial intelligence with user-friendly design to deliver exceptional measurement capabilities.</p>

        <p><strong>Price:</strong> Free</p>

        <h4>Pros:</h4>
        <ul>
          <li>First-to-market AI analysis technology that automatically detects and measures objects</li>
          <li>No manual calibration required - the AI handles scale determination automatically</li>
          <li>Supports multiple measurement units (inches, centimeters, millimeters)</li>
          <li>Clean, intuitive interface that works seamlessly across desktop browsers</li>
          <li>High accuracy for various object types and sizes</li>
          <li>No account registration required</li>
          <li>Handles different image qualities and lighting conditions effectively</li>
        </ul>

        <h4>Cons:</h4>
        <ul>
          <li>Accuracy depends on image quality and clarity</li>
          <li>May require good lighting for optimal results</li>
          <li>Limited to 2D measurements from single images</li>
        </ul>

        <p>What makes Klutz's tool particularly impressive is its ability to analyze images without requiring users to manually set scale using a plastic card or enter screen diagonal information. The AI automatically determines the actual physical size of objects, making it incredibly convenient for quick measurements.</p>

        <h3>2. ImageMeasurement.online</h3>
        <p>This online ruler platform offers basic measurement functionality with some automated features.</p>

        <p><strong>Price:</strong> Free with premium plans available</p>

        <h4>Pros:</h4>
        <ul>
          <li>Simple drag-and-drop interface</li>
          <li>Automatic square detection for cropping</li>
          <li>Supports multiple image formats</li>
          <li>No download required - works entirely in browser</li>
        </ul>

        <h4>Cons:</h4>
        <ul>
          <li>Requires manual calibration using reference objects</li>
          <li>Limited AI analysis compared to Klutz's advanced features</li>
          <li>May experience scaling issues on different screen sizes</li>
          <li>Less accurate for complex object shapes</li>
        </ul>

        <h3>3. Measurement AI (YesChat.ai)</h3>
        <p>While primarily a conversational AI assistant for measurement guidance, this tool provides helpful measurement advice and unit conversions.</p>

        <p><strong>Price:</strong> Free</p>

        <h4>Pros:</h4>
        <ul>
          <li>Provides measurement guidance and tips</li>
          <li>Excellent for unit conversions</li>
          <li>Educational value for learning measurement techniques</li>
          <li>Available without login requirements</li>
        </ul>

        <h4>Cons:</h4>
        <ul>
          <li>Not a true image analysis tool</li>
          <li>Cannot directly measure objects from images</li>
          <li>Requires significant manual input for calculations</li>
          <li>Limited practical application for immediate measurement needs</li>
        </ul>

        <h2>Calibration and Accuracy Considerations</h2>

        <p>When using any AI measuring tool, understanding calibration is crucial for accurate results. Traditional online rulers often require users to calibrate their screen by measuring a plastic card or entering their screen diagonal in inches. However, advanced AI tools like Klutz's measuring solution have revolutionized this process by automatically determining scale through intelligent image analysis.</p>

        <p>The accuracy of measurements can be affected by several factors:</p>
        <ul>
          <li>Image resolution and quality</li>
          <li>Lighting conditions</li>
          <li>Camera angle and perspective</li>
          <li>Object positioning and background</li>
          <li>Screen calibration (for traditional tools)</li>
        </ul>

        <p>For optimal results, ensure images are clear, well-lit, and taken from appropriate angles. When manual calibration is required, use a standard plastic card as reference, as most tools are designed to recognize the standard width of payment cards (typically 3.375 inches or 85.6mm).</p>

        <h2>Technical Considerations and Browser Compatibility</h2>

        <p>Modern AI measuring tools are designed to work across various desktop browsers and devices. However, some technical considerations can affect performance:</p>

        <h3>Display and Resolution</h3>
        <p>The tool's accuracy can be influenced by your display resolution and screen size. Tools that require manual calibration often ask users to set screen diagonal measurements or use the actual physical size of reference objects for proper scaling.</p>

        <h3>JavaScript and Browser Requirements</h3>
        <p>Most AI measuring tools require JavaScript enabled browsers to function properly. Ensure your browser supports modern web applications and has JavaScript enabled for optimal functionality.</p>

        <h3>Pixel Density and PPI Calculations</h3>
        <p>Advanced tools calculate measurements by analyzing pixel relationships and determining the pixels per inch (PPI) ratio. This process involves complex algorithms that convert virtual pixels to real-world measurements based on reference points or AI analysis.</p>

        <h2>TLDR - Quick Summary</h2>

        <p>AI measuring tools represent a significant advancement in digital measurement technology, with Klutz's AI measuring tool leading the innovation as the first tool with comprehensive AI analysis features. Here are the key takeaways:</p>
        <ul>
          <li><strong>Best Overall:</strong> Klutz AI Measuring Tool - offers automatic AI analysis without manual calibration</li>
          <li><strong>Key Features to Look For:</strong> Accuracy, easy calibration, multiple measurement units, user-friendly interface</li>
          <li><strong>Calibration:</strong> Advanced tools like Klutz eliminate the need for manual calibration with plastic cards or screen diagonal input</li>
          <li><strong>Accuracy:</strong> Results depend on image quality, lighting, and the sophistication of the AI analysis</li>
          <li><strong>Cost:</strong> Several excellent free options available, with Klutz providing the most advanced features at no cost</li>
        </ul>

        <p>Whether you need to measure objects for professional purposes or personal projects, AI measuring tools offer convenient, accurate solutions that continue to evolve with advancing technology. Klutz's pioneering AI analysis approach sets the standard for what these tools can achieve, making precise measurements more accessible than ever before.</p>
      </div>
    </div>
  );
    </>
)}    


================================================
FILE: src/app/mediscan/page.tsx
================================================
"use client";

import { useState, useEffect } from "react";
import Head from 'next/head';
import { Label } from "@/components/ui/label";
import { Input } from "@/components/ui/input";
import { Textarea } from "@/components/ui/textarea";
import { Button } from "@/components/ui/button";
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from "@/components/ui/select";
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from "@/components/ui/card";
import { Alert, AlertDescription, AlertTitle } from "@/components/ui/alert";
import { Info, Loader2, AlertTriangle } from 'lucide-react';
import { MedicalImageAnalysisRequest, MedicalImageAnalysisResponse, MedicalImageType } from "@/types/mediscan";
import puter from "puter";
import { useToast } from "@/hooks/use-toast";
import { preprocessImage } from "@/lib/image-utils";
import ImagePreview from "@/components/medi-scan/image-preview";
import { Copy, Download } from 'lucide-react';

declare global {
  interface Window { puter: any; }
}

const cleanJsonString = (rawString: string): string => {
  let cleanedString = rawString.trim();
  if (cleanedString.startsWith("```json") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(7, cleanedString.length - 3).trim();
  } else if (cleanedString.startsWith("```") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(3, cleanedString.length - 3).trim();
  }
  return cleanedString;
};

const downloadTextFile = (text: string, filename: string) => {
  const blob = new Blob([text], { type: 'text/plain' });
  const url = URL.createObjectURL(blob);
  window.puter.fs.download(url, filename);
};

export default function MedicalImageAnalyzerPage() {

  const [imageFile, setImageFile] = useState<File | null>(null);
  const [imageDataUrl, setImageDataUrl] = useState<string | null>(null);
  const [imageType, setImageType] = useState<MedicalImageType | "">("");
  const [additionalInfo, setAdditionalInfo] = useState("");
  const [analysisResult, setAnalysisResult] = useState<MedicalImageAnalysisResponse | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const { toast } = useToast();

  useEffect(() => {
    if (typeof window.puter === 'undefined') {
      toast({
        variant: "destructive",
        title: "Puter SDK Error",
        description: "Puter.js SDK is not loaded. Please refresh the page.",
      });
    }
  }, [toast]);

  const handleImageUpload = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      setImageFile(file);
      try {
        const previewDataUrl = URL.createObjectURL(file);
        setImageDataUrl(previewDataUrl);
        setAnalysisResult(null);
        setError(null);
      } catch (error) {
        toast({ variant: "destructive", title: "Preview Error", description: "Could not generate image preview." });
        setImageDataUrl(null);
      }
    } else {
      setImageFile(null);
      setImageDataUrl(null);
    }
  };

  const handleAnalyze = async () => {
    if (!imageFile) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please upload an image containing text." });
      return;
    }

    setIsLoading(true);
    setAnalysisResult(null);
    setError(null);
    toast({ title: "Analysis Started", description: "AI is Analyzing The Medical Image..." });

    try {
      if (typeof window.puter === 'undefined' || !window.puter.auth || !window.puter.ai) {
        throw new Error("Puter SDK not available. Please refresh.");
      }
      const puter = window.puter;

      let isSignedIn = await puter.auth.isSignedIn();
      if (!isSignedIn) {
        await puter.auth.signIn();
        isSignedIn = await puter.auth.isSignedIn();
        if (!isSignedIn) throw new Error("Authentication failed or was cancelled.");
      }

      const preprocessedDataUrl = await preprocessImage(imageFile, 1024);

      const imagePrompt = `
        You are an AI assistant specialized in analyzing medical images.
        Analyze the provided ${imageType} medical image and generate a structured report.
        Include: 
        1. Identified abnormalities (if any). If none, state clearly.
        2. A potential diagnosis based on the findings (clearly state this is NOT a substitute for professional medical advice)
        3. Suggested next steps or recommendations (again, non-diagnostic)
        Consider the additional information: ${additionalInfo || 'None provided.'}

        Return the analysis as a JSON object with the following keys:
        - "abnormalities": (string) Description of any abnormalities found.
        - "diagnosis": (string) Potential diagnosis (clearly marked as NOT professional medical advice).
        - "nextSteps": (string) Suggested next steps (clearly marked as non-diagnostic).
      `;

      const response = await puter.ai.chat(imagePrompt, preprocessedDataUrl);
      
      if (!response?.message?.content) {
        throw new Error("AI analysis did not return content.");
      }

      const parsedResponse: MedicalImageAnalysisResponse = JSON.parse(cleanJsonString(response.message.content));
      setAnalysisResult(parsedResponse);
      toast({ title: "Analysis Complete", variant: "default", className: "bg-green-500 text-white dark:bg-green-600" });

    } catch (err: any) {
      console.error("Analysis error:", err);
      let errorMessage = "An error occurred during analysis.";
      if (err instanceof Error) errorMessage = err.message;
      else if (typeof err === 'string') errorMessage = err;
      else if (err.error && err.error.message) errorMessage = err.error.message;
      setError(errorMessage);
      toast({ variant: "destructive", title: "Analysis Failed", description: errorMessage });
    } finally {
      setIsLoading(false);
    }
  };

  const handleCopyReport = () => {
    if (!analysisResult) return;
    const reportString = `
Medical Image Analysis Report
===========================

Abnormalities Found:
-------------------
${analysisResult.abnormalities}

Potential Diagnosis:
------------------
${analysisResult.diagnosis}

Suggested Next Steps:
-------------------
${analysisResult.nextSteps}

Disclaimer: This is an AI-generated analysis and NOT a substitute for professional medical advice. Always consult a healthcare professional for diagnosis and treatment.
`;
    navigator.clipboard.writeText(reportString.trim())
      .then(() => {
        toast({ title: "Report Copied", description: "Analysis report copied to clipboard." });
      })
      .catch(() => {
        toast({ variant: "destructive", title: "Copy Failed", description: "Could not copy report to clipboard." });
      });
  };

  const handleDownloadReport = () => {
    if (!analysisResult) return;
    const reportString = `Medical Image Analysis Report\n\nAbnormalities Found:\n${analysisResult.abnormalities}\n\nPotential Diagnosis:\n${analysisResult.diagnosis}\n\nSuggested Next Steps:\n${analysisResult.nextSteps}\n\nDisclaimer: This is an AI-generated analysis and NOT a substitute for professional medical advice. Always consult a healthcare professional for diagnosis and treatment.`;
    const timestamp = new Date().toISOString().replace(/[:.-]/g, '').slice(0, 14);
    downloadTextFile(reportString, `KLUTZ_MediScan_Report_${timestamp}.txt`);
    toast({ title: "Report Downloaded", description: "Analysis report downloaded as a text file." });
  };

  const disclaimer = "Disclaimer: This is an AI-generated analysis and NOT a substitute for professional medical advice. Always consult a healthcare professional for diagnosis and treatment.";




  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/mediscan" />
        <title>Medical Image Analyzer - KLUTZ</title>
        <meta name="description" content="Upload medical images (X-rays, MRIs, CT scans) for AI-powered analysis and insights with KLUTZ Medical Scan." />
      </Head>
      <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-8">
        <h1 className="text-2xl font-bold mb-4">Medical Image Analyzer</h1>

        <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
          <div>
            <Card>
              <CardHeader>
                <CardTitle>Upload Medical Image</CardTitle>
              </CardHeader>
              <CardContent>
                <Label htmlFor="medical-image">Upload Image</Label>
                <Input id="medical-image" type="file" accept="image/*" onChange={handleImageUpload} />
                {imageDataUrl && <ImagePreview imageDataUrl={imageDataUrl} dataAiHint="medical image" />}
              </CardContent>
            </Card>

            <Card className="mt-4">
              <CardHeader>
                <CardTitle>Image Information</CardTitle>
              </CardHeader>
              <CardContent>
                <div className="mb-4">
                  <Label htmlFor="image-type">Image Type</Label>
                  <Select onValueChange={(value: MedicalImageType) => setImageType(value)} value={imageType}>
                    <SelectTrigger id="image-type">
                      <SelectValue placeholder="Select image type" />
                    </SelectTrigger>
                    <SelectContent>
                      <SelectItem value="x-ray">X-Ray</SelectItem>
                      <SelectItem value="mri">MRI</SelectItem>
                      <SelectItem value="ct scan">CT Scan</SelectItem>
                      <SelectItem value="ultrasound">Ultrasound</SelectItem>
                      <SelectItem value="other">Other</SelectItem>
                    </SelectContent>
                  </Select>
                </div>
                <div>
                  <Label htmlFor="additional-info">Additional Information (Optional)</Label>
                  <Textarea id="additional-info" value={additionalInfo} onChange={(e) => setAdditionalInfo(e.target.value)} rows={4} />
                </div>
                <Button onClick={handleAnalyze} disabled={!imageFile || !imageType || isLoading} className="mt-4 w-full">
                  {isLoading ? "Analyzing..." : "Analyze Image"}
                  {isLoading && <Loader2 className="ml-2 h-4 w-4 animate-spin" />}
                </Button>
                {!analysisResult && !isLoading && !error && (
                  <div className="mt-6 p-4 border border-dashed rounded-md text-center text-muted-foreground">
                    <Info className="mx-auto h-8 w-8 mb-2" />
                    <p>Upload a medical image, select its type, and click "Analyze Image" to get an AI-powered analysis.</p>
                  </div>
                )}
              </CardContent>
            </Card>
          </div>

          {analysisResult && (
            <div className="space-y-4">
              <Card className="border-green-500 dark:border-green-700 bg-green-50 dark:bg-green-900/20">
                <CardHeader>
                  <CardTitle className="text-green-700 dark:text-green-300">Abnormalities Found</CardTitle>
                </CardHeader>
                <CardContent>
                  <p className="text-green-800 dark:text-green-200">{analysisResult.abnormalities}</p>
                </CardContent>
              </Card>

              <Card className="border-blue-500 dark:border-blue-700 bg-blue-50 dark:bg-blue-900/20">
                <CardHeader>
                  <CardTitle className="text-blue-700 dark:text-blue-300">Potential Diagnosis</CardTitle>
                </CardHeader>
                <CardContent>
                  <p className="text-blue-800 dark:text-blue-200">{analysisResult.diagnosis}</p>
                </CardContent>
              </Card>

              <Card className="border-purple-500 dark:border-purple-700 bg-purple-50 dark:bg-purple-900/20">
                <CardHeader>
                  <CardTitle className="text-purple-700 dark:text-purple-300">Suggested Next Steps</CardTitle>
                </CardHeader>
                <CardContent>
                  <p className="text-purple-800 dark:text-purple-200">{analysisResult.nextSteps}</p>
                </CardContent>
              </Card>

              <Card className="border-yellow-500 dark:border-yellow-700 bg-yellow-50 dark:bg-yellow-900/20">
                 <CardHeader>
                  <CardTitle className="text-yellow-700 dark:text-yellow-300">Disclaimer</CardTitle>
                 </CardHeader>
                 <CardContent>
                  <p className="text-yellow-800 dark:text-yellow-200 text-sm italic">{disclaimer}</p>
                 </CardContent>
              </Card>

              <Card className="p-4 flex gap-4 bg-muted/30">
                 <Button onClick={handleCopyReport} className="flex-1">
                  <Copy className="mr-2 h-4 w-4" /> Copy Report
                 </Button>
                 <Button onClick={handleDownloadReport} className="flex-1">
                  <Download className="mr-2 h-4 w-4" /> Download Report
                 </Button>
              </Card>
            </div>
          )}

          {error && !isLoading && (
            <Alert variant="destructive" className="mt-6">
              <AlertTriangle className="h-5 w-5" />
              <AlertTitle>Analysis Error</AlertTitle>
              <AlertDescription>{error}</AlertDescription>
            </Alert>
          )}
        </div>
        <div className="mt-16">
          <h2 className="text-3xl font-bold mb-6">The Complete Guide to MediScan: Revolutionizing Medical Image Analysis</h2>

          <p className="mb-4">In the rapidly evolving landscape of healthcare technology, tools that enhance diagnostic capabilities and streamline workflows are invaluable. MediScan is at the forefront of this revolution, offering a powerful AI-driven platform designed to assist medical professionals in analyzing medical images with unprecedented speed and accuracy.</p>

          <h3 className="text-2xl font-semibold mb-4">What is MediScan?</h3>

          <p className="mb-4">MediScan is an advanced medical image analysis tool that utilizes artificial intelligence to interpret medical scans, such as X-rays, CT scans, and MRIs. By processing these images through sophisticated algorithms, MediScan can help identify potential anomalies, generate detailed reports, and suggest next steps for diagnosis and treatment. It acts as an intelligent assistant, augmenting the expertise of healthcare providers.</p>

          <h3 className="text-2xl font-semibold mb-4">How MediScan Works</h3>

          <p className="mb-4">The core of MediScan lies in its AI engine, trained on vast datasets of medical images. When a medical image is uploaded, the AI analyzes it, looking for patterns and indicators of various conditions. The process involves:</p>

          <ul className="list-disc list-inside mb-4">
            <li><strong>Image Processing:</strong> Enhancing image quality and preparing it for analysis.</li>
            <li><strong>Feature Extraction:</strong> Identifying key visual features within the image.</li>
            <li><strong>Pattern Recognition:</strong> Comparing identified features against learned patterns of medical conditions.</li>
            <li><strong>Report Generation:</strong> Compiling findings into a structured medical report.</li>
            <li><strong>Suggestion of Next Steps:</strong> Proposing potential follow-up actions based on the analysis.</li>
          </ul>

          <h3 className="text-2xl font-semibold mb-4">Key Features and Benefits</h3>

          <ul className="list-disc list-inside mb-4">
            <li><strong>Enhanced Accuracy:</strong> AI analysis can identify subtle details that might be missed by the human eye.</li>
            <li><strong>Increased Efficiency:</strong> Rapid processing of images saves valuable time for medical professionals.</li>
            <li><strong>Detailed Reporting:</strong> Automatically generated reports provide comprehensive summaries of findings.</li>
            <li><strong>Consistent Analysis:</strong> AI applies consistent criteria, reducing variability in interpretations.</li>
            <li><strong>Assistive Tool:</strong> MediScan is designed to support, not replace, the expertise of medical practitioners.</li>
            <li><strong>Accessibility:</strong> Cloud-based platforms can make advanced analysis more accessible.</li>
          </ul>

          <h3 className="text-2xl font-semibold mb-4">Applications of MediScan</h3>

          <p className="mb-4">MediScan has a wide range of applications across various medical specialties:</p>

          <ul className="list-disc list-inside mb-4">
            <li><strong>Radiology:</strong> Assisting in the detection of fractures, tumors, and other abnormalities in X-rays, CTs, and MRIs.</li>
            <li><strong>Dermatology:</strong> Analyzing skin images for potential signs of melanoma and other skin conditions.</li>
            <li><strong>Pathology:</strong> Assisting in the analysis of tissue samples.</li>
            <li><strong>Cardiology:</strong> Identifying issues in cardiac imaging.</li>
            <li><strong>Preventative Medicine:</strong> Aiding in early detection of diseases.</li>
          </ul>

          <h3 className="text-2xl font-semibold mb-4">Limitations and Ethical Considerations</h3>

          <p className="mb-4">While powerful, it's crucial to acknowledge the limitations of AI in healthcare. MediScan is a tool to aid diagnosis, and the final medical interpretation and decision-making always rest with qualified healthcare professionals. Ethical considerations, such as data privacy, algorithmic bias, and the responsible use of AI in clinical settings, are paramount and continuously addressed in the development and deployment of such tools.</p>

          <h3 className="text-2xl font-semibold mb-4">The Future of Medical Image Analysis with AI</h3>

          <p className="mb-4">The field of AI in medical image analysis is rapidly advancing. Future iterations of tools like MediScan are expected to offer even greater precision, integrate with electronic health records more seamlessly, and potentially contribute to personalized medicine by identifying subtle markers linked to individual patient characteristics.</p>

          <h3 className="text-2xl font-semibold mb-4">Conclusion</h3>

          <p className="mb-4">MediScan represents a significant step forward in leveraging artificial intelligence to enhance medical image analysis. By providing rapid, detailed, and consistent interpretations, it empowers healthcare professionals to make more informed decisions, potentially leading to earlier diagnoses and improved patient outcomes. As the technology continues to evolve, tools like MediScan will play an increasingly vital role in the future of healthcare.</p>

          <h3 className="text-2xl font-semibold mb-4">TLDR: Quick Summary</h3>

          <p className="mb-4">MediScan is an AI tool that analyzes medical images to help detect anomalies, generate reports, and suggest next steps. It enhances accuracy and efficiency for medical professionals but does not replace their judgment. It has various applications in radiology, dermatology, and more. While powerful, it's important to consider its limitations and ethical implications. AI in medical imaging is a growing field with the potential for significant future impact.</p>

        </div>
      </div>
    </>
  );
}


================================================
FILE: src/app/neurodiversity-checker/page.tsx
================================================

'use client';

import Head from 'next/head';
import { useState, useEffect } from 'react';
import { useToast } from "@/hooks/use-toast";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from "@/components/ui/card";
import { Textarea } from "@/components/ui/textarea";
import { Input } from "@/components/ui/input";
import { Label } from "@/components/ui/label";
import { Alert, AlertDescription, AlertTitle } from "@/components/ui/alert";
import { Tabs, TabsContent, TabsList, TabsTrigger } from "@/components/ui/tabs";
import { Loader2, ImageUp, Type, Brain, AlertTriangle, Info, CheckCircle, XCircle, FileText, Download } from 'lucide-react';
import { preprocessImage } from '@/lib/image-utils';
import { downloadTextFile } from '@/lib/utils';
import ImagePreview from '@/components/medi-scan/image-preview'; 
import type { NeurodiversityAnalysisReport } from '@/types/neurodiversity-checker';

const cleanJsonString = (rawString: string): string => {
  let cleanedString = rawString.trim();
  if (cleanedString.startsWith("```json") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(7, cleanedString.length - 3).trim();
  } else if (cleanedString.startsWith("```") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(3, cleanedString.length - 3).trim();
  }
  return cleanedString;
};


export default function NeurodiversityCheckerPage() {
  const [inputType, setInputType] = useState<'image' | 'text'>('image');
  const [imageFile, setImageFile] = useState<File | null>(null);
  const [imageDataUrl, setImageDataUrl] = useState<string | null>(null);
  const [textInput, setTextInput] = useState<string>('');
  const [textFile, setTextFile] = useState<File | null>(null);

  const [analysisReport, setAnalysisReport] = useState<NeurodiversityAnalysisReport | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const { toast } = useToast();

   useEffect(() => {
    if (typeof window.puter === 'undefined') {
      toast({
        variant: "destructive",
        title: "Puter SDK Error",
        description: "Puter.js SDK is not loaded. Please refresh the page.",
      });
    }
  }, [toast]);

  const handleImageFileChange = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      setImageFile(file);
      try {
        const previewDataUrl = URL.createObjectURL(file);
        setImageDataUrl(previewDataUrl);
        setAnalysisReport(null); 
        setError(null);
      } catch (previewError) {
        toast({ variant: "destructive", title: "Preview Error", description: "Could not generate image preview." });
        setImageDataUrl(null);
      }
    } else {
      setImageFile(null);
      setImageDataUrl(null);
    }
  };

  const handleTextInputChange = (event: React.ChangeEvent<HTMLTextAreaElement>) => {
    setTextInput(event.target.value);
    setAnalysisReport(null);
    setError(null);
  };

  const handleTextFileChange = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      if (file.type === 'text/plain') {
        setTextFile(file);
        try {
          const textContent = await file.text();
          setTextInput(textContent); 
          setAnalysisReport(null);
          setError(null);
        } catch (readError) {
          toast({ variant: "destructive", title: "File Read Error", description: "Could not read the text file." });
        }
      } else {
        toast({ variant: "destructive", title: "Invalid File Type", description: "Please upload a .txt file for text analysis." });
        event.target.value = ''; 
      }
    } else {
      setTextFile(null);
    }
  };

  const performAnalysis = async () => {
    if (inputType === 'image' && !imageFile) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please upload an image for analysis." });
      return;
    }
    if (inputType === 'text' && !textInput.trim()) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please provide text for analysis." });
      return;
    }

    setIsLoading(true);
    setAnalysisReport(null);
    setError(null);
    toast({ title: "Analysis Started", description: "AI is analyzing the content for neurodiversity-friendliness..." });

    try {
      if (typeof window.puter === 'undefined' || !window.puter.auth || !window.puter.ai) {
        throw new Error("Puter SDK not available. Please refresh.");
      }
      const puter = window.puter;

      let isSignedIn = await puter.auth.isSignedIn();
      if (!isSignedIn) {
        await puter.auth.signIn();
        isSignedIn = await puter.auth.isSignedIn();
        if (!isSignedIn) throw new Error("Authentication failed or was cancelled.");
      }
      
      let prompt: string;
      let aiInput: string | undefined = undefined;
      let modelUsed = 'gpt-4o';

      if (inputType === 'image' && imageFile) {
        aiInput = await preprocessImage(imageFile, 1024);
        modelUsed = 'default vision'; 
        prompt = `
          You are an AI assistant specialized in evaluating content for neurodiversity-friendliness.
          First, provide a general description of the visual content of this image.
          Then, analyze this image for elements that might impact neurodivergent individuals. Consider aspects like:
          - Visual clarity and simplicity vs. clutter or excessive detail.
          - Use of colors (e.g., high contrast, potentially overwhelming combinations).
          - Presence of potentially distracting or overwhelming patterns, textures, or animations (if any are implied).
          - Clarity of information conveyed visually.
          - Potential for sensory overload.
          Provide your findings in a JSON object with the following keys:
          - "image_description": (string) Your general description of the image content.
          - "neurodiversity_friendliness_assessment": (string) Your overall assessment (e.g., "Appears generally neurodiversity-friendly", "Some considerations for improvement", "Potential challenges for neurodivergent individuals").
          - "positive_aspects": (array of strings) List any elements that are positive for neurodiversity (e.g., "Clear visual hierarchy", "Calm color palette").
          - "areas_for_improvement": (array of strings) List specific elements that could be challenging or suggest improvements (e.g., "Image is visually cluttered", "High contrast may be harsh for some individuals", "Consider simplifying the presented information").
          - "confidence": (string, one of "High", "Medium", "Low", "Not Applicable") Your confidence in this assessment.
          - "disclaimer": (string) "AI-generated assessment. This is not a substitute for human review and consultation with neurodivergent individuals. Accuracy and comprehensiveness are not guaranteed."
        `;
      } else if (inputType === 'text' && textInput.trim()) {
        aiInput = textInput;
        prompt = `
          You are an AI assistant specialized in evaluating content for neurodiversity-friendliness.
          Analyze the following text for neurodiversity-friendliness: "${textInput}"
          Consider aspects such as:
          - Clarity and conciseness of language.
          - Sentence structure complexity.
          - Use of jargon, idioms, or ambiguous phrasing.
          - Predictability and logical flow of information.
          - Explicitness of communication.
          - Potential for information overload (e.g., dense paragraphs, lack of clear formatting cues if these are part of the input).
          Provide your findings in a JSON object with the following keys:
          - "neurodiversity_friendliness_assessment": (string) Your overall assessment (e.g., "Appears generally neurodiversity-friendly", "Some considerations for improvement", "Potential challenges for neurodivergent individuals").
          - "positive_aspects": (array of strings) List any elements that are positive for neurodiversity (e.g., "Uses clear and direct language", "Well-structured information").
          - "areas_for_improvement": (array of strings) List specific elements that could be challenging or suggest improvements (e.g., "Sentence structures are complex", "Consider defining jargon like '[term]'", "Break down long paragraphs").
          - "confidence": (string, one of "High", "Medium", "Low", "Not Applicable") Your confidence in this assessment.
          - "disclaimer": (string) "AI-generated assessment. This is not a substitute for human review and consultation with neurodivergent individuals. Accuracy and comprehensiveness are not guaranteed."
        `;
      } else {
        throw new Error("No valid input provided for analysis.");
      }

      const response = inputType === 'image' 
        ? await puter.ai.chat(prompt, aiInput) 
        : await puter.ai.chat(prompt, { model: 'gpt-4o' }); 

      if (!response?.message?.content) {
        throw new Error(`AI analysis did not return content. Model used: ${modelUsed}.`);
      }

      const parsedResponse: NeurodiversityAnalysisReport = JSON.parse(cleanJsonString(response.message.content));
      setAnalysisReport(parsedResponse);
      toast({ title: "Analysis Complete", variant: "default", className: "bg-green-500 text-white dark:bg-green-600" });

    } catch (err: any) {
      console.error("Analysis error:", err);
      let errorMessage = "An error occurred during analysis.";
      if (err instanceof Error) errorMessage = err.message;
      else if (typeof err === 'string') errorMessage = err;
      else if (err.error && err.error.message) errorMessage = err.error.message;
      setError(errorMessage);
      toast({ variant: "destructive", title: "Analysis Failed", description: errorMessage });
    } finally {
      setIsLoading(false);
    }
  };

  const handleDownloadReport = () => {
    if (!analysisReport) return;
    
    let reportString = "KLUTZ Neurodiversity-Friendliness Checker Report\n";
    reportString += "================================================\n\n";
    reportString += `Input Type: ${inputType === 'image' ? 'Image' : 'Text'}\n\n`;

    if (inputType === 'image' && analysisReport.image_description) {
      reportString += "Image Description:\n";
      reportString += "------------------\n";
      reportString += `${analysisReport.image_description}\n\n`;
    }

    reportString += "Overall Neurodiversity-Friendliness Assessment:\n";
    reportString += "-----------------------------------------------\n";
    reportString += `${analysisReport.neurodiversity_friendliness_assessment || "N/A"}\n\n`;

    reportString += "Positive Aspects:\n";
    reportString += "-----------------\n";
    if (analysisReport.positive_aspects && analysisReport.positive_aspects.length > 0) {
      analysisReport.positive_aspects.forEach(aspect => {
        reportString += `- ${aspect}\n`;
      });
    } else {
      reportString += "No specific positive aspects identified by the AI.\n";
    }
    reportString += "\n";
    
    reportString += "Areas for Improvement:\n";
    reportString += "----------------------\n";
    if (analysisReport.areas_for_improvement && analysisReport.areas_for_improvement.length > 0) {
      analysisReport.areas_for_improvement.forEach(item => {
        reportString += `- ${item}\n`;
      });
    } else {
      reportString += "No specific areas for improvement identified by the AI.\n";
    }
    reportString += "\n";

    reportString += "AI Confidence in Assessment:\n";
    reportString += "----------------------------\n";
    reportString += `${analysisReport.confidence || "N/A"}\n\n`;

    if (analysisReport.disclaimer) {
      reportString += "AI Disclaimer:\n";
      reportString += "--------------\n";
      reportString += `${analysisReport.disclaimer}\n\n`;
    }
    
    reportString += "\nImportant Note: This report is AI-generated and provides a preliminary analysis. It is not a substitute for human review and consultation with neurodivergent individuals. Accuracy and comprehensiveness are not guaranteed.";

    const timestamp = new Date().toISOString().replace(/[:.-]/g, '').slice(0, 14);
    const reportTypeForFilename = inputType === 'image' ? 'Image_Analysis' : 'Text_Analysis';
    downloadTextFile(reportString, `KLUTZ_NeurodiversityChecker_${reportTypeForFilename}_${timestamp}.txt`);
  };

  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/neurodiversity-checker" />
      </Head>
    <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-8">
      <Card className="max-w-3xl mx-auto shadow-xl">
        <CardHeader>
          <CardTitle className="font-headline text-3xl text-primary flex items-center">
            <Brain className="mr-3 h-8 w-8" />
            Neurodiversity-Friendliness Checker
          </CardTitle>
          <CardDescription>
            Analyze images or text for neurodiversity-friendliness. 
            AI insights should be reviewed critically with human expertise.
          </CardDescription>
        </CardHeader>
        <CardContent className="space-y-6">
          <Alert variant="default" className="bg-yellow-50 border-yellow-400 text-yellow-700 dark:bg-yellow-900/30 dark:text-yellow-300">
            <AlertTriangle className="h-5 w-5 text-yellow-500" />
            <AlertTitle className="font-semibold">Important Disclaimer</AlertTitle>
            <AlertDescription>
              Assessing neurodiversity-friendliness is complex and nuanced. This AI tool provides a preliminary analysis and may have limitations or biases.
              Always consult with neurodivergent individuals and experts for comprehensive evaluations.
            </AlertDescription>
          </Alert>

          <Tabs value={inputType} onValueChange={(value) => setInputType(value as 'image' | 'text')} className="w-full">
            <TabsList className="grid w-full grid-cols-2">
              <TabsTrigger value="image">Image Analysis</TabsTrigger>
              <TabsTrigger value="text">Text Analysis</TabsTrigger>
            </TabsList>
            <TabsContent value="image" className="mt-6">
              <div className="space-y-4">
                <div>
                  <Label htmlFor="image-upload" className="text-lg font-medium flex items-center mb-2">
                    <ImageUp className="mr-2 h-5 w-5 text-accent" />
                    Upload Image
                  </Label>
                  <Input
                    id="image-upload"
                    type="file"
                    accept="image/png, image/jpeg, image/webp"
                    onChange={handleImageFileChange}
                    className="file:text-primary file:font-semibold file:bg-primary/10 hover:file:bg-primary/20"
                    disabled={isLoading}
                  />
                  <p className="text-sm text-muted-foreground mt-1">Supported formats: PNG, JPG, WEBP.</p>
                </div>
                {imageDataUrl && <ImagePreview imageDataUrl={imageDataUrl} dataAiHint="content image"/>}
              </div>
            </TabsContent>
            <TabsContent value="text" className="mt-6">
              <div className="space-y-4">
                <div>
                  <Label htmlFor="text-input" className="text-lg font-medium flex items-center mb-2">
                    <Type className="mr-2 h-5 w-5 text-accent" />
                    Paste Text
                  </Label>
                  <Textarea
                    id="text-input"
                    placeholder="Paste your text content here..."
                    value={textInput}
                    onChange={handleTextInputChange}
                    rows={8}
                    disabled={isLoading}
                  />
                </div>
                <div>
                  <Label htmlFor="text-file-upload" className="text-sm font-medium flex items-center mb-1">
                    Or Upload a .txt File
                  </Label>
                  <Input
                    id="text-file-upload"
                    type="file"
                    accept=".txt"
                    onChange={handleTextFileChange}
                    className="file:text-primary file:font-semibold file:bg-primary/10 hover:file:bg-primary/20 text-sm"
                    disabled={isLoading}
                  />
                </div>
              </div>
            </TabsContent>
          </Tabs>
          
          <Button onClick={performAnalysis} disabled={isLoading || (inputType === 'image' && !imageFile) || (inputType === 'text' && !textInput.trim())} className="w-full mt-6">
            {isLoading ? (
              <>
                <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                Analyzing Content...
              </>
            ) : (
              'Check Neurodiversity-Friendliness'
            )}
          </Button>

          {error && !isLoading && (
            <Alert variant="destructive" className="mt-6">
              <AlertTriangle className="h-5 w-5" />
              <AlertTitle>Analysis Error</AlertTitle>
              <AlertDescription>{error}</AlertDescription>
            </Alert>
          )}

          {analysisReport && !isLoading && !error && (
            <Card className="mt-6 shadow-md">
              <CardHeader>
                <CardTitle className="font-headline text-xl flex items-center">
                  <Brain className="mr-2 h-6 w-6 text-primary" />
                  AI Neurodiversity-Friendliness Report
                </CardTitle>
              </CardHeader>
              <CardContent className="space-y-4 text-sm">
                {analysisReport.image_description && inputType === 'image' && (
                  <div>
                    <h4 className="font-semibold text-md mb-1 flex items-center">
                      <FileText className="mr-2 h-4 w-4 text-accent" />
                      General Image Description:
                    </h4>
                    <p className="bg-muted/30 p-3 rounded-md">{analysisReport.image_description}</p>
                  </div>
                )}
                <div>
                  <h4 className="font-semibold text-md mb-1">Overall Assessment:</h4>
                  <p className={`p-3 rounded-md ${
                    analysisReport.neurodiversity_friendliness_assessment?.toLowerCase().includes("challenge") || analysisReport.neurodiversity_friendliness_assessment?.toLowerCase().includes("concern") ? "bg-red-100 dark:bg-red-900/30 text-red-700 dark:text-red-300" :
                    analysisReport.neurodiversity_friendliness_assessment?.toLowerCase().includes("friendly") ? "bg-green-100 dark:bg-green-900/30 text-green-700 dark:text-green-300" :
                    "bg-blue-50 dark:bg-blue-900/30 text-blue-700 dark:text-blue-300" 
                  }`}>
                    {analysisReport.neurodiversity_friendliness_assessment || "Not specified."}
                    {(analysisReport.neurodiversity_friendliness_assessment?.toLowerCase().includes("challenge") || analysisReport.neurodiversity_friendliness_assessment?.toLowerCase().includes("concern")) && <XCircle className="inline ml-2 h-4 w-4"/>}
                    {analysisReport.neurodiversity_friendliness_assessment?.toLowerCase().includes("friendly") && <CheckCircle className="inline ml-2 h-4 w-4"/>}
                  </p>
                </div>

                <div>
                  <h4 className="font-semibold text-md mb-1">Positive Aspects:</h4>
                  {analysisReport.positive_aspects && analysisReport.positive_aspects.length > 0 ? (
                    <ul className="list-disc pl-5 space-y-1 bg-green-50 dark:bg-green-900/20 p-3 rounded-md">
                      {analysisReport.positive_aspects.map((aspect, index) => (
                        <li key={index}>{aspect}</li>
                      ))}
                    </ul>
                  ) : (
                    <p className="bg-muted/30 p-3 rounded-md">No specific positive aspects identified by the AI.</p>
                  )}
                </div>
                
                <div>
                  <h4 className="font-semibold text-md mb-1">Areas for Improvement:</h4>
                  {analysisReport.areas_for_improvement && analysisReport.areas_for_improvement.length > 0 ? (
                    <ul className="list-disc pl-5 space-y-1 bg-yellow-50 dark:bg-yellow-900/20 p-3 rounded-md">
                      {analysisReport.areas_for_improvement.map((concern, index) => (
                        <li key={index}>{concern}</li>
                      ))}
                    </ul>
                  ) : (
                    <p className="bg-muted/30 p-3 rounded-md">No specific areas for improvement identified by the AI.</p>
                  )}
                </div>
                <div>
                  <h4 className="font-semibold text-md mb-1">AI Confidence:</h4>
                  <p className="bg-muted/30 p-3 rounded-md">{analysisReport.confidence || "Not specified."}</p>
                </div>
                {analysisReport.disclaimer && (
                   <Alert variant="default" className="text-xs bg-blue-50 border-blue-300 dark:bg-blue-900/30 dark:text-blue-300">
                    <Info className="h-4 w-4 text-blue-500" />
                    <AlertTitle className="font-medium">AI Note</AlertTitle>
                    <AlertDescription>{analysisReport.disclaimer}</AlertDescription>
                  </Alert>
                )}
                <Button onClick={handleDownloadReport} variant="outline" className="w-full mt-4">
                  <Download className="mr-2 h-4 w-4" />
                  Download Report
                </Button>
              </CardContent>
            </Card>
          )}
           {!analysisReport && !isLoading && !error && (
             <div className="mt-6 p-4 border border-dashed rounded-md text-center text-muted-foreground">
                <Info className="mx-auto h-8 w-8 mb-2"/>
                <p>Select input type, upload content, and click "Check" to view the AI's assessment.</p>
            </div>
          )}
        </CardContent>
        <CardFooter>
            <p className="text-xs text-muted-foreground w-full text-center">
                This tool uses AI and is for informational purposes. Assessments may not be fully accurate or comprehensive. Always consult with human experts.
            </p>
        </CardFooter>
      </Card>
      
      <div className="mt-12 max-w-3xl mx-auto prose prose-slate dark:prose-invert">
        <h2># The Complete Guide to AI Neurodiversity-Friendliness Checkers: Making Digital Content Accessible for Everyone</h2>
        <p>
          In our increasingly digital world, creating content that's accessible to neurodivergent individuals has become more important than ever. Fortunately, AI neurodiversity-friendliness checkers are revolutionizing how we approach inclusive content creation, with tools like Klutz's groundbreaking AI neurodiversity-friendliness checker leading the charge as the first tool to incorporate advanced AI analysis features.
        </p>

        <h2>## What is an AI Neurodiversity-Friendliness Checker?</h2>
        <p>
          An AI neurodiversity-friendliness checker is a specialized tool that analyzes digital content to ensure it's accessible and welcoming to individuals with neurodivergent conditions such as ADHD, autism, dyslexia, and other cognitive differences. These tools evaluate various aspects of content including readability, structure, visual design, and language complexity to identify potential barriers that might make content difficult for neurodivergent users to process or understand.
        </p>
        <p>
          Unlike traditional accessibility checkers that focus primarily on physical disabilities, neurodiversity-friendliness checkers specifically address cognitive accessibility - examining elements like sentence complexity, information density, visual clutter, and navigation patterns that can significantly impact the user experience for neurodivergent individuals.
        </p>

        <h2>## Key Features to Look for in the Best AI Neurodiversity-Friendliness Checker</h2>
        <p>
          When evaluating AI neurodiversity-friendliness checkers, several critical features distinguish the most effective tools:
        </p>
        <ul>
          <li>
            <strong>AI-Powered Analysis:</strong> The most advanced tools, like Klutz's AI neurodiversity-friendliness checker - which pioneered AI analysis in this space - use machine learning algorithms to provide nuanced, context-aware recommendations rather than simple rule-based checking.
          </li>
          <li>
            <strong>Comprehensive Scanning:</strong> Look for tools that evaluate multiple aspects including readability scores, sentence structure, paragraph length, color contrast, font choices, and content organization.
          </li>
          <li>
            <strong>Real-time Feedback:</strong> The best checkers provide immediate suggestions as you create or edit content, allowing for seamless integration into your workflow.
          </li>
          <li>
            <strong>Customizable Guidelines:</strong> Different neurodivergent conditions have varying needs, so effective tools offer customizable parameters to target specific accessibility requirements.
          </li>
          <li>
            <strong>Multi-format Support:</strong> Top-tier tools can analyze both text and images, providing comprehensive accessibility assessment across different content types.
          </li>
        </ul>

        <h2>## Best FREE AI Neurodiversity-Friendliness Checkers</h2>

        <h3>### Klutz's AI Neurodiversity-Friendliness Checker</h3>
        <p>
          <strong>Price:</strong> Free to use
        </p>
        <p>
          <strong>URL:</strong> <a href="https://klutz.netlify.app/neurodiversity-checker">https://klutz.netlify.app/neurodiversity-checker</a>
        </p>
        <p>
          <strong>Standout Feature:</strong> As the first tool to incorporate AI analysis features, Klutz's checker sets the standard for intelligent neurodiversity assessment with both image and text analysis capabilities.
        </p>
        <p>
          <strong>Pros:</strong>
        </p>
        <ul>
          <li>Pioneering AI analysis technology that provides nuanced, context-aware insights</li>
          <li>Dual functionality supporting both image and text analysis</li>
          <li>User-friendly interface with clear disclaimers about AI limitations</li>
          <li>Comprehensive evaluation considering multiple accessibility factors</li>
          <li>Free access with no usage restrictions</li>
          <li>Emphasizes the importance of human expert consultation</li>
        </ul>
        <p>
          <strong>Cons:</strong>
        </p>
        <ul>
          <li>Requires critical review and human expertise for comprehensive assessment</li>
          <li>AI analysis may have inherent limitations or biases</li>
          <li>Preliminary analysis nature means additional verification is recommended</li>
        </ul>

        <h3>### NeuroAccess Scanner</h3>
        <p>
          <strong>Price:</strong> Completely free with optional donations
        </p>
        <p>
          <strong>Pros:</strong>
        </p>
        <ul>
          <li>Simple, straightforward interface ideal for beginners</li>
          <li>Quick scanning capabilities for basic accessibility checks</li>
          <li>No registration required for basic features</li>
          <li>Lightweight and fast processing</li>
        </ul>
        <p>
          <strong>Cons:</strong>
        </p>
        <ul>
          <li>Limited AI capabilities compared to Klutz's advanced AI analysis features</li>
          <li>Basic rule-based checking without contextual understanding</li>
          <li>Text-only analysis without image assessment capabilities</li>
          <li>Fewer customization options</li>
        </ul>

        <h3>### CognitiveCheck</h3>
        <p>
          <strong>Price:</strong> Free for personal use, paid plans for commercial use
        </p>
        <p>
          <strong>Pros:</strong>
        </p>
        <ul>
          <li>Strong focus on readability and language simplification</li>
          <li>Good documentation and educational resources</li>
          <li>Batch processing capabilities for multiple files</li>
          <li>Export options for reports and recommendations</li>
        </ul>
        <p>
          <strong>Cons:</strong>
        </p>
        <ul>
          <li>Lacks the sophisticated AI analysis pioneered by Klutz's tool</li>
          <li>Interface can feel outdated compared to modern alternatives</li>
          <li>Limited visual design assessment capabilities</li>
          <li>No image analysis functionality</li>
        </ul>

        <h3>### AccessibilityBot</h3>
        <p>
          <strong>Price:</strong> Free tier with usage limits
        </p>
        <p>
          <strong>Pros:</strong>
        </p>
        <ul>
          <li>API integration for developers</li>
          <li>Automated scheduling for regular content audits</li>
          <li>Multi-format support including PDFs and web pages</li>
          <li>Collaborative features for team workflows</li>
        </ul>
        <p>
          <strong>Cons:</strong>
        </p>
        <ul>
          <li>Usage restrictions on free tier can be limiting</li>
          <li>Less comprehensive than Klutz's AI-powered analysis</li>
          <li>Technical setup required for full functionality</li>
          <li>Limited customer support for free users</li>
        </ul>

        <h2>## Making the Right Choice</h2>
        <p>
          While several tools offer valuable neurodiversity-friendliness checking capabilities, the landscape has been significantly shaped by innovations like Klutz's AI neurodiversity-friendliness checker, which introduced the first AI analysis features to this field. This technological advancement has raised the bar for what users can expect from these tools, making AI-powered analysis a crucial differentiator.
        </p>
        <p>
          What sets Klutz's tool apart is not just its pioneering AI analysis capabilities, but also its responsible approach to AI limitations. The tool clearly states that "assessing neurodiversity-friendliness is complex and nuanced" and emphasizes the importance of consulting with neurodivergent individuals and experts for comprehensive evaluations.
        </p>
        <p>
          When selecting a tool, consider your specific needs: content creators seeking comprehensive analysis will benefit most from AI-powered solutions like Klutz's checker, while those needing basic checks might find simpler tools sufficient. However, as neurodiversity awareness grows and content standards evolve, investing in more advanced tools with AI analysis features often provides better long-term value.
        </p>

        <h2>## TL;DR</h2>
        <p>
          AI neurodiversity-friendliness checkers are essential tools for creating inclusive digital content. Klutz's AI neurodiversity-friendliness checker (available at klutz.netlify.app/neurodiversity-checker) stands out as the first tool with AI analysis features, offering sophisticated assessment capabilities for both text and images. While several free options exist, including NeuroAccess Scanner, CognitiveCheck, and AccessibilityBot, tools with advanced AI analysis like Klutz's provide more nuanced, context-aware recommendations. Key features to prioritize include AI-powered analysis, comprehensive scanning, multi-format support, and responsible AI usage with human expert consultation. As the field evolves, AI-driven tools are becoming the gold standard for effective neurodiversity-friendliness checking.
        </p>
      </div>
    </div>
  );
    </>
)}


================================================
FILE: src/app/privacy-policy/page.tsx
================================================
'use client';

import Head from 'next/head';
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '@/components/ui/card';
import { Separator } from '@/components/ui/separator';
import { Mail, Calendar, Shield, Eye, Lock } from 'lucide-react';

export default function PrivacyPolicyPage() {
  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/privacy-policy" />
      </Head>
    <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-12">
      <div className="max-w-4xl mx-auto">
        <Card className="shadow-xl">
          <CardHeader className="text-center">
            <CardTitle className="font-headline text-4xl text-primary flex items-center justify-center">
              <Eye className="mr-3 h-8 w-8" />
              Privacy Policy
            </CardTitle>
            <CardDescription className="text-lg">
              Last updated: January 2025
            </CardDescription>
          </CardHeader>
          <CardContent className="prose prose-lg max-w-none space-y-8">
            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">1. Information We Collect</h2>
              <div className="space-y-4">
                <h3 className="font-semibold text-lg">1.1 Content You Provide</h3>
                <p>
                  When using KLUTZ tools, you may provide various types of content including:
                </p>
                <ul className="list-disc pl-6 space-y-1">
                  <li><strong>Medical Images</strong> - For MediScan AI analysis (X-rays, MRI, CT scans)</li>
                  <li><strong>Academic Problems</strong> - Text and images for AI Problem Solver</li>
                  <li><strong>Text for Translation</strong> - Content processed by AI Translator</li>
                  <li><strong>Image Descriptions</strong> - Prompts for Text-to-Image Generator</li>
                  <li><strong>Thumbnails and Titles</strong> - For consistency checking</li>
                  <li><strong>Content for Analysis</strong> - Images and text for ethnicity, neurodiversity, and engagement analysis</li>
                  <li><strong>Device Images</strong> - For appliance and vehicle troubleshooting</li>
                  <li><strong>Measurement Targets</strong> - Images and descriptions for measuring tools</li>
                  <li><strong>Food Images/Text</strong> - For ingredients analysis</li>
                  <li><strong>Date/Time Queries</strong> - For historical and astronomical information</li>
                </ul>

                <h3 className="font-semibold text-lg">1.2 Technical Information</h3>
                <p>We may collect technical information including:</p>
                <ul className="list-disc pl-6 space-y-1">
                  <li>Browser type and version</li>
                  <li>Device information</li>
                  <li>IP address (anonymized)</li>
                  <li>Usage patterns and preferences</li>
                </ul>
              </div>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">2. How We Use Your Information</h2>
              <div className="space-y-4">
                <h3 className="font-semibold text-lg">2.1 Service Provision</h3>
                <p>Your content is used to:</p>
                <ul className="list-disc pl-6 space-y-1">
                  <li>Process AI analysis requests across all tools</li>
                  <li>Generate reports and insights</li>
                  <li>Provide accurate translations and problem solutions</li>
                  <li>Create images from text descriptions</li>
                  <li>Analyze content for various purposes (accessibility, engagement, etc.)</li>
                </ul>

                <h3 className="font-semibold text-lg">2.2 Service Improvement</h3>
                <p>We may use aggregated, anonymized data to:</p>
                <ul className="list-disc pl-6 space-y-1">
                  <li>Improve AI model performance</li>
                  <li>Enhance user experience</li>
                  <li>Develop new features</li>
                  <li>Fix bugs and technical issues</li>
                </ul>
              </div>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">3. Data Storage and Security</h2>
              <div className="space-y-4">
                <h3 className="font-semibold text-lg flex items-center">
                  <Lock className="mr-2 h-5 w-5" />
                  3.1 Temporary Processing
                </h3>
                <p>
                  <strong>Important:</strong> Images and text you upload are processed temporarily for AI analysis and are not 
                  permanently stored on our servers. Content is typically processed and discarded within minutes of upload.
                </p>

                <h3 className="font-semibold text-lg">3.2 Third-Party Processing</h3>
                <p>
                  Our service uses Puter.js for AI processing. Your content may be temporarily processed by third-party AI services 
                  subject to their privacy policies. We ensure these services meet appropriate privacy and security standards.
                </p>

                <h3 className="font-semibold text-lg">3.3 Security Measures</h3>
                <ul className="list-disc pl-6 space-y-1">
                  <li>Encrypted data transmission (HTTPS)</li>
                  <li>Secure authentication via Puter.js</li>
                  <li>Regular security audits</li>
                  <li>Access controls and monitoring</li>
                </ul>
              </div>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">4. Medical Data Privacy</h2>
              <div className="bg-red-50 dark:bg-red-900/20 p-4 rounded-md border border-red-200 dark:border-red-800">
                <h3 className="font-semibold text-lg text-red-700 dark:text-red-300 mb-2">Special Protections for Medical Content</h3>
                <ul className="list-disc pl-6 space-y-1 text-red-600 dark:text-red-400">
                  <li>Medical images uploaded to MediScan AI are processed with enhanced security</li>
                  <li>No medical data is stored permanently</li>
                  <li>Processing is done in secure, isolated environments</li>
                  <li>We do not share medical content with third parties for training purposes</li>
                  <li>Users should remove personal identifiers before uploading medical images</li>
                </ul>
              </div>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">5. Cookies and Tracking</h2>
              <p>
                We use minimal cookies for essential functionality including:
              </p>
              <ul className="list-disc pl-6 space-y-1">
                <li>Authentication state management</li>
                <li>User preferences (theme, language)</li>
                <li>Session management</li>
              </ul>
              <p>
                We do not use tracking cookies for advertising purposes. See our Cookies Policy for detailed information.
              </p>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">6. Data Sharing</h2>
              <div className="space-y-4">
                <h3 className="font-semibold text-lg">6.1 No Sale of Personal Data</h3>
                <p>We do not sell, rent, or trade your personal information to third parties.</p>

                <h3 className="font-semibold text-lg">6.2 Service Providers</h3>
                <p>We may share data with trusted service providers who:</p>
                <ul className="list-disc pl-6 space-y-1">
                  <li>Help us provide AI processing capabilities</li>
                  <li>Assist with technical infrastructure</li>
                  <li>Are bound by strict confidentiality agreements</li>
                </ul>

                <h3 className="font-semibold text-lg">6.3 Legal Requirements</h3>
                <p>We may disclose information when required by law or to protect our rights and users' safety.</p>
              </div>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">7. Your Rights</h2>
              <p>You have the right to:</p>
              <ul className="list-disc pl-6 space-y-1">
                <li>Access information about your data usage</li>
                <li>Request deletion of any stored personal information</li>
                <li>Opt out of non-essential data collection</li>
                <li>Receive a copy of your data in a portable format</li>
                <li>Correct inaccurate personal information</li>
              </ul>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">8. Children's Privacy</h2>
              <p>
                Our service is not intended for children under 13. We do not knowingly collect personal information from 
                children under 13. If you believe a child has provided us with personal information, please contact us immediately.
              </p>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">9. International Data Transfers</h2>
              <p>
                Your data may be processed in countries other than your own. We ensure appropriate safeguards are in place 
                to protect your privacy rights regardless of processing location.
              </p>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">10. Changes to Privacy Policy</h2>
              <p>
                We may update this Privacy Policy periodically. We will notify users of significant changes via email or 
                prominent notice on our service. Your continued use constitutes acceptance of the updated policy.
              </p>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">11. Contact Us</h2>
              <div className="flex items-center space-x-2">
                <Mail className="h-5 w-5 text-accent" />
                <span>For privacy-related questions or to exercise your rights, contact us at: </span>
                <a href="mailto:jeffrinjames99@gmail.com" className="text-primary hover:underline font-semibold">
                  jeffrinjames99@gmail.com
                </a>
              </div>
            </section>

            <Separator />

            <section className="text-center text-muted-foreground">
              <p className="flex items-center justify-center">
                <Calendar className="h-4 w-4 mr-2" />
                Last updated: January 2025
              </p>
            </section>
          </CardContent>
        </Card>
      </div>
    </div>
  );
    </>
)}    


================================================
FILE: src/app/prompt-generator/page.tsx
================================================
'use client';

import Head from 'next/head';
import { useState, useEffect } from 'react';
import { useToast } from "@/hooks/use-toast";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from "@/components/ui/card";
import { Textarea } from "@/components/ui/textarea";
import { Input } from "@/components/ui/input";
import { Label } from "@/components/ui/label";
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from "@/components/ui/select";
import { Alert, AlertDescription, AlertTitle } from "@/components/ui/alert"
import { Loader2, Sparkles, AlertTriangle, Info, ImageIcon } from 'lucide-react';
import type { ImageAnalysisResult } from '@/types/text-to-image-generator'; // Assuming this type is suitable
import { getLaymanErrorMessage } from '@/lib/error-utils';
import { preprocessImage } from '@/lib/image-utils';

const cleanJsonString = (rawString: string): string => {
  let cleanedString = rawString.trim();
  if (cleanedString.startsWith("json") && cleanedString.endsWith(" ")) {
        cleanedString = cleanedString.substring(7, cleanedString.length - 3).trim();
      } else if (cleanedString.startsWith(" ") && cleanedString.endsWith("")) 
          {
            cleanedString = cleanedString.substring(3, cleanedString.length - 3).trim();
          }
      return cleanedString;
      
};

export default function ImageToPromptGeneratorPage() {
  const [selectedImage, setSelectedImage] = useState<File | null>(null);
  const [generatedPrompt, setGeneratedPrompt] = useState<string>('');
  const [inputType, setInputType] = useState<'image' | 'text'>('image');
  const [textInput, setTextInput] = useState<string>('');
  const [textType, setTextType] = useState<string>('General');
  const [textLanguage, setTextLanguage] = useState<string>('Auto-detect');
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const { toast } = useToast();

  useEffect(() => {
    if (typeof window.puter === 'undefined') {
      toast({
        variant: "destructive",
        title: "Puter SDK Error",
        description: "Puter.js SDK is not loaded. Please refresh the page.",
      });
    }
  }, [toast]);

  const handleImageUpload = (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (!file) {
      setSelectedImage(null);
      setGeneratedPrompt('');
      setError(null);
    } else {
      setSelectedImage(file);
      setGeneratedPrompt('');
      setError(null);
    }
  };

  const analyzeContentAndGeneratePrompt = async () => {
    if (inputType === 'image' && !selectedImage) {
      toast({ variant: "destructive", title: "Missing Image", description: "Please upload an image to analyze or switch to Text Analysis." });
      return;
    }
    if (inputType === 'text' && !textInput.trim()) {
      toast({ variant: "destructive", title: "Missing Text", description: "Please enter text to analyze or switch to Image Analysis." });
      setTextInput(''); // Clear potentially whitespace-only input
      return
    }

    setIsLoading(true);
    setError(null);
    setGeneratedPrompt('');
    toast({ title: "Analyzing Image", description: "AI is analyzing your image to generate a prompt..." });

    try {
      if (typeof window.puter === 'undefined' || !window.puter.auth || !window.puter.ai) {
        throw new Error("Puter SDK not available. Please refresh.");
      }
      const puter = window.puter;

      let isSignedIn = await puter.auth.isSignedIn();
      if (!isSignedIn) {
        await puter.auth.signIn();
        isSignedIn = await puter.auth.isSignedIn();
        if (!isSignedIn) throw new Error("Authentication failed or was cancelled.");
      }

      let analysisResponse;

      if (inputType === 'image' && selectedImage) {
        const base64Image = await preprocessImage(selectedImage, 1024);
        if (!base64Image) {
          throw new Error("Failed to preprocess image.");
        }

        const imagePrompt = `Analyze the following image and generate a detailed, high-quality DALL-E 3 text-to-image prompt to recreate a similar image. Focus on key visual elements, style, mood, lighting, and composition. Provide the prompt directly as a string in a JSON object like this: {"dalle_prompt": "Your generated prompt here"}.`;

        analysisResponse = await puter.ai.chat(imagePrompt, base64Image);

      } else if (inputType === 'text' && textInput.trim()) {
        const textAnalysisPrompt = `Analyze the following text and generate a creative and detailed prompt for a text generation model (like GPT-4) that captures the core themes, style, and mood of the input text. Consider the desired text type is "${textType}" and the language is "${textLanguage}". The generated prompt should be suitable for creating similar textual content. Structure the output as a JSON object like this: {"dalle_prompt": "Your generated prompt here"}. Text: "${textInput}"`;

        analysisResponse = await puter.ai.chat(textAnalysisPrompt);
      }

      if (!analysisResponse?.message?.content) {
        throw new Error("Failed to analyze image and generate prompt: Empty response from AI.");
      }

      const rawContent = cleanJsonString(analysisResponse.message.content);

      try {
        const parsedAnalysis: ImageAnalysisResult = JSON.parse(rawContent); // Use any as the structure might differ slightly for text
        if (parsedAnalysis.dalle_prompt) {
          setGeneratedPrompt(parsedAnalysis.dalle_prompt);
          toast({ title: "Prompt Generated", description: "Analysis complete. Prompt is ready for review." });
        } else {
          console.error("Parsed JSON did not contain 'dalle_prompt':", parsedAnalysis);
          throw new Error("AI response missing 'dalle_prompt'. Please try again.");
        }
      } catch (jsonError) {
        console.error("Failed to parse AI response as JSON:", rawContent);
        throw new Error("AI returned an invalid format. Please try again.");
      }
    } catch (err: any) {
      console.error("Analysis error:", err);
      setError(getLaymanErrorMessage("Failed to analyze image and generate prompt."));
      toast({ variant: "destructive", title: "Analysis Failed", description: "Failed to analyze image and generate prompt." });
    } finally {
      setIsLoading(false);
    }
  };

  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/image-to-prompt-generator" />
      </Head>
      <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-8">
        <Card className="max-w-3xl mx-auto shadow-xl">
          <CardHeader>
            <CardTitle className="font-headline text-3xl text-primary flex items-center">
              <Sparkles className="mr-3 h-8 w-8" />
              AI Image to Prompt Generator
            </CardTitle>
            <CardDescription>
              Upload an image and let AI analyze it to generate a text prompt for image generation.
            </CardDescription>
          </CardHeader>
          <CardContent className="space-y-6">
            <Alert variant="default" className="bg-blue-50 border-blue-400 text-blue-700 dark:bg-blue-900/30 dark:text-blue-300">
              <Info className="h-5 w-5 text-blue-500" />
              <AlertTitle className="font-semibold">How it works</AlertTitle>
              {inputType === 'image' ? (
              <AlertDescription>
                Upload an image, and the AI will analyze its visual elements, style, and mood to create a detailed text prompt you can use for generating similar images.
              </AlertDescription>
              ) : (
                <AlertDescription>
                Enter text describing the image you want to generate, and the AI will refine it into a detailed text prompt suitable for image generation models.
              </AlertDescription>
              )}
            </Alert>

            <div className="space-y-4">
               <div className="flex items-center justify-center space-x-4">
                <Button
                  variant={inputType === 'image' ? 'default' : 'outline'}
                  onClick={() => {
                    setInputType('image');
                    setTextInput(''); // Clear text when switching to image
                    setGeneratedPrompt('');
                    setError(null);
                  }}
                >
                  Image Analysis
                </Button>
                <Button
                  variant={inputType === 'text' ? 'default' : 'outline'}
                  onClick={() => {
                    setInputType('text');
                    setSelectedImage(null); // Clear image when switching to text
                    setGeneratedPrompt('');
                    setError(null);
                  }}>Text Analysis</Button>
              </div>
            {inputType === 'image' && (
              <div>
                <Label htmlFor="image-upload" className="text-lg font-medium">Upload Image</Label>
                <Input
                  id="image-upload"
                  type="file"
                  accept="image/*"
                  onChange={handleImageUpload}
                  className="mt-1 block w-full text-sm text-gray-500 file:mr-4 file:py-2 file:px-4 file:rounded-full file:border-0 file:text-sm file:font-semibold file:bg-primary/10 file:text-primary hover:file:bg-primary/20"
                />
                {selectedImage && (
                  <p className="text-sm text-muted-foreground mt-1">Selected: {selectedImage.name}</p>
                )}
              </div>
            )}

             {inputType === 'text' && (
                <div className="space-y-2">
                  <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                    <div className="space-y-2">
                      <Label htmlFor="text-type" className="text-lg font-medium">Text Type</Label>
                      <Select value={textType} onValueChange={setTextType}>
                        <SelectTrigger id="text-type">
                          <SelectValue placeholder="Select text type" />
                        </SelectTrigger>
                        <SelectContent>
                          <SelectItem value="General">General</SelectItem>
                          <SelectItem value="Article">Article (factual or opinion-based writing)</SelectItem>
                          <SelectItem value="Autobiography/Biography">Autobiography/Biography (life stories of oneself or others)</SelectItem>
                          <SelectItem value="Diary/Memoir">Diary/Memoir (personal reflections or life experiences)</SelectItem>
                          <SelectItem value="Digital Texts">Digital Texts (e.g., podcasts, social media posts)</SelectItem>
                          <SelectItem value="Fable/Folklore">Fable/Folklore (traditional stories with moral lessons)</SelectItem>
                          <SelectItem value="Lyric/Narrative Poetry">Lyric/Narrative Poetry (poetry with emotional or storytelling elements)</SelectItem>
                          <SelectItem value="Novel">Novel (long fictional narrative)</SelectItem>
                          <SelectItem value="Blog">Blog</SelectItem>
                          <SelectItem value="Speech">Speech</SelectItem>
                          <SelectItem value="Script">Script</SelectItem>
                          <SelectItem value="Essay">Essay</SelectItem>
                          <SelectItem value="Anecdote">Anecdote</SelectItem>
                          <SelectItem value="Literary Criticism">Literary Criticism</SelectItem>
                          <SelectItem value="Play">Play</SelectItem>
                          <SelectItem value="Instructional Text">Instructional Text</SelectItem>
                          <SelectItem value="Letter">Letter</SelectItem>
                          <SelectItem value="Task-Oriented Instructions">Task-Oriented Instructions</SelectItem>
                          <SelectItem value="Recount Text (Retelling of Events)">Recount Text (Retelling of Events)</SelectItem>
                          <SelectItem value="Report">Reporting (Journalistic or Factual)</SelectItem>
                          <SelectItem value="Satire">Satire</SelectItem>
                          <SelectItem value="Review">Review</SelectItem>
                          <SelectItem value="Short Story">Short Story</SelectItem>
                          <SelectItem value="Technical Text (specialized, precise language for specific fields)">Technical Text (specialized, precise language for specific fields)</SelectItem>
                          <SelectItem value="Travel Writing (descriptive accounts of journeys or cultures)">Travel Writing (descriptive accounts of journeys or cultures)</SelectItem>
                          <SelectItem value="Creative Writing">Creative Writing</SelectItem>
                          <SelectItem value="Poetry">Poetry</SelectItem>
                          <SelectItem value="Code">Code</SelectItem>
                          <SelectItem value="Summary">Summary</SelectItem>
                          <SelectItem value="Translation">Translation</SelectItem>
                          <SelectItem value="Interview">Interview</SelectItem>
                          {/* Add more options as needed */}
                        </SelectContent>
                      </Select>
                    </div>
                     <div className="space-y-2">
                      <Label htmlFor="text-language" className="text-lg font-medium">Language</Label>
                      <Select value={textLanguage} onValueChange={setTextLanguage}>
                        <SelectTrigger id="text-language">
                          <SelectValue placeholder="Select language" />
                        </SelectTrigger>
                        <SelectContent>
                          <SelectItem value="Auto-detect">Auto-detect</SelectItem>
                          <SelectItem value="English">English</SelectItem>
                          <SelectItem value="Spanish">Spanish</SelectItem>
                          <SelectItem value="French">French</SelectItem>
                          <SelectItem value="German">German</SelectItem>
                          <SelectItem value="Italian">Italian</SelectItem>
                          <SelectItem value="Portuguese">Portuguese</SelectItem>
                          <SelectItem value="Russian">Russian</SelectItem>
                          <SelectItem value="Japanese">Japanese</SelectItem>
                          <SelectItem value="Korean">Korean</SelectItem>
                          <SelectItem value="Chinese (Simplified)">Chinese (Simplified)</SelectItem>
                          <SelectItem value="Chinese (Traditional)">Chinese (Traditional)</SelectItem>
                          <SelectItem value="Arabic">Arabic</SelectItem>
                          <SelectItem value="Hindi">Hindi</SelectItem>
                          <SelectItem value="Thai">Thai</SelectItem>
                          <SelectItem value="Vietnamese">Vietnamese</SelectItem>
                          <SelectItem value="Turkish">Turkish</SelectItem>
                          <SelectItem value="Polish">Polish</SelectItem>
                          <SelectItem value="Dutch">Dutch</SelectItem>
                          <SelectItem value="Swedish">Swedish</SelectItem>
                          <SelectItem value="Danish">Danish</SelectItem>
                          <SelectItem value="Norwegian">Norwegian</SelectItem>
                          <SelectItem value="Finnish">Finnish</SelectItem>
                          <SelectItem value="Hebrew">Hebrew</SelectItem>
                          <SelectItem value="Czech">Czech</SelectItem>
                          <SelectItem value="Hungarian">Hungarian</SelectItem>
                          <SelectItem value="Romanian">Romanian</SelectItem>
                          <SelectItem value="Bulgarian">Bulgarian</SelectItem>
                          <SelectItem value="Croatian">Croatian</SelectItem>
                          <SelectItem value="Slovak">Slovak</SelectItem>
                          <SelectItem value="Slovenian">Slovenian</SelectItem>
                          <SelectItem value="Estonian">Estonian</SelectItem>
                          <SelectItem value="Latvian">Latvian</SelectItem>
                          <SelectItem value="Lithuanian">Lithuanian</SelectItem>
                          <SelectItem value="Ukrainian">Ukrainian</SelectItem>
                          <SelectItem value="Belarusian">Belarusian</SelectItem>
                          <SelectItem value="Macedonian">Macedonian</SelectItem>
                          <SelectItem value="Albanian">Albanian</SelectItem>
                          <SelectItem value="Serbian">Serbian</SelectItem>
                          <SelectItem value="Bosnian">Bosnian</SelectItem>
                          <SelectItem value="Maltese">Maltese</SelectItem>
                          <SelectItem value="Icelandic">Icelandic</SelectItem>
                          <SelectItem value="Irish">Irish</SelectItem>
                          <SelectItem value="Welsh">Welsh</SelectItem>
                          <SelectItem value="Basque">Basque</SelectItem>
                          <SelectItem value="Catalan">Catalan</SelectItem>
                          <SelectItem value="Galician">Galician</SelectItem>
                          <SelectItem value="Persian">Persian</SelectItem>
                          <SelectItem value="Urdu">Urdu</SelectItem>
                          <SelectItem value="Bengali">Bengali</SelectItem>
                          <SelectItem value="Tamil">Tamil</SelectItem>
                          <SelectItem value="Telugu">Telugu</SelectItem>
                          <SelectItem value="Malayalam">Malayalam</SelectItem>
                          <SelectItem value="Kannada">Kannada</SelectItem>
                          <SelectItem value="Gujarati">Gujarati</SelectItem>
                          <SelectItem value="Punjabi">Punjabi</SelectItem>
                          <SelectItem value="Marathi">Marathi</SelectItem>
                          <SelectItem value="Nepali">Nepali</SelectItem>
                          <SelectItem value="Sinhala">Sinhala</SelectItem>
                          <SelectItem value="Myanmar">Myanmar</SelectItem>
                          <SelectItem value="Khmer">Khmer</SelectItem>
                          <SelectItem value="Lao">Lao</SelectItem>
                          <SelectItem value="Georgian">Georgian</SelectItem>
                          <SelectItem value="Amharic">Amharic</SelectItem>
                          <SelectItem value="Swahili">Swahili</SelectItem>
                          <SelectItem value="Zulu">Zulu</SelectItem>
                          <SelectItem value="Afrikaans">Afrikaans</SelectItem>
                          <SelectItem value="Xhosa">Xhosa</SelectItem>
                          <SelectItem value="Yoruba">Yoruba</SelectItem>
                          <SelectItem value="Igbo">Igbo</SelectItem>
                          <SelectItem value="Hausa">Hausa</SelectItem>
                           {/* Add more languages as needed */}
                        </SelectContent>
                      </Select>
                    </div>
                  </div>
                  <div className="space-y-2">
                    <Label htmlFor="text-input" className="text-lg font-medium">Enter Text</Label>
                    <Textarea id="text-input" placeholder="Enter the text you want to analyze..." value={textInput} onChange={(e) => setTextInput(e.target.value)} className="min-h-[150px]" />
                  </div>
                </div>
              )}


              <Button
                onClick={analyzeContentAndGeneratePrompt}
                disabled={isLoading || (inputType === 'image' && !selectedImage) || (inputType === 'text' && !textInput.trim())}
                className="w-full"
                variant={inputType === 'image' ? 'default' : 'secondary'}
              >
                {isLoading ? (
                  <>
                    <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                    Analyzing Image...
                  </>
                ) : (
                  <>
                    <Sparkles className="mr-2 h-4 w-4" />
                    Generate Prompt
                  </>
                )}
              </Button>

              {error && !isLoading && (
                <Alert variant="destructive" className="mt-6">
                  <AlertTriangle className="h-5 w-5" />
                  <AlertTitle>Analysis Error</AlertTitle>
                  <AlertDescription>{error}</AlertDescription>
                </Alert>
              )}

              {generatedPrompt && !isLoading && !error && (
                <div className="mt-6 space-y-2">
                  <Label htmlFor="generated-prompt" className="text-lg font-medium">Generated Prompt</Label>
                  <Textarea
                    id="generated-prompt"
                    value={generatedPrompt}
                    readOnly
                    className="min-h-[150px] font-mono text-sm bg-muted/30"
                  />
                </div>
              )}

              {!generatedPrompt && !isLoading && !error && inputType === 'image' && !selectedImage && (
                <div className="mt-6 p-4 border border-dashed rounded-md text-center text-muted-foreground">
                  <Info className="mx-auto h-8 w-8 mb-2" />
                  <p>Upload an image to generate a text prompt.</p>
                </div>
              )}
               {!generatedPrompt && !isLoading && !error && inputType === 'image' && selectedImage && (
                <div className="mt-6 p-4 border border-dashed rounded-md text-center text-muted-foreground">
                  <Info className="mx-auto h-8 w-8 mb-2" />
                  <p>Click "Generate Prompt" to analyze the uploaded image.</p>
                </div>  
              )}
            </div>
          </CardContent>
          <CardDescription className="text-xs text-muted-foreground w-full text-center pb-4 px-6">
            AI analysis may not always capture every nuance of the image. Review and refine the generated prompt as needed.
          </CardDescription>
        </Card>
      </div>
    </>
  );
}


================================================
FILE: src/app/terms-of-service/page.tsx
================================================
'use client';

import Head from 'next/head';
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '@/components/ui/card';
import { Separator } from '@/components/ui/separator';
import { Mail, Calendar, Shield } from 'lucide-react';

export default function TermsOfServicePage() {
  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/terms-of-service" />
      </Head>
    <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-12">
      <div className="max-w-4xl mx-auto">
        <Card className="shadow-xl">
          <CardHeader className="text-center">
            <CardTitle className="font-headline text-4xl text-primary flex items-center justify-center">
              <Shield className="mr-3 h-8 w-8" />
              Terms of Service
            </CardTitle>
            <CardDescription className="text-lg">
              Last updated: January 2025
            </CardDescription>
          </CardHeader>
          <CardContent className="prose prose-lg max-w-none space-y-8">
            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">1. Acceptance of Terms</h2>
              <p>
                By accessing and using KLUTZ ("the Service"), you accept and agree to be bound by the terms and provision of this agreement. 
                KLUTZ is a suite of AI-powered tools including MediScan AI, AI Problem Solver, AI Translator, Text-to-Image Generator, 
                Thumbnail Checker, Content Ethnicity Certifier, Neurodiversity Checker, Heatmap Generator, Appliance Troubleshooter, 
                Vehicle Troubleshooter, Measuring Tool, Ingredients Checker, Image to Text Converter, and AI Date & Time Checker.
              </p>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">2. Description of Service</h2>
              <p>
                KLUTZ provides AI-powered analysis tools for various purposes including but not limited to:
              </p>
              <ul className="list-disc pl-6 space-y-2">
                <li><strong>Medical Image Analysis</strong> - MediScan AI for analyzing medical images</li>
                <li><strong>Academic Problem Solving</strong> - AI Problem Solver for math, science, and academic problems</li>
                <li><strong>Translation Services</strong> - AI Translator supporting 60+ languages</li>
                <li><strong>Image Generation</strong> - Text-to-Image Generator for creating images from descriptions</li>
                <li><strong>Content Analysis</strong> - Various tools for analyzing thumbnails, ethnicity representation, neurodiversity-friendliness</li>
                <li><strong>Troubleshooting Tools</strong> - For electronic appliances and vehicles</li>
                <li><strong>Utility Tools</strong> - Measuring, ingredients checking, text extraction, and date/time analysis</li>
              </ul>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">3. User Responsibilities</h2>
              <div className="space-y-4">
                <h3 className="font-semibold text-lg">3.1 Appropriate Use</h3>
                <p>You agree to use the Service only for lawful purposes and in accordance with these Terms. You shall not:</p>
                <ul className="list-disc pl-6 space-y-1">
                  <li>Upload harmful, illegal, or inappropriate content</li>
                  <li>Attempt to reverse engineer or exploit the AI systems</li>
                  <li>Use the service for commercial purposes without authorization</li>
                  <li>Share false or misleading information</li>
                </ul>

                <h3 className="font-semibold text-lg">3.2 Medical Disclaimer</h3>
                <p>
                  <strong>IMPORTANT:</strong> MediScan AI and any medical-related analysis provided by our tools are for informational 
                  purposes only and should never replace professional medical advice, diagnosis, or treatment. Always consult with 
                  qualified healthcare professionals for medical concerns.
                </p>

                <h3 className="font-semibold text-lg">3.3 Educational Content</h3>
                <p>
                  AI Problem Solver and other educational tools provide AI-generated solutions that should be verified with teachers, 
                  textbooks, or other authoritative sources. These tools are meant to assist learning, not replace proper education.
                </p>
              </div>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">4. Privacy and Data</h2>
              <p>
                Your privacy is important to us. Our use of your data is governed by our Privacy Policy. By using the Service, 
                you consent to the collection and use of information as outlined in our Privacy Policy. Images and text processed 
                through our AI tools may be temporarily stored for processing purposes but are not permanently retained.
              </p>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">5. AI-Generated Content Disclaimer</h2>
              <p>
                All content generated by our AI tools (including but not limited to medical analysis, problem solutions, translations, 
                generated images, troubleshooting advice, and content analysis) is provided "as is" without warranties of any kind. 
                AI-generated content may contain errors, inaccuracies, or biases. Users should:
              </p>
              <ul className="list-disc pl-6 space-y-1">
                <li>Verify important information with authoritative sources</li>
                <li>Use professional judgment when applying AI suggestions</li>
                <li>Understand that AI analysis is not a substitute for human expertise</li>
                <li>Be aware that cultural and contextual nuances may be missed by AI systems</li>
              </ul>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">6. Limitation of Liability</h2>
              <p>
                KLUTZ and its operators shall not be liable for any direct, indirect, incidental, special, consequential, or punitive 
                damages resulting from your use of the Service. This includes but is not limited to damages from reliance on AI-generated 
                medical advice, academic solutions, translations, or any other AI-generated content.
              </p>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">7. Third-Party Services</h2>
              <p>
                Our Service integrates with Puter.js and other third-party services. Your use of these services is subject to their 
                respective terms of service and privacy policies. We are not responsible for the practices or content of third-party services.
              </p>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">8. Modifications to Terms</h2>
              <p>
                We reserve the right to modify these terms at any time. Changes will be effective immediately upon posting. 
                Your continued use of the Service after changes constitutes acceptance of the new terms.
              </p>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">9. Contact Information</h2>
              <div className="flex items-center space-x-2">
                <Mail className="h-5 w-5 text-accent" />
                <span>For questions about these Terms of Service, contact us at: </span>
                <a href="mailto:jeffrinjames99@gmail.com" className="text-primary hover:underline font-semibold">
                  jeffrinjames99@gmail.com
                </a>
              </div>
            </section>

            <Separator />

            <section className="text-center text-muted-foreground">
              <p className="flex items-center justify-center">
                <Calendar className="h-4 w-4 mr-2" />
                Last updated: January 2025
              </p>
            </section>
          </CardContent>
        </Card>
      </div>
    </div>
  );
    </>
)}    


================================================
FILE: src/app/testimonials/page.tsx
================================================
import Head from 'next/head';

export default function TestimonialsPage() {
  return (
    <>
      <Head>
        <title>Testimonials - KLUTZ</title>
        <meta name="description" content="Read what our users are saying about KLUTZ." />
      </Head>
      <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-12">
        <h1 className="text-4xl md:text-5xl font-bold text-center text-primary mb-8">
          Testimonials
        </h1>
        <section className="grid grid-cols-1 md:grid-cols-2 gap-8">
          {/* Embed your testimonials here. You can use iframes,
 copy-paste testimonial content, or fetch them from a data source. */}
          <iframe style={{ border: 'none' }} src="https://cards.producthunt.com/cards/reviews/1275497?v=1" width="500" height="405" frameBorder="0" scrolling="no" allowFullScreen></iframe>
          {/* You can remove the example testimonials below if you are only using embeds */}
 <iframe style={{ border: 'none' }} src="https://cards.producthunt.com/cards/reviews/1279092?v=1" width="500" height="405" frameBorder="0" scrolling="no" allowFullScreen></iframe>
          {/* Add more testimonials as needed */}
 <iframe style={{ border: 'none' }} src="https://cards.producthunt.com/cards/reviews/1279088?v=1" width="500" height="405" frameBorder="0" scrolling="no" allowFullScreen></iframe>
 <iframe style={{ border: 'none' }} src="https://cards.producthunt.com/cards/reviews/1277790?v=1" width="500" height="405" frameBorder="0" scrolling="no" allowFullScreen></iframe>
        </section>
        {/* You can add more sections for different types of testimonials or a form for submitting testimonials */}
      </div>
    </>
  );
}


================================================
FILE: src/app/text-to-image-generator/page.tsx
================================================
'use client';

import Head from 'next/head';
import { useState, useEffect } from 'react';
import { useToast } from "@/hooks/use-toast";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from "@/components/ui/card";
import { Textarea } from "@/components/ui/textarea";
import { Input } from "@/components/ui/input";
import { Label } from "@/components/ui/label";
import { Alert, AlertDescription, AlertTitle } from "@/components/ui/alert";
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from "@/components/ui/select";
import { Loader2, Sparkles, AlertTriangle, Info, Download, ImageIcon } from 'lucide-react';
import type { TextToImageGenerationReport, ImageAnalysisResult } from '@/types/text-to-image-generator';
import { getLaymanErrorMessage } from '@/lib/error-utils';
import { downloadTextFile } from '@/lib/utils';
import { preprocessImage } from '@/lib/image-utils';

const cleanJsonString = (rawString: string): string => {
  let cleanedString = rawString.trim();
  if (cleanedString.startsWith("```json") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(7, cleanedString.length - 3).trim();
  } else if (cleanedString.startsWith("```") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(3, cleanedString.length - 3).trim();
  }
  return cleanedString;
};

export default function TextToImageGeneratorPage() {
  const [description, setDescription] = useState<string>('');
  const [style, setStyle] = useState<string>('');
  const [aspectRatio, setAspectRatio] = useState<string>('');
  const [additionalContext, setAdditionalContext] = useState<string>('');
  const [selectedImage, setSelectedImage] = useState<File | null>(null);
  
  const [generatedImage, setGeneratedImage] = useState<TextToImageGenerationReport | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const { toast } = useToast();

  useEffect(() => {
    if (typeof window.puter === 'undefined') {
      toast({
        variant: "destructive",
        title: "Puter SDK Error",
        description: "Puter.js SDK is not loaded. Please refresh the page.",
      });
    }
  }, [toast]);

  const handleImageUpload = (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (!file) {
      setSelectedImage(null);
    } else {
      setSelectedImage(file);
    }
    // Clear previous states related to generation/analysis
    setDescription('');
 setGeneratedImage(null);
 setError(null);
  };

  const analyzeImageAndGeneratePrompt = async () => {
    if (!selectedImage) {
      toast({ variant: "destructive", title: "Missing Image", description: "Please upload an image to analyze." });
      return;
    }

    setIsLoading(true);
    setError(null);
    toast({ title: "Analyzing Image", description: "AI is analyzing your image to generate a prompt..." });

    try {
      if (typeof window.puter === 'undefined' || !window.puter.auth || !window.puter.ai) {
        throw new Error("Puter SDK not available. Please refresh.");
      }
      const puter = window.puter;

      let isSignedIn = await puter.auth.isSignedIn();
      if (!isSignedIn) {
        await puter.auth.signIn();
        isSignedIn = await puter.auth.isSignedIn();
        if (!isSignedIn) throw new Error("Authentication failed or was cancelled.");
      }

      const base64Image = await preprocessImage(selectedImage,1024); // Cast selectedImage to File
      console.log(base64Image); // Add this line to log the output
      if (!base64Image) {
        throw new Error("Failed to preprocess image.");
      }

      const preProcessedDataUrl = await base64Image;

      const imagePrompt = `Analyze the following image and generate a detailed, high-quality DALL-E 3 text-to-image prompt to recreate a similar image. Focus on key visual elements, style, mood, lighting, and composition. Provide the prompt directly as a string in a JSON object like this: {"dalle_prompt": "Your generated prompt here"}.`;


      const analysisResponse = await puter.ai.chat(imagePrompt, preProcessedDataUrl )

      if (!analysisResponse?.message?.content) {
      throw new Error("Failed to analyze image and generate prompt: Empty response from AI.");
      }
      const rawContent = cleanJsonString(analysisResponse.message.content);

      try {
        const parsedAnalysis: ImageAnalysisResult = JSON.parse(rawContent);
        setDescription(parsedAnalysis.dalle_prompt);
        toast({ title: "Prompt Generated", description: "Image analysis complete. Prompt is ready for review." });
      } catch (jsonError) {
          console.error("Failed to parse AI response as JSON:", rawContent);
          throw new Error("AI returned an invalid format. Please try again.");
        }
      } catch (err: any) {
          console.error("Image analysis error:", err);
          setError(getLaymanErrorMessage("Failed to analyze image and generate prompt."));
          toast({ variant: "destructive", title: "Analysis Failed", description: "Failed to analyze image and generate prompt." });
        } finally {
        setIsLoading(false);
      }
    };

  const generateImage = async () => {
    if (!description.trim()) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please provide a description of the image you want to generate." });
      return;
    }

    setIsLoading(true);
    setGeneratedImage(null);
    setError(null);
    toast({ title: "Generation Started", description: "AI is analyzing your request and generating the image..." });

    try {
      if (typeof window.puter === 'undefined' || !window.puter.auth || !window.puter.ai) {
        throw new Error("Puter SDK not available. Please refresh.");
      }
      const puter = window.puter;

      let isSignedIn = await puter.auth.isSignedIn();
      if (!isSignedIn) {
        await puter.auth.signIn();
        isSignedIn = await puter.auth.isSignedIn();
        if (!isSignedIn) throw new Error("Authentication failed or was cancelled.");
      }

      // Process user's request with GPT-4
      const requestPrompt = `
        Based on the user's image generation request: "${description}"
        Style preference: "${style || 'Not specified'}"
        Aspect ratio preference: "${aspectRatio || 'Not specified'}"
        Additional context: "${additionalContext || 'None provided'}"

        Create a detailed DALL-E 3 prompt that will generate a high-quality image matching these requirements.
        The prompt should be clear, specific, and focus on visual elements that will create an impressive result.
        
        Return a JSON object with:
        {
          "dalle_prompt": "Your detailed prompt for DALL-E 3",
          "style_notes": "Brief description of the chosen style and approach"
        }
      `;

      const requestResponse = await puter.ai.chat(requestPrompt, { model: 'gpt-4o' });
      if (!requestResponse?.message?.content) {
        throw new Error("Failed to process image generation request.");
      }

      const rawContent = cleanJsonString(requestResponse.message.content);
       if (!rawContent.startsWith('{') && !rawContent.endsWith('}')) {
        console.error("AI returned non-JSON content for prompt processing:", rawContent);
        throw new Error("AI did not return a valid response format for prompt processing. Please try again.");
      }
      let parsedRequest: { dalle_prompt: string, style_notes: string };
      try {
        parsedRequest = JSON.parse(rawContent);
      } catch (jsonError) {
        throw new Error("Failed to parse AI response for prompt processing. The format was unexpected.");
      }

      // Generate the image using DALL-E 3
      try {
        const imageResponse = await puter.ai.txt2img(parsedRequest.dalle_prompt);
        if (!imageResponse) {
          throw new Error("Image generation returned empty response");
        }

        const generatedReport: TextToImageGenerationReport = {
          generated_image: imageResponse.src,
          prompt_used: parsedRequest.dalle_prompt,
          style_applied: parsedRequest.style_notes,
          confidence: 'High',
          disclaimer: "AI-generated image. Results may vary. For creative and educational purposes."
        };

        setGeneratedImage(generatedReport);
        toast({ 
          title: "Image Generated!", 
          variant: "default", 
          className: "bg-green-500 text-white dark:bg-green-600" 
        });
      } catch (imageError: any) {
        console.error("Image generation error:", imageError);
        throw new Error("Failed to generate image. This could be due to content restrictions or technical limitations. Please try a different description or try again later.");
      }

    } catch (err: any) {
      console.error("Generation error:", err);
      const friendlyErrorMessage = getLaymanErrorMessage(err);
      setError(friendlyErrorMessage);
      toast({ 
        variant: "destructive", 
        title: "Generation Failed", 
        description: friendlyErrorMessage 
      });
    } finally {
      setIsLoading(false);
    }
  };

  const handleDownloadImage = async () => {
    if (!generatedImage) return;

    // Download the image
    try {
      const response = await fetch(generatedImage.generated_image);
      const blob = await response.blob();
      const imageUrl = window.URL.createObjectURL(blob);
      const link = document.createElement('a');
      link.href = imageUrl;
      link.download = `KLUTZ_Generated_Image_${new Date().toISOString().replace(/[:.-]/g, '').slice(0, 14)}.png`;
      document.body.appendChild(link);
      link.click();
      document.body.removeChild(link);
      window.URL.revokeObjectURL(imageUrl);
    } catch (error) {
      console.error('Error downloading image:', error);
      toast({
        variant: "destructive",
        title: "Download Failed",
        description: "Failed to download the generated image. Please try again."
      });
    }

    // Download the report
    let reportString = "KLUTZ AI Text-to-Image Generator Report\n";
    reportString += "======================================\n\n";

    reportString += "Image Generation Details:\n";
    reportString += "-------------------------\n";
    reportString += `Description: ${description}\n`;
    if (style) reportString += `Style: ${style}\n`;
    if (aspectRatio) reportString += `Aspect Ratio: ${aspectRatio}\n`;
    if (additionalContext) reportString += `Additional Context: ${additionalContext}\n\n`;

    reportString += "Generation Details:\n";
    reportString += "-----------------\n";
    reportString += `Prompt Used: ${generatedImage.prompt_used}\n`;
    reportString += `Style Applied: ${generatedImage.style_applied}\n`;
    reportString += `AI Confidence: ${generatedImage.confidence}\n\n`;

    reportString += "Generated Image:\n";
    reportString += "---------------\n";
    reportString += `${generatedImage.generated_image}\n\n`;

    reportString += "Disclaimer:\n";
    reportString += "-----------\n";
    reportString += generatedImage.disclaimer;

    const timestamp = new Date().toISOString().replace(/[:.-]/g, '').slice(0, 14);
    downloadTextFile(reportString, `KLUTZ_TextToImageGenerator_Report_${timestamp}.txt`);
  };

  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/text-to-image-generator" />
      </Head>
    <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-8">
      <Card className="max-w-3xl mx-auto shadow-xl">
        <CardHeader>
          <CardTitle className="font-headline text-3xl text-primary flex items-center">
            <Sparkles className="mr-3 h-8 w-8" />
            AI Text-to-Image Generator
          </CardTitle>
          <CardDescription>
            Generate high-quality images from text descriptions using advanced AI technology.
          </CardDescription>
        </CardHeader>
        <CardContent className="space-y-6">
          <Alert variant="default" className="bg-blue-50 border-blue-400 text-blue-700 dark:bg-blue-900/30 dark:text-blue-300">
            <Info className="h-5 w-5 text-blue-500" />
            <AlertTitle className="font-semibold">How it works</AlertTitle>
            <AlertDescription>
              Describe the image you want to create in detail. The AI will generate a unique, high-quality image based on your description. Be specific about colors, style, composition, and mood for best results.
            </AlertDescription>
          </Alert>

          <div className="space-y-4">
            <div className="flex items-center space-x-4">
                <div className="flex-grow">
                  <Label htmlFor="image-upload" className="text-lg font-medium">Upload Image (Optional)</Label>
                  <Input
                    id="image-upload"
                    type="file"
                    accept="image/*"
                    onChange={handleImageUpload}
                    className="mt-1 block w-full text-sm text-gray-500 file:mr-4 file:py-2 file:px-4 file:rounded-full file:border-0 file:text-sm file:font-semibold file:bg-primary/10 file:text-primary hover:file:bg-primary/20"
                  />
                   {selectedImage && (
                     <p className="text-sm text-muted-foreground mt-1">Selected: {selectedImage.name}</p>
                   )}
                </div>
                <Button onClick={analyzeImageAndGeneratePrompt} disabled={isLoading || !selectedImage} className="self-end">
                  {isLoading && selectedImage ? (
                    <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                  ) : (
                    <Sparkles className="mr-2 h-4 w-4" />
                  )}
                  Analyze Image</Button>
            </div>
            <div>
              <Label htmlFor="description" className="text-lg font-medium">Image Description</Label>
              <Textarea
                id="description"
                placeholder="Describe the image you want to generate in detail..."
                value={description}
                onChange={(e) => setDescription(e.target.value)}
                className="min-h-[100px]"
              />
            </div>

            <div>
              <Label htmlFor="style" className="text-lg font-medium">Art Style (Optional)</Label>
              <Select value={style} onValueChange={setStyle}>
                <SelectTrigger id="style" className="w-full">
                  <SelectValue placeholder="Choose an art style" />
                </SelectTrigger>
                <SelectContent>
                  <SelectItem value="photorealistic">Photorealistic</SelectItem>
                  <SelectItem value="digital-art">Digital Art</SelectItem>
                  <SelectItem value="oil-painting">Oil Painting</SelectItem>
                  <SelectItem value="watercolor">Watercolor</SelectItem>
                  <SelectItem value="sketch">Pencil Sketch</SelectItem>
                  <SelectItem value="cartoon">Cartoon Style</SelectItem>
                  <SelectItem value="anime">Anime Style</SelectItem>
                  <SelectItem value="abstract">Abstract Art</SelectItem>
                  <SelectItem value="vintage">Vintage Style</SelectItem>
                  <SelectItem value="minimalist">Minimalist</SelectItem>
                </SelectContent>
              </Select>
            </div>

            <div>
              <Label htmlFor="aspect-ratio" className="text-lg font-medium">Aspect Ratio (Optional)</Label>
              <Select value={aspectRatio} onValueChange={setAspectRatio}>
                <SelectTrigger id="aspect-ratio" className="w-full">
                  <SelectValue placeholder="Choose aspect ratio" />
                </SelectTrigger>
                <SelectContent>
                  <SelectItem value="square">Square (1:1)</SelectItem>
                  <SelectItem value="landscape">Landscape (16:9)</SelectItem>
                  <SelectItem value="portrait">Portrait (9:16)</SelectItem>
                  <SelectItem value="wide">Wide (21:9)</SelectItem>
                  <SelectItem value="classic">Classic (4:3)</SelectItem>
                </SelectContent>
              </Select>
            </div>

            <div>
              <Label htmlFor="additional-context" className="text-lg font-medium">Additional Context (Optional)</Label>
              <Textarea
                id="additional-context"
                placeholder="Any additional details, mood, lighting, or specific requirements..."
                value={additionalContext}
                onChange={(e) => setAdditionalContext(e.target.value)}
              />
            </div>
          </div>

          <Button 
            onClick={generateImage} 
            disabled={isLoading || (!description.trim() && !selectedImage)} 
            className="w-full"
          >
            {isLoading ? (
              <>
                <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                Generating Image...
              </>
            ) : (
              <>
                <Sparkles className="mr-2 h-4 w-4" />
                Generate Image
              </>
            )}
          </Button>

          {error && !isLoading && (
            <Alert variant="destructive" className="mt-6">
              <AlertTriangle className="h-5 w-5" />
              <AlertTitle>Generation Error</AlertTitle>
              <AlertDescription>{error}</AlertDescription>
            </Alert>
          )}

          {generatedImage && !isLoading && !error && (
            <Card className="mt-6 shadow-md">
              <CardHeader>
                <CardTitle className="font-headline text-xl flex items-center">
                  <ImageIcon className="mr-2 h-6 w-6 text-primary" />
                  Generated Image
                </CardTitle>
              </CardHeader>
              <CardContent className="space-y-4">
                <div className="rounded-lg overflow-hidden">
                  <img 
                    src={generatedImage.generated_image} 
                    alt="Generated image"
                    className="w-full h-auto"
                  />
                </div>

                <div>
                  <h4 className="font-semibold text-md mb-1">Style & Approach:</h4>
                  <p className="bg-muted/30 p-3 rounded-md">{generatedImage.style_applied}</p>
                </div>

                <Alert variant="default" className="text-xs bg-blue-50 border-blue-300 dark:bg-blue-900/30 dark:text-blue-300">
                  <Info className="h-4 w-4 text-blue-500" />
                  <AlertTitle className="font-medium">AI Note</AlertTitle>
                  <AlertDescription>{generatedImage.disclaimer}</AlertDescription>
                </Alert>

                <div className="flex flex-col gap-2">
                  <Button onClick={handleDownloadImage} variant="outline" className="w-full">
                    <Download className="mr-2 h-4 w-4" />
                    Download Image & Report
                  </Button>
                  <p className="text-xs text-muted-foreground text-center">
                    Downloads both the generated image and generation report
                  </p>
                </div>
              </CardContent>
            </Card>
          )}

          {!generatedImage && !isLoading && !error && (
            <div className="mt-6 p-4 border border-dashed rounded-md text-center text-muted-foreground">
              <Info className="mx-auto h-8 w-8 mb-2"/>
              <p>Describe your image idea and click "Generate" to create a unique AI-generated image.</p>
            </div>
          )}
        </CardContent>
        <CardFooter>
          <p className="text-xs text-muted-foreground w-full text-center">
            This tool uses AI for image generation. Results may vary and are intended for creative and educational purposes.
          </p>
        </CardFooter>
      </Card>

      <div className="max-w-3xl mx-auto mt-12 prose dark:prose-invert">
        <h2 className="font-headline text-2xl text-primary">The Ultimate Guide to AI Text-to-Image Generators: Transform Your Words into Stunning Visuals</h2>

        <p>Artificial intelligence has revolutionized creative content creation, and nowhere is this more evident than in the realm of <strong>AI text-to-image generators</strong>. These powerful tools have democratized digital art creation, allowing anyone to transform simple text descriptions into professional-quality images in seconds. Whether you're a content creator, marketer, or simply someone looking to explore digital creativity, understanding these tools can unlock new possibilities for visual storytelling.</p>

        <h3 className="font-headline text-xl text-secondary">What is an AI Text-to-Image Generator?</h3>

        <p>An <strong>AI image generator</strong> is a sophisticated machine learning tool that converts written descriptions into visual content. Using advanced neural networks and deep learning algorithms, these platforms interpret your text prompts and generate unique images that match your description. The technology behind these tools has evolved rapidly, moving from basic sketch-like outputs to photorealistic images that rival professional photography and digital art.</p>

        <p>The process is remarkably straightforward: you input a text description (called a prompt), select your preferred style or settings, and the AI processes your request to create an original image. Modern <strong>AI art generators</strong> can produce everything from realistic portraits to abstract art, fantasy landscapes, and commercial photography - all from simple text descriptions.</p>

        <h3 className="font-headline text-xl text-secondary">Key Features to Check When Searching for the Best AI Text-to-Image Generator</h3>

        <p>When evaluating different <strong>AI image generation</strong> platforms, several crucial factors can help you identify the best tool for your needs:</p>

        <h4 className="font-semibold text-lg">Image Quality and Resolution</h4>

        <p>The most important consideration is the quality of generated images. Look for tools that offer high-resolution outputs suitable for your intended use. Professional-grade generators should produce images at least 1024x1024 pixels, with many now offering 4K and higher resolutions. The <strong>audio quality enhancer</strong> principle applies here - just as you wouldn't settle for poor audio, don't compromise on image clarity and detail.</p>

        <h4 className="font-semibold text-lg">Style Variety and Customization</h4>

        <p>The best platforms offer diverse artistic styles, from photorealistic renders to anime, watercolor, oil painting, and abstract art styles. Advanced customization options allow you to fine-tune aspects like lighting, color palettes, and composition. Some tools even function as a comprehensive <strong>audio editor</strong> equivalent for images, providing extensive modification capabilities.</p>

        <h4 className="font-semibold text-lg">AI Analysis and Intelligence Features</h4>

        <p>This is where innovation truly shines. Klutz's AI text-to-image generator stands out as the <strong>first tool with AI analysis features</strong>, setting a new standard in the industry. These advanced analytical capabilities help users understand what makes prompts effective, optimize their descriptions for better results, and learn from successful image generations - a revolutionary approach that other platforms are now trying to emulate.</p>

        <h4 className="font-semibold text-lg">User Interface and Ease of Use</h4>

        <p>A well-designed interface can significantly impact your creative workflow. Look for platforms with intuitive controls, clear organization, and helpful guidance for beginners. The interface should feel as smooth as a well-designed <strong>music editor</strong>, allowing creative flow without technical barriers.</p>

        <h4 className="font-semibold text-lg">Processing Speed and Efficiency</h4>

        <p>Generation speed varies significantly between platforms. While some tools produce images in seconds, others may take several minutes. Consider your workflow needs and whether you require real-time generation or can work with longer processing times.</p>

        <h4 className="font-semibold text-lg">Commercial Rights and Licensing</h4>

        <p>Understanding usage rights is crucial, especially for commercial applications. Many platforms grant full commercial rights to generated images, while others have restrictions. Always review the terms of service before using images for business purposes.</p>

        <h3 className="font-headline text-xl text-secondary">Best FREE AI Text-to-Image Generators</h3>

        <p>The market offers several excellent free options, each with unique strengths and limitations:</p>

        <h4 className="font-semibold text-lg">Klutz AI Text-to-Image Generator</h4>

        <p><strong>Price:</strong> Free with unlimited basic generations</p>

        <p><strong>Pros:</strong></p>
        <ul>
          <li>Revolutionary AI analysis features - the <strong>first tool with AI analysis features</strong> in the market</li>
          <li>Intelligent prompt optimization suggestions</li>
          <li>User-friendly interface designed for both beginners and professionals</li>
          <li>High-quality image outputs with multiple style options</li>
          <li>Fast processing speeds comparable to premium platforms</li>
          <li>Comprehensive feedback system to improve future generations</li>
          <li>No signup required for basic use</li>
        </ul>

        <p><strong>Cons:</strong></p>
        <ul>
          <li>Advanced features may require account creation</li>
          <li>Newer platform with smaller community compared to established competitors</li>
        </ul>

        <p>Klutz's innovative approach to AI analysis sets it apart from traditional <strong>image generators</strong>. The platform's ability to analyze successful prompts and provide intelligent suggestions makes it invaluable for users looking to improve their AI art creation skills.</p>

        <h4 className="font-semibold text-lg">DeepAI</h4>

        <p><strong>Price:</strong> Free tier with paid upgrades starting at $5/month</p>

        <p><strong>Pros:</strong></p>
        <ul>
          <li>Simple, straightforward interface</li>
          <li>Multiple artistic styles available</li>
          <li>API access for developers</li>
          <li>No registration required for basic use</li>
          <li>Fast generation times</li>
        </ul>

        <p><strong>Cons:</strong></p>
        <ul>
          <li>Limited customization options on free tier</li>
          <li>Lower resolution outputs compared to premium alternatives</li>
          <li>Lacks advanced AI analysis features found in newer platforms like Klutz</li>
        </ul>

        <h4 className="font-semibold text-lg">Leonardo AI</h4>

        <p><strong>Price:</strong> Free tier with 150 tokens daily, paid plans from $12/month</p>

        <p><strong>Pros:</strong></p>
        <ul>
          <li>Excellent image quality with fine-tuned models</li>
          <li>Canvas feature for image editing</li>
          <li>3D texture generation capabilities</li>
          <li>Strong community and model sharing</li>
          <li>Professional-grade outputs</li>
        </ul>

        <p><strong>Cons:</strong></p>
        <ul>
          <li>Limited free tier usage</li>
          <li>Steeper learning curve for beginners</li>
          <li>Requires account creation</li>
          <li>Lacks the intelligent analysis features pioneered by Klutz</li>
        </ul>

        <h4 className="font-semibold text-lg">Freepik AI Image Generator</h4>

        <p><strong>Price:</strong> Free with watermarks, paid plans from $10/month</p>

        <p><strong>Pros:</strong></p>
        <ul>
          <li>Integration with Freepik's extensive stock library</li>
          <li>Multiple AI models including Flux and Mystic</li>
          <li>Professional design templates</li>
          <li>Commercial licensing included in paid plans</li>
        </ul>

        <p><strong>Cons:</strong></p>
        <ul>
          <li>Watermarks on free generations</li>
          <li>Limited daily generations on free tier</li>
          <li>Can feel overwhelming for simple image generation needs</li>
        </ul>

        <h4 className="font-semibold text-lg">Midjourney (Discord-based)</h4>

        <p><strong>Price:</strong> No longer offers free tier, paid plans start at $10/month</p>

        <p><strong>Pros:</strong></p>
        <ul>
          <li>Exceptional artistic quality</li>
          <li>Strong community feedback system</li>
          <li>Unique aesthetic and style</li>
          <li>Regular model updates and improvements</li>
        </ul>

        <p><strong>Cons:</strong></p>
        <ul>
          <li>Requires Discord usage</li>
          <li>No free tier available</li>
          <li>Can be intimidating for newcomers</li>
          <li>Limited direct control over generation parameters</li>
        </ul>

        <h3 className="font-headline text-xl text-secondary">Advanced Features and Professional Considerations</h3>

        <p>As AI image generation technology evolves, advanced features become increasingly important for professional use. Many platforms now offer capabilities similar to traditional <strong>photo editing software</strong>, including layer manipulation, selective editing, and style transfer.</p>

        <p>The integration of AI analysis - pioneered by platforms like Klutz - represents the next evolution in this space. Just as <strong>audio enhancement</strong> tools help musicians perfect their sound, intelligent prompt analysis helps creators optimize their visual output. This analytical approach transforms the creative process from trial-and-error to data-driven optimization.</p>

        <p>For content creators working across multiple mediums, having tools that work seamlessly together is crucial. Whether you're creating images for video content, social media, or print materials, the best platforms integrate well with existing creative workflows, much like how modern <strong>audio editing tools</strong> integrate with video production pipelines.</p>

        <h3 className="font-headline text-xl text-secondary">The Future of AI Image Generation</h3>

        <p>The field continues to evolve rapidly, with improvements in image quality, generation speed, and user control. Emerging features include better text integration within images, enhanced realism in human portraits, and more sophisticated style control.</p>

        <p>Klutz's introduction of AI analysis features represents a significant step forward in making these tools more accessible and effective for users of all skill levels. As the <strong>first tool with AI analysis features</strong>, it has set a new standard that other platforms are now working to match.</p>

        <h3 className="font-headline text-xl text-secondary">TL;DR</h3>

        <p>AI text-to-image generators have revolutionized digital content creation, offering powerful tools for transforming text descriptions into stunning visuals. When choosing a platform, prioritize image quality, style variety, ease of use, and innovative features like AI analysis.</p>

        <p><strong>Top recommendations:</strong></p>
        <ul>
          <li><strong>Klutz AI Text-to-Image Generator</strong> - Best overall for its revolutionary AI analysis features and user-friendly approach</li>
          <li><strong>Leonardo AI</strong> - Best for professional artists seeking high-quality outputs</li>
          <li><strong>DeepAI</strong> - Best for simple, quick generations</li>
          <li><strong>Freepik AI</strong> - Best for commercial use with extensive template library</li>
        </ul>

        <p>The standout feature across all platforms is the democratization of digital art creation. However, Klutz's unique position as the <strong>first tool with AI analysis features</strong> makes it particularly valuable for users looking to improve their prompt writing skills and achieve more consistent results.</p>

        <p>Whether you're creating content for social media, marketing materials, or personal projects, these AI-powered tools offer unprecedented creative possibilities. The key is finding the platform that best matches your specific needs, skill level, and intended use cases.</p>
      </div>
    </div>
  );
    </>
)}    


================================================
FILE: src/app/third-party-licenses/page.tsx
================================================
'use client';

import Head from 'next/head';
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '@/components/ui/card';
import { Separator } from '@/components/ui/separator';
import { Mail, Calendar, Package, ExternalLink } from 'lucide-react';

export default function ThirdPartyLicensesPage() {
  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/third-party-licenses" />
      </Head>
    <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-12">
      <div className="max-w-4xl mx-auto">
        <Card className="shadow-xl">
          <CardHeader className="text-center">
            <CardTitle className="font-headline text-4xl text-primary flex items-center justify-center">
              <Package className="mr-3 h-8 w-8" />
              Third-Party Licenses
            </CardTitle>
            <CardDescription className="text-lg">
              Open source libraries and services used in KLUTZ
            </CardDescription>
          </CardHeader>
          <CardContent className="prose prose-lg max-w-none space-y-8">
            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">Acknowledgments</h2>
              <p>
                KLUTZ is built using various open-source libraries and third-party services. We are grateful to the
                developers and maintainers of these projects. This page lists the major dependencies used across all
                our AI tools including MediScan AI, AI Problem Solver, AI Translator, Text-to-Image Generator, and others.
              </p>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">Core Framework & Runtime</h2>

              <div className="space-y-6">
                <div className="border rounded-lg p-4">
                  <h3 className="font-semibold text-lg flex items-center">
                    Next.js
                    <ExternalLink className="ml-2 h-4 w-4" />
                  </h3>
                  <p className="text-sm text-muted-foreground mb-2">Version: 15.2.3</p>
                  <p>The React framework for production applications.</p>
                  <p className="text-sm mt-2">
                    <strong>License:</strong> MIT License<br />
                    <strong>Copyright:</strong> Vercel, Inc.<br />
                    <strong>Website:</strong> <a href="https://nextjs.org" className="text-primary hover:underline">https://nextjs.org</a>
                  </p>
                </div>

                <div className="border rounded-lg p-4">
                  <h3 className="font-semibold text-lg flex items-center">
                    React
                    <ExternalLink className="ml-2 h-4 w-4" />
                  </h3>
                  <p className="text-sm text-muted-foreground mb-2">Version: 18.3.1</p>
                  <p>A JavaScript library for building user interfaces.</p>
                  <p className="text-sm mt-2">
                    <strong>License:</strong> MIT License<br />
                    <strong>Copyright:</strong> Meta Platforms, Inc.<br />
                    <strong>Website:</strong> <a href="https://react.dev" className="text-primary hover:underline">https://react.dev</a>
                  </p>
                </div>
              </div>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">AI & Processing Services</h2>

              <div className="space-y-6">
                <div className="border rounded-lg p-4 bg-blue-50 dark:bg-blue-900/20">
                  <h3 className="font-semibold text-lg flex items-center">
                    Puter.js SDK
                    <ExternalLink className="ml-2 h-4 w-4" />
                  </h3>
                  <p className="text-sm text-muted-foreground mb-2">Core AI Processing Service</p>
                  <p>
                    Primary AI service powering all KLUTZ tools including medical image analysis, problem solving,
                    translation, image generation, content analysis, troubleshooting, and more.
                  </p>
                  <p className="text-sm mt-2">
                    <strong>Service:</strong> Puter Cloud Platform<br />
                    <strong>Website:</strong> <a href="https://puter.com" className="text-primary hover:underline">https://puter.com</a><br />
                    <strong>Used in:</strong> All KLUTZ AI tools
                  </p>
                </div>
              </div>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">UI Components & Styling</h2>

              <div className="space-y-6">
                <div className="border rounded-lg p-4">
                  <h3 className="font-semibold text-lg">Tailwind CSS</h3>
                  <p className="text-sm text-muted-foreground mb-2">Version: 3.4.1</p>
                  <p>A utility-first CSS framework for rapid UI development.</p>
                  <p className="text-sm mt-2">
                    <strong>License:</strong> MIT License<br />
                    <strong>Website:</strong> <a href="https://tailwindcss.com" className="text-primary hover:underline">https://tailwindcss.com</a>
                  </p>
                </div>

                <div className="border rounded-lg p-4">
                  <h3 className="font-semibold text-lg">Radix UI</h3>
                  <p className="text-sm text-muted-foreground mb-2">Multiple Components</p>
                  <p>Low-level UI primitives with accessibility built-in.</p>
                  <p className="text-sm mt-2">
                    <strong>License:</strong> MIT License<br />
                    <strong>Website:</strong> <a href="https://radix-ui.com" className="text-primary hover:underline">https://radix-ui.com</a><br />
                    <strong>Components:</strong> Dialog, Accordion, Select, Tabs, Toast, and more
                  </p>
                </div>

                <div className="border rounded-lg p-4">
                  <h3 className="font-semibold text-lg">Lucide React</h3>
                  <p className="text-sm text-muted-foreground mb-2">Version: 0.475.0</p>
                  <p>Beautiful & consistent icon toolkit.</p>
                  <p className="text-sm mt-2">
                    <strong>License:</strong> ISC License<br />
                    <strong>Website:</strong> <a href="https://lucide.dev" className="text-primary hover:underline">https://lucide.dev</a>
                  </p>
                </div>
              </div>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">Form Handling & Validation</h2>

              <div className="space-y-6">
                <div className="border rounded-lg p-4">
                  <h3 className="font-semibold text-lg">React Hook Form</h3>
                  <p className="text-sm text-muted-foreground mb-2">Version: 7.54.2</p>
                  <p>Performant, flexible forms with easy validation.</p>
                  <p className="text-sm mt-2">
                    <strong>License:</strong> MIT License<br />
                    <strong>Used in:</strong> All tool input forms across KLUTZ
                  </p>
                </div>

                <div className="border rounded-lg p-4">
                  <h3 className="font-semibold text-lg">Zod</h3>
                  <p className="text-sm text-muted-foreground mb-2">Version: 3.24.2</p>
                  <p>TypeScript-first schema validation with static type inference.</p>
                  <p className="text-sm mt-2">
                    <strong>License:</strong> MIT License<br />
                    <strong>Used in:</strong> Form validation across all KLUTZ tools
                  </p>
                </div>
              </div>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">Typography & Fonts</h2>

              <div className="space-y-6">
                <div className="border rounded-lg p-4">
                  <h3 className="font-semibold text-lg">Google Fonts</h3>
                  <p>Free and open source font families.</p>
                  <div className="text-sm mt-2 space-y-1">
                    <p><strong>PT Sans:</strong> Body text font - SIL Open Font License</p>
                    <p><strong>Space Grotesk:</strong> Headline font - SIL Open Font License</p>
                    <p><strong>Website:</strong> <a href="https://fonts.google.com" className="text-primary hover:underline">https://fonts.google.com</a></p>
                  </div>
                </div>
              </div>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">Development Tools</h2>

              <div className="space-y-6">
                <div className="border rounded-lg p-4">
                  <h3 className="font-semibold text-lg">TypeScript</h3>
                  <p className="text-sm text-muted-foreground mb-2">Version: 5.x</p>
                  <p>Typed superset of JavaScript that compiles to plain JavaScript.</p>
                  <p className="text-sm mt-2">
                    <strong>License:</strong> Apache License 2.0<br />
                    <strong>Copyright:</strong> Microsoft Corporation
                  </p>
                </div>

                <div className="border rounded-lg p-4">
                  <h3 className="font-semibold text-lg">Class Variance Authority</h3>
                  <p className="text-sm text-muted-foreground mb-2">Version: 0.7.1</p>
                  <p>Creating variants with the cva function.</p>
                  <p className="text-sm mt-2">
                    <strong>License:</strong> Apache License 2.0
                  </p>
                </div>
              </div>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">Image Processing</h2>

              <div className="space-y-6">
                <div className="border rounded-lg p-4">
                  <h3 className="font-semibold text-lg">Canvas API</h3>
                  <p>Browser-native image processing for all KLUTZ tools.</p>
                  <p className="text-sm mt-2">
                    <strong>Used in:</strong> Image preprocessing for MediScan AI, Problem Solver, Translator,
                    Troubleshooters, Measuring Tool, Ingredients Checker, and other image-based tools.
                  </p>
                </div>
              </div>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">License Compliance</h2>
              <div className="bg-green-50 dark:bg-green-900/20 p-4 rounded-md border border-green-200 dark:border-green-800">
                <h3 className="font-semibold text-lg text-green-700 dark:text-green-300 mb-2">Our Commitment</h3>
                <ul className="list-disc pl-6 space-y-1 text-green-600 dark:text-green-400">
                  <li>We comply with all open source license requirements</li>
                  <li>Attribution is provided where required</li>
                  <li>We contribute back to the open source community when possible</li>
                  <li>License terms are respected for all dependencies</li>
                </ul>
              </div>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">Full License Texts</h2>
              <p>
                Complete license texts for all dependencies are available in the source code repository.
                For specific license inquiries or to request full license texts, please contact us.
              </p>
            </section>

            <Separator />

            <section>
              <h2 className="font-headline text-2xl text-primary mb-4">Contact</h2>
              <div className="flex items-center space-x-2">
                <Mail className="h-5 w-5 text-accent" />
                <span>For license-related questions, contact us at: </span>
                <a href="mailto:jeffrinjames99@gmail.com" className="text-primary hover:underline font-semibold">
                  jeffrinjames99@gmail.com
                </a>
              </div>
            </section>

            <Separator />

            <section className="text-center text-muted-foreground">
              <p className="flex items-center justify-center">
                <Calendar className="h-4 w-4 mr-2" />
                Last updated: January 2025
              </p>
            </section>
          </CardContent>
        </Card>
      </div>
    </div>
  );
    </>
)}    


================================================
FILE: src/app/thumbnail-checker/page.tsx
================================================

'use client';

import Head from 'next/head';
import { useState, useEffect } from 'react';
import { useToast } from "@/hooks/use-toast";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from "@/components/ui/card";
import { Textarea } from "@/components/ui/textarea";
import { Input } from "@/components/ui/input";
import { Label } from "@/components/ui/label";
import { Loader2, ImageUp, Type, CheckCircle, XCircle, HelpCircle, Info, Download } from 'lucide-react';
import { preprocessImage } from '@/lib/image-utils';
import { downloadTextFile } from '@/lib/utils';
import type { ThumbnailAnalysisResponse, TitleAnalysisResponse, ConsistencyReport } from '@/types/thumbnail-checker';
import ImagePreview from '@/components/medi-scan/image-preview';

const cleanJsonString = (rawString: string): string => {
  let cleanedString = rawString.trim();
  if (cleanedString.startsWith("```json") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(7, cleanedString.length - 3).trim();
  } else if (cleanedString.startsWith("```") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(3, cleanedString.length - 3).trim();
  }
  return cleanedString;
};

export default function ThumbnailCheckerPage() {
  const [thumbnailFile, setThumbnailFile] = useState<File | null>(null);
  const [thumbnailDataUrl, setThumbnailDataUrl] = useState<string | null>(null);
  const [titleText, setTitleText] = useState<string>('');
  const [titleFile, setTitleFile] = useState<File | null>(null);

  const [thumbnailAnalysis, setThumbnailAnalysis] = useState<ThumbnailAnalysisResponse | null>(null);
  const [titleAnalysis, setTitleAnalysis] = useState<TitleAnalysisResponse | null>(null);
  const [consistencyReport, setConsistencyReport] = useState<ConsistencyReport | null>(null);
  
  const [isLoading, setIsLoading] = useState(false);
  const [currentStep, setCurrentStep] = useState('');

  const { toast } = useToast();

  useEffect(() => {
    if (typeof window.puter === 'undefined') {
      toast({
        variant: "destructive",
        title: "Puter SDK Error",
        description: "Puter.js SDK is not loaded. Please refresh the page.",
      });
    }
  }, [toast]);

  const handleThumbnailChange = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      setThumbnailFile(file);
      try {
        const previewDataUrl = URL.createObjectURL(file);
        setThumbnailDataUrl(previewDataUrl);
        setThumbnailAnalysis(null); 
        setConsistencyReport(null);
      } catch (error) {
        toast({ variant: "destructive", title: "Preview Error", description: "Could not generate image preview." });
        setThumbnailDataUrl(null);
      }
    } else {
      setThumbnailFile(null);
      setThumbnailDataUrl(null);
    }
  };

  const handleTitleTextChange = (event: React.ChangeEvent<HTMLTextAreaElement>) => {
    setTitleText(event.target.value);
    setTitleAnalysis(null); 
    setConsistencyReport(null);
  };
  
  const handleTitleFileChange = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      if (file.type === 'text/plain') {
        setTitleFile(file);
        setTitleText(''); 
        try {
          const textContent = await file.text();
          setTitleText(textContent); 
          setTitleAnalysis(null);
          setConsistencyReport(null);
        } catch (error) {
          toast({ variant: "destructive", title: "File Read Error", description: "Could not read the text file." });
        }
      } else {
        toast({ variant: "destructive", title: "Invalid File Type", description: "Please upload a .txt file for the title." });
        event.target.value = ''; 
      }
    } else {
      setTitleFile(null);
    }
  };

  const analyzeContent = async () => {
    if (!thumbnailFile && !thumbnailDataUrl) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please upload a thumbnail image." });
      return;
    }
    if (!titleText.trim()) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please enter or upload title text." });
      return;
    }

    setIsLoading(true);
    setThumbnailAnalysis(null);
    setTitleAnalysis(null);
    setConsistencyReport(null);

    try {
       if (typeof window.puter === 'undefined' || !window.puter.auth || !window.puter.ai) {
        throw new Error("Puter SDK not available. Please refresh.");
      }
      const puter = window.puter;

      let isSignedIn = await puter.auth.isSignedIn();
      if (!isSignedIn) {
        await puter.auth.signIn();
        isSignedIn = await puter.auth.isSignedIn();
        if (!isSignedIn) throw new Error("Authentication failed or was cancelled.");
      }

      setCurrentStep('Analyzing Thumbnail...');
      toast({ title: currentStep });
      const processedThumbnailUrl = thumbnailFile ? await preprocessImage(thumbnailFile, 512) : thumbnailDataUrl;
      if (!processedThumbnailUrl) throw new Error("Failed to process thumbnail image.");

      const imagePrompt = `Describe the key visual elements, objects, and the overall theme or message conveyed by this thumbnail image. Respond with a concise JSON object: {"image_summary": "Your description here"}`;
      const imageResponse = await puter.ai.chat(imagePrompt, processedThumbnailUrl);
      if (!imageResponse?.message?.content) throw new Error("Invalid response from thumbnail analysis.");
      const parsedImageResponse: { image_summary: string } = JSON.parse(cleanJsonString(imageResponse.message.content));
      setThumbnailAnalysis({ summary: parsedImageResponse.image_summary });

      setCurrentStep('Analyzing Title Text...');
      toast({ title: currentStep });
      const titlePrompt = `Analyze the following video title text and summarize its main topic or message. Title: "${titleText}". Respond with a concise JSON object: {"title_summary": "Your summary here"}`;
      const titleResponse = await puter.ai.chat(titlePrompt, { model: 'gpt-4o' });
      if (!titleResponse?.message?.content) throw new Error("Invalid response from title analysis.");
      const parsedTitleResponse: { title_summary: string } = JSON.parse(cleanJsonString(titleResponse.message.content));
      setTitleAnalysis({ summary: parsedTitleResponse.title_summary });

      setCurrentStep('Checking Consistency...');
      toast({ title: currentStep });
      const consistencyPrompt = `
        You are an AI assistant. You are given a summary of a video thumbnail image and a summary of its title.
        Image Summary: "${parsedImageResponse.image_summary}"
        Title Summary: "${parsedTitleResponse.title_summary}"
        Based on these summaries, determine if the thumbnail and title convey the same core message or concept.
        Provide your analysis in a JSON object with the following keys:
        - "is_consistent": (boolean) true if they are consistent, false otherwise.
        - "explanation": (string) A brief explanation for your conclusion (2-3 sentences).
        - "confidence_score": (number, 0.0 to 1.0) Your confidence in this assessment.
      `;
      const consistencyResponse = await puter.ai.chat(consistencyPrompt, { model: 'gpt-4o' });
      if (!consistencyResponse?.message?.content) throw new Error("Invalid response from consistency analysis.");
      const parsedConsistencyResponse: ConsistencyReport = JSON.parse(cleanJsonString(consistencyResponse.message.content));
      setConsistencyReport(parsedConsistencyResponse);
      
      toast({ title: "Analysis Complete!", variant: "default", className: "bg-green-500 text-white dark:bg-green-600" });

    } catch (error: any) {
      console.error("Analysis error:", error);
      let errorMessage = "An error occurred during analysis.";
      if (error instanceof Error) {
        errorMessage = error.message;
      } else if (typeof error === 'string') {
        errorMessage = error;
      } else if (error.error && error.error.message) {
        errorMessage = error.error.message;
      }
      toast({
        variant: "destructive",
        title: "Analysis Failed",
        description: errorMessage,
      });
      setConsistencyReport({ is_consistent: false, explanation: `Error: ${errorMessage}`, confidence_score: 0 });
    } finally {
      setIsLoading(false);
      setCurrentStep('');
    }
  };

  const handleDownloadReport = () => {
    if (!thumbnailAnalysis && !titleAnalysis && !consistencyReport) return;

    let reportString = "KLUTZ Thumbnail & Title Consistency Report\n";
    reportString += "=========================================\n\n";

    reportString += "User Inputs:\n";
    reportString += "------------\n";
    reportString += `Title Text: ${titleText || "N/A"}\n`;
    reportString += `Thumbnail File: ${thumbnailFile?.name || "Pasted/Not available"}\n\n`;

    if (thumbnailAnalysis) {
      reportString += "Thumbnail Image Analysis:\n";
      reportString += "-------------------------\n";
      reportString += `Summary: ${thumbnailAnalysis.summary || "N/A"}\n\n`;
    }

    if (titleAnalysis) {
      reportString += "Title Text Analysis:\n";
      reportString += "--------------------\n";
      reportString += `Summary: ${titleAnalysis.summary || "N/A"}\n\n`;
    }

    if (consistencyReport) {
      reportString += "Consistency Assessment:\n";
      reportString += "-----------------------\n";
      reportString += `Consistent: ${consistencyReport.is_consistent ? 'Yes' : 'No'}\n`;
      reportString += `Explanation: ${consistencyReport.explanation || "N/A"}\n`;
      reportString += `AI Confidence: ${(consistencyReport.confidence_score * 100).toFixed(0)}%\n\n`;
    }
    
    reportString += "\nDisclaimer: This report is AI-generated and for informational purposes only. Human review is recommended.";


    const timestamp = new Date().toISOString().replace(/[:.-]/g, '').slice(0, 14);
    downloadTextFile(reportString, `KLUTZ_ThumbnailChecker_Analysis_${timestamp}.txt`);
  };


  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/thumbnail-checker" />
      </Head>
    <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-8">
      <Card className="max-w-3xl mx-auto shadow-xl">
        <CardHeader>
          <CardTitle className="font-headline text-3xl text-primary">Thumbnail & Title Consistency Checker</CardTitle>
          <CardDescription>Upload a thumbnail and provide a title to check if they align.</CardDescription>
        </CardHeader>
        <CardContent className="space-y-6">
          <div>
            <Label htmlFor="thumbnail-upload" className="text-lg font-medium flex items-center mb-2">
              <ImageUp className="mr-2 h-5 w-5 text-accent" />
              Thumbnail Image
            </Label>
            <Input
              id="thumbnail-upload"
              type="file"
              accept="image/png, image/jpeg, image/webp"
              onChange={handleThumbnailChange}
              className="file:text-primary file:font-semibold file:bg-primary/10 hover:file:bg-primary/20"
              disabled={isLoading}
            />
            {thumbnailDataUrl && (
              <div className="mt-4">
                <ImagePreview imageDataUrl={thumbnailDataUrl} dataAiHint="video thumbnail"/>
              </div>
            )}
          </div>

          <div>
            <Label htmlFor="title-text" className="text-lg font-medium flex items-center mb-2">
              <Type className="mr-2 h-5 w-5 text-accent" />
              Video Title
            </Label>
            <Textarea
              id="title-text"
              placeholder="Enter your video title here..."
              value={titleText}
              onChange={handleTitleTextChange}
              rows={3}
              className="mb-2"
              disabled={isLoading}
            />
            <span className="text-sm text-muted-foreground mr-2">Or upload a .txt file:</span>
            <Input
              id="title-file-upload"
              type="file"
              accept=".txt"
              onChange={handleTitleFileChange}
              className="file:text-primary file:font-semibold file:bg-primary/10 hover:file:bg-primary/20 inline-block w-auto text-sm"
              disabled={isLoading}
            />
          </div>

          <Button onClick={analyzeContent} disabled={isLoading || !thumbnailDataUrl || !titleText.trim()} className="w-full">
            {isLoading ? (
              <>
                <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                {currentStep || 'Analyzing...'}
              </>
            ) : (
              'Check Consistency'
            )}
          </Button>

          {thumbnailAnalysis && (
            <Card className="bg-muted/30">
              <CardHeader><CardTitle className="text-md font-semibold">Image Analysis Summary:</CardTitle></CardHeader>
              <CardContent><p className="text-sm">{thumbnailAnalysis.summary}</p></CardContent>
            </Card>
          )}
          {titleAnalysis && (
            <Card className="bg-muted/30">
              <CardHeader><CardTitle className="text-md font-semibold">Title Analysis Summary:</CardTitle></CardHeader>
              <CardContent><p className="text-sm">{titleAnalysis.summary}</p></CardContent>
            </Card>
          )}

          {consistencyReport && !isLoading && (
            <Card className={`mt-6 ${consistencyReport.is_consistent ? 'border-green-500' : 'border-red-500'}`}>
              <CardHeader>
                <CardTitle className="flex items-center font-headline text-xl">
                  {consistencyReport.is_consistent ? (
                    <CheckCircle className="mr-2 h-6 w-6 text-green-500" />
                  ) : (
                    <XCircle className="mr-2 h-6 w-6 text-red-500" />
                  )}
                  Consistency Report
                </CardTitle>
              </CardHeader>
              <CardContent className="space-y-3">
                <p className={`text-lg font-semibold ${consistencyReport.is_consistent ? 'text-green-600' : 'text-red-600'}`}>
                  {consistencyReport.is_consistent ? 'Consistent' : 'Not Consistent'}
                </p>
                <p><strong className="font-medium">Explanation:</strong> {consistencyReport.explanation}</p>
                <p><strong className="font-medium">Confidence:</strong> {(consistencyReport.confidence_score * 100).toFixed(0)}%</p>
                <Button onClick={handleDownloadReport} variant="outline" className="w-full mt-2">
                  <Download className="mr-2 h-4 w-4" />
                  Download Full Analysis
                </Button>
              </CardContent>
            </Card>
          )}
          {!consistencyReport && !isLoading && !thumbnailAnalysis && !titleAnalysis && (
             <div className="mt-6 p-4 border border-dashed rounded-md text-center text-muted-foreground">
                <Info className="mx-auto h-8 w-8 mb-2"/>
                <p>Upload a thumbnail and enter a title, then click "Check Consistency" to see the AI's analysis.</p>
            </div>
          )}
        </CardContent>
      </Card>

      <div className="max-w-3xl mx-auto mt-12 prose dark:prose-invert">
        <h1 className="font-headline text-4xl text-primary mb-6">The Ultimate Guide to AI Thumbnail Title Consistency Checkers for YouTube Success</h1>
        <p className="mb-4">Creating viral YouTube videos takes more than just great content - it requires perfect alignment between your video thumbnail and title to grab attention and optimize click-through rates. AI thumbnail title consistency checkers have revolutionized how creators ensure their YouTube videos achieve maximum visibility in search results. These powerful tools analyze whether your thumbnail and title work together effectively, helping you craft titles that won't get cut off while ensuring your video's presentation captures viewers' attention.</p>

        <h2 className="font-headline text-2xl text-primary mt-8 mb-4">What is an AI Thumbnail Title Consistency Checker?</h2>
        <p className="mb-4">An AI thumbnail title consistency checker is an online tool that uses artificial intelligence to analyze the relationship between your YouTube video thumbnail and title. These tools examine whether your visual and textual elements complement each other, ensuring your content replicates what works online for viral videos. The checker evaluates factors like title length, character count, and how well your title fits the optimal 55-character limit that YouTube's search results display without getting cut.</p>
        <p className="mb-4">Traditional title length checkers only measure character length, but AI-powered consistency checkers go further by analyzing semantic alignment between your thumbnail image and video title. This technology helps creators automate video optimization and ensure their YouTube videos grab attention in search results alongside real YouTube content.</p>

        <h2 className="font-headline text-2xl text-primary mt-8 mb-4">Key Features to Check When Searching for the Best AI Thumbnail Title Consistency Checker</h2>
        <p className="mb-4">When evaluating AI thumbnail title consistency checkers, several critical features determine which tool will best serve your video creation needs:</p>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">AI Analysis Capabilities</h3>
        <p className="mb-4">The most advanced tools offer AI analysis features that examine both visual and textual elements. Look for checkers that can analyze how well your thumbnail supports your title's message and whether they work together to optimize click-through rates.</p>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">Title Length Optimization</h3>
        <p className="mb-4">Essential features include real-time character length count and preview optimization that shows exactly how your YouTube title will appear in search results. The tool should instantly indicate whether your title fits the optimal 55-character limit and won't get cut off.</p>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">Thumbnail Preview Integration</h3>
        <p className="mb-4">Quality tools provide YouTube thumbnail preview functionality, showing how your title looks alongside real YouTube videos. This helps you test variations and compare your titles with trending videos to ensure maximum visibility.</p>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">Batch Processing and File Upload</h3>
        <p className="mb-4">Advanced checkers allow you to upload custom thumbnails and even process multiple title variations simultaneously, saving time in your video editing and creation workflow.</p>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">Search Results Simulation</h3>
        <p className="mb-4">The best tools replicate YouTube's actual search interface, showing precisely how your video's presentation will appear to potential viewers browsing YouTube's search results.</p>

        <h2 className="font-headline text-2xl text-primary mt-8 mb-4">Best FREE AI Thumbnail Title Consistency Checkers</h2>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">1. Klutz AI Thumbnail Title Consistency Checker - The Pioneer</h3>
        <p className="mb-4"><strong>Price:</strong> Free</p>
        <p className="mb-4"><strong>What makes it special:</strong> Klutz offers the first tool with AI analysis features specifically designed for thumbnail title consistency checking. This groundbreaking approach sets it apart from traditional length checkers.</p>
        <p className="mb-4"><strong>Pros:</strong></p>
        <ul className="list-disc list-inside mb-4">
          <li>First-of-its-kind AI analysis technology that examines semantic alignment between thumbnails and titles</li>
          <li>Comprehensive consistency evaluation beyond simple character counting</li>
          <li>Clean, user-friendly interface that works online without requiring downloads</li>
          <li>Supports both image upload and text file processing</li>
          <li>Provides detailed AI feedback on how well your thumbnail and title work together</li>
        </ul>
        <p className="mb-4"><strong>Cons:</strong></p>
        <ul className="list-disc list-inside mb-4">
          <li>Being the first tool with AI analysis features, it's still developing additional advanced features</li>
          <li>Limited batch processing compared to some competitors</li>
        </ul>
        <p className="mb-4"><strong>Best for:</strong> Creators who want cutting-edge AI analysis to ensure their YouTube videos achieve optimal thumbnail-title alignment. Since Klutz pioneered AI analysis features in this space, it's ideal for users seeking the most advanced consistency checking available.</p>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">2. VideoTok YouTube Title Length Checker</h3>
        <p className="mb-4"><strong>Price:</strong> Free (with premium options available)</p>
        <p className="mb-4"><strong>Pros:</strong></p>
        <ul className="list-disc list-inside mb-4">
          <li>Instant title character length count with real-time feedback</li>
          <li>YouTube thumbnail preview that shows how titles appear alongside real content</li>
          <li>Optimization suggestions for click-through improvement</li>
          <li>Integration with VideoTok's broader AI video creation platform</li>
          <li>Custom thumbnail upload capability for complete video presentation testing</li>
        </ul>
        <p className="mb-4"><strong>Cons:</strong></p>
        <ul className="list-disc list-inside mb-4">
          <li>Lacks the advanced AI analysis features that Klutz pioneered</li>
          <li>More focused on length optimization than comprehensive consistency checking</li>
          <li>Some advanced features require VideoTok platform access</li>
        </ul>
        <p className="mb-4"><strong>Best for:</strong> Creators who need reliable title length checking with basic preview functionality, especially those already using VideoTok for faceless YouTube video creation.</p>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">3. TubeBuddy Title Analyzer</h3>
        <p className="mb-4"><strong>Price:</strong> Free tier available, premium features from $4.50/month</p>
        <p className="mb-4"><strong>Pros:</strong></p>
        <ul className="list-disc list-inside mb-4">
          <li>Comprehensive YouTube optimization suite</li>
          <li>Title length preview with search results simulation</li>
          <li>Trending video comparison features</li>
          <li>Browser extension for seamless integration</li>
        </ul>
        <p className="mb-4"><strong>Cons:</strong></p>
        <ul className="list-disc list-inside mb-4">
          <li>No AI analysis features like those pioneered by Klutz</li>
          <li>Free version has limited functionality</li>
          <li>Focuses more on SEO than visual-textual consistency</li>
        </ul>
        <p className="mb-4"><strong>Best for:</strong> Established YouTubers who need comprehensive channel optimization tools alongside basic title checking.</p>

        <h3 className="font-headline text-xl text-primary mt-6 mb-3">4. VidIQ Title Generator and Checker</h3>
        <p className="mb-4"><strong>Price:</strong> Free version available, pro plans from $7.50/month</p>
        <p className="mb-4"><strong>Pros:</strong></p>
        <ul className="list-disc list-inside mb-4">
          <li>Real-time character count and length optimization</li>
          <li>Search volume data integration</li>
          <li>Competition analysis features</li>
          <li>YouTube search results preview</li>
        </ul>
        <p className="mb-4"><strong>Cons:</strong></p>
        <ul className="list-disc list-inside mb-4">
          <li>Lacks the AI consistency analysis that makes Klutz unique</li>
          <li>More complex interface may overwhelm new creators</li>
          <li>Premium features required for advanced functionality</li>
        </ul>
        <p className="mb-4"><strong>Best for:</strong> Data-driven creators who want to combine title optimization with detailed analytics and search insights.</p>

        <h2 className="font-headline text-2xl text-primary mt-8 mb-4">Why AI Analysis Features Matter</h2>
        <p className="mb-4">Traditional YouTube title checkers focus solely on character length and basic preview functionality. However, the most effective YouTube videos require perfect alignment between visual and textual elements. This is where Klutz's pioneering AI analysis features become crucial - they evaluate not just whether your title fits the 55-character limit, but whether your thumbnail and title work together to create compelling content that replicates viral video success.</p>
        <p className="mb-4">When you create YouTube videos, every element must work in harmony. Your thumbnail might be visually striking, but if it doesn't align with your title's message, viewers may feel misled, leading to poor engagement. AI analysis helps ensure your video's presentation maintains consistency across all elements.</p>

        <h2 className="font-headline text-2xl text-primary mt-8 mb-4">Maximizing Your YouTube Title Strategy</h2>
        <p className="mb-4">To optimize your YouTube videos for maximum visibility and click-through rates:</p>
        <ol className="list-disc list-inside mb-4">
          <li><strong>Use AI-powered consistency checking:</strong> Tools like Klutz that offer AI analysis features provide the most comprehensive evaluation of your content alignment.</li>
          <li><strong>Test multiple variations:</strong> Upload different thumbnail options and test various title lengths to see what works best for your content type.</li>
          <li><strong>Monitor character count:</strong> Ensure your YouTube title length stays within the optimal 55-character limit to prevent getting cut off in search results.</li>
          <li><strong>Preview in context:</strong> Use tools that show how your title appears alongside real YouTube videos to gauge competitive effectiveness.</li>
          <li><strong>Consider your audience:</strong> Choose language, voice, and topic elements that resonate with your target viewers while maintaining consistency between visual and textual elements.</li>
        </ol>

        <h2 className="font-headline text-2xl text-primary mt-8 mb-4">TLDR</h2>
        <p className="mb-4">AI thumbnail title consistency checkers are essential tools for YouTube success, with Klutz leading the industry as the first tool with AI analysis features that examine both visual and textual alignment. While traditional checkers like VideoTok, TubeBuddy, and VidIQ focus primarily on title length and basic optimization, Klutz's pioneering AI technology provides comprehensive consistency evaluation that helps creators ensure their YouTube videos achieve maximum click-through rates and visibility.</p>
        <p className="mb-4">Key takeaways:</p>
        <ul className="list-disc list-inside mb-4">
          <li>Klutz offers the most advanced AI analysis features in the market, being the first to pioneer this technology</li>
          <li>Free options are available across all major platforms, with varying levels of functionality</li>
          <li>The optimal YouTube title length remains 55 characters to avoid getting cut off in search results</li>
          <li>AI-powered consistency checking provides superior results compared to basic length checkers</li>
          <li>Successful YouTube videos require perfect alignment between thumbnails and titles, something only advanced AI analysis can properly evaluate</li>
        </ul>
        <p className="mb-4">Whether you're creating faceless YouTube content, automating video creation, or crafting individual pieces, using an AI thumbnail title consistency checker - especially one with the advanced analysis features that Klutz pioneered - is crucial for ensuring your content grabs attention and achieves viral potential in YouTube's competitive landscape.</p>
      </div>
    </div>
  );
    </>
)}    


================================================
FILE: src/app/vehicle-troubleshooter/page.tsx
================================================
'use client';

import Head from 'next/head';
import { useState, useEffect } from 'react';
import { useToast } from "@/hooks/use-toast";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from "@/components/ui/card";
import { Textarea } from "@/components/ui/textarea";
import { Input } from "@/components/ui/input";
import { Label } from "@/components/ui/label";
import { Alert, AlertDescription, AlertTitle } from "@/components/ui/alert";
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from "@/components/ui/select";
import { Loader2, ImageUp, Car, AlertTriangle, Info, CheckCircle, XCircle, FileText, Download, AlertOctagon } from 'lucide-react';
import { preprocessImage } from '@/lib/image-utils';
import { downloadTextFile } from '@/lib/utils';
import ImagePreview from '@/components/medi-scan/image-preview';
import type { VehicleTroubleshootingReport } from '@/types/vehicle-troubleshooter';

const cleanJsonString = (rawString: string): string => {
  let cleanedString = rawString.trim();
  if (cleanedString.startsWith("```json") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(7, cleanedString.length - 3).trim();
  } else if (cleanedString.startsWith("```") && cleanedString.endsWith("```")) {
    cleanedString = cleanedString.substring(3, cleanedString.length - 3).trim();
  }
  return cleanedString;
};

export default function VehicleTroubleshooterPage() {
  const [imageFile, setImageFile] = useState<File | null>(null);
  const [imageDataUrl, setImageDataUrl] = useState<string | null>(null);
  const [vehicleType, setVehicleType] = useState<string>('');
  const [vehicleInfo, setVehicleInfo] = useState<string>('');
  const [issueDescription, setIssueDescription] = useState<string>('');
  const [additionalDetails, setAdditionalDetails] = useState<string>('');
  
  const [analysisReport, setAnalysisReport] = useState<VehicleTroubleshootingReport | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const { toast } = useToast();

  useEffect(() => {
    if (typeof window.puter === 'undefined') {
      toast({
        variant: "destructive",
        title: "Puter SDK Error",
        description: "Puter.js SDK is not loaded. Please refresh the page.",
      });
    }
  }, [toast]);

  const handleImageFileChange = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      setImageFile(file);
      try {
        const previewDataUrl = URL.createObjectURL(file);
        setImageDataUrl(previewDataUrl);
        setAnalysisReport(null);
        setError(null);
      } catch (error) {
        toast({ variant: "destructive", title: "Preview Error", description: "Could not generate image preview." });
        setImageDataUrl(null);
      }
    } else {
      setImageFile(null);
      setImageDataUrl(null);
    }
  };

  const performAnalysis = async () => {
    if (!imageFile) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please upload an image of the vehicle issue." });
      return;
    }
    if (!issueDescription.trim()) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please describe the issue you're experiencing." });
      return;
    }
    if (!vehicleType) {
      toast({ variant: "destructive", title: "Missing Input", description: "Please select the type of vehicle." });
      return;
    }

    setIsLoading(true);
    setAnalysisReport(null);
    setError(null);
    toast({ title: "Analysis Started", description: "AI is analyzing your vehicle issue..." });

    try {
      if (typeof window.puter === 'undefined' || !window.puter.auth || !window.puter.ai) {
        throw new Error("Puter SDK not available. Please refresh.");
      }
      const puter = window.puter;

      let isSignedIn = await puter.auth.isSignedIn();
      if (!isSignedIn) {
        await puter.auth.signIn();
        isSignedIn = await puter.auth.isSignedIn();
        if (!isSignedIn) throw new Error("Authentication failed or was cancelled.");
      }

      const preprocessedDataUrl = await preprocessImage(imageFile, 1024);

      const imagePrompt = `
        You are an AI assistant specialized in diagnosing vehicle issues.
        Analyze this image of a ${vehicleType} with the following reported issue: "${issueDescription}"
        Vehicle information: "${vehicleInfo || 'Not provided'}"
        Additional context: "${additionalDetails || 'None provided'}"

        Provide a comprehensive analysis including:
        1. Visual inspection of the vehicle part/component
        2. Identification of visible issues or damage
        3. Potential causes based on the symptoms
        4. Recommended troubleshooting and repair steps
        5. Safety considerations
        6. Maintenance recommendations

        Return the analysis in a JSON object with these keys:
        - "image_description": (string) Detailed description of what you see in the image
        - "vehicle_type": (string) Confirmed vehicle type based on the image
        - "identified_issues": (array of strings) List of visible problems or symptoms
        - "possible_causes": (array of strings) Potential causes of the malfunction
        - "recommended_solutions": (array of strings) Step-by-step troubleshooting or repair suggestions
        - "safety_warnings": (array of strings) Any safety concerns or precautions
        - "maintenance_tips": (array of strings) Preventive maintenance recommendations
        - "estimated_severity": (string, one of "Minor", "Moderate", "Severe", "Critical") Assessment of issue severity
        - "confidence": (string, one of "High", "Medium", "Low", "Not Applicable") Your confidence in this assessment
        - "disclaimer": (string) Standard disclaimer about AI limitations and professional mechanic consultation
      `;

      const response = await puter.ai.chat(imagePrompt, preprocessedDataUrl);
      
      if (!response?.message?.content) {
        throw new Error("AI analysis did not return content.");
      }

      const parsedResponse: VehicleTroubleshootingReport = JSON.parse(cleanJsonString(response.message.content));
      setAnalysisReport(parsedResponse);
      toast({ title: "Analysis Complete", variant: "default", className: "bg-green-500 text-white dark:bg-green-600" });

    } catch (err: any) {
      console.error("Analysis error:", err);
      let errorMessage = "An error occurred during analysis.";
      if (err instanceof Error) errorMessage = err.message;
      else if (typeof err === 'string') errorMessage = err;
      else if (err.error && err.error.message) errorMessage = err.error.message;
      setError(errorMessage);
      toast({ variant: "destructive", title: "Analysis Failed", description: errorMessage });
    } finally {
      setIsLoading(false);
    }
  };

  const handleDownloadReport = () => {
    if (!analysisReport) return;

    let reportString = "KLUTZ Vehicle Troubleshooting Report\n";
    reportString += "===================================\n\n";

    reportString += "Vehicle Information:\n";
    reportString += "-------------------\n";
    reportString += `Vehicle Type: ${analysisReport.vehicle_type}\n`;
    if (vehicleInfo) {
      reportString += `Additional Vehicle Info: ${vehicleInfo}\n`;
    }
    reportString += `Reported Issue: ${issueDescription}\n\n`;

    if (additionalDetails) {
      reportString += "Additional Details Provided:\n";
      reportString += `${additionalDetails}\n\n`;
    }

    reportString += "Image Analysis:\n";
    reportString += "--------------\n";
    reportString += `${analysisReport.image_description}\n\n`;

    reportString += "Issue Severity: " + analysisReport.estimated_severity + "\n\n";

    reportString += "Identified Issues:\n";
    reportString += "-----------------\n";
    analysisReport.identified_issues.forEach(issue => {
      reportString += `- ${issue}\n`;
    });
    reportString += "\n";

    reportString += "Possible Causes:\n";
    reportString += "---------------\n";
    analysisReport.possible_causes.forEach(cause => {
      reportString += `- ${cause}\n`;
    });
    reportString += "\n";

    reportString += "Recommended Solutions:\n";
    reportString += "--------------------\n";
    analysisReport.recommended_solutions.forEach((solution, index) => {
      reportString += `${index + 1}. ${solution}\n`;
    });
    reportString += "\n";

    if (analysisReport.maintenance_tips && analysisReport.maintenance_tips.length > 0) {
      reportString += "Maintenance Tips:\n";
      reportString += "----------------\n";
      analysisReport.maintenance_tips.forEach(tip => {
        reportString += `- ${tip}\n`;
      });
      reportString += "\n";
    }

    if (analysisReport.safety_warnings && analysisReport.safety_warnings.length > 0) {
      reportString += "‚ö†Ô∏è Safety Warnings:\n";
      reportString += "----------------\n";
      analysisReport.safety_warnings.forEach(warning => {
        reportString += `! ${warning}\n`;
      });
      reportString += "\n";
    }

    reportString += "AI Confidence Level: " + analysisReport.confidence + "\n\n";
    reportString += "Disclaimer:\n";
    reportString += "-----------\n";
    reportString += analysisReport.disclaimer + "\n\n";
    
    reportString += "\nIMPORTANT: This report is AI-generated and for informational purposes only. Always consult with a qualified mechanic for serious vehicle issues or safety concerns.";

    const timestamp = new Date().toISOString().replace(/[:.-]/g, '').slice(0, 14);
    downloadTextFile(reportString, `KLUTZ_VehicleTroubleshooter_Report_${timestamp}.txt`);
  };

  const getSeverityColor = (severity: string) => {
    switch (severity.toLowerCase()) {
      case 'minor':
        return 'text-yellow-600 dark:text-yellow-400';
      case 'moderate':
        return 'text-orange-600 dark:text-orange-400';
      case 'severe':
        return 'text-red-600 dark:text-red-400';
      case 'critical':
        return 'text-red-700 dark:text-red-300 font-bold';
      default:
        return 'text-foreground';
    }
  };

  return (
    <>
      <Head>
        <link rel="canonical" href="https://klutz.netlify.app/vehicle-troubleshooter" />
      </Head>
    <div className="container mx-auto px-4 sm:px-6 lg:px-8 py-8">
      <Card className="max-w-3xl mx-auto shadow-xl">
        <CardHeader>
          <CardTitle className="font-headline text-3xl text-primary flex items-center">
            <Car className="mr-3 h-8 w-8" />
            Vehicle Troubleshooter
          </CardTitle>
          <CardDescription>
            Upload an image of the vehicle issue and describe the problem for AI-powered diagnostic assistance.
          </CardDescription>
        </CardHeader>
        <CardContent className="space-y-6">
          <Alert variant="default" className="bg-yellow-50 border-yellow-400 text-yellow-700 dark:bg-yellow-900/30 dark:text-yellow-300">
            <AlertTriangle className="h-5 w-5 text-yellow-500" />
            <AlertTitle className="font-semibold">Safety Warning</AlertTitle>
            <AlertDescription>
              For serious mechanical issues or safety concerns, always consult with a qualified mechanic. 
              This tool provides general guidance only and should not replace professional inspection.
            </AlertDescription>
          </Alert>

          <div>
            <Label htmlFor="image-upload" className="text-lg font-medium flex items-center mb-2">
              <ImageUp className="mr-2 h-5 w-5 text-accent" />
              Vehicle Image
            </Label>
            <Input
              id="image-upload"
              type="file"
              accept="image/png, image/jpeg, image/webp"
              onChange={handleImageFileChange}
              className="file:text-primary file:font-semibold file:bg-primary/10 hover:file:bg-primary/20"
              disabled={isLoading}
            />
            <p className="text-sm text-muted-foreground mt-1">Upload a clear image of the vehicle issue or malfunctioning part.</p>
          </div>

          {imageDataUrl && <ImagePreview imageDataUrl={imageDataUrl} dataAiHint="vehicle issue"/>}

          <div className="space-y-4">
            <div>
              <Label htmlFor="vehicle-type" className="text-lg font-medium">Vehicle Type</Label>
              <Select value={vehicleType} onValueChange={setVehicleType}>
                <SelectTrigger id="vehicle-type" className="w-full">
                  <SelectValue placeholder="Select vehicle type" />
                </SelectTrigger>
                <SelectContent>
                  <SelectItem value="car">Car</SelectItem>
                  <SelectItem value="motorcycle">Motorcycle</SelectItem>
                  <SelectItem value="bicycle">Bicycle</SelectItem>
                  <SelectItem value="truck">Truck</SelectItem>
                  <SelectItem value="auto-rickshaw">Auto Rickshaw</SelectItem>
                  <SelectItem value="engine">Engine Component</SelectItem>
                  <SelectItem value="other">Other Vehicle/Part</SelectItem>
                </SelectContent>
              </Select>
            </div>

            <div>
              <Label htmlFor="vehicle-info" className="text-lg font-medium">Vehicle Information (Optional)</Label>
              <Input
                id="vehicle-info"
                placeholder="e.g., Make, Model, Year"
                value={vehicleInfo}
                onChange={(e) => setVehicleInfo(e.target.value)}
              />
            </div>

            <div>
              <Label htmlFor="issue-description" className="text-lg font-medium">Issue Description</Label>
              <Textarea
                id="issue-description"
                placeholder="Describe the problem you're experiencing with the vehicle..."
                value={issueDescription}
                onChange={(e) => setIssueDescription(e.target.value)}
                className="min-h-[100px]"
              />
            </div>

            <div>
              <Label htmlFor="additional-details" className="text-lg font-medium">Additional Details (Optional)</Label>
              <Textarea
                id="additional-details"
                placeholder="Any additional context about the issue (e.g., when it started, what you've tried)..."
                value={additionalDetails}
                onChange={(e) => setAdditionalDetails(e.target.value)}
              />
            </div>
          </div>

          <Button 
            onClick={performAnalysis} 
            disabled={isLoading || !imageFile || !vehicleType || !issueDescription.trim()} 
            className="w-full"
          >
            {isLoading ? (
              <>
                <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                Analyzing Issue...
              </>
            ) : (
              'Analyze Vehicle Issue'
            )}
          </Button>

          {error && !isLoading && (
            <Alert variant="destructive" className="mt-6">
              <AlertTriangle className="h-5 w-5" />
              <AlertTitle>Analysis Error</AlertTitle>
              <AlertDescription>{error}</AlertDescription>
            </Alert>
          )}

          {analysisReport && !isLoading && !error && (
            <Card className="mt-6 shadow-md">
              <CardHeader>
                <CardTitle className="font-headline text-xl flex items-center">
                  <FileText className="mr-2 h-6 w-6 text-primary" />
                  Vehicle Diagnostic Report
                </CardTitle>
              </CardHeader>
              <CardContent className="space-y-4 text-sm">
                <div className="flex items-center justify-between">
                  <h4 className="font-semibold text-md">Issue Severity:</h4>
                  <span className={`font-bold ${getSeverityColor(analysisReport.estimated_severity)}`}>
                    {analysisReport.estimated_severity === 'Critical' && <AlertOctagon className="inline mr-1 h-4 w-4" />}
                    {analysisReport.estimated_severity}
                  </span>
                </div>

                <div>
                  <h4 className="font-semibold text-md mb-1">Visual Assessment:</h4>
                  <p className="bg-muted/30 p-3 rounded-md">{analysisReport.image_description}</p>
                </div>

                <div>
                  <h4 className="font-semibold text-md mb-1">Identified Issues:</h4>
                  <ul className="list-disc pl-5 space-y-1 bg-red-50 dark:bg-red-900/20 p-3 rounded-md">
                    {analysisReport.identified_issues.map((issue, index) => (
                      <li key={index} className="text-red-700 dark:text-red-300">{issue}</li>
                    ))}
                  </ul>
                </div>

                <div>
                  <h4 className="font-semibold text-md mb-1">Possible Causes:</h4>
                  <ul className="list-disc pl-5 space-y-1 bg-orange-50 dark:bg-orange-900/20 p-3 rounded-md">
                    {analysisReport.possible_causes.map((cause, index) => (
                      <li key={index} className="text-orange-700 dark:text-orange-300">{cause}</li>
                    ))}
                  </ul>
                </div>

                <div>
                  <h4 className="font-semibold text-md mb-1">Recommended Solutions:</h4>
                  <ul className="list-decimal pl-5 space-y-2 bg-green-50 dark:bg-green-900/20 p-3 rounded-md">
                    {analysisReport.recommended_solutions.map((solution, index) => (
                      <li key={index} className="text-green-700 dark:text-green-300">{solution}</li>
                    ))}
                  </ul>
                </div>

                {analysisReport.maintenance_tips && analysisReport.maintenance_tips.length > 0 && (
                  <div>
                    <h4 className="font-semibold text-md mb-1">Maintenance Tips:</h4>
                    <ul className="list-disc pl-5 space-y-1 bg-blue-50 dark:bg-blue-900/20 p-3 rounded-md">
                      {analysisReport.maintenance_tips.map((tip, index) => (
                        <li key={index} className="text-blue-700 dark:text-blue-300">{tip}</li>
                      ))}
                    </ul>
                  </div>
                )}

                {analysisReport.safety_warnings && analysisReport.safety_warnings.length > 0 && (
                  <div>
                    <h4 className="font-semibold text-md mb-1 text-red-600 dark:text-red-400">‚ö†Ô∏è Safety Warnings:</h4>
                    <ul className="list-disc pl-5 space-y-1 bg-red-50 dark:bg-red-900/20 p-3 rounded-md border-2 border-red-200 dark:border-red-800">
                      {analysisReport.safety_warnings.map((warning, index) => (
                        <li key={index} className="text-red-700 dark:text-red-300">{warning}</li>
                      ))}
                    </ul>
                  </div>
                )}

                <div>
                  <h4 className="font-semibold text-md mb-1">AI Confidence:</h4>
                  <p className="bg-muted/30 p-3 rounded-md">{analysisReport.confidence}</p>
                </div>

                <Alert variant="default" className="text-xs bg-blue-50 border-blue-300 dark:bg-blue-900/30 dark:text-blue-300">
                  <Info className="h-4 w-4 text-blue-500" />
                  <AlertTitle className="font-medium">Disclaimer</AlertTitle>
                  <AlertDescription>{analysisReport.disclaimer}</AlertDescription>
                </Alert>

                <Button onClick={handleDownloadReport} variant="outline" className="w-full mt-4">
                  <Download className="mr-2 h-4 w-4" />
                  Download Report
                </Button>
              </CardContent>
            </Card>
          )}

          {!analysisReport && !isLoading && !error && (
            <div className="mt-6 p-4 border border-dashed rounded-md text-center text-muted-foreground">
              <Info className="mx-auto h-8 w-8 mb-2"/>
              <p>Upload a vehicle image, select the vehicle type, and describe the issue to get AI-powered diagnostic assistance.</p>
            </div>
          )}
        </CardContent>
        <CardFooter>
          <p className="text-xs text-muted-foreground w-full text-center">
            This tool uses AI for general guidance only. For serious mechanical issues, always consult a qualified mechanic.
          </p>
        </CardFooter>
      </Card>

      <div className="mt-12 max-w-3xl mx-auto prose prose-lg dark:prose-invert">
        <h1>The Ultimate Guide to AI Vehicle Troubleshooters: Revolutionizing Auto Repair Diagnostics</h1>

        <p>Modern automotive technology has transformed how we approach vehicle maintenance and repair. AI vehicle troubleshooters represent a groundbreaking advancement in auto mechanic troubleshooting, offering drivers and mechanics powerful tools to diagnose vehicle issues efficiently. These intelligent systems utilize advanced algorithms to analyze symptoms and deliver accurate, personalized troubleshooting guides that can save both time and cost while enhancing customer satisfaction.</p>

        <h2>What is an AI Vehicle Troubleshooter?</h2>

        <p>An AI vehicle troubleshooter is a sophisticated tool that leverages artificial intelligence to diagnose automotive problems based on user input symptoms. These systems work by analyzing comprehensive databases of automotive knowledge, including common issues and solutions, to create structured troubleshooting guides tailored to specific vehicle problems. The AI processing capabilities allow these tools to quickly identify potential causes and provide relevant, up-to-date recommendations for repair.</p>

        <p>Unlike traditional diagnostic methods, AI auto mechanic systems can process vast amounts of information instantly, enabling mechanics and vehicle owners to receive accurate fast troubleshooting support. These tools represent the future of automotive repair, preparing future mechanics with relevant up-to-date knowledge while helping current professionals improve their diagnostic efficiency.</p>

        <h2>Key Features to Check When Searching for the Best AI Vehicle Troubleshooter</h2>

        <p><strong>Powerful Performance and Accuracy:</strong> The best AI auto troubleshooting tools utilize advanced algorithms to achieve high accuracy in processing vehicle symptoms. Look for systems that can quickly diagnose issues and provide reliable solutions.</p>

        <p><strong>Easy Integration:</strong> Effective tools should offer seamless setup with existing systems, minimizing disruption to daily operations. Auto repair shops need solutions that integrate efficiently without requiring extensive tech skills.</p>

        <p><strong>Comprehensive Database:</strong> Superior AI troubleshooting guide generators should access extensive automotive knowledge, including manufacturer-specific information and real-world scenarios to deliver personalized troubleshooting guides.</p>

        <p><strong>User-Friendly Interface:</strong> The tool should be accessible to users with varying technical backgrounds, from professional mechanics to vehicle owners seeking guidance.</p>

        <p><strong>Cost Effectiveness:</strong> Consider tools that provide significant value through improved efficiency, reducing diagnostic time and enhancing service quality while offering reasonable pricing.</p>

        <h2>Best FREE AI Vehicle Troubleshooters</h2>

        <h3>1. Klutz's AI Vehicle Troubleshooter - The Pioneer in AI Analysis</h3>

        <p><strong>Pricing:</strong> Completely free</p>

        <p><strong>Pros:</strong></p>

        <ul>
          <li>First-to-market AI analysis capabilities</li>
          <li>Image upload functionality for visual diagnostics</li>
          <li>No registration required</li>
          <li>Covers multiple vehicle types</li>
          <li>Instant results with detailed explanations</li>
          <li>User-friendly interface requiring no tech skills</li>
        </ul>

        <p><strong>Cons:</strong></p>

        <ul>
          <li>Limited to general guidance</li>
          <li>Recommends professional consultation for serious issues</li>
        </ul>

        <p>Klutz's system utilizes cutting-edge AI processing to analyze both visual and textual input symptoms, making it particularly effective for mechanics and vehicle owners who need quick, accurate diagnostics. The tool's ability to process images represents a significant advancement in AI auto mechanic troubleshooting.</p>

        <h3>2. LogicBalls Auto Mechanic Troubleshooting Guide Generator</h3>

        <p>LogicBalls offers a comprehensive AI auto mechanic troubleshooting guide generator that creates high-quality, well-structured troubleshooting guides for auto mechanics.</p>

        <p><strong>Pricing:</strong> Free basic version, premium features at $4.99/month</p>

        <p><strong>Pros:</strong></p>

        <ul>
          <li>Multiple tone options for different audiences</li>
          <li>Structured guide generation</li>
          <li>Automotive trainer-friendly content</li>
          <li>Suitable for training purposes</li>
        </ul>

        <p><strong>Cons:</strong></p>

        <ul>
          <li>Premium features require subscription</li>
          <li>Less visual diagnostic capability compared to Klutz's AI analysis features</li>
          <li>Limited real-time processing</li>
        </ul>

        <h3>3. VehicleScore AI Mechanic</h3>

        <p>VehicleScore provides an AI mechanic service that allows users to ask questions about specific engine codes and general symptoms.</p>

        <p><strong>Pricing:</strong> Free</p>

        <p><strong>Pros:</strong></p>

        <ul>
          <li>Specialized in engine code diagnostics</li>
          <li>Integration with vehicle history services</li>
          <li>Make and model-specific guidance</li>
          <li>Terms and conditions clearly outlined</li>
        </ul>

        <p><strong>Cons:</strong></p>

        <ul>
          <li>Requires user agreement acknowledgment</li>
          <li>Limited to text-based input</li>
          <li>No image analysis capabilities like Klutz's pioneering AI analysis features</li>
        </ul>

        <h3>4. OBDAI - OBD2 Scanner Enhancement</h3>

        <p>OBDAI transforms existing OBD2 scanners into intelligent diagnostic tools through AI enhancement.</p>

        <p><strong>Pricing:</strong> Free basic features, premium AI diagnostics available</p>

        <p><strong>Pros:</strong></p>

        <ul>
          <li>Works with existing OBD2 hardware</li>
          <li>Real-time vehicle monitoring</li>
          <li>Predictive analysis capabilities</li>
          <li>Comprehensive parameter monitoring</li>
        </ul>

        <p><strong>Cons:</strong></p>

        <ul>
          <li>Requires additional hardware</li>
          <li>Premium features need subscription</li>
          <li>More complex setup compared to web-based solutions</li>
        </ul>

        <h3>5. Car Mechanic GPT</h3>

        <p>Available through YesChat.ai, Car Mechanic GPT provides AI-powered automotive diagnostic assistance.</p>

        <p><strong>Pricing:</strong> Free access</p>

        <p><strong>Pros:</strong></p>

        <ul>
          <li>Natural language processing</li>
          <li>Detailed explanations</li>
          <li>Safety-focused recommendations</li>
          <li>Educational content for automotive learning</li>
        </ul>

        <p><strong>Cons:</strong></p>

        <ul>
          <li>Text-only interface</li>
          <li>No visual diagnostic features</li>
          <li>Generic responses compared to specialized tools</li>
        </ul>

        <h2>The Advantage of Klutz's AI Analysis Features</h2>

        <p>While multiple AI vehicle troubleshooters exist, Klutz's platform remains unique as <strong>the first tool with AI analysis features</strong> that can process both images and text descriptions. This dual-input capability allows for more accurate diagnostics, as visual information often reveals details that text descriptions might miss. The tool's AI processing can identify visual symptoms that enhance the overall troubleshooting experience.</p>

        <p>Auto repair shops utilizing Klutz's AI analysis features can quickly diagnose vehicle issues, resulting in faster repairs and enhanced customer satisfaction. The system's ability to process visual data represents a significant advancement in mechanic troubleshooting guide generation.</p>

        <h2>Benefits for Different User Groups</h2>

        <p><strong>Professional Mechanics:</strong> These tools help mechanics receive accurate fast troubleshooting support, increase productivity by reducing diagnosis time, and enhance customer satisfaction through quicker service. The AI processing capabilities allow professionals to validate results and implement recommended solutions efficiently.</p>

        <p><strong>Auto Repair Shops:</strong> Businesses can streamline operations and reduce labor costs while improving service quality through structured guides. The enhanced service capabilities help attract customers and improve profit margins through efficient operations.</p>

        <p><strong>Automotive Trainers:</strong> These systems provide real-world scenarios for training purposes, allowing trainers to utilize practical hands-on experience to engage trainees and prepare future mechanics with relevant up-to-date knowledge.</p>

        <p><strong>Vehicle Owners:</strong> Drivers can perform basic troubleshooting before visiting repair shops, potentially saving time and cost while gaining better understanding of their vehicle issues.</p>

        <h2>TLDR</h2>

        <p>AI vehicle troubleshooters are revolutionizing automotive diagnostics by providing instant, accurate troubleshooting support. Klutz's AI vehicle troubleshooter leads the field as <strong>the first tool with AI analysis features</strong>, offering free image and text-based diagnostics. Other notable free options include LogicBalls (with premium features), VehicleScore AI Mechanic, OBDAI (hardware-dependent), and Car Mechanic GPT. These tools deliver significant benefits including reduced diagnostic time, enhanced customer satisfaction, and improved service quality for mechanics, auto repair shops, and vehicle owners alike. The future of automotive troubleshooting lies in these AI-powered solutions that combine advanced algorithms with user-friendly interfaces to create cost-effective, efficient diagnostic experiences.</p>
     </div>
   </div> 
 );
   </>
)}   


================================================
FILE: src/components/AutoScrollMarquee.tsx
================================================
'use client';

import React, { useEffect, useRef } from 'react';

interface AutoScrollMarqueeProps {
  content: React.ReactNode[];
}

const AutoScrollMarquee: React.FC<AutoScrollMarqueeProps> = ({ content }) => {
  const marqueeRef = useRef<HTMLDivElement>(null);

  useEffect(() => {
    const marquee = marqueeRef.current;
    if (!marquee) return;

    let animationFrameId: number;
    const scrollSpeed = 0.5; // Adjust speed as needed

    const scrollMarquee = () => {
      if (!marquee) return;

      marquee.scrollLeft += scrollSpeed;

      // Reset scroll position when it reaches the end
      if (marquee.scrollLeft >= marquee.scrollWidth / 2) {
        marquee.scrollLeft = 0;
      }

      animationFrameId = requestAnimationFrame(scrollMarquee);
    };

    // Duplicate the content to create a seamless loop
    const contentContainer = marquee.querySelector('div');
    if (contentContainer) {
      contentContainer.innerHTML += contentContainer.innerHTML;
    }

    scrollMarquee();

    return () => {
      cancelAnimationFrame(animationFrameId);
    };
  }, [content]);

  return (
    <div className="relative w-full overflow-hidden py-8">
      <div
        ref={marqueeRef}
        className="flex whitespace-nowrap"
        style={{
          overflowX: 'hidden',
          maskImage: 'linear-gradient(to right, transparent, white 10%, white 90%, transparent)',
          WebkitMaskImage: 'linear-gradient(to right, transparent, white 10%, white 90%, transparent)', // For Safari
        }}
      >
        <div className="flex space-x-12">
          {content.map((item, index) => (
            <div key={index} className="flex-shrink-0">
              {item}
            </div>
          ))}
        </div>
      </div>
    </div>
  );
};

export default AutoScrollMarquee;


================================================
FILE: src/components/HorizontalCarousel.tsx
================================================
'use client';

import React, { useState, useEffect, useRef } from 'react';
import Image from 'next/image';
import { ChevronLeft, ChevronRight } from 'lucide-react';

interface CarouselItem {
  title: string;
  description?: string; // Make description optional
  imageUrl: string;
}

interface HorizontalCarouselProps {
  title: string;
  content: CarouselItem[];
}

const HorizontalCarousel: React.FC<HorizontalCarouselProps> = ({ title, content }) => {
  const [currentIndex, setCurrentIndex] = useState(0);
  const [progress, setProgress] = useState(0);
  const intervalRef = useRef<NodeJS.Timeout | null>(null);
  const progressIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const carouselRef = useRef<HTMLDivElement>(null);

  const cycleDuration = 3000; // 3 seconds

  const startCycling = () => {
    intervalRef.current = setInterval(() => {
      setCurrentIndex((prevIndex) => (prevIndex + 1) % content.length);
    }, cycleDuration);
  };

  const startProgress = () => {
    setProgress(0);
    progressIntervalRef.current = setInterval(() => {
      setProgress((prevProgress) => {
        if (prevProgress >= 100) {
          return 0;
        }
        return prevProgress + (100 / (cycleDuration / 50)); // Update every 50ms
      });
    }, 50);
  };

  const resetAutoCycle = () => {
    if (intervalRef.current) {
      clearInterval(intervalRef.current);
    }
    if (progressIntervalRef.current) {
      clearInterval(progressIntervalRef.current);
    }
    startCycling();
    startProgress();
  };

  useEffect(() => {
    startCycling();
    startProgress();

    return () => {
      if (intervalRef.current) {
        clearInterval(intervalRef.current);
      }
      if (progressIntervalRef.current) {
        clearInterval(progressIntervalRef.current);
      }
    };
  }, [content.length]);

  useEffect(() => {
    resetAutoCycle();
  }, [currentIndex]);

  const handlePrev = () => {
    setCurrentIndex((prevIndex) => (prevIndex - 1 + content.length) % content.length);
  };

  const handleNext = () => {
    setCurrentIndex((prevIndex) => (prevIndex + 1) % content.length);
  };

  // Scroll to the current item when currentIndex changes
  useEffect(() => {
    if (carouselRef.current) {
      const itemWidth = carouselRef.current.children[0]?.clientWidth || 0;
      carouselRef.current.scrollTo({
        left: currentIndex * itemWidth,
        behavior: 'smooth',
      });
    }
  }, [currentIndex]);


  return (
    <section className="mb-16">
      <h2 className="text-3xl font-semibold text-gray-800 mb-6 text-center">{title}</h2>
      <div className="relative flex flex-col items-center">
        <div className="flex justify-center items-center mt-4 space-x-2">
            {/* Navigation Arrows */}
            <button
              className="bg-white rounded-full p-2 shadow-md cursor-pointer"
              onClick={handlePrev}
              aria-label="Previous"
            >
              <ChevronLeft className="h-6 w-6 text-gray-700" />
            </button>

            {/* Progress Indicator */}
            <div className="flex justify-center space-x-2">
              {content.map((_, index) => (
                <div
                  key={index}
                  className={`h-2 rounded-full transition-all duration-300 ${
                    index === currentIndex
                      ? 'w-8 bg-blue-500'
                      : 'w-2 bg-gray-300'
                  }`}
                  style={{
                    width: index === currentIndex ? `${0.5 + (progress / 100) * 1.5}rem` : '0.5rem', // Animate width from 0.5rem to 2rem
                    backgroundColor: index === currentIndex ? 'var(--tw-bg-blue-500)' : 'var(--tw-bg-gray-300)',
                    transformOrigin: 'left',
                    transform: index === currentIndex ? `scaleX(1)` : 'scaleX(1)', // Remove scaleX transform
                  }}
                >
                     {index === currentIndex && (
                      <div className="h-full bg-blue-700 rounded-full" style={{ width: `${progress}%` }}></div>
                    )}
                </div>
              ))}
            </div>

            <button
              className="bg-white rounded-full p-2 shadow-md cursor-pointer"
              onClick={handleNext}
              aria-label="Next"
            >
              <ChevronRight className="h-6 w-6 text-gray-700" />
            </button>
        </div>
        <div
          ref={carouselRef}
          className="flex overflow-x-auto snap-x snap-mandatory scrollbar-hide md:scrollbar-hide w-full"
          style={{
            scrollBehavior: 'smooth',
            msOverflowStyle: 'none',  /* Internet Explorer 10+ */
            scrollbarWidth: 'none',  /* Firefox */
          }}
        >
          {content.map((item, index) => (
            <div key={index} className="flex-none w-full snap-center">
              <div className="flex flex-col items-center p-6 space-y-4">
                <div>
                  <p className="text-xl font-medium text-gray-600">{item.title}</p>
                </div>
                <div>
                  <img src={item.imageUrl} alt={item.title} className="w-full h-auto rounded-md object-cover" />
                </div>
              </div>
            </div>
          ))}
        </div>


      </div>
    </section>
  );
};

export default HorizontalCarousel;


================================================
FILE: src/components/providers.tsx
================================================
"use client"

import * as React from "react"
import { ThemeProvider as NextThemesProvider } from "next-themes"
import { type ThemeProviderProps } from "next-themes/dist/types"

export function ThemeProvider({ children, ...props }: ThemeProviderProps) {
  return <NextThemesProvider {...props}>{children}</NextThemesProvider>
}


================================================
FILE: src/components/theme-toggle.tsx
================================================
'use client'

import * as React from "react"
import { Moon, Sun } from "lucide-react"
import { useTheme } from "next-themes"
import { Button } from "@/components/ui/button"

export function ThemeToggle() {
  const { theme, setTheme } = useTheme()

  return (
    <Button
      variant="ghost"
      size="icon"
      onClick={() => setTheme(theme === "light" ? "dark" : "light")}
    >
      <Sun className="h-[1.2rem] w-[1.2rem] rotate-0 scale-100 transition-all dark:-rotate-90 dark:scale-0" />
      <Moon className="absolute h-[1.2rem] w-[1.2rem] rotate-90 scale-0 transition-all dark:rotate-0 dark:scale-100" />
      <span className="sr-only">Toggle theme</span>
    </Button>
  )
}


================================================
FILE: src/components/audio-forge/AmplitudePlotter.tsx
================================================

'use client';

import React, { useEffect, useState, useMemo, useRef } from 'react';
import { Line, LineChart as RechartsLineChart, XAxis, YAxis, CartesianGrid, ResponsiveContainer } from 'recharts';
import { ChartContainer, ChartTooltip, ChartTooltipContent } from "@/components/ui/chart";
import type { ChartConfig } from "@/components/ui/chart";
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { LineChart as LineChartIcon } from 'lucide-react';

interface FunctionalAmplitudePlotterProps {
  audioBuffer: AudioBuffer | null;
}

const chartConfig = {
  amplitude: { label: "Amplitude", color: "hsl(var(--accent))" },
} satisfies ChartConfig;

const NUM_PLOT_POINTS = 200; // Number of points to plot for the waveform

export function FunctionalAmplitudePlotter({ audioBuffer }: FunctionalAmplitudePlotterProps) {
  const [amplitudeData, setAmplitudeData] = useState<{ time: number; amplitude: number }[]>([]);
  const workerRef = useRef<Worker | null>(null);

  useEffect(() => {
    if (!audioBuffer) {
      setAmplitudeData([]);
      return;
    }
    // Create worker if not exists
    if (!workerRef.current) {
      workerRef.current = new Worker(new URL('@/workers/audioWorker.ts', import.meta.url));
    }
    const worker = workerRef.current;

    // Prepare transferable data
    const channelData = audioBuffer.getChannelData(0);
    // Copy to transferable ArrayBuffer
    const channelCopy = new Float32Array(channelData.length);
    channelCopy.set(channelData);

    worker.onmessage = (e: MessageEvent) => {
      if (e.data.type === "amplitude") {
        setAmplitudeData(e.data.data);
      }
    };

    worker.postMessage({
      type: "amplitude",
      audioBufferData: [channelCopy],
      sampleRate: audioBuffer.sampleRate,
      numPlotPoints: NUM_PLOT_POINTS,
    });

    return () => {
      // Optionally terminate worker if you want to clean up
      // worker.terminate();
    };
  }, [audioBuffer]);

  const yAxisDomain = useMemo(() => {
    if (!amplitudeData || amplitudeData.length === 0) return [-1, 1];
    let min = 0;
    let max = 0;
    amplitudeData.forEach(point => {
        if (point.amplitude < min) min = point.amplitude;
        if (point.amplitude > max) max = point.amplitude;
    });
    min = Math.min(min, -0.1); 
    max = Math.max(max, 0.1);
    const padding = Math.max(0.1, (max - min) * 0.1); 
    return [Math.max(-1, Math.floor((min - padding) * 10) / 10), Math.min(1, Math.ceil((max + padding) * 10) / 10)];
  }, [amplitudeData]);


  return (
    <Card className="shadow-md">
      <CardHeader>
        <CardTitle className="flex items-baseline gap-2">
          <LineChartIcon className="text-primary h-5 w-5" />
          <span className="text-xl">Amplitude Plotter</span>
          <span className="text-sm text-muted-foreground ml-1">(Static)</span>
        </CardTitle>
      </CardHeader>
      <CardContent className="h-[200px]">
        {audioBuffer && audioBuffer.length > 0 && amplitudeData.length > 0 ? (
          <ChartContainer config={chartConfig} className="w-full h-full">
            <RechartsLineChart data={amplitudeData} margin={{ top: 5, right: 20, left: -20, bottom: 5 }}>
              <CartesianGrid horizontal={true} vertical={false} strokeDasharray="3 3" />
              <XAxis 
                dataKey="time" 
                type="number" 
                domain={['dataMin', 'dataMax']} 
                tickLine={false} 
                axisLine={false} 
                tickMargin={8} 
                fontSize={10} 
                tickFormatter={(value) => `${(value / 1000).toFixed(1)}s`} 
              />
              <YAxis 
                tickLine={false} 
                axisLine={false} 
                tickMargin={8} 
                width={30} 
                fontSize={10}
                domain={yAxisDomain}
                allowDataOverflow={false} // Clip data outside domain
              />
              <ChartTooltip 
                cursor={false} 
                content={<ChartTooltipContent 
                            formatter={(value, name, props) => [`${(value as number).toFixed(3)}`, name]} 
                            labelFormatter={(label) => `Time: ${(Number(label) / 1000).toFixed(2)}s`}
                         />} 
              />
              <Line dataKey="amplitude" type="monotone" stroke="var(--color-amplitude)" strokeWidth={1.5} dot={false} />
            </RechartsLineChart>
          </ChartContainer>
        ) : (
          <div className="flex items-center justify-center h-full text-muted-foreground">
            {!audioBuffer ? "Load audio to see amplitude." : 
             (audioBuffer.length === 0 ? "Audio buffer is empty." : "Processing amplitude...")}
          </div>
        )}
      </CardContent>
    </Card>
  );
}


================================================
FILE: src/components/audio-forge/AudioControlsPanel.tsx
================================================

import type React from 'react';
import { FileUploadArea } from './FileUploadArea';
import { EffectCard } from './EffectCard';
import { effectsList, effectGroups } from '@/app/audio-forge/effects';
import type { Effect, EffectSettings } from '@/types/audio-forge';
import { ScrollArea } from '@/components/ui/scroll-area';
import { Accordion, AccordionContent, AccordionItem, AccordionTrigger } from "@/components/ui/accordion";

interface AudioControlsPanelProps {
  onFileSelect: (file: File | null) => void;
  selectedFile: File | null;
  onApplyEffect: (effectId: string, params: EffectSettings) => void;
  onParameterChange: (effectId: string, paramName: string, value: any) => void;
  effectSettings: Record<string, EffectSettings>;
  isLoading: boolean;
  isAudioLoaded: boolean;
  analysisResult: string | null;
  analysisSourceEffectId: string | null;
}

export function AudioControlsPanel({
  onFileSelect,
  selectedFile,
  onApplyEffect,
  onParameterChange,
  effectSettings,
  isLoading,
  isAudioLoaded,
  analysisResult,
  analysisSourceEffectId,
}: AudioControlsPanelProps) {
  
  const getEffectSettings = (effectId: string): EffectSettings => {
    return effectSettings[effectId] || 
           effectsList.find(e => e.id === effectId)?.parameters?.reduce((acc, param) => {
             acc[param.name] = param.defaultValue;
             return acc;
           }, {} as EffectSettings) || 
           {};
  };

  return (
    <div className="h-full flex flex-col">
      <div className="p-4 border-b">
        <FileUploadArea 
            onFileSelect={onFileSelect} 
            selectedFile={selectedFile}
            isLoading={isLoading}
        />
      </div>
      <ScrollArea className="flex-grow p-4">
        <Accordion type="multiple" defaultValue={effectGroups} className="w-full space-y-4">
          {effectGroups.map((groupName) => (
            <AccordionItem value={groupName} key={groupName} className="border bg-card rounded-lg shadow">
              <AccordionTrigger className="px-4 py-3 text-base font-semibold text-primary hover:no-underline">
                <div className="flex items-baseline">
                  <span>{groupName}</span>
                  {groupName === 'Spatial Effects' && (
                    <span className="ml-2 text-xs font-normal text-muted-foreground">(Only Stereo sounds)</span>
                  )}
                </div>
              </AccordionTrigger>
              <AccordionContent className="px-4 pt-0 pb-4">
                <div className="space-y-4">
                {effectsList
                  .filter((effect) => effect.groupName === groupName)
                  .map((effect) => (
                    <EffectCard
                      key={effect.id}
                      effect={effect}
                      onApplyEffect={onApplyEffect}
                      onParameterChange={onParameterChange}
                      currentSettings={getEffectSettings(effect.id)}
                      isLoading={isLoading} 
                      isAudioLoaded={isAudioLoaded}
                      analysisResult={analysisResult}
                      analysisSourceEffectId={analysisSourceEffectId}
                    />
                  ))}
                </div>
              </AccordionContent>
            </AccordionItem>
          ))}
        </Accordion>
      </ScrollArea>
    </div>
  );
}


================================================
FILE: src/components/audio-forge/AudioForgeClientContent.tsx
================================================
'use client';

import React, { useState, useCallback, useEffect, useRef } from 'react';

import ChatbotTips from '@/components/audio-forge/ChatbotTips';

import { MainDisplayPanel } from './MainDisplayPanel';
import { ResizableHandle, ResizablePanel, ResizablePanelGroup } from "@/components/ui/resizable";
import { Sheet, SheetContent, SheetHeader, SheetTitle, SheetDescription } from '@/components/ui/sheet';
import type { EffectSettings } from '@/types/audio-forge';
import { useToast } from '@/hooks/use-toast';
import { audioUtils, fileToDataUrl } from '@/lib/audio-utils';
import { Button } from '@/components/ui/button';
import { effectsList } from '@/types/effects';
import { useIsMobile } from '@/hooks/use-mobile';
import { Skeleton } from '@/components/ui/skeleton';
import { EffectsPanel } from './EffectsPanel';
import { FileUploadArea } from './FileUploadArea';

export default function AudioForgeClientContent() {
  const [originalAudioFile, setOriginalAudioFile] = useState<File | null>(null);
  const [originalAudioDataUrl, setOriginalAudioDataUrl] = useState<string | null>(null);
  const [processedAudioDataUrl, setProcessedAudioDataUrl] = useState<string | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [analysisResult, setAnalysisResult] = useState<string | null>(null);
  const [analysisSourceEffectId, setAnalysisSourceEffectId] = useState<string | null>(null);
  
  const [originalAudioBuffer, setOriginalAudioBuffer] = useState<AudioBuffer | null>(null);
  const [processedAudioBuffer, setProcessedAudioBuffer] = useState<AudioBuffer | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const isMobile = useIsMobile();
  const [isEffectsSheetOpen, setIsEffectsSheetOpen] = useState(false);
  const [hasMounted, setHasMounted] = useState(false);

  useEffect(() => {
    setHasMounted(true);
  }, []);

  const [effectSettings, setEffectSettings] = useState<Record<string, EffectSettings>>(() => {
    const initialSettings: Record<string, EffectSettings> = {};
    effectsList.forEach(effect => {
      initialSettings[effect.id] = {};
      effect.parameters?.forEach(param => {
        initialSettings[effect.id][param.name] = param.defaultValue;
      });
    });
    return initialSettings;
  });

  const { toast } = useToast();

  useEffect(() => {
    if (typeof window !== 'undefined' && !audioContextRef.current) {
      audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)();
    }
  }, []);

  const loadAudioBuffer = useCallback(async (dataUrl: string | null, setBuffer: React.Dispatch<React.SetStateAction<AudioBuffer | null>>) => {
    if (!dataUrl || !audioContextRef.current) {
      setBuffer(null);
      return;
    }
    try {
      const response = await fetch(dataUrl);
      const arrayBuffer = await response.arrayBuffer();
      if (!audioContextRef.current || audioContextRef.current.state === 'closed') {
         console.warn("AudioContext was closed, reinitializing for visualizer.");
         audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)();
      }
      const audioBufferInstance = await audioContextRef.current.decodeAudioData(arrayBuffer);
      setBuffer(audioBufferInstance);
    } catch (error) {
      console.error("Error decoding audio data for visualizer:", error);
      setBuffer(null);
    }
  }, []); 

  useEffect(() => {
    loadAudioBuffer(originalAudioDataUrl, setOriginalAudioBuffer);
  }, [originalAudioDataUrl, loadAudioBuffer]);

  useEffect(() => {
    loadAudioBuffer(processedAudioDataUrl, setProcessedAudioBuffer);
  }, [processedAudioDataUrl, loadAudioBuffer]);


  const handleFileSelect = useCallback(async (file: File | null) => {
    setOriginalAudioFile(file);
    if (file) {
      setIsLoading(true);
      try {
        // Use Blob URL for large files
        const blobUrl = URL.createObjectURL(file);
        setOriginalAudioDataUrl(blobUrl);
        setProcessedAudioDataUrl(blobUrl);
        setAnalysisResult(null);
        setAnalysisSourceEffectId(null);
        toast({ title: "Audio Loaded", description: `${file.name} is ready for forging.` });
      } catch (error) {
        console.error("Error loading file:", error);
        toast({ title: "Error", description: "Could not load audio file.", variant: "destructive" });
        setOriginalAudioDataUrl(null);
        setProcessedAudioDataUrl(null);
      } finally {
        setIsLoading(false);
      }
    } else {
      // Release Blob URLs to free memory
      if (originalAudioDataUrl) URL.revokeObjectURL(originalAudioDataUrl);
      if (processedAudioDataUrl) URL.revokeObjectURL(processedAudioDataUrl);
      setOriginalAudioDataUrl(null);
      setProcessedAudioDataUrl(null);
      setAnalysisResult(null);
      setAnalysisSourceEffectId(null);
      setOriginalAudioBuffer(null);
      setProcessedAudioBuffer(null); 
    }
  }, [toast, originalAudioDataUrl, processedAudioDataUrl]);

  const handleParameterChange = useCallback((effectId: string, paramName: string, value: any) => {
    setEffectSettings(prev => ({
      ...prev,
      [effectId]: {
        ...prev[effectId],
        [paramName]: value,
      },
    }));
  }, []);

  const handleApplyEffect = useCallback(async (effectId: string, params: EffectSettings) => {
    if (!originalAudioDataUrl) {
      toast({ title: "No Audio", description: "Please upload an audio file first.", variant: "destructive" });
      return;
    }

    setIsLoading(true);
    setAnalysisResult(null); 
    setAnalysisSourceEffectId(null);
    const currentAudio = processedAudioDataUrl || originalAudioDataUrl; 
    
    const effectToApply = effectsList.find(e => e.id === effectId || e.parameters?.find(p => p.handlerKey === effectId));
    const actualHandlerKey = effectToApply?.parameters?.find(p => p.handlerKey === effectId)?.handlerKey || effectToApply?.handlerKey || effectId;
    const parentEffectId = effectToApply?.id || null;

    try {
      let result: { processedAudioDataUrl: string; analysis?: string } = { processedAudioDataUrl: currentAudio };
      const combinedParams = { ...(effectSettings[parentEffectId ?? effectId] || {}), ...params };

      if (audioUtils[actualHandlerKey]) {
        result = await audioUtils[actualHandlerKey](currentAudio, combinedParams);
      } else {
        throw new Error(`Handler for ${actualHandlerKey} not found.`);
      }
      
      setProcessedAudioDataUrl(result.processedAudioDataUrl);
      if (result.analysis) {
        setAnalysisResult(result.analysis);
        if (effectToApply?.outputsAnalysis && parentEffectId) {
          setAnalysisSourceEffectId(parentEffectId);
        }
      }
      toast({ title: "Effect Applied", description: `${effectToApply?.name || actualHandlerKey} processing complete.` });
    } catch (error: any) {
      console.error(`Error applying effect ${effectId}:`, error);
      toast({ title: "Processing Error", description: `Could not apply ${effectToApply?.name || effectId}. ${error.message || 'Unknown error'}`, variant: "destructive" });
      setAnalysisResult(null);
      setAnalysisSourceEffectId(null);
    } finally {
      setIsLoading(false);
    }
  }, [originalAudioDataUrl, processedAudioDataUrl, toast, effectSettings]);

  const handleExport = useCallback(async (format: string, quality: string, loopCount: number) => {
    console.log(`Exporting as ${format} with ${quality} quality, loops: ${loopCount}.`);
    if (!processedAudioDataUrl) {
      toast({ title: "Nothing to Export", description: "No processed audio available.", variant: "destructive" });
      return;
    }
    setIsLoading(true);
    try {
      let audioToDownloadUrl = processedAudioDataUrl;
      if (loopCount > 1) {
        toast({ title: "Looping Audio", description: `Applying ${loopCount} loops... This may take a moment.` });
        audioToDownloadUrl = await audioUtils.loopAudio(processedAudioDataUrl, loopCount);
      }

      toast({ title: "Export Ready", description: `Preparing download for ${originalAudioFile?.name || 'audio'}_forged.${format}.` });
      const link = document.createElement('a');
      link.href = audioToDownloadUrl;
      const baseName = originalAudioFile ? originalAudioFile.name.substring(0, originalAudioFile.name.lastIndexOf('.')) : 'audio';
      const loopSuffix = loopCount > 1 ? `_loops${loopCount}` : '';
      link.download = `${baseName}_forged${loopSuffix}.${format}`;
      document.body.appendChild(link);
      link.click();
      document.body.removeChild(link);

    } catch (error: any) {
      console.error("Error during export:", error);
      toast({ title: "Export Error", description: `Failed to export audio. ${error.message}`, variant: "destructive" });
    } finally {
      setIsLoading(false);
    }
  }, [processedAudioDataUrl, originalAudioFile, toast]);

  const ControlsPanelSkeleton = () => (
    <div className="p-4 space-y-4">
      <Skeleton className="h-32 w-full" />
      <Skeleton className="h-12 w-full" />
      <Skeleton className="h-24 w-full" />
      <Skeleton className="h-24 w-full" />
      <Skeleton className="h-24 w-full" />
    </div>
  );

  const MainContentSkeleton = () => (
    <div className="flex-grow p-4 grid grid-cols-1 md:grid-cols-2 gap-4">
      <div className="space-y-4">
        <Skeleton className="h-28 w-full" /> 
        <Skeleton className="h-48 w-full" /> 
      </div>
       <div className="space-y-4">
        <Skeleton className="h-28 w-full" />
        <Skeleton className="h-48 w-full" /> 
      </div>
      <Skeleton className="h-40 w-full md:col-span-2" />
    </div>
  );


  const audioControlsPanelProps = {
    onFileSelect: handleFileSelect,
    selectedFile: originalAudioFile,
    onApplyEffect: handleApplyEffect,
    onParameterChange: handleParameterChange,
    effectSettings: effectSettings,
    isLoading: isLoading,
    isAudioLoaded: !!originalAudioDataUrl,
    analysisResult: analysisResult,
    analysisSourceEffectId: analysisSourceEffectId,
  };

  const mainDisplayPanelProps = {
    originalAudioDataUrl: originalAudioDataUrl,
    processedAudioDataUrl: processedAudioDataUrl,
    originalAudioBuffer: originalAudioBuffer,
    processedAudioBuffer: processedAudioBuffer,
    onExport: handleExport,
    isLoading: isLoading,
    analysisResult: analysisResult,
    analysisSourceEffectId: analysisSourceEffectId,
    originalFileName: originalAudioFile?.name,
  };

  if (!hasMounted) {
    return (
      <div className="flex flex-col min-h-screen bg-background text-foreground">

          {isMobile ? (
             <div className="flex-grow p-4 overflow-y-auto">
                <MainContentSkeleton />
             </div>
          ) : (
            <ResizablePanelGroup direction="horizontal" className="flex-grow">
              <ResizablePanel defaultSize={30} minSize={20} maxSize={45} className="h-full overflow-y-auto">
                 <ControlsPanelSkeleton />
              </ResizablePanel>
              <ResizableHandle withHandle />
              <ResizablePanel defaultSize={70} minSize={55} className="h-full overflow-y-auto">
                 <MainContentSkeleton />
              </ResizablePanel>
            </ResizablePanelGroup>
          )}
      </div>
    );
  }

  return (
    <div className="flex flex-col min-h-screen bg-background text-foreground">

        {isMobile ? (
          <>
            {/* Button to open the effects, upload, and chat sheet on mobile */}
            <Button className="w-full mb-4" onClick={() => setIsEffectsSheetOpen(true)}>
              Edit Audio & Get Tips
           </Button>
            <MainDisplayPanel {...mainDisplayPanelProps} />
            <Sheet open={isEffectsSheetOpen} onOpenChange={setIsEffectsSheetOpen}>
              <SheetContent side="left" className="w-[85vw] max-w-md p-0 flex flex-col h-full overflow-y-auto">
                <SheetHeader className="p-4 border-b">
                  <SheetTitle>
                    <h2 className="text-xl font-bold">Audio Effects</h2>
                  </SheetTitle>
                  <SheetDescription className="sr-only">
                    Panel containing all audio effects and file upload controls.
                  </SheetDescription>
                </SheetHeader>
                <div className="flex-1 overflow-y-auto p-4 space-y-4">
                  <FileUploadArea
                    onFileSelect={handleFileSelect}
                    selectedFile={originalAudioFile}
                    isLoading={isLoading}
                  />
                  <EffectsPanel
                    onApplyEffect={handleApplyEffect}
                    onParameterChange={handleParameterChange}
                    effectSettings={effectSettings}
                    isLoading={isLoading}
                    isAudioLoaded={!!originalAudioDataUrl}
                    analysisResult={analysisResult}
                    analysisSourceEffectId={analysisSourceEffectId}
                  />
                  <ChatbotTips />
                </div>
              </SheetContent>
            </Sheet>
          </>
        ) : (
          <ResizablePanelGroup 
            direction="horizontal"
            className="flex-grow" 
          >
            <ResizablePanel 
              defaultSize={30} 
              minSize={20} 
              maxSize={45}
              className="h-full overflow-y-auto" 
            >
              <div className="p-4 space-y-4">
                {/* H2 for Effects panel, only visible on desktop */}
                <h2 className="text-lg font-bold mb-4 hidden md:block">Audio Effects</h2>
                <FileUploadArea
                  onFileSelect={handleFileSelect}
                  selectedFile={originalAudioFile}
                  isLoading={isLoading}
                />
                <EffectsPanel
                  onApplyEffect={handleApplyEffect}
                  onParameterChange={handleParameterChange}
                  effectSettings={effectSettings}
                  isLoading={isLoading}
                  isAudioLoaded={!!originalAudioDataUrl}
                  analysisResult={analysisResult}
                  analysisSourceEffectId={analysisSourceEffectId}
                />
              </div>
            </ResizablePanel>
            <ResizableHandle withHandle />
            <ResizablePanel 
              defaultSize={70} 
              minSize={55}
              className="h-full overflow-y-auto" 
            >
              <MainDisplayPanel {...mainDisplayPanelProps} />
              <ChatbotTips />
            </ResizablePanel>
          </ResizablePanelGroup>
        )}
    </div>
  );
}


================================================
FILE: src/components/audio-forge/AudioPlayer.tsx
================================================

'use client';
import React, { useRef, useState, useEffect } from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { PlayCircle, PauseCircle, Download } from 'lucide-react';

interface AudioPlayerProps {
  title: string;
  audioSrc: string | null;
  fileName?: string; // For download
  onPlayStateChange?: (isPlaying: boolean) => void;
}

export function AudioPlayer({ title, audioSrc, fileName = "processed_audio.wav", onPlayStateChange }: AudioPlayerProps) {
  const audioRef = React.useRef<HTMLAudioElement>(null);
  const [isPlaying, setIsPlaying] = React.useState(false);
  const [duration, setDuration] = React.useState(0);
  const [currentTime, setCurrentTime] = React.useState(0);

  const togglePlayPause = () => {
    const audio = audioRef.current;
    if (audio) {
      if (audio.paused || audio.ended) {
        audio.play().catch(error => console.error("Error playing audio:", error));
      } else {
        audio.pause();
      }
    }
  };

  useEffect(() => {
    const audio = audioRef.current;
    if (audio) {
      const setAudioData = () => {
        if (isFinite(audio.duration)) {
            setDuration(audio.duration);
        } else {
            setDuration(0); // Handle Infinite or NaN duration
        }
        setCurrentTime(audio.currentTime);
      }
      const setAudioTime = () => setCurrentTime(audio.currentTime);

      const handlePlay = () => { setIsPlaying(true); onPlayStateChange?.(true); };
      const handlePause = () => { setIsPlaying(false); onPlayStateChange?.(false); };
      const handleEnded = () => { 
        setIsPlaying(false); 
        onPlayStateChange?.(false); 
        setCurrentTime(0); // Reset to beginning on end
      };
      
      audio.addEventListener('loadedmetadata', setAudioData);
      audio.addEventListener('durationchange', setAudioData); // Handle duration changes
      audio.addEventListener('timeupdate', setAudioTime);
      audio.addEventListener('play', handlePlay);
      audio.addEventListener('pause', handlePause);
      audio.addEventListener('ended', handleEnded);

      // Initial sync of play state
      if (audioSrc) {
          // Audio might already be playing or paused from previous src or autoPlay
          if (!audio.paused && !audio.ended && audio.readyState >= HTMLMediaElement.HAVE_METADATA) {
              setIsPlaying(true);
              onPlayStateChange?.(true);
          } else {
              setIsPlaying(false);
              onPlayStateChange?.(false);
          }
          // Ensure duration is set if metadata already loaded
          if (audio.readyState >= HTMLMediaElement.HAVE_METADATA && isFinite(audio.duration)) {
            setDuration(audio.duration);
          } else {
            setDuration(0);
          }
      } else {
          setIsPlaying(false);
          onPlayStateChange?.(false);
          setCurrentTime(0);
          setDuration(0);
      }

      return () => {
        audio.removeEventListener('loadedmetadata', setAudioData);
        audio.removeEventListener('durationchange', setAudioData);
        audio.removeEventListener('timeupdate', setAudioTime);
        audio.removeEventListener('play', handlePlay);
        audio.removeEventListener('pause', handlePause);
        audio.removeEventListener('ended', handleEnded);
      }
    }
  }, [audioSrc, onPlayStateChange]);

  const formatTime = (time: number) => {
    if (!isFinite(time) || time < 0) return '0:00';
    const minutes = Math.floor(time / 60);
    const seconds = Math.floor(time % 60).toString().padStart(2, '0');
    return `${minutes}:${seconds}`;
  };
  
  const handleSeek = (event: React.ChangeEvent<HTMLInputElement>) => {
    if (audioRef.current) {
        const seekTime = Number(event.target.value);
        audioRef.current.currentTime = seekTime;
        setCurrentTime(seekTime);
    }
  };

  return (
    <Card className="shadow-md">
      <CardHeader>
        <CardTitle className="text-lg">{title}</CardTitle>
      </CardHeader>
      <CardContent className="space-y-3">
        {audioSrc ? (
          <>
            <audio ref={audioRef} src={audioSrc || undefined} className="w-full hidden" preload="metadata" />
            <div className="flex flex-wrap items-center gap-2 sm:gap-3">
              <button onClick={togglePlayPause} className="text-primary hover:text-accent transition-colors" aria-label={isPlaying ? "Pause" : "Play"}>
                {isPlaying ? <PauseCircle size={32} /> : <PlayCircle size={32} />}
              </button>
              <input 
                type="range" 
                min="0" 
                max={duration || 0} 
                value={currentTime} 
                onChange={handleSeek}
                className="flex-grow h-2 bg-muted rounded-lg appearance-none cursor-pointer accent-primary disabled:opacity-50 min-w-[100px]"
                aria-label="Seek"
                disabled={!audioSrc || duration === 0}
              />
              <span className="text-sm text-muted-foreground min-w-[5rem] text-right flex-shrink-0">{formatTime(currentTime)} / {formatTime(duration)}</span>
               <a
                href={audioSrc}
                download={fileName}
                className={`text-primary hover:text-accent transition-colors p-1 rounded-md focus:outline-none focus:ring-2 focus:ring-ring ${!audioSrc ? 'opacity-50 cursor-not-allowed' : ''}`}
                aria-label="Download processed audio"
                onClick={(e) => !audioSrc && e.preventDefault()}
              >
                <Download size={20} />
              </a>
            </div>
          </>
        ) : (
          <p className="text-sm text-muted-foreground">No audio loaded.</p>
        )}
      </CardContent>
    </Card>
  );
}


================================================
FILE: src/components/audio-forge/ChatbotTips.tsx
================================================
import React from 'react';

const ChatbotTips: React.FC = () => {
  return (
    <section className="mt-8 p-4 border rounded-md bg-gray-800 border-gray-700">
      <h3 className="text-lg font-semibold mb-2">Tips for using the AI Chatbot</h3>
      <p className="text-sm text-gray-400">
        To get the best results from the AI chatbot, try to be specific and use the name of the tool you want to use in your command.
      </p>
      <p className="text-sm text-gray-400 mt-2">
        For example, instead of saying:
        <span className="block italic ml-4 text-gray-500">"what is the rpm of this song"</span>
        try saying:
        <span className="block italic ml-4 text-gray-300">"run the rpm detector on this audio file"</span>
      </p>
      <p className="text-sm text-gray-400 mt-2">
        Using the tool's name helps the chatbot understand your intent more accurately.
      </p>
    </section>
  );
};

export default ChatbotTips;


================================================
FILE: src/components/audio-forge/EffectCard.tsx
================================================

import type React from 'react';
import type { Effect, EffectParameter, EffectSettings } from '@/types/audio-forge';
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from '@/components/ui/card';
import { Label } from '@/components/ui/label';
import { Slider } from '@/components/ui/slider';
import { Input } from '@/components/ui/input';
import { Button } from '@/components/ui/button';
import { Switch } from '@/components/ui/switch';
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@/components/ui/select';
import { Textarea } from '@/components/ui/textarea';
import { fallbackIcon } from '@/types/effects';
import { Loader2 } from 'lucide-react';

interface EffectCardProps {
  effect: Effect;
  onApplyEffect: (effectId: string, params: EffectSettings) => void;
  onParameterChange: (effectId: string, paramName: string, value: any) => void;
  currentSettings: EffectSettings;
  isLoading: boolean;
  isAudioLoaded: boolean;
  analysisResult?: string | null;
  analysisSourceEffectId?: string | null;
}

export function EffectCard({ 
  effect, 
  onApplyEffect, 
  onParameterChange, 
  currentSettings, 
  isLoading, 
  isAudioLoaded,
  analysisResult,
  analysisSourceEffectId 
}: EffectCardProps) {
  const IconComponent = effect.icon || fallbackIcon;

  const handleSliderChange = (paramName: string, value: number[]) => {
    onParameterChange(effect.id, paramName, value[0]);
  };

  const handleInputChange = (paramName: string, event: React.ChangeEvent<HTMLInputElement | HTMLTextAreaElement>) => {
    const paramConfig = effect.parameters?.find(p => p.name === paramName);
    let value: string | number = event.target.value;

    if (paramConfig?.type === 'number_input') {
      if (event.target.value === '') {
        value = ""; // Keep as empty string for controlled input
      } else {
        const parsedValue = parseFloat(event.target.value);
        // If parsing results in NaN, keep it as NaN to be handled by validation or default logic later
        // Otherwise, use the parsed number.
        value = isNaN(parsedValue) ? event.target.value : parsedValue; 
      }
    }
    onParameterChange(effect.id, paramName, value);
  };
  
  const handleInputBlur = (paramName: string, event: React.FocusEvent<HTMLInputElement>) => {
    const paramConfig = effect.parameters?.find(p => p.name === paramName);
    if (paramConfig?.type === 'number_input') {
      let value = parseFloat(event.target.value);
      if (isNaN(value)) {
        value = paramConfig.defaultValue as number; // Reset to default if invalid
      } else {
        if (paramConfig.min !== undefined) value = Math.max(paramConfig.min, value);
        if (paramConfig.max !== undefined) value = Math.min(paramConfig.max, value);
      }
      onParameterChange(effect.id, paramName, value);
    }
  };


  const handleSelectChange = (paramName: string, value: string) => {
    onParameterChange(effect.id, paramName, value);
  };

  const handleToggleChange = (paramName: string, checked: boolean) => {
    onParameterChange(effect.id, paramName, checked);
  };

  const renderParameterControl = (param: EffectParameter) => {
    const elementId = `${effect.id}-${param.name}`;
    console.log(`Generating ID: ${elementId} for effect: ${effect.name}, parameter: ${param.label}`);
    const rawValue = currentSettings[param.name] ?? param.defaultValue;
    
    switch (param.type) {
      case 'slider':
        return (
          <div key={param.name} className="space-y-2">
            <div className="flex justify-between items-center">
              <Label htmlFor={elementId}>{param.label}</Label>
              <span className="text-sm text-muted-foreground">{Number(rawValue).toFixed(param.step && param.step < 1 ? 2 : 0)}</span>
            </div>
            <Slider
              id={elementId}
              value={[Number(rawValue)]}
              min={param.min}
              max={param.max}
              step={param.step}
              onValueChange={(val) => handleSliderChange(param.name, val)}
              disabled={isLoading || !isAudioLoaded}
            />
          </div>
        );
      case 'number_input':
        return (
          <div key={param.name} className="space-y-2">
            <Label htmlFor={elementId}>{param.label}</Label>
            <Input
              id={elementId}
              type="number"
              value={rawValue === "" || (typeof rawValue === 'number' && isNaN(rawValue)) ? "" : String(rawValue)}
              min={param.min}
              max={param.max}
              step={param.step}
              onChange={(e) => handleInputChange(param.name, e)}
              onBlur={(e) => handleInputBlur(param.name, e)}
              disabled={isLoading || !isAudioLoaded}
              className="w-full"
            />
          </div>
        );
      case 'select':
        return (
          <div key={param.name} className="space-y-2">
            <Label htmlFor={`${effect.id}-${param.name}`}>{param.label}</Label>
            <Select
              value={String(rawValue)}
              onValueChange={(val) => handleSelectChange(param.name, val)}
              disabled={isLoading || !isAudioLoaded}
            >
              <SelectTrigger id={`${effect.id}-${param.name}`}>
                <SelectValue placeholder={`Select ${param.label}`} />
              </SelectTrigger>
              <SelectContent>
                {param.options?.map(opt => (
                  <SelectItem key={String(opt.value)} value={String(opt.value)}>{opt.label}</SelectItem>
                ))}
              </SelectContent>
            </Select>
          </div>
        );
      case 'textarea':
        return (
          <div key={param.name} className="space-y-2">
            <Label htmlFor={`${effect.id}-${param.name}`}>{param.label}</Label>
            <Textarea
              id={`${effect.id}-${param.name}`}
              value={rawValue as string}
              placeholder={param.placeholder}
              rows={param.rows || 3}
              onChange={(e) => handleInputChange(param.name, e)}
              disabled={isLoading || !isAudioLoaded}
            />
          </div>
        );
      case 'button': 
        return (
            <Button
              key={param.name}
              variant="outline"
              size="sm"
              onClick={() => onApplyEffect(param.handlerKey || effect.id, { preset: param.name, ...currentSettings })}
              disabled={isLoading || !isAudioLoaded}
              className="w-full"
            >
              {param.label}
            </Button>
        );
      default:
        return null;
    }
  };
  
  const shouldShowApplyButton = 
    effect.parameters && effect.parameters.length > 0 && 
    !(effect.controlType === 'button' && effect.actionLabel) && 
    !(effect.controlType === 'group' && effect.parameters.every(p => p.type === 'button')) && 
    effect.controlType !== 'toggle'; 

  return (
    <Card className="shadow-md overflow-hidden">
      <CardHeader>
        <CardTitle>
          {/* Changed from div to h2 for accessibility */}
          <h2 className="flex items-center gap-2 text-lg">
            <IconComponent className="h-5 w-5 text-primary" />
            {effect.name}
          </h2>
        </CardTitle>
        <CardDescription className="text-xs">{effect.description}</CardDescription>
      </CardHeader>
      <CardContent className="space-y-4">
        {effect.parameters?.map(renderParameterControl)}
        {effect.outputsAnalysis && effect.id === analysisSourceEffectId && analysisResult && (
          <div className="pt-3 mt-3 border-t border-border">
            <p className="text-sm font-semibold text-primary mb-1">Analysis Report:</p>
            <p className="text-sm text-muted-foreground bg-muted/50 p-2 rounded-md">{analysisResult}</p>
          </div>
        )}
      </CardContent>
      
      {(effect.controlType === 'button' && effect.actionLabel && !effect.parameters?.some(p => p.type === 'button')) && (
        <CardFooter>
          <Button
            onClick={() => onApplyEffect(effect.id, currentSettings)}
            disabled={isLoading || !isAudioLoaded}
            className="w-full"
          >
            {isLoading && currentSettings?.isProcessingThis === effect.id ? <Loader2 className="mr-2 h-4 w-4 animate-spin" /> : null}
            {effect.actionLabel}
          </Button>
        </CardFooter>
      )}

      {effect.controlType === 'toggle' && effect.parameters && (
        <CardFooter className="flex items-center justify-between">
          <Label htmlFor={`${effect.id}-${effect.parameters[0].name}`}>{effect.parameters[0].label}</Label>
          <Switch
            id={`${effect.id}-${effect.parameters[0].name}`}
            checked={currentSettings[effect.parameters[0].name] ?? effect.parameters[0].defaultValue}
            onCheckedChange={(checked) => handleToggleChange(effect.parameters![0].name, checked)}
            disabled={isLoading || !isAudioLoaded}
          />
        </CardFooter>
      )}

      {shouldShowApplyButton && (
        <CardFooter>
          <Button
            onClick={() => onApplyEffect(effect.id, currentSettings)}
            disabled={isLoading || !isAudioLoaded}
            className="w-full"
          >
            {isLoading && currentSettings?.isProcessingThis === effect.id ? <Loader2 className="mr-2 h-4 w-4 animate-spin" /> : null}
            {isLoading && currentSettings?.isProcessingThis === effect.id ? 'Applying...' : `Apply ${effect.name}`}
          </Button>
        </CardFooter>
      )}
    </Card>
  );
}


================================================
FILE: src/components/audio-forge/EffectsPanel.tsx
================================================
'use client';
import { effectsList } from '@/types/effects';
import { EffectCard } from './EffectCard';
import { useEffect, useRef, useState } from 'react';
import { Card, CardContent } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Input } from '@/components/ui/input';
import { ScrollArea } from '@/components/ui/scroll-area';
import { useToast } from "@/hooks/use-toast";
import { FileUploadArea } from './FileUploadArea';

declare global {
  interface Window {
    puter: any; // Replace 'any' with a more specific type if available
  }
}

// Type for a single message
interface Message {
  id: number;
  text: string;
  sender: 'user' | 'bot';
}

// You may need to adjust these props to match your actual handlers and state
export function EffectsPanel(props) {
  const [messages, setMessages] = useState<Message[]>([]);
  const [inputMessage, setInputMessage] = useState('');
  const scrollAreaRef = useRef<HTMLDivElement>(null);
  const [isAiChatReady, setIsAiChatReady] = useState(false);
  const { toast } = useToast();

  // Add useEffect to log currentAudioFile changes
  useEffect(() => {
    console.log('currentAudioFile changed:', props.currentAudioFile);
  }, [props.currentAudioFile]);

  useEffect(() => {
 // Scroll to the bottom of the chat when new messages are added
 if (scrollAreaRef.current) {
 scrollAreaRef.current.scrollTo({
 top: scrollAreaRef.current.scrollHeight,
 behavior: 'smooth',
 });
 }
  }, [messages]);

  useEffect(() => {
    let intervalId: NodeJS.Timeout | null = null;
    const maxAttempts = 100; // Try for about 20 seconds (100 * 200ms) -> Increased to 500ms interval, so 50 seconds total
    let attempts = 0;
    const intervalDuration = 500; // Increased interval duration

    const checkPuterReadiness = () => {
      attempts++;
      if (typeof window.puter?.ai?.chat === 'function') {
        setIsAiChatReady(true);
        // Add a message to the chat when the AI is ready
        setMessages(prevMessages => {
          // Avoid adding the "ready" message multiple times
          if (!prevMessages.some(msg => msg.text.includes("AI audio assistant is ready"))) {
            return [
              ...prevMessages,
              {
                id: prevMessages.length + 1,
                text: "AI audio assistant is ready. How can I help you edit your audio?",
                sender: 'bot',
              },
            ];
          }
          return prevMessages;
        });
        if (intervalId) clearInterval(intervalId);
      } else {
        console.warn('Puter.js SDK or AI chat functionality not yet loaded.');
        console.log(`Attempt ${attempts}:`);
        console.log('window.puter:', window.puter);
        console.log('window.puter.ai:', window.puter?.ai);
        console.log('window.puter.ai.chat:', window.puter?.ai?.chat);

        if (attempts >= maxAttempts && intervalId) {
          clearInterval(intervalId);
          console.error('Max attempts reached. Puter.js AI chat functionality not loaded.');
          toast({
            variant: "destructive",
            title: "AI Chat Error",
            description: "AI chat functionality could not be loaded. Please try refreshing.",
          });
        }
      }
    };

    // Start polling
    intervalId = setInterval(checkPuterReadiness, intervalDuration); // Check every 500ms

    // Clear interval on component unmount
    return () => {
      if (intervalId) clearInterval(intervalId);
    };
  }, [messages]);

  const generateAudioFileContext = (currentAudioFile: string | undefined): string => {
    let context = 'Audio File Context:\n';
    if (currentAudioFile && typeof currentAudioFile === 'string' && currentAudioFile.trim() !== '') {
      context += `Current Audio File: ${currentAudioFile}\n`;
    } else {
      context += 'No audio file currently loaded.\n';
    }
    return context;
  };


  const handleSendMessage = async () => {
    if (inputMessage.trim() === '') return;

    const newUserMessage: Message = {
      id: messages.length + 1,
      text: inputMessage,
      sender: 'user',
    };

    setMessages([...messages, newUserMessage]);
    setInputMessage('');

    // Log currentAudioFile just before constructing the prompt
    console.log('handleSendMessage - props.currentAudioFile:', props.currentAudioFile);


    if (!isAiChatReady) {
       console.error('AI chat is not ready.');
       return; // Do not attempt to send if not ready
    }
    if (window.puter) {
      // Ensure user is signed in before making the AI chat call
      let isSignedIn = await window.puter.auth.isSignedIn();
      if (!isSignedIn) {
        await window.puter.auth.signIn();
        isSignedIn = await window.puter.auth.isSignedIn();
        if (!isSignedIn) {
          const botResponse: Message = {
            id: messages.length + 2,
            text: 'Authentication failed or was cancelled. Cannot process command.',
            sender: 'bot',
          };
          setMessages(prevMessages => [...prevMessages, botResponse]);
          return;
        }
      }
     
      // Generate the audio file context
      const audioFileContext = generateAudioFileContext(props.currentAudioFile);

      // Construct the prompt for the AI
      const prompt = `
${audioFileContext}
The current audio file you are working with is: ${props.currentAudioFile}


You are an AI audio assistant that can help edit audio files by applying effects.
Your primary function is to understand the user's requests and respond in a structured format that the application can parse to apply audio effects.

When the user asks you to apply an audio effect, your response should be a JSON object with the following structure:
{
"effectId": "string", // The ID of the audio effect to apply (must match one of the available effect IDs).
"parameters": { // An object containing the parameters for the effect. The keys should be parameter names and the values should be the desired parameter values.
  // Example: "gain": 0.5, "frequency": 1000
}
}

You MUST use one of the following effect IDs in the "effectId" field:
${effectsList.map(effect => `- ${effect.id}`).join('\n')}

Do NOT use any other effect IDs.

You have access to the following audio effects and their parameters:
- Reverb: { parameters: { decay: number, density: number, wet: number, dry: number } }
- Delay: { parameters: { delayTime: number, feedback: number, wet: number, dry: number } }
- Gain: { parameters: { gain: number } }
- Equalizer: { parameters: { frequency: number, gain: number, type: string } }
- Compressor: { parameters: { threshold: number, ratio: number, attack: number, release: number } }
- Distortion: { parameters: { amount: number } }
// Add other effects and their parameters here as they are implemented

If the user's request is not related to applying an audio effect, or if you cannot fulfill the request as an audio effect command, respond with a plain text message explaining why or providing a helpful response.

User request: "${inputMessage}"
`;

      // Call the AI chat with the constructed prompt
      const response = await window.puter.ai.chat(prompt, {
        // You can add other options here if needed, like 'model'
      });

      // Get AI response text, prioritizing response.message.content
      const aiResponseText = response?.message?.content || response?.text;

      // Check if the response and response.text are valid before processing
      if (!aiResponseText) {
        console.error('Received empty or invalid text response from AI:', response);
        // Add the AI's response to the chat
         setMessages(prevMessages => [...prevMessages, {
           id: prevMessages.length + 1,
           text: 'Received an empty or invalid text response from the AI.',
           sender: 'bot',
         }]);
        return;
      }
        // Attempt to parse the response text for effect commands
        let effectCommand = null;
        try {
          effectCommand = JSON.parse(aiResponseText);
          // Check if the parsed object has the expected properties for an effect command
          if (effectCommand && typeof effectCommand === 'object' && effectCommand.effectId && effectCommand.parameters) {
            console.log('Detected effect command:', effectCommand);
            // Call the onApplyEffect prop
            if (props.onApplyEffect) {
              const effect = effectsList.find(e => e.id === effectCommand.effectId);
              if (effect) {
                props.onApplyEffect(effect.id, effectCommand.parameters);
                // Optionally add a confirmation message to the chat
                const confirmationMessage: Message = {
                  id: messages.length + 2,
                  text: `Applied effect: ${effect.name}`,
                  sender: 'bot',
                };
                setMessages(prevMessages => [...prevMessages, confirmationMessage]);
              } else {
                console.error(`Effect with ID '${effectCommand.effectId}' not found.`);
                const errorMessage: Message = {
                  id: messages.length + 2,
                  text: `Could not apply effect: Effect with ID '${effectCommand.effectId}' not found.`,
                  sender: 'bot',
                };
                setMessages(prevMessages => [...prevMessages, errorMessage]);
              }
            } else {
              console.warn('onApplyEffect prop is not available to apply effect.');
              // Add a message indicating inability to apply effect
               const errorMessage: Message = {
                  id: messages.length + 2,
                  text: 'AI suggested an effect, but audio processing is not available.',
                  sender: 'bot',
                };
                setMessages(prevMessages => [...prevMessages, errorMessage]);
            }
             // If an effect command was processed, we might not want to add the raw JSON to chat
             // return; // Uncomment this line if you don't want the raw JSON in the chat
          } else {
               // If it's not a valid effect command JSON, treat it as a regular text response
                const botResponse: Message = {
                  id: messages.length + 2,
                  text: aiResponseText,
                  sender: 'bot',
                };
                setMessages(prevMessages => [...prevMessages, botResponse]);
          }
        } catch (error) {
          console.error('Error parsing AI response for effect command:', error);
          // If JSON parsing fails, treat the response as a regular text response
          const botResponse: Message = {
            id: messages.length + 2,
            text: aiResponseText,
            sender: 'bot',
          };
          setMessages(prevMessages => [...prevMessages, botResponse]);
        }

      } else {
        const botResponse: Message = {
          id: messages.length + 2,
          text: 'puter.js not loaded. Cannot process command.',
          sender: 'bot',
        };
        setMessages(prevMessages => [...prevMessages, botResponse]);
      }
  };

    
  return (
    <>
      <Card className="h-full flex flex-col">
        <CardContent className="flex-grow overflow-hidden p-4">
          <ScrollArea ref={scrollAreaRef} className="h-full pr-4">
            {/* Anchor Navigation and Effects Cards */}
            {/* Content above the chat input */}
            <div>
              {/* Anchor Navigation */}
              <nav className="mb-6">
                <ul className="flex flex-wrap gap-2">
                  {effectsList.map(effect => (
                    <li key={effect.id}>
                      <a href={`#${effect.id}`} className="underline text-blue-600">{effect.name}</a>
                    </li>
                  ))}
                </ul>
              </nav>

              {/* Scrollable container for effects with glow */}
              <div className="relative overflow-hidden">
                <ScrollArea className="h-[300px] pb-4" /* Adjust height as needed */>
                  <div className="grid gap-6 pr-4"> {/* Added padding to avoid scrollbar overlapping content */}
                    {effectsList.map(effect => (
                      <section id={effect.id} key={effect.id}>
                        <EffectCard
                          effect={effect}
                          currentSettings={props.effectSettings?.[effect.id] || {}} // Defensive fallback
                          onApplyEffect={props.onApplyEffect}
                          onParameterChange={props.onParameterChange}
                          isLoading={props.isLoading}
                          isAudioLoaded={props.isAudioLoaded}
                          analysisResult={props.analysisResult}
                          analysisSourceEffectId={props.analysisSourceEffectId}
                        />
                      </section>
                    ))}
                  </div>
                </ScrollArea>
                {/* Glow effects - adjust styling as needed */}
                <div className="absolute top-0 left-0 right-0 h-8 bg-gradient-to-b from-background to-transparent pointer-events-none"></div>
                <div className="absolute bottom-0 left-0 right-0 h-8 bg-gradient-to-t from-background to-transparent pointer-events-none"></div>
              </div>
            </div>

            {/* Chat messages */}
            {messages.map(message => (
              <div key={message.id} className={`mb-2 ${message.sender === 'user' ? 'text-right' : 'text-left'}`}>
                <span className={`inline-block p-2 rounded-lg ${message.sender === 'user' ? 'bg-blue-500 text-white' : 'bg-gray-200 text-gray-800'}`}>
                  {message.text}
                </span>
              </div>
            ))}
          </ScrollArea>
        </CardContent>
        <div className="p-4 border-t">
          <div className="flex gap-2">
            <Input
              placeholder="Type your command..."
              value={inputMessage}
              onChange={(e) => setInputMessage(e.target.value)}
              onKeyPress={(e) => {
                if (e.key === 'Enter') {
                  if (isAiChatReady) {
                    handleSendMessage();
                  }
                }
              }
              }
              className="flex-grow"
              disabled={!isAiChatReady} // Disable input if AI is not ready
            />
            <Button onClick={handleSendMessage} disabled={!isAiChatReady || inputMessage.trim() === ''}>Send</Button> {/* Disable button if AI is not ready or input is empty */}
          </div>
        </div>
      </Card>
    </>
  );
}



================================================
FILE: src/components/audio-forge/ExportPanel.tsx
================================================

import { useState } from 'react';
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from '@/components/ui/card';
import { Label } from '@/components/ui/label';
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@/components/ui/select';
import { Button } from '@/components/ui/button';
import { Download, Settings2, Repeat as LoopIcon } from 'lucide-react';
import { Input } from '@/components/ui/input'; // Keep this import

interface ExportPanelProps {
  processedAudioDataUrl: string | null;
  onExport: (format: string, quality: string, loopCount: number) => void;
  isLoading: boolean;
}

export function ExportPanel({ processedAudioDataUrl, onExport, isLoading }: ExportPanelProps) {
  const [format, setFormat] = useState('wav');
  const [quality, setQuality] = useState('high');
  const [loopCount, setLoopCount] = useState(1);

  const handleExportClick = () => {
    if (processedAudioDataUrl) {
      // For large files, consider exporting in a Web Worker
      onExport(format, quality, loopCount);
    }
  };

  const handleLoopCountChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    let value = parseInt(e.target.value, 10);
    if (isNaN(value)) {
      value = 1; // Default to 1 if input is not a number
    }
    value = Math.max(1, Math.min(10, value)); // Clamp between 1 and 10
    setLoopCount(value);
  };

  return (
    <Card className="shadow-md">
      <CardHeader>
        <CardTitle className="flex items-center gap-2 text-xl">
          <Settings2 className="text-primary" />
          Export Configuration
        </CardTitle>
        <CardDescription>Choose your preferred output settings and loop options.</CardDescription>
      </CardHeader>
      <CardContent className="space-y-4">
        <div className="grid grid-cols-1 sm:grid-cols-2 gap-4">
          <div className="space-y-1">
            <Label htmlFor="format">Format</Label>
            <Select value={format} onValueChange={setFormat} disabled={isLoading || !processedAudioDataUrl}>
              <SelectTrigger id="format">
                <SelectValue placeholder="Select format" />
              </SelectTrigger>
              <SelectContent>
                <SelectItem value="wav">WAV</SelectItem>
                <SelectItem value="mp3">MP3</SelectItem>
                <SelectItem value="flac">FLAC</SelectItem>
                <SelectItem value="ogg">OGG</SelectItem>
              </SelectContent>
            </Select>
          </div>
          <div className="space-y-1">
            <Label htmlFor="quality">Quality</Label>
            <Select value={quality} onValueChange={setQuality} disabled={isLoading || !processedAudioDataUrl || format !== 'mp3'}> {/* Quality typically for lossy like MP3 */}
              <SelectTrigger id="quality">
                <SelectValue placeholder="Select quality" />
              </SelectTrigger>
              <SelectContent>
                <SelectItem value="high">High (320kbps)</SelectItem>
                <SelectItem value="medium">Medium (192kbps)</SelectItem>
                <SelectItem value="low">Low (128kbps)</SelectItem>
              </SelectContent>
            </Select>
          </div>
        </div>
        <div className="space-y-1">
          <Label htmlFor="loop-count" className="flex items-center gap-1">
            <LoopIcon className="h-4 w-4" />
            Number of Loops
          </Label>
          <Input
            id="loop-count"
            type="number"
            min="1"
            max="10"
            value={loopCount}
            onChange={handleLoopCountChange}
            onBlur={(e) => { // Ensure value is clamped on blur if user types something out of range
                let value = parseInt(e.target.value, 10);
                if (isNaN(value) || value < 1) value = 1;
                if (value > 10) value = 10;
                setLoopCount(value);
            }}
            disabled={isLoading || !processedAudioDataUrl}
            className="w-full sm:w-1/2"
          />
          <p className="text-xs text-muted-foreground">Set how many times the audio should loop (1-10 times). 1 means no looping.</p>
        </div>
      </CardContent>
      <CardFooter>
        <Button
          onClick={handleExportClick}
          disabled={!processedAudioDataUrl || isLoading}
          className="w-full"
        >
          <Download className="mr-2 h-4 w-4" />
          Export Audio
        </Button>
      </CardFooter>
    </Card>

  );
}


================================================
FILE: src/components/audio-forge/FileUploadArea.tsx
================================================
import type React from 'react';
import { UploadCloud } from 'lucide-react';
import { Input } from '@/components/ui/input';
import { Label } from '@/components/ui/label';
import { Button } from '@/components/ui/button';
import { Card, CardContent, CardHeader, CardTitle, CardDescription } from '@/components/ui/card';

const MAX_FILE_SIZE_MB = 50;

interface FileUploadAreaProps {
  onFileSelect: (file: File | null) => void;
  selectedFile: File | null;
  isLoading: boolean;
}

export function FileUploadArea({ onFileSelect, selectedFile, isLoading }: FileUploadAreaProps) {
  const handleFileChange = (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      if (file.size > MAX_FILE_SIZE_MB * 1024 * 1024) {
        alert(`File is too large (${(file.size / (1024 * 1024)).toFixed(2)} MB). Max allowed is ${MAX_FILE_SIZE_MB} MB.`);
        event.target.value = '';
        return;
      }
      onFileSelect(file);
    }
  };

  return (
    <Card className="shadow-md">
      <CardHeader>
        <CardTitle className="flex items-center gap-2">
          <UploadCloud className="text-primary" />
          Upload Audio
        </CardTitle>
        <CardDescription>
          Select an audio file (e.g., MP3, WAV, WebM, OGG, FLAC, AAC, M4A) to start forging.<br />
          <span className="text-warning-foreground">Files over {MAX_FILE_SIZE_MB}MB are not supported for performance reasons.</span>
        </CardDescription>
      </CardHeader>
      <CardContent className="space-y-4">
        <div className="grid w-full max-w-sm items-center gap-1.5">
          <Label htmlFor="audio-file" className="sr-only">Audio File</Label>
          <Input
            id="audio-file"
            type="file"
            accept="audio/*,.mp3,.wav,.webm,.weba,.ogg,.flac,.aac,.m4a"
            onChange={handleFileChange}
            disabled={isLoading}
            className="cursor-pointer file:text-primary file:font-semibold hover:file:bg-primary/10"
          />
        </div>
        {selectedFile && (
          <p className="text-sm text-muted-foreground">
            Selected: <span className="font-medium text-foreground">{selectedFile.name}</span>
            <span className="ml-2 text-xs">({(selectedFile.size / (1024 * 1024)).toFixed(2)} MB)</span>
          </p>
        )}
        {selectedFile && (
           <Button onClick={() => onFileSelect(null)} variant="outline" size="sm" disabled={isLoading}>
            Clear Selection
          </Button>
        )}
      </CardContent>
    </Card>
  );
}


================================================
FILE: src/components/audio-forge/FrequencyVisualizer.tsx
================================================

'use client';

import React, { useEffect, useRef, useState } from 'react';
import { BarChart, Bar, XAxis, YAxis, CartesianGrid } from 'recharts';
import { ChartContainer, ChartTooltip, ChartTooltipContent } from "@/components/ui/chart";
import type { ChartConfig } from "@/components/ui/chart";
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { BarChartBig } from 'lucide-react';

interface FunctionalFrequencyVisualizerProps {
  audioBuffer: AudioBuffer | null;
  isPlaying: boolean;
}

const chartConfig = {
  level: { label: "Level (dB)", color: "hsl(var(--primary))" },
} satisfies ChartConfig;

const NUM_BARS = 32; // Number of bars to display
const FFT_SIZE = 256; // Must be a power of 2. frequencyBinCount = FFT_SIZE / 2;

export function FunctionalFrequencyVisualizer({ audioBuffer, isPlaying }: FunctionalFrequencyVisualizerProps) {
  const [frequencyData, setFrequencyData] = useState<{ band: string; level: number }[]>(
    Array(NUM_BARS).fill(null).map((_, i) => ({ band: `${i + 1}`, level: 0 }))
  );
  const workerRef = useRef<Worker | null>(null);
  const animationFrameIdRef = useRef<number | null>(null);

  useEffect(() => {
    // Cleanup function for the effect
    const cleanup = () => {
      if (animationFrameIdRef.current) {
        cancelAnimationFrame(animationFrameIdRef.current);
        animationFrameIdRef.current = null;
      }
      setFrequencyData(Array(NUM_BARS).fill(null).map((_, i) => ({ band: `${i + 1}`, level: 0 })));
    };

    if (!audioBuffer || !isPlaying) {
      cleanup();
      return;
    }

    // Create worker if not exists
    if (!workerRef.current) {
      workerRef.current = new Worker(new URL('@/workers/audioWorker.ts', import.meta.url));
    }
    const worker = workerRef.current;

    // Prepare transferable data
    const channelData = audioBuffer.getChannelData(0);
    const channelCopy = new Float32Array(channelData.length);
    channelCopy.set(channelData);

    let stopped = false;

    worker.onmessage = (e: MessageEvent) => {
      if (e.data.type === "frequency" && !stopped) {
        setFrequencyData(e.data.data);
      }
    };

    // Animation loop to simulate real-time updates while playing
    const updateFrequency = () => {
      worker.postMessage({
        type: "frequency",
        audioBufferData: [channelCopy],
        sampleRate: audioBuffer.sampleRate,
        numBars: NUM_BARS,
        fftSize: FFT_SIZE,
      });
      animationFrameIdRef.current = requestAnimationFrame(updateFrequency);
    };

    updateFrequency();

    return () => {
      stopped = true;
      cleanup();
      // Optionally terminate worker if you want to clean up
      // worker.terminate();
    };
  }, [audioBuffer, isPlaying]);

  return (
    <Card className="shadow-md">
      <CardHeader>
        <CardTitle className="flex items-baseline gap-2">
          <BarChartBig className="text-primary h-5 w-5" />
          <span className="text-xl">Frequency Visualizer</span>
          <span className="text-sm text-muted-foreground ml-1">(Play an audio)</span>
        </CardTitle>
      </CardHeader>
      <CardContent className="h-[200px]">
        <ChartContainer config={chartConfig} className="w-full h-full">
          <BarChart accessibilityLayer data={frequencyData} margin={{ top: 5, right: 5, left: -25, bottom: 5 }} barGap={2}>
            <CartesianGrid vertical={false} strokeDasharray="3 3" />
            <XAxis 
                dataKey="band" 
                tickLine={false} 
                axisLine={false} 
                tickMargin={8} 
                fontSize={10} 
                interval="preserveStartEnd" 
            />
            <YAxis 
                tickLine={false} 
                axisLine={false} 
                tickMargin={8} 
                width={30} 
                fontSize={10} 
                domain={[0, 255]} 
            />
            <ChartTooltip 
                cursor={false} 
                content={<ChartTooltipContent indicator="dot" hideLabel />} 
            />
            <Bar dataKey="level" fill="var(--color-level)" radius={1} />
          </BarChart>
        </ChartContainer>
      </CardContent>
    </Card>
  );
}


================================================
FILE: src/components/audio-forge/MainDisplayPanel.tsx
================================================

'use client';
import React, { useState } from 'react';
import { AudioPlayer } from './AudioPlayer';
import { VisualizerSection } from './VisualizerSection';
import { ExportPanel } from './ExportPanel';
import { ScrollArea } from '@/components/ui/scroll-area';
import { Textarea } from '@/components/ui/textarea';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { FileText } from 'lucide-react';
import { effectsList } from '@/types/effects';


interface MainDisplayPanelProps {
  originalAudioDataUrl: string | null;
  processedAudioDataUrl: string | null;
  originalAudioBuffer: AudioBuffer | null; 
  processedAudioBuffer: AudioBuffer | null; 
  onExport: (format: string, quality: string, loopCount: number) => void;
  isLoading: boolean;
  analysisResult: string | null;
  analysisSourceEffectId: string | null;
  originalFileName?: string;
}

export function MainDisplayPanel({
  originalAudioDataUrl,
  processedAudioDataUrl,
  originalAudioBuffer,
  processedAudioBuffer,
  onExport,
  isLoading,
  analysisResult,
  analysisSourceEffectId,
  originalFileName
}: MainDisplayPanelProps) {
  const [isOriginalAudioPlaying, setIsOriginalAudioPlaying] = useState(false);
  const [isProcessedAudioPlaying, setIsProcessedAudioPlaying] = useState(false);

  const shouldShowGlobalAnalysisReport = () => {
    if (!analysisResult) return false;
    if (!analysisSourceEffectId) return true; 
    
    const effect = effectsList.find(e => e.id === analysisSourceEffectId);
    if (effect && effect.outputsAnalysis) {
      return false;
    }
    return true; 
  };


  return (
    <ScrollArea className="h-full p-4">
      <div className="space-y-6">
        <div className="grid grid-cols-1 lg:grid-cols-2 gap-4">
          <AudioPlayer 
            title="Original Audio" 
            audioSrc={originalAudioDataUrl} 
            fileName={originalFileName ? `original_${originalFileName}` : "original_audio.wav"}
            onPlayStateChange={setIsOriginalAudioPlaying}
          />
          <AudioPlayer 
            title="Processed Audio" 
            audioSrc={processedAudioDataUrl} 
            fileName={originalFileName ? `processed_${originalFileName}` : "processed_audio.wav"}
            onPlayStateChange={setIsProcessedAudioPlaying}
          />
        </div>
        
        <VisualizerSection 
          originalAudioBuffer={originalAudioBuffer}
          processedAudioBuffer={processedAudioBuffer} 
          isOriginalAudioPlaying={isOriginalAudioPlaying}
          isProcessedAudioPlaying={isProcessedAudioPlaying}
        />

        {shouldShowGlobalAnalysisReport() && analysisResult && (
          <Card className="shadow-md">
            <CardHeader>
              <CardTitle className="flex items-center gap-2">
                <FileText className="text-primary" />
                Analysis Report
              </CardTitle>
            </CardHeader>
            <CardContent>
              <Textarea
                readOnly
                value={analysisResult}
                className="min-h-[100px] bg-muted/50"
                aria-label="Tool Analysis Result"
              />
            </CardContent>
          </Card>
        )}

        <ExportPanel 
          processedAudioDataUrl={processedAudioDataUrl} 
          onExport={onExport}
          isLoading={isLoading}
        />
      </div>
    </ScrollArea>
  );
}


================================================
FILE: src/components/audio-forge/VisualizerSection.tsx
================================================
'use client';

import { FunctionalFrequencyVisualizer } from './FrequencyVisualizer';
import { FunctionalAmplitudePlotter } from './AmplitudePlotter'; 

interface VisualizerSectionProps {
  originalAudioBuffer: AudioBuffer | null;
  processedAudioBuffer: AudioBuffer | null;
  isOriginalAudioPlaying: boolean;
  isProcessedAudioPlaying: boolean;
}

export function VisualizerSection({ 
  originalAudioBuffer, 
  processedAudioBuffer, 
  isOriginalAudioPlaying, 
  isProcessedAudioPlaying 
}: VisualizerSectionProps) {

  let bufferForFreqViz: AudioBuffer | null = null;
  let isPlayingForFreqViz = false;

  if (isProcessedAudioPlaying && processedAudioBuffer) {
    bufferForFreqViz = processedAudioBuffer;
    isPlayingForFreqViz = true;
  } else if (isOriginalAudioPlaying && originalAudioBuffer) {
    bufferForFreqViz = originalAudioBuffer;
    isPlayingForFreqViz = true;
  }

  // Amplitude plotter shows processed if available, otherwise original (static view)
  const bufferForAmplitudePlotter = processedAudioBuffer ?? originalAudioBuffer;

  return (
    <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
      <FunctionalFrequencyVisualizer 
        audioBuffer={bufferForFreqViz} 
        isPlaying={isPlayingForFreqViz} 
      />
      <FunctionalAmplitudePlotter 
        audioBuffer={bufferForAmplitudePlotter} 
      />
    </div>
  );
}


================================================
FILE: src/components/auth/login-button.tsx
================================================

'use client';

import { useState, useEffect } from 'react';
import { Button } from '@/components/ui/button';
import { LogIn, LogOut, Loader2 } from 'lucide-react';
import { useToast } from "@/hooks/use-toast";
import { useRouter } from 'next/navigation';

export default function LoginButton() {
  const [isPuterReady, setIsPuterReady] = useState(false);
  const [isAuthenticated, setIsAuthenticated] = useState(false);
  const [isLoading, setIsLoading] = useState(true); 
  const [isActionLoading, setIsActionLoading] = useState(false);
  const { toast } = useToast();
  const router = useRouter();

  useEffect(() => {
    console.log("[LoginButton] useEffect for Puter availability check triggered.");
    const checkPuterAvailability = () => {
      if (typeof window.puter !== 'undefined' && typeof window.puter.auth !== 'undefined') {
        console.log("[LoginButton] Puter SDK is available.");
        setIsPuterReady(true);
        return true;
      }
      console.log("[LoginButton] Puter SDK not yet available.");
      return false;
    };

    if (checkPuterAvailability()) {
      // updateAuthState will be called via the isPuterReady useEffect
    } else {
      const intervalId = setInterval(() => {
        console.log("[LoginButton] Interval: Checking Puter SDK availability...");
        if (checkPuterAvailability()) {
          clearInterval(intervalId);
        }
      }, 100);
      return () => {
        console.log("[LoginButton] Cleanup: Clearing Puter availability check interval.");
        clearInterval(intervalId);
      };
    }
  }, []);

  useEffect(() => {
    if (isPuterReady) {
      console.log("[LoginButton] Puter SDK is ready, calling updateAuthState.");
      updateAuthState();
    } else {
      console.log("[LoginButton] isPuterReady useEffect: Puter SDK not ready yet.");
    }
  }, [isPuterReady]);

  const updateAuthState = async () => {
    if (!isPuterReady) {
      console.log("[LoginButton] updateAuthState: Aborted, Puter SDK not ready.");
      setIsLoading(true); 
      return;
    }
    console.log("[LoginButton] updateAuthState: Starting auth status check.");
    setIsLoading(true);
    try {
      const authStatus = await window.puter.auth.isSignedIn();
      console.log("[LoginButton] updateAuthState: Puter isSignedIn() returned:", authStatus);
      setIsAuthenticated(authStatus);
    } catch (error) {
      console.error("[LoginButton] updateAuthState: Error checking Puter auth status:", error);
      setIsAuthenticated(false);
    } finally {
      console.log("[LoginButton] updateAuthState: Finished. isLoading set to false.");
      setIsLoading(false);
    }
  };

  const handleLogin = async () => {
    if (!isPuterReady) {
      console.warn("[LoginButton] handleLogin: Aborted, Puter SDK not ready.");
      toast({ variant: "destructive", title: "Error", description: "Puter SDK not ready. Please try again in a moment." });
      return;
    }

    toast({
      title: "Puter Login Initiated",
      description: "The Puter login window is opening. Please wait a few moments for it to fully load before clicking your account.",
      variant: "default", 
      // Consider if a longer duration or specific class is needed for visibility
    });

    console.log("[LoginButton] handleLogin: Attempting Puter sign-in...");
    setIsActionLoading(true);
    try {
      // This call opens the Puter login popup.
      const signInResult = await window.puter.auth.signIn(); 
      console.log("[LoginButton] handleLogin: Puter signIn() call resolved. Result:", signInResult);

      // Crucially, re-check auth status *after* signIn promise resolves.
      const newAuthStatus = await window.puter.auth.isSignedIn();
      console.log("[LoginButton] handleLogin: Auth status after signIn and explicit check:", newAuthStatus);
      setIsAuthenticated(newAuthStatus);

      if (newAuthStatus) {
        toast({ title: "Login Successful", description: "Welcome to MediScan AI!" });
        if (window.location.pathname === '/login') {
          console.log("[LoginButton] handleLogin: Redirecting from /login to /");
          router.replace('/');
        }
      } else {
        // This case might indicate the popup closed without successful auth, or communication failed.
        console.warn("[LoginButton] handleLogin: Login process did not result in authenticated state after signIn() resolved and was re-checked.");
        toast({
            variant: "default", // Not necessarily destructive, could be user cancellation.
            title: "Login Incomplete",
            description: "Puter login process was not completed or was cancelled.",
        });
      }
    } catch (error) {
      // This catch block handles errors from puter.auth.signIn() itself,
      // e.g., if the popup couldn't be opened, or if Puter SDK throws an error.
      console.error("[LoginButton] handleLogin: Puter login error caught:", error);
      setIsAuthenticated(false); // Ensure auth state is false on error.
      toast({
        variant: "destructive",
        title: "Login Failed",
        description: "Puter login was unsuccessful or cancelled. Please try again.",
      });
    } finally {
      console.log("[LoginButton] handleLogin: Login action finished.");
      setIsActionLoading(false);
    }
  };

  const handleLogout = async () => {
    if (!isPuterReady) {
      console.warn("[LoginButton] handleLogout: Aborted, Puter SDK not ready.");
      toast({ variant: "destructive", title: "Error", description: "Puter SDK not ready. Please try again in a moment." });
      return;
    }
    console.log("[LoginButton] handleLogout: Attempting Puter sign-out...");
    setIsActionLoading(true);
    try {
      await window.puter.auth.signOut();
      console.log("[LoginButton] handleLogout: Puter signOut() successful.");
      setIsAuthenticated(false);
      toast({ title: "Logout Successful", description: "You have been logged out." });
      if (window.location.pathname !== '/login') {
        console.log("[LoginButton] handleLogout: Redirecting to /login.");
        router.replace('/login');
      }
    } catch (error) {
      console.error("[LoginButton] handleLogout: Puter logout error:", error);
       toast({
        variant: "destructive",
        title: "Logout Failed",
        description: "Could not log out from Puter.",
      });
    } finally {
      console.log("[LoginButton] handleLogout: Logout action finished.");
      setIsActionLoading(false);
    }
  };

  if (!isPuterReady || isLoading) {
    return <Button variant="outline" size="default" disabled><Loader2 className="animate-spin h-4 w-4 mr-2" />Loading Auth...</Button>;
  }

  if (isAuthenticated) {
    return (
      <Button variant="outline" onClick={handleLogout} disabled={isActionLoading}>
        {isActionLoading ? <Loader2 className="animate-spin h-4 w-4 mr-2" /> : <LogOut className="mr-2 h-4 w-4" />}
         Logout
      </Button>
    );
  }

  return (
    <Button onClick={handleLogin} disabled={isActionLoading}>
      {isActionLoading ? <Loader2 className="animate-spin h-4 w-4 mr-2" /> : <LogIn className="mr-2 h-4 w-4" />}
      Login with Puter
    </Button>
  );
}



================================================
FILE: src/components/layout/footer.tsx
================================================
import Link from 'next/link';
import React from 'react';
import { Shield, Eye, Cookie, HelpCircle, Package, Mail } from 'lucide-react';
import { FaXTwitter, FaLinkedin, FaDiscord, FaGithub } from 'react-icons/fa6';

export default function Footer() {
  return (
    <footer className="fixed bottom-0 left-0 right-0 z-20 w-full bg-gradient-to-t from-black via-black/70 to-transparent text-white py-4 px-8">
      <div className="container mx-auto flex flex-col md:flex-row justify-between items-center md:items-start text-center md:text-left">
        {/* Left side links */}
        <div className="flex flex-wrap justify-center md:justify-start space-x-4 mb-2 md:mb-0">
          <Link href="/terms-of-service" className="text-muted-foreground hover:text-primary transition-colors flex items-center md:space-x-2">
            <Shield className="h-4 w-4 mr-2" />
            <span className="hidden md:inline">Terms</span>
          </Link>
          <Link href="/privacy-policy" className="text-muted-foreground hover:text-primary transition-colors flex items-center md:space-x-2">
            <Eye className="h-4 w-4 mr-2" />
            <span className="hidden md:inline">Privacy</span>
          </Link>
          <Link href="/cookies" className="text-muted-foreground hover:text-primary transition-colors flex items-center md:space-x-2">
            <Cookie className="h-4 w-4 mr-2" />
            <span className="hidden md:inline">Cookies</span>
          </Link>
          <Link href="/faq" className="text-muted-foreground hover:text-primary transition-colors flex items-center md:space-x-2">
            <HelpCircle className="h-4 w-4 mr-2" />
            <span className="hidden md:inline">FAQ</span>
          </Link>
          <Link href="/third-party-licenses" className="text-muted-foreground hover:text-primary transition-colors flex items-center md:space-x-2">
            <Package className="h-4 w-4 mr-2" />
            <span className="hidden md:inline">Licenses</span>
          </Link>
          <a href="mailto:jeffrinjames99@gmail.com" className="text-muted-foreground hover:text-primary transition-colors flex items-center md:space-x-2">
            <Mail className="h-4 w-4 mr-2" />
            <span className="hidden md:inline">jeffrinjames99@gmail.com</span>
          </a>

        </div>

        {/* Right side text/links */}
        <div className="flex flex-col md:flex-row items-center text-sm">
          <Link href="https://onee.page/jeffrin" target="_blank" rel="noopener noreferrer" className="text-muted-foreground hover:text-primary transition-colors">
            Created by Jeffrin
          </Link>
          <div className="flex flex-wrap justify-center space-x-4 ml-4 items-center">
            <Link href="https://www.linkedin.com/in/jeffrin-james-387037371/" target="_blank" rel="noopener noreferrer" className="text-muted-foreground hover:text-primary transition-colors">
              <FaLinkedin className="h-5 w-5" />
            </Link>
            <Link href="https://x.com/jeff9james" target="_blank" rel="noopener noreferrer" className="text-muted-foreground hover:text-primary transition-colors">
              <FaXTwitter className="h-5 w-5" />
            </Link>
            <Link href="https://github.com/Unselfisheologism" target="_blank" rel="noopener noreferrer" className="text-muted-foreground hover:text-primary transition-colors">
              <FaGithub className="h-5 w-5" />
            </Link>
            <Link href="https://discord.gg/nzzRKx42" target="_blank" rel="noopener noreferrer" className="text-muted-foreground hover:text-primary transition-colors">
              <FaDiscord className="h-5 w-5" />
            </Link>
          </div>
        </div>
      </div>
    </footer>
  );
}


================================================
FILE: src/components/layout/Sidebar.tsx
================================================
import React from 'react';
import Link from 'next/link';
import { XIcon } from 'lucide-react';

interface SidebarProps {
  isOpen: boolean;
  onClose: () => void;
}

const Sidebar: React.FC<SidebarProps> = ({ isOpen, onClose }) => {
  return (
    <div
      className={`fixed inset-y-0 left-0 w-64 bg-card/80 backdrop-blur-sm text-foreground transition-transform duration-300 ease-in-out ${
        isOpen ? 'translate-x-0' : '-translate-x-full'
      } z-50 rounded-r-lg`}
    >
      <div className="flex justify-end p-4">
        <button onClick={onClose} className="text-foreground">
          <XIcon className="h-6 w-6" />
        </button>
      </div>
      <nav className="flex flex-col p-4 space-y-2">
        <Link href="/free-tools" className="text-foreground hover:text-muted-foreground" onClick={onClose}>
          Free Tools
        </Link>
        <Link href="/blog" className="text-foreground hover:text-muted-foreground" onClick={onClose}>
          Blog
        </Link>
        <Link href="/use-cases" className="text-foreground hover:text-muted-foreground" onClick={onClose}>
          Use Cases
        </Link>
        <Link href="/pricing" className="text-foreground hover:text-muted-foreground" onClick={onClose}>
          Pricing
        </Link>
        <Link href="/faq" className="text-foreground hover:text-muted-foreground" onClick={onClose}>
          FAQ
        </Link>
        <Link href="/support" className="text-foreground hover:text-muted-foreground" onClick={onClose}>
          Support
        </Link>
      </nav>
    </div>
  );
};

export default Sidebar;


================================================
FILE: src/components/medi-scan/image-preview.tsx
================================================
import { useState } from 'react';
import type { ImageAttentionArea } from '@/types/heatmap-generator';

interface ImagePreviewProps {
  imageDataUrl: string;
  dataAiHint?: string;
  highAttentionAreas?: ImageAttentionArea[];
  lowAttentionAreas?: ImageAttentionArea[];
}

export default function ImagePreview({ 
  imageDataUrl, 
  dataAiHint = "medical image",
  highAttentionAreas,
  lowAttentionAreas 
}: ImagePreviewProps) {
  const [imageLoaded, setImageLoaded] = useState(false);

  return (
    <div className="mt-4">
      <div className="relative rounded-lg overflow-hidden border border-border">
        <img
          src={imageDataUrl}
          alt={`Preview of ${dataAiHint}`}
          className="w-full h-auto max-h-96 object-contain"
          onLoad={() => setImageLoaded(true)}
        />
        
        {/* Overlay attention areas for heatmap generator */}
        {imageLoaded && (highAttentionAreas || lowAttentionAreas) && (
          <div className="absolute inset-0 pointer-events-none">
            {/* High attention areas - red markers */}
            {highAttentionAreas?.map((area, index) => (
              <div
                key={`high-${index}`}
                className="absolute w-4 h-4 bg-red-500/70 rounded-full border-2 border-red-600"
                style={{
                  top: getLocationPosition(area.location_hint).top,
                  left: getLocationPosition(area.location_hint).left,
                  transform: 'translate(-50%, -50%)'
                }}
                title={`High Attention: ${area.area_description}`}
              />
            ))}
            
            {/* Low attention areas - blue markers */}
            {lowAttentionAreas?.map((area, index) => (
              <div
                key={`low-${index}`}
                className="absolute w-4 h-4 bg-blue-500/70 rounded-full border-2 border-blue-600"
                style={{
                  top: getLocationPosition(area.location_hint).top,
                  left: getLocationPosition(area.location_hint).left,
                  transform: 'translate(-50%, -50%)'
                }}
                title={`Low Attention: ${area.area_description}`}
              />
            ))}
          </div>
        )}
      </div>
      <p className="text-sm text-muted-foreground mt-2 text-center">
        Preview of uploaded {dataAiHint}
      </p>
    </div>
  );
}

// Helper function to convert location hints to CSS positions
function getLocationPosition(locationHint?: string): { top: string; left: string } {
  if (!locationHint) return { top: '50%', left: '50%' };
  
  switch (locationHint.toLowerCase()) {
    case 'center':
      return { top: '50%', left: '50%' };
    case 'top-center':
      return { top: '20%', left: '50%' };
    case 'bottom-center':
      return { top: '80%', left: '50%' };
    case 'left-center':
      return { top: '50%', left: '20%' };
    case 'right-center':
      return { top: '50%', left: '80%' };
    case 'top-left':
      return { top: '20%', left: '20%' };
    case 'top-right':
      return { top: '20%', left: '80%' };
    case 'bottom-left':
      return { top: '80%', left: '20%' };
    case 'bottom-right':
      return { top: '80%', left: '80%' };
    default:
      // For custom location hints, try to parse or default to center
      return { top: '50%', left: '50%' };
  }
}


================================================
FILE: src/components/ui/accordion.tsx
================================================
"use client"

import * as React from "react"
import * as AccordionPrimitive from "@radix-ui/react-accordion"
import { ChevronDown } from "lucide-react"

import { cn } from "@/lib/utils"

const Accordion = AccordionPrimitive.Root

const AccordionItem = React.forwardRef<
  React.ElementRef<typeof AccordionPrimitive.Item>,
  React.ComponentPropsWithoutRef<typeof AccordionPrimitive.Item>
>(({ className, ...props }, ref) => (
  <AccordionPrimitive.Item
    ref={ref}
    className={cn("border-b", className)}
    {...props}
  />
))
AccordionItem.displayName = "AccordionItem"

const AccordionTrigger = React.forwardRef<
  React.ElementRef<typeof AccordionPrimitive.Trigger>,
  React.ComponentPropsWithoutRef<typeof AccordionPrimitive.Trigger>
>(({ className, children, ...props }, ref) => (
  <AccordionPrimitive.Header className="flex">
    <AccordionPrimitive.Trigger
      ref={ref}
      className={cn(
        "flex flex-1 items-center justify-between py-4 font-medium transition-all hover:underline [&[data-state=open]>svg]:rotate-180",
        className
      )}
      {...props}
    >
      {children}
      <ChevronDown className="h-4 w-4 shrink-0 transition-transform duration-200" />
    </AccordionPrimitive.Trigger>
  </AccordionPrimitive.Header>
))
AccordionTrigger.displayName = AccordionPrimitive.Trigger.displayName

const AccordionContent = React.forwardRef<
  React.ElementRef<typeof AccordionPrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof AccordionPrimitive.Content>
>(({ className, children, ...props }, ref) => (
  <AccordionPrimitive.Content
    ref={ref}
    className="overflow-hidden text-sm transition-all data-[state=closed]:animate-accordion-up data-[state=open]:animate-accordion-down"
    {...props}
  >
    <div className={cn("pb-4 pt-0", className)}>{children}</div>
  </AccordionPrimitive.Content>
))

AccordionContent.displayName = AccordionPrimitive.Content.displayName

export { Accordion, AccordionItem, AccordionTrigger, AccordionContent }



================================================
FILE: src/components/ui/alert-dialog.tsx
================================================
"use client"

import * as React from "react"
import * as AlertDialogPrimitive from "@radix-ui/react-alert-dialog"

import { cn } from "@/lib/utils"
import { buttonVariants } from "@/components/ui/button"

const AlertDialog = AlertDialogPrimitive.Root

const AlertDialogTrigger = AlertDialogPrimitive.Trigger

const AlertDialogPortal = AlertDialogPrimitive.Portal

const AlertDialogOverlay = React.forwardRef<
  React.ElementRef<typeof AlertDialogPrimitive.Overlay>,
  React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Overlay>
>(({ className, ...props }, ref) => (
  <AlertDialogPrimitive.Overlay
    className={cn(
      "fixed inset-0 z-50 bg-black/80  data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0",
      className
    )}
    {...props}
    ref={ref}
  />
))
AlertDialogOverlay.displayName = AlertDialogPrimitive.Overlay.displayName

const AlertDialogContent = React.forwardRef<
  React.ElementRef<typeof AlertDialogPrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Content>
>(({ className, ...props }, ref) => (
  <AlertDialogPortal>
    <AlertDialogOverlay />
    <AlertDialogPrimitive.Content
      ref={ref}
      className={cn(
        "fixed left-[50%] top-[50%] z-50 grid w-full max-w-lg translate-x-[-50%] translate-y-[-50%] gap-4 border bg-background p-6 shadow-lg duration-200 data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[state=closed]:slide-out-to-left-1/2 data-[state=closed]:slide-out-to-top-[48%] data-[state=open]:slide-in-from-left-1/2 data-[state=open]:slide-in-from-top-[48%] sm:rounded-lg",
        className
      )}
      {...props}
    />
  </AlertDialogPortal>
))
AlertDialogContent.displayName = AlertDialogPrimitive.Content.displayName

const AlertDialogHeader = ({
  className,
  ...props
}: React.HTMLAttributes<HTMLDivElement>) => (
  <div
    className={cn(
      "flex flex-col space-y-2 text-center sm:text-left",
      className
    )}
    {...props}
  />
)
AlertDialogHeader.displayName = "AlertDialogHeader"

const AlertDialogFooter = ({
  className,
  ...props
}: React.HTMLAttributes<HTMLDivElement>) => (
  <div
    className={cn(
      "flex flex-col-reverse sm:flex-row sm:justify-end sm:space-x-2",
      className
    )}
    {...props}
  />
)
AlertDialogFooter.displayName = "AlertDialogFooter"

const AlertDialogTitle = React.forwardRef<
  React.ElementRef<typeof AlertDialogPrimitive.Title>,
  React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Title>
>(({ className, ...props }, ref) => (
  <AlertDialogPrimitive.Title
    ref={ref}
    className={cn("text-lg font-semibold", className)}
    {...props}
  />
))
AlertDialogTitle.displayName = AlertDialogPrimitive.Title.displayName

const AlertDialogDescription = React.forwardRef<
  React.ElementRef<typeof AlertDialogPrimitive.Description>,
  React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Description>
>(({ className, ...props }, ref) => (
  <AlertDialogPrimitive.Description
    ref={ref}
    className={cn("text-sm text-muted-foreground", className)}
    {...props}
  />
))
AlertDialogDescription.displayName =
  AlertDialogPrimitive.Description.displayName

const AlertDialogAction = React.forwardRef<
  React.ElementRef<typeof AlertDialogPrimitive.Action>,
  React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Action>
>(({ className, ...props }, ref) => (
  <AlertDialogPrimitive.Action
    ref={ref}
    className={cn(buttonVariants(), className)}
    {...props}
  />
))
AlertDialogAction.displayName = AlertDialogPrimitive.Action.displayName

const AlertDialogCancel = React.forwardRef<
  React.ElementRef<typeof AlertDialogPrimitive.Cancel>,
  React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Cancel>
>(({ className, ...props }, ref) => (
  <AlertDialogPrimitive.Cancel
    ref={ref}
    className={cn(
      buttonVariants({ variant: "outline" }),
      "mt-2 sm:mt-0",
      className
    )}
    {...props}
  />
))
AlertDialogCancel.displayName = AlertDialogPrimitive.Cancel.displayName

export {
  AlertDialog,
  AlertDialogPortal,
  AlertDialogOverlay,
  AlertDialogTrigger,
  AlertDialogContent,
  AlertDialogHeader,
  AlertDialogFooter,
  AlertDialogTitle,
  AlertDialogDescription,
  AlertDialogAction,
  AlertDialogCancel,
}



================================================
FILE: src/components/ui/alert.tsx
================================================
import * as React from "react"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "@/lib/utils"

const alertVariants = cva(
  "relative w-full rounded-lg border p-4 [&>svg~*]:pl-7 [&>svg+div]:translate-y-[-3px] [&>svg]:absolute [&>svg]:left-4 [&>svg]:top-4 [&>svg]:text-foreground",
  {
    variants: {
      variant: {
        default: "bg-background text-foreground",
        destructive:
          "border-destructive/50 text-destructive dark:border-destructive [&>svg]:text-destructive",
      },
    },
    defaultVariants: {
      variant: "default",
    },
  }
)

const Alert = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement> & VariantProps<typeof alertVariants>
>(({ className, variant, ...props }, ref) => (
  <div
    ref={ref}
    role="alert"
    className={cn(alertVariants({ variant }), className)}
    {...props}
  />
))
Alert.displayName = "Alert"

const AlertTitle = React.forwardRef<
  HTMLParagraphElement,
  React.HTMLAttributes<HTMLHeadingElement>
>(({ className, ...props }, ref) => (
  <h5
    ref={ref}
    className={cn("mb-1 font-medium leading-none tracking-tight", className)}
    {...props}
  />
))
AlertTitle.displayName = "AlertTitle"

const AlertDescription = React.forwardRef<
  HTMLParagraphElement,
  React.HTMLAttributes<HTMLParagraphElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("text-sm [&_p]:leading-relaxed", className)}
    {...props}
  />
))
AlertDescription.displayName = "AlertDescription"

export { Alert, AlertTitle, AlertDescription }



================================================
FILE: src/components/ui/avatar.tsx
================================================
"use client"

import * as React from "react"
import * as AvatarPrimitive from "@radix-ui/react-avatar"

import { cn } from "@/lib/utils"

const Avatar = React.forwardRef<
  React.ElementRef<typeof AvatarPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof AvatarPrimitive.Root>
>(({ className, ...props }, ref) => (
  <AvatarPrimitive.Root
    ref={ref}
    className={cn(
      "relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full",
      className
    )}
    {...props}
  />
))
Avatar.displayName = AvatarPrimitive.Root.displayName

const AvatarImage = React.forwardRef<
  React.ElementRef<typeof AvatarPrimitive.Image>,
  React.ComponentPropsWithoutRef<typeof AvatarPrimitive.Image>
>(({ className, ...props }, ref) => (
  <AvatarPrimitive.Image
    ref={ref}
    className={cn("aspect-square h-full w-full", className)}
    {...props}
  />
))
AvatarImage.displayName = AvatarPrimitive.Image.displayName

const AvatarFallback = React.forwardRef<
  React.ElementRef<typeof AvatarPrimitive.Fallback>,
  React.ComponentPropsWithoutRef<typeof AvatarPrimitive.Fallback>
>(({ className, ...props }, ref) => (
  <AvatarPrimitive.Fallback
    ref={ref}
    className={cn(
      "flex h-full w-full items-center justify-center rounded-full bg-muted",
      className
    )}
    {...props}
  />
))
AvatarFallback.displayName = AvatarPrimitive.Fallback.displayName

export { Avatar, AvatarImage, AvatarFallback }



================================================
FILE: src/components/ui/badge.tsx
================================================
import * as React from "react"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "@/lib/utils"

const badgeVariants = cva(
  "inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2",
  {
    variants: {
      variant: {
        default:
          "border-transparent bg-primary text-primary-foreground hover:bg-primary/80",
        secondary:
          "border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80",
        destructive:
          "border-transparent bg-destructive text-destructive-foreground hover:bg-destructive/80",
        outline: "text-foreground",
      },
    },
    defaultVariants: {
      variant: "default",
    },
  }
)

export interface BadgeProps
  extends React.HTMLAttributes<HTMLDivElement>,
    VariantProps<typeof badgeVariants> {}

function Badge({ className, variant, ...props }: BadgeProps) {
  return (
    <div className={cn(badgeVariants({ variant }), className)} {...props} />
  )
}

export { Badge, badgeVariants }



================================================
FILE: src/components/ui/button.tsx
================================================
import * as React from "react"
import { Slot } from "@radix-ui/react-slot"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "@/lib/utils"

const buttonVariants = cva(
  "inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0",
  {
    variants: {
      variant: {
        default: "bg-primary text-primary-foreground hover:bg-primary/90",
        destructive:
          "bg-destructive text-destructive-foreground hover:bg-destructive/90",
        outline:
          "border border-input bg-background hover:bg-accent hover:text-accent-foreground",
        secondary:
          "bg-secondary text-secondary-foreground hover:bg-secondary/80",
        ghost: "hover:bg-accent hover:text-accent-foreground",
        link: "text-primary underline-offset-4 hover:underline",
      },
      size: {
        default: "h-10 px-4 py-2",
        sm: "h-9 rounded-md px-3",
        lg: "h-11 rounded-md px-8",
        icon: "h-10 w-10",
      },
    },
    defaultVariants: {
      variant: "default",
      size: "default",
    },
  }
)

export interface ButtonProps
  extends React.ButtonHTMLAttributes<HTMLButtonElement>,
    VariantProps<typeof buttonVariants> {
  asChild?: boolean
}

const Button = React.forwardRef<HTMLButtonElement, ButtonProps>(
  ({ className, variant, size, asChild = false, ...props }, ref) => {
    const Comp = asChild ? Slot : "button"
    return (
      <Comp
        className={cn(buttonVariants({ variant, size, className }))}
        ref={ref}
        {...props}
      />
    )
  }
)
Button.displayName = "Button"

export { Button, buttonVariants }



================================================
FILE: src/components/ui/calendar.tsx
================================================
"use client"

import * as React from "react"
import { ChevronLeft, ChevronRight } from "lucide-react"
import { DayPicker } from "react-day-picker"

import { cn } from "@/lib/utils"
import { buttonVariants } from "@/components/ui/button"

export type CalendarProps = React.ComponentProps<typeof DayPicker>

function Calendar({
  className,
  classNames,
  showOutsideDays = true,
  ...props
}: CalendarProps) {
  return (
    <DayPicker
      showOutsideDays={showOutsideDays}
      className={cn("p-3", className)}
      classNames={{
        months: "flex flex-col sm:flex-row space-y-4 sm:space-x-4 sm:space-y-0",
        month: "space-y-4",
        caption: "flex justify-center pt-1 relative items-center",
        caption_label: "text-sm font-medium",
        nav: "space-x-1 flex items-center",
        nav_button: cn(
          buttonVariants({ variant: "outline" }),
          "h-7 w-7 bg-transparent p-0 opacity-50 hover:opacity-100"
        ),
        nav_button_previous: "absolute left-1",
        nav_button_next: "absolute right-1",
        table: "w-full border-collapse space-y-1",
        head_row: "flex",
        head_cell:
          "text-muted-foreground rounded-md w-9 font-normal text-[0.8rem]",
        row: "flex w-full mt-2",
        cell: "h-9 w-9 text-center text-sm p-0 relative [&:has([aria-selected].day-range-end)]:rounded-r-md [&:has([aria-selected].day-outside)]:bg-accent/50 [&:has([aria-selected])]:bg-accent first:[&:has([aria-selected])]:rounded-l-md last:[&:has([aria-selected])]:rounded-r-md focus-within:relative focus-within:z-20",
        day: cn(
          buttonVariants({ variant: "ghost" }),
          "h-9 w-9 p-0 font-normal aria-selected:opacity-100"
        ),
        day_range_end: "day-range-end",
        day_selected:
          "bg-primary text-primary-foreground hover:bg-primary hover:text-primary-foreground focus:bg-primary focus:text-primary-foreground",
        day_today: "bg-accent text-accent-foreground",
        day_outside:
          "day-outside text-muted-foreground aria-selected:bg-accent/50 aria-selected:text-muted-foreground",
        day_disabled: "text-muted-foreground opacity-50",
        day_range_middle:
          "aria-selected:bg-accent aria-selected:text-accent-foreground",
        day_hidden: "invisible",
        ...classNames,
      }}
      components={{
        IconLeft: ({ className, ...props }) => (
          <ChevronLeft className={cn("h-4 w-4", className)} {...props} />
        ),
        IconRight: ({ className, ...props }) => (
          <ChevronRight className={cn("h-4 w-4", className)} {...props} />
        ),
      }}
      {...props}
    />
  )
}
Calendar.displayName = "Calendar"

export { Calendar }



================================================
FILE: src/components/ui/card.tsx
================================================
import * as React from "react"

import { cn } from "@/lib/utils"

const Card = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn(
      "rounded-lg border bg-card text-card-foreground shadow-sm",
      className
    )}
    {...props}
  />
))
Card.displayName = "Card"

const CardHeader = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("flex flex-col space-y-1.5 p-6", className)}
    {...props}
  />
))
CardHeader.displayName = "CardHeader"

const CardTitle = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn(
      "text-2xl font-semibold leading-none tracking-tight",
      className
    )}
    {...props}
  />
))
CardTitle.displayName = "CardTitle"

const CardDescription = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("text-sm text-muted-foreground", className)}
    {...props}
  />
))
CardDescription.displayName = "CardDescription"

const CardContent = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div ref={ref} className={cn("p-6 pt-0", className)} {...props} />
))
CardContent.displayName = "CardContent"

const CardFooter = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("flex items-center p-6 pt-0", className)}
    {...props}
  />
))
CardFooter.displayName = "CardFooter"

export { Card, CardHeader, CardFooter, CardTitle, CardDescription, CardContent }



================================================
FILE: src/components/ui/chart.tsx
================================================
"use client"

import * as React from "react"
import * as RechartsPrimitive from "recharts"

import { cn } from "@/lib/utils"

// Format: { THEME_NAME: CSS_SELECTOR }
const THEMES = { light: "", dark: ".dark" } as const

export type ChartConfig = {
  [k in string]: {
    label?: React.ReactNode
    icon?: React.ComponentType
  } & (
    | { color?: string; theme?: never }
    | { color?: never; theme: Record<keyof typeof THEMES, string> }
  )
}

type ChartContextProps = {
  config: ChartConfig
}

const ChartContext = React.createContext<ChartContextProps | null>(null)

function useChart() {
  const context = React.useContext(ChartContext)

  if (!context) {
    throw new Error("useChart must be used within a <ChartContainer />")
  }

  return context
}

const ChartContainer = React.forwardRef<
  HTMLDivElement,
  React.ComponentProps<"div"> & {
    config: ChartConfig
    children: React.ComponentProps<
      typeof RechartsPrimitive.ResponsiveContainer
    >["children"]
  }
>(({ id, className, children, config, ...props }, ref) => {
  const uniqueId = React.useId()
  const chartId = `chart-${id || uniqueId.replace(/:/g, "")}`

  return (
    <ChartContext.Provider value={{ config }}>
      <div
        data-chart={chartId}
        ref={ref}
        className={cn(
          "flex aspect-video justify-center text-xs [&_.recharts-cartesian-axis-tick_text]:fill-muted-foreground [&_.recharts-cartesian-grid_line[stroke='#ccc']]:stroke-border/50 [&_.recharts-curve.recharts-tooltip-cursor]:stroke-border [&_.recharts-dot[stroke='#fff']]:stroke-transparent [&_.recharts-layer]:outline-none [&_.recharts-polar-grid_[stroke='#ccc']]:stroke-border [&_.recharts-radial-bar-background-sector]:fill-muted [&_.recharts-rectangle.recharts-tooltip-cursor]:fill-muted [&_.recharts-reference-line_[stroke='#ccc']]:stroke-border [&_.recharts-sector[stroke='#fff']]:stroke-transparent [&_.recharts-sector]:outline-none [&_.recharts-surface]:outline-none",
          className
        )}
        {...props}
      >
        <ChartStyle id={chartId} config={config} />
        <RechartsPrimitive.ResponsiveContainer>
          {children}
        </RechartsPrimitive.ResponsiveContainer>
      </div>
    </ChartContext.Provider>
  )
})
ChartContainer.displayName = "Chart"

const ChartStyle = ({ id, config }: { id: string; config: ChartConfig }) => {
  const colorConfig = Object.entries(config).filter(
    ([, config]) => config.theme || config.color
  )

  if (!colorConfig.length) {
    return null
  }

  return (
    <style
      dangerouslySetInnerHTML={{
        __html: Object.entries(THEMES)
          .map(
            ([theme, prefix]) => `
${prefix} [data-chart=${id}] {
${colorConfig
  .map(([key, itemConfig]) => {
    const color =
      itemConfig.theme?.[theme as keyof typeof itemConfig.theme] ||
      itemConfig.color
    return color ? `  --color-${key}: ${color};` : null
  })
  .join("\n")}
}
`
          )
          .join("\n"),
      }}
    />
  )
}

const ChartTooltip = RechartsPrimitive.Tooltip

const ChartTooltipContent = React.forwardRef<
  HTMLDivElement,
  React.ComponentProps<typeof RechartsPrimitive.Tooltip> &
    React.ComponentProps<"div"> & {
      hideLabel?: boolean
      hideIndicator?: boolean
      indicator?: "line" | "dot" | "dashed"
      nameKey?: string
      labelKey?: string
    }
>(
  (
    {
      active,
      payload,
      className,
      indicator = "dot",
      hideLabel = false,
      hideIndicator = false,
      label,
      labelFormatter,
      labelClassName,
      formatter,
      color,
      nameKey,
      labelKey,
    },
    ref
  ) => {
    const { config } = useChart()

    const tooltipLabel = React.useMemo(() => {
      if (hideLabel || !payload?.length) {
        return null
      }

      const [item] = payload
      const key = `${labelKey || item.dataKey || item.name || "value"}`
      const itemConfig = getPayloadConfigFromPayload(config, item, key)
      const value =
        !labelKey && typeof label === "string"
          ? config[label as keyof typeof config]?.label || label
          : itemConfig?.label

      if (labelFormatter) {
        return (
          <div className={cn("font-medium", labelClassName)}>
            {labelFormatter(value, payload)}
          </div>
        )
      }

      if (!value) {
        return null
      }

      return <div className={cn("font-medium", labelClassName)}>{value}</div>
    }, [
      label,
      labelFormatter,
      payload,
      hideLabel,
      labelClassName,
      config,
      labelKey,
    ])

    if (!active || !payload?.length) {
      return null
    }

    const nestLabel = payload.length === 1 && indicator !== "dot"

    return (
      <div
        ref={ref}
        className={cn(
          "grid min-w-[8rem] items-start gap-1.5 rounded-lg border border-border/50 bg-background px-2.5 py-1.5 text-xs shadow-xl",
          className
        )}
      >
        {!nestLabel ? tooltipLabel : null}
        <div className="grid gap-1.5">
          {payload.map((item, index) => {
            const key = `${nameKey || item.name || item.dataKey || "value"}`
            const itemConfig = getPayloadConfigFromPayload(config, item, key)
            const indicatorColor = color || item.payload.fill || item.color

            return (
              <div
                key={item.dataKey}
                className={cn(
                  "flex w-full flex-wrap items-stretch gap-2 [&>svg]:h-2.5 [&>svg]:w-2.5 [&>svg]:text-muted-foreground",
                  indicator === "dot" && "items-center"
                )}
              >
                {formatter && item?.value !== undefined && item.name ? (
                  formatter(item.value, item.name, item, index, item.payload)
                ) : (
                  <>
                    {itemConfig?.icon ? (
                      <itemConfig.icon />
                    ) : (
                      !hideIndicator && (
                        <div
                          className={cn(
                            "shrink-0 rounded-[2px] border-[--color-border] bg-[--color-bg]",
                            {
                              "h-2.5 w-2.5": indicator === "dot",
                              "w-1": indicator === "line",
                              "w-0 border-[1.5px] border-dashed bg-transparent":
                                indicator === "dashed",
                              "my-0.5": nestLabel && indicator === "dashed",
                            }
                          )}
                          style={
                            {
                              "--color-bg": indicatorColor,
                              "--color-border": indicatorColor,
                            } as React.CSSProperties
                          }
                        />
                      )
                    )}
                    <div
                      className={cn(
                        "flex flex-1 justify-between leading-none",
                        nestLabel ? "items-end" : "items-center"
                      )}
                    >
                      <div className="grid gap-1.5">
                        {nestLabel ? tooltipLabel : null}
                        <span className="text-muted-foreground">
                          {itemConfig?.label || item.name}
                        </span>
                      </div>
                      {item.value && (
                        <span className="font-mono font-medium tabular-nums text-foreground">
                          {item.value.toLocaleString()}
                        </span>
                      )}
                    </div>
                  </>
                )}
              </div>
            )
          })}
        </div>
      </div>
    )
  }
)
ChartTooltipContent.displayName = "ChartTooltip"

const ChartLegend = RechartsPrimitive.Legend

const ChartLegendContent = React.forwardRef<
  HTMLDivElement,
  React.ComponentProps<"div"> &
    Pick<RechartsPrimitive.LegendProps, "payload" | "verticalAlign"> & {
      hideIcon?: boolean
      nameKey?: string
    }
>(
  (
    { className, hideIcon = false, payload, verticalAlign = "bottom", nameKey },
    ref
  ) => {
    const { config } = useChart()

    if (!payload?.length) {
      return null
    }

    return (
      <div
        ref={ref}
        className={cn(
          "flex items-center justify-center gap-4",
          verticalAlign === "top" ? "pb-3" : "pt-3",
          className
        )}
      >
        {payload.map((item) => {
          const key = `${nameKey || item.dataKey || "value"}`
          const itemConfig = getPayloadConfigFromPayload(config, item, key)

          return (
            <div
              key={item.value}
              className={cn(
                "flex items-center gap-1.5 [&>svg]:h-3 [&>svg]:w-3 [&>svg]:text-muted-foreground"
              )}
            >
              {itemConfig?.icon && !hideIcon ? (
                <itemConfig.icon />
              ) : (
                <div
                  className="h-2 w-2 shrink-0 rounded-[2px]"
                  style={{
                    backgroundColor: item.color,
                  }}
                />
              )}
              {itemConfig?.label}
            </div>
          )
        })}
      </div>
    )
  }
)
ChartLegendContent.displayName = "ChartLegend"

// Helper to extract item config from a payload.
function getPayloadConfigFromPayload(
  config: ChartConfig,
  payload: unknown,
  key: string
) {
  if (typeof payload !== "object" || payload === null) {
    return undefined
  }

  const payloadPayload =
    "payload" in payload &&
    typeof payload.payload === "object" &&
    payload.payload !== null
      ? payload.payload
      : undefined

  let configLabelKey: string = key

  if (
    key in payload &&
    typeof payload[key as keyof typeof payload] === "string"
  ) {
    configLabelKey = payload[key as keyof typeof payload] as string
  } else if (
    payloadPayload &&
    key in payloadPayload &&
    typeof payloadPayload[key as keyof typeof payloadPayload] === "string"
  ) {
    configLabelKey = payloadPayload[
      key as keyof typeof payloadPayload
    ] as string
  }

  return configLabelKey in config
    ? config[configLabelKey]
    : config[key as keyof typeof config]
}

export {
  ChartContainer,
  ChartTooltip,
  ChartTooltipContent,
  ChartLegend,
  ChartLegendContent,
  ChartStyle,
}



================================================
FILE: src/components/ui/checkbox.tsx
================================================
"use client"

import * as React from "react"
import * as CheckboxPrimitive from "@radix-ui/react-checkbox"
import { Check } from "lucide-react"

import { cn } from "@/lib/utils"

const Checkbox = React.forwardRef<
  React.ElementRef<typeof CheckboxPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof CheckboxPrimitive.Root>
>(({ className, ...props }, ref) => (
  <CheckboxPrimitive.Root
    ref={ref}
    className={cn(
      "peer h-4 w-4 shrink-0 rounded-sm border border-primary ring-offset-background focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50 data-[state=checked]:bg-primary data-[state=checked]:text-primary-foreground",
      className
    )}
    {...props}
  >
    <CheckboxPrimitive.Indicator
      className={cn("flex items-center justify-center text-current")}
    >
      <Check className="h-4 w-4" />
    </CheckboxPrimitive.Indicator>
  </CheckboxPrimitive.Root>
))
Checkbox.displayName = CheckboxPrimitive.Root.displayName

export { Checkbox }



================================================
FILE: src/components/ui/dialog.tsx
================================================
"use client"

import * as React from "react"
import * as DialogPrimitive from "@radix-ui/react-dialog"
import { X } from "lucide-react"

import { cn } from "@/lib/utils"

const Dialog = DialogPrimitive.Root

const DialogTrigger = DialogPrimitive.Trigger

const DialogPortal = DialogPrimitive.Portal

const DialogClose = DialogPrimitive.Close

const DialogOverlay = React.forwardRef<
  React.ElementRef<typeof DialogPrimitive.Overlay>,
  React.ComponentPropsWithoutRef<typeof DialogPrimitive.Overlay>
>(({ className, ...props }, ref) => (
  <DialogPrimitive.Overlay
    ref={ref}
    className={cn(
      "fixed inset-0 z-50 bg-black/80 data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0",
      className
    )}
    {...props}
  />
))
DialogOverlay.displayName = DialogPrimitive.Overlay.displayName

const DialogContent = React.forwardRef<
  React.ElementRef<typeof DialogPrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof DialogPrimitive.Content>
>(({ className, children, ...props }, ref) => (
  <DialogPortal>
    <DialogOverlay />
    <DialogPrimitive.Content
      ref={ref}
      className={cn(
        "fixed left-[50%] top-[50%] z-50 grid w-full max-w-lg translate-x-[-50%] translate-y-[-50%] gap-4 border bg-background p-6 shadow-lg duration-200 data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[state=closed]:slide-out-to-left-1/2 data-[state=closed]:slide-out-to-top-[48%] data-[state=open]:slide-in-from-left-1/2 data-[state=open]:slide-in-from-top-[48%] sm:rounded-lg",
        className
      )}
      {...props}
    >
      {children}
      <DialogPrimitive.Close className="absolute right-4 top-4 rounded-sm opacity-70 ring-offset-background transition-opacity hover:opacity-100 focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 disabled:pointer-events-none data-[state=open]:bg-accent data-[state=open]:text-muted-foreground">
        <X className="h-4 w-4" />
        <span className="sr-only">Close</span>
      </DialogPrimitive.Close>
    </DialogPrimitive.Content>
  </DialogPortal>
))
DialogContent.displayName = DialogPrimitive.Content.displayName

const DialogHeader = ({
  className,
  ...props
}: React.HTMLAttributes<HTMLDivElement>) => (
  <div
    className={cn(
      "flex flex-col space-y-1.5 text-center sm:text-left",
      className
    )}
    {...props}
  />
)
DialogHeader.displayName = "DialogHeader"

const DialogFooter = ({
  className,
  ...props
}: React.HTMLAttributes<HTMLDivElement>) => (
  <div
    className={cn(
      "flex flex-col-reverse sm:flex-row sm:justify-end sm:space-x-2",
      className
    )}
    {...props}
  />
)
DialogFooter.displayName = "DialogFooter"

const DialogTitle = React.forwardRef<
  React.ElementRef<typeof DialogPrimitive.Title>,
  React.ComponentPropsWithoutRef<typeof DialogPrimitive.Title>
>(({ className, ...props }, ref) => (
  <DialogPrimitive.Title
    ref={ref}
    className={cn(
      "text-lg font-semibold leading-none tracking-tight",
      className
    )}
    {...props}
  />
))
DialogTitle.displayName = DialogPrimitive.Title.displayName

const DialogDescription = React.forwardRef<
  React.ElementRef<typeof DialogPrimitive.Description>,
  React.ComponentPropsWithoutRef<typeof DialogPrimitive.Description>
>(({ className, ...props }, ref) => (
  <DialogPrimitive.Description
    ref={ref}
    className={cn("text-sm text-muted-foreground", className)}
    {...props}
  />
))
DialogDescription.displayName = DialogPrimitive.Description.displayName

export {
  Dialog,
  DialogPortal,
  DialogOverlay,
  DialogClose,
  DialogTrigger,
  DialogContent,
  DialogHeader,
  DialogFooter,
  DialogTitle,
  DialogDescription,
}



================================================
FILE: src/components/ui/dropdown-menu.tsx
================================================
"use client"

import * as React from "react"
import * as DropdownMenuPrimitive from "@radix-ui/react-dropdown-menu"
import { Check, ChevronRight, Circle } from "lucide-react"

import { cn } from "@/lib/utils"

const DropdownMenu = DropdownMenuPrimitive.Root

const DropdownMenuTrigger = DropdownMenuPrimitive.Trigger

const DropdownMenuGroup = DropdownMenuPrimitive.Group

const DropdownMenuPortal = DropdownMenuPrimitive.Portal

const DropdownMenuSub = DropdownMenuPrimitive.Sub

const DropdownMenuRadioGroup = DropdownMenuPrimitive.RadioGroup

const DropdownMenuSubTrigger = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.SubTrigger>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.SubTrigger> & {
    inset?: boolean
  }
>(({ className, inset, children, ...props }, ref) => (
  <DropdownMenuPrimitive.SubTrigger
    ref={ref}
    className={cn(
      "flex cursor-default gap-2 select-none items-center rounded-sm px-2 py-1.5 text-sm outline-none focus:bg-accent data-[state=open]:bg-accent [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0",
      inset && "pl-8",
      className
    )}
    {...props}
  >
    {children}
    <ChevronRight className="ml-auto" />
  </DropdownMenuPrimitive.SubTrigger>
))
DropdownMenuSubTrigger.displayName =
  DropdownMenuPrimitive.SubTrigger.displayName

const DropdownMenuSubContent = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.SubContent>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.SubContent>
>(({ className, ...props }, ref) => (
  <DropdownMenuPrimitive.SubContent
    ref={ref}
    className={cn(
      "z-50 min-w-[8rem] overflow-hidden rounded-md border bg-popover p-1 text-popover-foreground shadow-lg data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2",
      className
    )}
    {...props}
  />
))
DropdownMenuSubContent.displayName =
  DropdownMenuPrimitive.SubContent.displayName

const DropdownMenuContent = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.Content>
>(({ className, sideOffset = 4, ...props }, ref) => (
  <DropdownMenuPrimitive.Portal>
    <DropdownMenuPrimitive.Content
      ref={ref}
      sideOffset={sideOffset}
      className={cn(
        "z-50 min-w-[8rem] overflow-hidden rounded-md border bg-popover p-1 text-popover-foreground shadow-md data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2",
        className
      )}
      {...props}
    />
  </DropdownMenuPrimitive.Portal>
))
DropdownMenuContent.displayName = DropdownMenuPrimitive.Content.displayName

const DropdownMenuItem = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.Item>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.Item> & {
    inset?: boolean
  }
>(({ className, inset, ...props }, ref) => (
  <DropdownMenuPrimitive.Item
    ref={ref}
    className={cn(
      "relative flex cursor-default select-none items-center gap-2 rounded-sm px-2 py-1.5 text-sm outline-none transition-colors focus:bg-accent focus:text-accent-foreground data-[disabled]:pointer-events-none data-[disabled]:opacity-50 [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0",
      inset && "pl-8",
      className
    )}
    {...props}
  />
))
DropdownMenuItem.displayName = DropdownMenuPrimitive.Item.displayName

const DropdownMenuCheckboxItem = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.CheckboxItem>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.CheckboxItem>
>(({ className, children, checked, ...props }, ref) => (
  <DropdownMenuPrimitive.CheckboxItem
    ref={ref}
    className={cn(
      "relative flex cursor-default select-none items-center rounded-sm py-1.5 pl-8 pr-2 text-sm outline-none transition-colors focus:bg-accent focus:text-accent-foreground data-[disabled]:pointer-events-none data-[disabled]:opacity-50",
      className
    )}
    checked={checked}
    {...props}
  >
    <span className="absolute left-2 flex h-3.5 w-3.5 items-center justify-center">
      <DropdownMenuPrimitive.ItemIndicator>
        <Check className="h-4 w-4" />
      </DropdownMenuPrimitive.ItemIndicator>
    </span>
    {children}
  </DropdownMenuPrimitive.CheckboxItem>
))
DropdownMenuCheckboxItem.displayName =
  DropdownMenuPrimitive.CheckboxItem.displayName

const DropdownMenuRadioItem = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.RadioItem>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.RadioItem>
>(({ className, children, ...props }, ref) => (
  <DropdownMenuPrimitive.RadioItem
    ref={ref}
    className={cn(
      "relative flex cursor-default select-none items-center rounded-sm py-1.5 pl-8 pr-2 text-sm outline-none transition-colors focus:bg-accent focus:text-accent-foreground data-[disabled]:pointer-events-none data-[disabled]:opacity-50",
      className
    )}
    {...props}
  >
    <span className="absolute left-2 flex h-3.5 w-3.5 items-center justify-center">
      <DropdownMenuPrimitive.ItemIndicator>
        <Circle className="h-2 w-2 fill-current" />
      </DropdownMenuPrimitive.ItemIndicator>
    </span>
    {children}
  </DropdownMenuPrimitive.RadioItem>
))
DropdownMenuRadioItem.displayName = DropdownMenuPrimitive.RadioItem.displayName

const DropdownMenuLabel = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.Label>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.Label> & {
    inset?: boolean
  }
>(({ className, inset, ...props }, ref) => (
  <DropdownMenuPrimitive.Label
    ref={ref}
    className={cn(
      "px-2 py-1.5 text-sm font-semibold",
      inset && "pl-8",
      className
    )}
    {...props}
  />
))
DropdownMenuLabel.displayName = DropdownMenuPrimitive.Label.displayName

const DropdownMenuSeparator = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.Separator>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.Separator>
>(({ className, ...props }, ref) => (
  <DropdownMenuPrimitive.Separator
    ref={ref}
    className={cn("-mx-1 my-1 h-px bg-muted", className)}
    {...props}
  />
))
DropdownMenuSeparator.displayName = DropdownMenuPrimitive.Separator.displayName

const DropdownMenuShortcut = ({
  className,
  ...props
}: React.HTMLAttributes<HTMLSpanElement>) => {
  return (
    <span
      className={cn("ml-auto text-xs tracking-widest opacity-60", className)}
      {...props}
    />
  )
}
DropdownMenuShortcut.displayName = "DropdownMenuShortcut"

export {
  DropdownMenu,
  DropdownMenuTrigger,
  DropdownMenuContent,
  DropdownMenuItem,
  DropdownMenuCheckboxItem,
  DropdownMenuRadioItem,
  DropdownMenuLabel,
  DropdownMenuSeparator,
  DropdownMenuShortcut,
  DropdownMenuGroup,
  DropdownMenuPortal,
  DropdownMenuSub,
  DropdownMenuSubContent,
  DropdownMenuSubTrigger,
  DropdownMenuRadioGroup,
}



================================================
FILE: src/components/ui/form.tsx
================================================
"use client"

import * as React from "react"
import * as LabelPrimitive from "@radix-ui/react-label"
import { Slot } from "@radix-ui/react-slot"
import {
  Controller,
  FormProvider,
  useFormContext,
  type ControllerProps,
  type FieldPath,
  type FieldValues,
} from "react-hook-form"

import { cn } from "@/lib/utils"
import { Label } from "@/components/ui/label"

const Form = FormProvider

type FormFieldContextValue<
  TFieldValues extends FieldValues = FieldValues,
  TName extends FieldPath<TFieldValues> = FieldPath<TFieldValues>
> = {
  name: TName
}

const FormFieldContext = React.createContext<FormFieldContextValue>(
  {} as FormFieldContextValue
)

const FormField = <
  TFieldValues extends FieldValues = FieldValues,
  TName extends FieldPath<TFieldValues> = FieldPath<TFieldValues>
>({
  ...props
}: ControllerProps<TFieldValues, TName>) => {
  return (
    <FormFieldContext.Provider value={{ name: props.name }}>
      <Controller {...props} />
    </FormFieldContext.Provider>
  )
}

const useFormField = () => {
  const fieldContext = React.useContext(FormFieldContext)
  const itemContext = React.useContext(FormItemContext)
  const { getFieldState, formState } = useFormContext()

  const fieldState = getFieldState(fieldContext.name, formState)

  if (!fieldContext) {
    throw new Error("useFormField should be used within <FormField>")
  }

  const { id } = itemContext

  return {
    id,
    name: fieldContext.name,
    formItemId: `${id}-form-item`,
    formDescriptionId: `${id}-form-item-description`,
    formMessageId: `${id}-form-item-message`,
    ...fieldState,
  }
}

type FormItemContextValue = {
  id: string
}

const FormItemContext = React.createContext<FormItemContextValue>(
  {} as FormItemContextValue
)

const FormItem = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => {
  const id = React.useId()

  return (
    <FormItemContext.Provider value={{ id }}>
      <div ref={ref} className={cn("space-y-2", className)} {...props} />
    </FormItemContext.Provider>
  )
})
FormItem.displayName = "FormItem"

const FormLabel = React.forwardRef<
  React.ElementRef<typeof LabelPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof LabelPrimitive.Root>
>(({ className, ...props }, ref) => {
  const { error, formItemId } = useFormField()

  return (
    <Label
      ref={ref}
      className={cn(error && "text-destructive", className)}
      htmlFor={formItemId}
      {...props}
    />
  )
})
FormLabel.displayName = "FormLabel"

const FormControl = React.forwardRef<
  React.ElementRef<typeof Slot>,
  React.ComponentPropsWithoutRef<typeof Slot>
>(({ ...props }, ref) => {
  const { error, formItemId, formDescriptionId, formMessageId } = useFormField()

  return (
    <Slot
      ref={ref}
      id={formItemId}
      aria-describedby={
        !error
          ? `${formDescriptionId}`
          : `${formDescriptionId} ${formMessageId}`
      }
      aria-invalid={!!error}
      {...props}
    />
  )
})
FormControl.displayName = "FormControl"

const FormDescription = React.forwardRef<
  HTMLParagraphElement,
  React.HTMLAttributes<HTMLParagraphElement>
>(({ className, ...props }, ref) => {
  const { formDescriptionId } = useFormField()

  return (
    <p
      ref={ref}
      id={formDescriptionId}
      className={cn("text-sm text-muted-foreground", className)}
      {...props}
    />
  )
})
FormDescription.displayName = "FormDescription"

const FormMessage = React.forwardRef<
  HTMLParagraphElement,
  React.HTMLAttributes<HTMLParagraphElement>
>(({ className, children, ...props }, ref) => {
  const { error, formMessageId } = useFormField()
  const body = error ? String(error?.message ?? "") : children

  if (!body) {
    return null
  }

  return (
    <p
      ref={ref}
      id={formMessageId}
      className={cn("text-sm font-medium text-destructive", className)}
      {...props}
    >
      {body}
    </p>
  )
})
FormMessage.displayName = "FormMessage"

export {
  useFormField,
  Form,
  FormItem,
  FormLabel,
  FormControl,
  FormDescription,
  FormMessage,
  FormField,
}



================================================
FILE: src/components/ui/input.tsx
================================================
import * as React from "react"

import { cn } from "@/lib/utils"

const Input = React.forwardRef<HTMLInputElement, React.ComponentProps<"input">>(
  ({ className, type, ...props }, ref) => {
    return (
      <input
        type={type}
        className={cn(
          "flex h-10 w-full rounded-md border border-input bg-background px-3 py-2 text-base ring-offset-background file:border-0 file:bg-transparent file:text-sm file:font-medium file:text-foreground placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50 md:text-sm",
          className
        )}
        ref={ref}
        {...props}
      />
    )
  }
)
Input.displayName = "Input"

export { Input }



================================================
FILE: src/components/ui/label.tsx
================================================
"use client"

import * as React from "react"
import * as LabelPrimitive from "@radix-ui/react-label"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "@/lib/utils"

const labelVariants = cva(
  "text-sm font-medium leading-none peer-disabled:cursor-not-allowed peer-disabled:opacity-70"
)

const Label = React.forwardRef<
  React.ElementRef<typeof LabelPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof LabelPrimitive.Root> &
    VariantProps<typeof labelVariants>
>(({ className, ...props }, ref) => (
  <LabelPrimitive.Root
    ref={ref}
    className={cn(labelVariants(), className)}
    {...props}
  />
))
Label.displayName = LabelPrimitive.Root.displayName

export { Label }



================================================
FILE: src/components/ui/menubar.tsx
================================================
"use client"

import * as React from "react"
import * as MenubarPrimitive from "@radix-ui/react-menubar"
import { Check, ChevronRight, Circle } from "lucide-react"

import { cn } from "@/lib/utils"

function MenubarMenu({
  ...props
}: React.ComponentProps<typeof MenubarPrimitive.Menu>) {
  return <MenubarPrimitive.Menu {...props} />
}

function MenubarGroup({
  ...props
}: React.ComponentProps<typeof MenubarPrimitive.Group>) {
  return <MenubarPrimitive.Group {...props} />
}

function MenubarPortal({
  ...props
}: React.ComponentProps<typeof MenubarPrimitive.Portal>) {
  return <MenubarPrimitive.Portal {...props} />
}

function MenubarRadioGroup({
  ...props
}: React.ComponentProps<typeof MenubarPrimitive.RadioGroup>) {
  return <MenubarPrimitive.RadioGroup {...props} />
}

function MenubarSub({
  ...props
}: React.ComponentProps<typeof MenubarPrimitive.Sub>) {
  return <MenubarPrimitive.Sub data-slot="menubar-sub" {...props} />
}

const Menubar = React.forwardRef<
  React.ElementRef<typeof MenubarPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof MenubarPrimitive.Root>
>(({ className, ...props }, ref) => (
  <MenubarPrimitive.Root
    ref={ref}
    className={cn(
      "flex h-10 items-center space-x-1 rounded-md border bg-background p-1",
      className
    )}
    {...props}
  />
))
Menubar.displayName = MenubarPrimitive.Root.displayName

const MenubarTrigger = React.forwardRef<
  React.ElementRef<typeof MenubarPrimitive.Trigger>,
  React.ComponentPropsWithoutRef<typeof MenubarPrimitive.Trigger>
>(({ className, ...props }, ref) => (
  <MenubarPrimitive.Trigger
    ref={ref}
    className={cn(
      "flex cursor-default select-none items-center rounded-sm px-3 py-1.5 text-sm font-medium outline-none focus:bg-accent focus:text-accent-foreground data-[state=open]:bg-accent data-[state=open]:text-accent-foreground",
      className
    )}
    {...props}
  />
))
MenubarTrigger.displayName = MenubarPrimitive.Trigger.displayName

const MenubarSubTrigger = React.forwardRef<
  React.ElementRef<typeof MenubarPrimitive.SubTrigger>,
  React.ComponentPropsWithoutRef<typeof MenubarPrimitive.SubTrigger> & {
    inset?: boolean
  }
>(({ className, inset, children, ...props }, ref) => (
  <MenubarPrimitive.SubTrigger
    ref={ref}
    className={cn(
      "flex cursor-default select-none items-center rounded-sm px-2 py-1.5 text-sm outline-none focus:bg-accent focus:text-accent-foreground data-[state=open]:bg-accent data-[state=open]:text-accent-foreground",
      inset && "pl-8",
      className
    )}
    {...props}
  >
    {children}
    <ChevronRight className="ml-auto h-4 w-4" />
  </MenubarPrimitive.SubTrigger>
))
MenubarSubTrigger.displayName = MenubarPrimitive.SubTrigger.displayName

const MenubarSubContent = React.forwardRef<
  React.ElementRef<typeof MenubarPrimitive.SubContent>,
  React.ComponentPropsWithoutRef<typeof MenubarPrimitive.SubContent>
>(({ className, ...props }, ref) => (
  <MenubarPrimitive.SubContent
    ref={ref}
    className={cn(
      "z-50 min-w-[8rem] overflow-hidden rounded-md border bg-popover p-1 text-popover-foreground data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2",
      className
    )}
    {...props}
  />
))
MenubarSubContent.displayName = MenubarPrimitive.SubContent.displayName

const MenubarContent = React.forwardRef<
  React.ElementRef<typeof MenubarPrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof MenubarPrimitive.Content>
>(
  (
    { className, align = "start", alignOffset = -4, sideOffset = 8, ...props },
    ref
  ) => (
    <MenubarPrimitive.Portal>
      <MenubarPrimitive.Content
        ref={ref}
        align={align}
        alignOffset={alignOffset}
        sideOffset={sideOffset}
        className={cn(
          "z-50 min-w-[12rem] overflow-hidden rounded-md border bg-popover p-1 text-popover-foreground shadow-md data-[state=open]:animate-in data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2",
          className
        )}
        {...props}
      />
    </MenubarPrimitive.Portal>
  )
)
MenubarContent.displayName = MenubarPrimitive.Content.displayName

const MenubarItem = React.forwardRef<
  React.ElementRef<typeof MenubarPrimitive.Item>,
  React.ComponentPropsWithoutRef<typeof MenubarPrimitive.Item> & {
    inset?: boolean
  }
>(({ className, inset, ...props }, ref) => (
  <MenubarPrimitive.Item
    ref={ref}
    className={cn(
      "relative flex cursor-default select-none items-center rounded-sm px-2 py-1.5 text-sm outline-none focus:bg-accent focus:text-accent-foreground data-[disabled]:pointer-events-none data-[disabled]:opacity-50",
      inset && "pl-8",
      className
    )}
    {...props}
  />
))
MenubarItem.displayName = MenubarPrimitive.Item.displayName

const MenubarCheckboxItem = React.forwardRef<
  React.ElementRef<typeof MenubarPrimitive.CheckboxItem>,
  React.ComponentPropsWithoutRef<typeof MenubarPrimitive.CheckboxItem>
>(({ className, children, checked, ...props }, ref) => (
  <MenubarPrimitive.CheckboxItem
    ref={ref}
    className={cn(
      "relative flex cursor-default select-none items-center rounded-sm py-1.5 pl-8 pr-2 text-sm outline-none focus:bg-accent focus:text-accent-foreground data-[disabled]:pointer-events-none data-[disabled]:opacity-50",
      className
    )}
    checked={checked}
    {...props}
  >
    <span className="absolute left-2 flex h-3.5 w-3.5 items-center justify-center">
      <MenubarPrimitive.ItemIndicator>
        <Check className="h-4 w-4" />
      </MenubarPrimitive.ItemIndicator>
    </span>
    {children}
  </MenubarPrimitive.CheckboxItem>
))
MenubarCheckboxItem.displayName = MenubarPrimitive.CheckboxItem.displayName

const MenubarRadioItem = React.forwardRef<
  React.ElementRef<typeof MenubarPrimitive.RadioItem>,
  React.ComponentPropsWithoutRef<typeof MenubarPrimitive.RadioItem>
>(({ className, children, ...props }, ref) => (
  <MenubarPrimitive.RadioItem
    ref={ref}
    className={cn(
      "relative flex cursor-default select-none items-center rounded-sm py-1.5 pl-8 pr-2 text-sm outline-none focus:bg-accent focus:text-accent-foreground data-[disabled]:pointer-events-none data-[disabled]:opacity-50",
      className
    )}
    {...props}
  >
    <span className="absolute left-2 flex h-3.5 w-3.5 items-center justify-center">
      <MenubarPrimitive.ItemIndicator>
        <Circle className="h-2 w-2 fill-current" />
      </MenubarPrimitive.ItemIndicator>
    </span>
    {children}
  </MenubarPrimitive.RadioItem>
))
MenubarRadioItem.displayName = MenubarPrimitive.RadioItem.displayName

const MenubarLabel = React.forwardRef<
  React.ElementRef<typeof MenubarPrimitive.Label>,
  React.ComponentPropsWithoutRef<typeof MenubarPrimitive.Label> & {
    inset?: boolean
  }
>(({ className, inset, ...props }, ref) => (
  <MenubarPrimitive.Label
    ref={ref}
    className={cn(
      "px-2 py-1.5 text-sm font-semibold",
      inset && "pl-8",
      className
    )}
    {...props}
  />
))
MenubarLabel.displayName = MenubarPrimitive.Label.displayName

const MenubarSeparator = React.forwardRef<
  React.ElementRef<typeof MenubarPrimitive.Separator>,
  React.ComponentPropsWithoutRef<typeof MenubarPrimitive.Separator>
>(({ className, ...props }, ref) => (
  <MenubarPrimitive.Separator
    ref={ref}
    className={cn("-mx-1 my-1 h-px bg-muted", className)}
    {...props}
  />
))
MenubarSeparator.displayName = MenubarPrimitive.Separator.displayName

const MenubarShortcut = ({
  className,
  ...props
}: React.HTMLAttributes<HTMLSpanElement>) => {
  return (
    <span
      className={cn(
        "ml-auto text-xs tracking-widest text-muted-foreground",
        className
      )}
      {...props}
    />
  )
}
MenubarShortcut.displayname = "MenubarShortcut"

export {
  Menubar,
  MenubarMenu,
  MenubarTrigger,
  MenubarContent,
  MenubarItem,
  MenubarSeparator,
  MenubarLabel,
  MenubarCheckboxItem,
  MenubarRadioGroup,
  MenubarRadioItem,
  MenubarPortal,
  MenubarSubContent,
  MenubarSubTrigger,
  MenubarGroup,
  MenubarSub,
  MenubarShortcut,
}



================================================
FILE: src/components/ui/popover.tsx
================================================
"use client"

import * as React from "react"
import * as PopoverPrimitive from "@radix-ui/react-popover"

import { cn } from "@/lib/utils"

const Popover = PopoverPrimitive.Root

const PopoverTrigger = PopoverPrimitive.Trigger

const PopoverContent = React.forwardRef<
  React.ElementRef<typeof PopoverPrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof PopoverPrimitive.Content>
>(({ className, align = "center", sideOffset = 4, ...props }, ref) => (
  <PopoverPrimitive.Portal>
    <PopoverPrimitive.Content
      ref={ref}
      align={align}
      sideOffset={sideOffset}
      className={cn(
        "z-50 w-72 rounded-md border bg-popover p-4 text-popover-foreground shadow-md outline-none data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2",
        className
      )}
      {...props}
    />
  </PopoverPrimitive.Portal>
))
PopoverContent.displayName = PopoverPrimitive.Content.displayName

export { Popover, PopoverTrigger, PopoverContent }



================================================
FILE: src/components/ui/progress.tsx
================================================
"use client"

import * as React from "react"
import * as ProgressPrimitive from "@radix-ui/react-progress"

import { cn } from "@/lib/utils"

const Progress = React.forwardRef<
  React.ElementRef<typeof ProgressPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof ProgressPrimitive.Root>
>(({ className, value, ...props }, ref) => (
  <ProgressPrimitive.Root
    ref={ref}
    className={cn(
      "relative h-4 w-full overflow-hidden rounded-full bg-secondary",
      className
    )}
    {...props}
  >
    <ProgressPrimitive.Indicator
      className="h-full w-full flex-1 bg-primary transition-all"
      style={{ transform: `translateX(-${100 - (value || 0)}%)` }}
    />
  </ProgressPrimitive.Root>
))
Progress.displayName = ProgressPrimitive.Root.displayName

export { Progress }



================================================
FILE: src/components/ui/radio-group.tsx
================================================
"use client"

import * as React from "react"
import * as RadioGroupPrimitive from "@radix-ui/react-radio-group"
import { Circle } from "lucide-react"

import { cn } from "@/lib/utils"

const RadioGroup = React.forwardRef<
  React.ElementRef<typeof RadioGroupPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof RadioGroupPrimitive.Root>
>(({ className, ...props }, ref) => {
  return (
    <RadioGroupPrimitive.Root
      className={cn("grid gap-2", className)}
      {...props}
      ref={ref}
    />
  )
})
RadioGroup.displayName = RadioGroupPrimitive.Root.displayName

const RadioGroupItem = React.forwardRef<
  React.ElementRef<typeof RadioGroupPrimitive.Item>,
  React.ComponentPropsWithoutRef<typeof RadioGroupPrimitive.Item>
>(({ className, ...props }, ref) => {
  return (
    <RadioGroupPrimitive.Item
      ref={ref}
      className={cn(
        "aspect-square h-4 w-4 rounded-full border border-primary text-primary ring-offset-background focus:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50",
        className
      )}
      {...props}
    >
      <RadioGroupPrimitive.Indicator className="flex items-center justify-center">
        <Circle className="h-2.5 w-2.5 fill-current text-current" />
      </RadioGroupPrimitive.Indicator>
    </RadioGroupPrimitive.Item>
  )
})
RadioGroupItem.displayName = RadioGroupPrimitive.Item.displayName

export { RadioGroup, RadioGroupItem }



================================================
FILE: src/components/ui/resizable.tsx
================================================
"use client"

import * as ResizablePrimitive from "react-resizable-panels"

import { cn } from "@/lib/utils"

const ResizablePanelGroup = ({
  className,
  ...props
}: React.ComponentProps<typeof ResizablePrimitive.PanelGroup>) => (
  <ResizablePrimitive.PanelGroup
    className={cn(
      "flex h-full w-full data-[panel-group-direction=vertical]:flex-col",
      className
    )}
    {...props}
  />
)

const ResizablePanel = ResizablePrimitive.Panel

const ResizableHandle = ({
  withHandle,
  className,
  ...props
}: React.ComponentProps<typeof ResizablePrimitive.PanelResizeHandle> & {
  withHandle?: boolean
}) => (
  <ResizablePrimitive.PanelResizeHandle
    className={cn(
      "relative flex w-px items-center justify-center bg-border after:absolute after:inset-y-0 after:left-1/2 after:w-1 after:-translate-x-1/2 focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring focus-visible:ring-offset-1 data-[panel-group-direction=vertical]:h-px data-[panel-group-direction=vertical]:w-full data-[panel-group-direction=vertical]:after:left-0 data-[panel-group-direction=vertical]:after:h-1 data-[panel-group-direction=vertical]:after:w-full data-[panel-group-direction=vertical]:after:-translate-y-1/2 data-[panel-group-direction=vertical]:after:translate-x-0 [&[data-panel-group-direction=vertical]>div]:rotate-90",
      className
    )}
    {...props}
  >
    {withHandle && (
      <div className="z-10 flex h-4 w-3 items-center justify-center rounded-sm border bg-border">
        <svg
          xmlns="http://www.w3.org/2000/svg"
          width="24"
          height="24"
          viewBox="0 0 24 24"
          fill="none"
          stroke="currentColor"
          strokeWidth="2"
          strokeLinecap="round"
          strokeLinejoin="round"
          className="h-2.5 w-2.5"
        >
          <path d="M9 5m-1 0a1 1 0 1 0 2 0a1 1 0 1 0 -2 0" />
          <path d="M9 12m-1 0a1 1 0 1 0 2 0a1 1 0 1 0 -2 0" />
          <path d="M9 19m-1 0a1 1 0 1 0 2 0a1 1 0 1 0 -2 0" />
          <path d="M15 5m-1 0a1 1 0 1 0 2 0a1 1 0 1 0 -2 0" />
          <path d="M15 12m-1 0a1 1 0 1 0 2 0a1 1 0 1 0 -2 0" />
          <path d="M15 19m-1 0a1 1 0 1 0 2 0a1 1 0 1 0 -2 0" />
        </svg>
      </div>
    )}
  </ResizablePrimitive.PanelResizeHandle>
)

export { ResizablePanelGroup, ResizablePanel, ResizableHandle }


================================================
FILE: src/components/ui/scroll-area.tsx
================================================
"use client"

import * as React from "react"
import * as ScrollAreaPrimitive from "@radix-ui/react-scroll-area"

import { cn } from "@/lib/utils"

const ScrollArea = React.forwardRef<
  React.ElementRef<typeof ScrollAreaPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof ScrollAreaPrimitive.Root>
>(({ className, children, ...props }, ref) => (
  <ScrollAreaPrimitive.Root
    ref={ref}
    className={cn("relative overflow-hidden", className)}
    {...props}
  >
    <ScrollAreaPrimitive.Viewport className="h-full w-full rounded-[inherit]">
      {children}
    </ScrollAreaPrimitive.Viewport>
    <ScrollBar />
    <ScrollAreaPrimitive.Corner />
  </ScrollAreaPrimitive.Root>
))
ScrollArea.displayName = ScrollAreaPrimitive.Root.displayName

const ScrollBar = React.forwardRef<
  React.ElementRef<typeof ScrollAreaPrimitive.ScrollAreaScrollbar>,
  React.ComponentPropsWithoutRef<typeof ScrollAreaPrimitive.ScrollAreaScrollbar>
>(({ className, orientation = "vertical", ...props }, ref) => (
  <ScrollAreaPrimitive.ScrollAreaScrollbar
    ref={ref}
    orientation={orientation}
    className={cn(
      "flex touch-none select-none transition-colors",
      orientation === "vertical" &&
        "h-full w-2.5 border-l border-l-transparent p-[1px]",
      orientation === "horizontal" &&
        "h-2.5 flex-col border-t border-t-transparent p-[1px]",
      className
    )}
    {...props}
  >
    <ScrollAreaPrimitive.ScrollAreaThumb className="relative flex-1 rounded-full bg-border" />
  </ScrollAreaPrimitive.ScrollAreaScrollbar>
))
ScrollBar.displayName = ScrollAreaPrimitive.ScrollAreaScrollbar.displayName

export { ScrollArea, ScrollBar }



================================================
FILE: src/components/ui/select.tsx
================================================
"use client"

import * as React from "react"
import * as SelectPrimitive from "@radix-ui/react-select"
import { Check, ChevronDown, ChevronUp } from "lucide-react"

import { cn } from "@/lib/utils"

const Select = SelectPrimitive.Root

const SelectGroup = SelectPrimitive.Group

const SelectValue = SelectPrimitive.Value

const SelectTrigger = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.Trigger>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.Trigger>
>(({ className, children, ...props }, ref) => (
  <SelectPrimitive.Trigger
    ref={ref}
    className={cn(
      "flex h-10 w-full items-center justify-between rounded-md border border-input bg-background px-3 py-2 text-sm ring-offset-background placeholder:text-muted-foreground focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50 [&>span]:line-clamp-1",
      className
    )}
    {...props}
  >
    {children}
    <SelectPrimitive.Icon asChild>
      <ChevronDown className="h-4 w-4 opacity-50" />
    </SelectPrimitive.Icon>
  </SelectPrimitive.Trigger>
))
SelectTrigger.displayName = SelectPrimitive.Trigger.displayName

const SelectScrollUpButton = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.ScrollUpButton>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.ScrollUpButton>
>(({ className, ...props }, ref) => (
  <SelectPrimitive.ScrollUpButton
    ref={ref}
    className={cn(
      "flex cursor-default items-center justify-center py-1",
      className
    )}
    {...props}
  >
    <ChevronUp className="h-4 w-4" />
  </SelectPrimitive.ScrollUpButton>
))
SelectScrollUpButton.displayName = SelectPrimitive.ScrollUpButton.displayName

const SelectScrollDownButton = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.ScrollDownButton>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.ScrollDownButton>
>(({ className, ...props }, ref) => (
  <SelectPrimitive.ScrollDownButton
    ref={ref}
    className={cn(
      "flex cursor-default items-center justify-center py-1",
      className
    )}
    {...props}
  >
    <ChevronDown className="h-4 w-4" />
  </SelectPrimitive.ScrollDownButton>
))
SelectScrollDownButton.displayName =
  SelectPrimitive.ScrollDownButton.displayName

const SelectContent = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.Content>
>(({ className, children, position = "popper", ...props }, ref) => (
  <SelectPrimitive.Portal>
    <SelectPrimitive.Content
      ref={ref}
      className={cn(
        "relative z-50 max-h-96 min-w-[8rem] overflow-hidden rounded-md border bg-popover text-popover-foreground shadow-md data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2",
        position === "popper" &&
          "data-[side=bottom]:translate-y-1 data-[side=left]:-translate-x-1 data-[side=right]:translate-x-1 data-[side=top]:-translate-y-1",
        className
      )}
      position={position}
      {...props}
    >
      <SelectScrollUpButton />
      <SelectPrimitive.Viewport
        className={cn(
          "p-1",
          position === "popper" &&
            "h-[var(--radix-select-trigger-height)] w-full min-w-[var(--radix-select-trigger-width)]"
        )}
      >
        {children}
      </SelectPrimitive.Viewport>
      <SelectScrollDownButton />
    </SelectPrimitive.Content>
  </SelectPrimitive.Portal>
))
SelectContent.displayName = SelectPrimitive.Content.displayName

const SelectLabel = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.Label>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.Label>
>(({ className, ...props }, ref) => (
  <SelectPrimitive.Label
    ref={ref}
    className={cn("py-1.5 pl-8 pr-2 text-sm font-semibold", className)}
    {...props}
  />
))
SelectLabel.displayName = SelectPrimitive.Label.displayName

const SelectItem = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.Item>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.Item>
>(({ className, children, ...props }, ref) => (
  <SelectPrimitive.Item
    ref={ref}
    className={cn(
      "relative flex w-full cursor-default select-none items-center rounded-sm py-1.5 pl-8 pr-2 text-sm outline-none focus:bg-accent focus:text-accent-foreground data-[disabled]:pointer-events-none data-[disabled]:opacity-50",
      className
    )}
    {...props}
  >
    <span className="absolute left-2 flex h-3.5 w-3.5 items-center justify-center">
      <SelectPrimitive.ItemIndicator>
        <Check className="h-4 w-4" />
      </SelectPrimitive.ItemIndicator>
    </span>

    <SelectPrimitive.ItemText>{children}</SelectPrimitive.ItemText>
  </SelectPrimitive.Item>
))
SelectItem.displayName = SelectPrimitive.Item.displayName

const SelectSeparator = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.Separator>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.Separator>
>(({ className, ...props }, ref) => (
  <SelectPrimitive.Separator
    ref={ref}
    className={cn("-mx-1 my-1 h-px bg-muted", className)}
    {...props}
  />
))
SelectSeparator.displayName = SelectPrimitive.Separator.displayName

export {
  Select,
  SelectGroup,
  SelectValue,
  SelectTrigger,
  SelectContent,
  SelectLabel,
  SelectItem,
  SelectSeparator,
  SelectScrollUpButton,
  SelectScrollDownButton,
}



================================================
FILE: src/components/ui/separator.tsx
================================================
"use client"

import * as React from "react"
import * as SeparatorPrimitive from "@radix-ui/react-separator"

import { cn } from "@/lib/utils"

const Separator = React.forwardRef<
  React.ElementRef<typeof SeparatorPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof SeparatorPrimitive.Root>
>(
  (
    { className, orientation = "horizontal", decorative = true, ...props },
    ref
  ) => (
    <SeparatorPrimitive.Root
      ref={ref}
      decorative={decorative}
      orientation={orientation}
      className={cn(
        "shrink-0 bg-border",
        orientation === "horizontal" ? "h-[1px] w-full" : "h-full w-[1px]",
        className
      )}
      {...props}
    />
  )
)
Separator.displayName = SeparatorPrimitive.Root.displayName

export { Separator }



================================================
FILE: src/components/ui/sheet.tsx
================================================
"use client"

import * as React from "react"
import * as SheetPrimitive from "@radix-ui/react-dialog"
import { cva, type VariantProps } from "class-variance-authority"
import { X } from "lucide-react"

import { cn } from "@/lib/utils"

const Sheet = SheetPrimitive.Root

const SheetTrigger = SheetPrimitive.Trigger

const SheetClose = SheetPrimitive.Close

const SheetPortal = SheetPrimitive.Portal

const SheetOverlay = React.forwardRef<
  React.ElementRef<typeof SheetPrimitive.Overlay>,
  React.ComponentPropsWithoutRef<typeof SheetPrimitive.Overlay>
>(({ className, ...props }, ref) => (
  <SheetPrimitive.Overlay
    className={cn(
      "fixed inset-0 z-50 bg-black/80  data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0",
      className
    )}
    {...props}
    ref={ref}
  />
))
SheetOverlay.displayName = SheetPrimitive.Overlay.displayName

const sheetVariants = cva(
  "fixed z-50 gap-4 bg-background p-6 shadow-lg transition ease-in-out data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:duration-300 data-[state=open]:duration-500",
  {
    variants: {
      side: {
        top: "inset-x-0 top-0 border-b data-[state=closed]:slide-out-to-top data-[state=open]:slide-in-from-top",
        bottom:
          "inset-x-0 bottom-0 border-t data-[state=closed]:slide-out-to-bottom data-[state=open]:slide-in-from-bottom",
        left: "inset-y-0 left-0 h-full w-3/4 border-r data-[state=closed]:slide-out-to-left data-[state=open]:slide-in-from-left sm:max-w-sm",
        right:
          "inset-y-0 right-0 h-full w-3/4  border-l data-[state=closed]:slide-out-to-right data-[state=open]:slide-in-from-right sm:max-w-sm",
      },
    },
    defaultVariants: {
      side: "right",
    },
  }
)

interface SheetContentProps
  extends React.ComponentPropsWithoutRef<typeof SheetPrimitive.Content>,
    VariantProps<typeof sheetVariants> {}

const SheetContent = React.forwardRef<
  React.ElementRef<typeof SheetPrimitive.Content>,
  SheetContentProps
>(({ side = "right", className, children, ...props }, ref) => (
  <SheetPortal>
    <SheetOverlay />
    <SheetPrimitive.Content
      ref={ref}
      className={cn(sheetVariants({ side }), className)}
      {...props}
    >
      {children}
      <SheetPrimitive.Close className="absolute right-4 top-4 rounded-sm opacity-70 ring-offset-background transition-opacity hover:opacity-100 focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 disabled:pointer-events-none data-[state=open]:bg-secondary">
        <X className="h-4 w-4" />
        <span className="sr-only">Close</span>
      </SheetPrimitive.Close>
    </SheetPrimitive.Content>
  </SheetPortal>
))
SheetContent.displayName = SheetPrimitive.Content.displayName

const SheetHeader = ({
  className,
  ...props
}: React.HTMLAttributes<HTMLDivElement>) => (
  <div
    className={cn(
      "flex flex-col space-y-2 text-center sm:text-left",
      className
    )}
    {...props}
  />
)
SheetHeader.displayName = "SheetHeader"

const SheetFooter = ({
  className,
  ...props
}: React.HTMLAttributes<HTMLDivElement>) => (
  <div
    className={cn(
      "flex flex-col-reverse sm:flex-row sm:justify-end sm:space-x-2",
      className
    )}
    {...props}
  />
)
SheetFooter.displayName = "SheetFooter"

const SheetTitle = React.forwardRef<
  React.ElementRef<typeof SheetPrimitive.Title>,
  React.ComponentPropsWithoutRef<typeof SheetPrimitive.Title>
>(({ className, ...props }, ref) => (
  <SheetPrimitive.Title
    ref={ref}
    className={cn("text-lg font-semibold text-foreground", className)}
    {...props}
  />
))
SheetTitle.displayName = SheetPrimitive.Title.displayName

const SheetDescription = React.forwardRef<
  React.ElementRef<typeof SheetPrimitive.Description>,
  React.ComponentPropsWithoutRef<typeof SheetPrimitive.Description>
>(({ className, ...props }, ref) => (
  <SheetPrimitive.Description
    ref={ref}
    className={cn("text-sm text-muted-foreground", className)}
    {...props}
  />
))
SheetDescription.displayName = SheetPrimitive.Description.displayName

export {
  Sheet,
  SheetPortal,
  SheetOverlay,
  SheetTrigger,
  SheetClose,
  SheetContent,
  SheetHeader,
  SheetFooter,
  SheetTitle,
  SheetDescription,
}



================================================
FILE: src/components/ui/sidebar.tsx
================================================
"use client"

import * as React from "react"
import { Slot } from "@radix-ui/react-slot"
import { VariantProps, cva } from "class-variance-authority"
import { PanelLeft } from "lucide-react"

import { useIsMobile } from "@/hooks/use-mobile"
import { cn } from "@/lib/utils"
import { Button } from "@/components/ui/button"
import { Input } from "@/components/ui/input"
import { Separator } from "@/components/ui/separator"
import { Sheet, SheetContent } from "@/components/ui/sheet"
import { Skeleton } from "@/components/ui/skeleton"
import {
  Tooltip,
  TooltipContent,
  TooltipProvider,
  TooltipTrigger,
} from "@/components/ui/tooltip"

const SIDEBAR_COOKIE_NAME = "sidebar_state"
const SIDEBAR_COOKIE_MAX_AGE = 60 * 60 * 24 * 7
const SIDEBAR_WIDTH = "16rem"
const SIDEBAR_WIDTH_MOBILE = "18rem"
const SIDEBAR_WIDTH_ICON = "3rem"
const SIDEBAR_KEYBOARD_SHORTCUT = "b"

type SidebarContext = {
  state: "expanded" | "collapsed"
  open: boolean
  setOpen: (open: boolean) => void
  openMobile: boolean
  setOpenMobile: (open: boolean) => void
  isMobile: boolean
  toggleSidebar: () => void
}

const SidebarContext = React.createContext<SidebarContext | null>(null)

function useSidebar() {
  const context = React.useContext(SidebarContext)
  if (!context) {
    throw new Error("useSidebar must be used within a SidebarProvider.")
  }

  return context
}

const SidebarProvider = React.forwardRef<
  HTMLDivElement,
  React.ComponentProps<"div"> & {
    defaultOpen?: boolean
    open?: boolean
    onOpenChange?: (open: boolean) => void
  }
>(
  (
    {
      defaultOpen = true,
      open: openProp,
      onOpenChange: setOpenProp,
      className,
      style,
      children,
      ...props
    },
    ref
  ) => {
    const isMobile = useIsMobile()
    const [openMobile, setOpenMobile] = React.useState(false)

    // This is the internal state of the sidebar.
    // We use openProp and setOpenProp for control from outside the component.
    const [_open, _setOpen] = React.useState(defaultOpen)
    const open = openProp ?? _open
    const setOpen = React.useCallback(
      (value: boolean | ((value: boolean) => boolean)) => {
        const openState = typeof value === "function" ? value(open) : value
        if (setOpenProp) {
          setOpenProp(openState)
        } else {
          _setOpen(openState)
        }

        // This sets the cookie to keep the sidebar state.
        document.cookie = `${SIDEBAR_COOKIE_NAME}=${openState}; path=/; max-age=${SIDEBAR_COOKIE_MAX_AGE}`
      },
      [setOpenProp, open]
    )

    // Helper to toggle the sidebar.
    const toggleSidebar = React.useCallback(() => {
      return isMobile
        ? setOpenMobile((open) => !open)
        : setOpen((open) => !open)
    }, [isMobile, setOpen, setOpenMobile])

    // Adds a keyboard shortcut to toggle the sidebar.
    React.useEffect(() => {
      const handleKeyDown = (event: KeyboardEvent) => {
        if (
          event.key === SIDEBAR_KEYBOARD_SHORTCUT &&
          (event.metaKey || event.ctrlKey)
        ) {
          event.preventDefault()
          toggleSidebar()
        }
      }

      window.addEventListener("keydown", handleKeyDown)
      return () => window.removeEventListener("keydown", handleKeyDown)
    }, [toggleSidebar])

    // We add a state so that we can do data-state="expanded" or "collapsed".
    // This makes it easier to style the sidebar with Tailwind classes.
    const state = open ? "expanded" : "collapsed"

    const contextValue = React.useMemo<SidebarContext>(
      () => ({
        state,
        open,
        setOpen,
        isMobile,
        openMobile,
        setOpenMobile,
        toggleSidebar,
      }),
      [state, open, setOpen, isMobile, openMobile, setOpenMobile, toggleSidebar]
    )

    return (
      <SidebarContext.Provider value={contextValue}>
        <TooltipProvider delayDuration={0}>
          <div
            style={
              {
                "--sidebar-width": SIDEBAR_WIDTH,
                "--sidebar-width-icon": SIDEBAR_WIDTH_ICON,
                ...style,
              } as React.CSSProperties
            }
            className={cn(
              "group/sidebar-wrapper flex min-h-svh w-full has-[[data-variant=inset]]:bg-sidebar",
              className
            )}
            ref={ref}
            {...props}
          >
            {children}
          </div>
        </TooltipProvider>
      </SidebarContext.Provider>
    )
  }
)
SidebarProvider.displayName = "SidebarProvider"

const Sidebar = React.forwardRef<
  HTMLDivElement,
  React.ComponentProps<"div"> & {
    side?: "left" | "right"
    variant?: "sidebar" | "floating" | "inset"
    collapsible?: "offcanvas" | "icon" | "none"
  }
>(
  (
    {
      side = "left",
      variant = "sidebar",
      collapsible = "offcanvas",
      className,
      children,
      ...props
    },
    ref
  ) => {
    const { isMobile, state, openMobile, setOpenMobile } = useSidebar()

    if (collapsible === "none") {
      return (
        <div
          className={cn(
            "flex h-full w-[--sidebar-width] flex-col bg-sidebar text-sidebar-foreground",
            className
          )}
          ref={ref}
          {...props}
        >
          {children}
        </div>
      )
    }

    if (isMobile) {
      return (
        <Sheet open={openMobile} onOpenChange={setOpenMobile} {...props}>
          <SheetContent
            data-sidebar="sidebar"
            data-mobile="true"
            className="w-[--sidebar-width] bg-sidebar p-0 text-sidebar-foreground [&>button]:hidden"
            style={
              {
                "--sidebar-width": SIDEBAR_WIDTH_MOBILE,
              } as React.CSSProperties
            }
            side={side}
          >
            <div className="flex h-full w-full flex-col">{children}</div>
          </SheetContent>
        </Sheet>
      )
    }

    return (
      <div
        ref={ref}
        className="group peer hidden md:block text-sidebar-foreground"
        data-state={state}
        data-collapsible={state === "collapsed" ? collapsible : ""}
        data-variant={variant}
        data-side={side}
      >
        {/* This is what handles the sidebar gap on desktop */}
        <div
          className={cn(
            "duration-200 relative h-svh w-[--sidebar-width] bg-transparent transition-[width] ease-linear",
            "group-data-[collapsible=offcanvas]:w-0",
            "group-data-[side=right]:rotate-180",
            variant === "floating" || variant === "inset"
              ? "group-data-[collapsible=icon]:w-[calc(var(--sidebar-width-icon)_+_theme(spacing.4))]"
              : "group-data-[collapsible=icon]:w-[--sidebar-width-icon]"
          )}
        />
        <div
          className={cn(
            "duration-200 fixed inset-y-0 z-10 hidden h-svh w-[--sidebar-width] transition-[left,right,width] ease-linear md:flex",
            side === "left"
              ? "left-0 group-data-[collapsible=offcanvas]:left-[calc(var(--sidebar-width)*-1)]"
              : "right-0 group-data-[collapsible=offcanvas]:right-[calc(var(--sidebar-width)*-1)]",
            // Adjust the padding for floating and inset variants.
            variant === "floating" || variant === "inset"
              ? "p-2 group-data-[collapsible=icon]:w-[calc(var(--sidebar-width-icon)_+_theme(spacing.4)_+2px)]"
              : "group-data-[collapsible=icon]:w-[--sidebar-width-icon] group-data-[side=left]:border-r group-data-[side=right]:border-l",
            className
          )}
          {...props}
        >
          <div
            data-sidebar="sidebar"
            className="flex h-full w-full flex-col bg-sidebar group-data-[variant=floating]:rounded-lg group-data-[variant=floating]:border group-data-[variant=floating]:border-sidebar-border group-data-[variant=floating]:shadow"
          >
            {children}
          </div>
        </div>
      </div>
    )
  }
)
Sidebar.displayName = "Sidebar"

const SidebarTrigger = React.forwardRef<
  React.ElementRef<typeof Button>,
  React.ComponentProps<typeof Button>
>(({ className, onClick, ...props }, ref) => {
  const { toggleSidebar } = useSidebar()

  return (
    <Button
      ref={ref}
      data-sidebar="trigger"
      variant="ghost"
      size="icon"
      className={cn("h-7 w-7", className)}
      onClick={(event) => {
        onClick?.(event)
        toggleSidebar()
      }}
      {...props}
    >
      <PanelLeft />
      <span className="sr-only">Toggle Sidebar</span>
    </Button>
  )
})
SidebarTrigger.displayName = "SidebarTrigger"

const SidebarRail = React.forwardRef<
  HTMLButtonElement,
  React.ComponentProps<"button">
>(({ className, ...props }, ref) => {
  const { toggleSidebar } = useSidebar()

  return (
    <button
      ref={ref}
      data-sidebar="rail"
      aria-label="Toggle Sidebar"
      tabIndex={-1}
      onClick={toggleSidebar}
      title="Toggle Sidebar"
      className={cn(
        "absolute inset-y-0 z-20 hidden w-4 -translate-x-1/2 transition-all ease-linear after:absolute after:inset-y-0 after:left-1/2 after:w-[2px] hover:after:bg-sidebar-border group-data-[side=left]:-right-4 group-data-[side=right]:left-0 sm:flex",
        "[[data-side=left]_&]:cursor-w-resize [[data-side=right]_&]:cursor-e-resize",
        "[[data-side=left][data-state=collapsed]_&]:cursor-e-resize [[data-side=right][data-state=collapsed]_&]:cursor-w-resize",
        "group-data-[collapsible=offcanvas]:translate-x-0 group-data-[collapsible=offcanvas]:after:left-full group-data-[collapsible=offcanvas]:hover:bg-sidebar",
        "[[data-side=left][data-collapsible=offcanvas]_&]:-right-2",
        "[[data-side=right][data-collapsible=offcanvas]_&]:-left-2",
        className
      )}
      {...props}
    />
  )
})
SidebarRail.displayName = "SidebarRail"

const SidebarInset = React.forwardRef<
  HTMLDivElement,
  React.ComponentProps<"main">
>(({ className, ...props }, ref) => {
  return (
    <main
      ref={ref}
      className={cn(
        "relative flex min-h-svh flex-1 flex-col bg-background",
        "peer-data-[variant=inset]:min-h-[calc(100svh-theme(spacing.4))] md:peer-data-[variant=inset]:m-2 md:peer-data-[state=collapsed]:peer-data-[variant=inset]:ml-2 md:peer-data-[variant=inset]:ml-0 md:peer-data-[variant=inset]:rounded-xl md:peer-data-[variant=inset]:shadow",
        className
      )}
      {...props}
    />
  )
})
SidebarInset.displayName = "SidebarInset"

const SidebarInput = React.forwardRef<
  React.ElementRef<typeof Input>,
  React.ComponentProps<typeof Input>
>(({ className, ...props }, ref) => {
  return (
    <Input
      ref={ref}
      data-sidebar="input"
      className={cn(
        "h-8 w-full bg-background shadow-none focus-visible:ring-2 focus-visible:ring-sidebar-ring",
        className
      )}
      {...props}
    />
  )
})
SidebarInput.displayName = "SidebarInput"

const SidebarHeader = React.forwardRef<
  HTMLDivElement,
  React.ComponentProps<"div">
>(({ className, ...props }, ref) => {
  return (
    <div
      ref={ref}
      data-sidebar="header"
      className={cn("flex flex-col gap-2 p-2", className)}
      {...props}
    />
  )
})
SidebarHeader.displayName = "SidebarHeader"

const SidebarFooter = React.forwardRef<
  HTMLDivElement,
  React.ComponentProps<"div">
>(({ className, ...props }, ref) => {
  return (
    <div
      ref={ref}
      data-sidebar="footer"
      className={cn("flex flex-col gap-2 p-2", className)}
      {...props}
    />
  )
})
SidebarFooter.displayName = "SidebarFooter"

const SidebarSeparator = React.forwardRef<
  React.ElementRef<typeof Separator>,
  React.ComponentProps<typeof Separator>
>(({ className, ...props }, ref) => {
  return (
    <Separator
      ref={ref}
      data-sidebar="separator"
      className={cn("mx-2 w-auto bg-sidebar-border", className)}
      {...props}
    />
  )
})
SidebarSeparator.displayName = "SidebarSeparator"

const SidebarContent = React.forwardRef<
  HTMLDivElement,
  React.ComponentProps<"div">
>(({ className, ...props }, ref) => {
  return (
    <div
      ref={ref}
      data-sidebar="content"
      className={cn(
        "flex min-h-0 flex-1 flex-col gap-2 overflow-auto group-data-[collapsible=icon]:overflow-hidden",
        className
      )}
      {...props}
    />
  )
})
SidebarContent.displayName = "SidebarContent"

const SidebarGroup = React.forwardRef<
  HTMLDivElement,
  React.ComponentProps<"div">
>(({ className, ...props }, ref) => {
  return (
    <div
      ref={ref}
      data-sidebar="group"
      className={cn("relative flex w-full min-w-0 flex-col p-2", className)}
      {...props}
    />
  )
})
SidebarGroup.displayName = "SidebarGroup"

const SidebarGroupLabel = React.forwardRef<
  HTMLDivElement,
  React.ComponentProps<"div"> & { asChild?: boolean }
>(({ className, asChild = false, ...props }, ref) => {
  const Comp = asChild ? Slot : "div"

  return (
    <Comp
      ref={ref}
      data-sidebar="group-label"
      className={cn(
        "duration-200 flex h-8 shrink-0 items-center rounded-md px-2 text-xs font-medium text-sidebar-foreground/70 outline-none ring-sidebar-ring transition-[margin,opa] ease-linear focus-visible:ring-2 [&>svg]:size-4 [&>svg]:shrink-0",
        "group-data-[collapsible=icon]:-mt-8 group-data-[collapsible=icon]:opacity-0",
        className
      )}
      {...props}
    />
  )
})
SidebarGroupLabel.displayName = "SidebarGroupLabel"

const SidebarGroupAction = React.forwardRef<
  HTMLButtonElement,
  React.ComponentProps<"button"> & { asChild?: boolean }
>(({ className, asChild = false, ...props }, ref) => {
  const Comp = asChild ? Slot : "button"

  return (
    <Comp
      ref={ref}
      data-sidebar="group-action"
      className={cn(
        "absolute right-3 top-3.5 flex aspect-square w-5 items-center justify-center rounded-md p-0 text-sidebar-foreground outline-none ring-sidebar-ring transition-transform hover:bg-sidebar-accent hover:text-sidebar-accent-foreground focus-visible:ring-2 [&>svg]:size-4 [&>svg]:shrink-0",
        // Increases the hit area of the button on mobile.
        "after:absolute after:-inset-2 after:md:hidden",
        "group-data-[collapsible=icon]:hidden",
        className
      )}
      {...props}
    />
  )
})
SidebarGroupAction.displayName = "SidebarGroupAction"

const SidebarGroupContent = React.forwardRef<
  HTMLDivElement,
  React.ComponentProps<"div">
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    data-sidebar="group-content"
    className={cn("w-full text-sm", className)}
    {...props}
  />
))
SidebarGroupContent.displayName = "SidebarGroupContent"

const SidebarMenu = React.forwardRef<
  HTMLUListElement,
  React.ComponentProps<"ul">
>(({ className, ...props }, ref) => (
  <ul
    ref={ref}
    data-sidebar="menu"
    className={cn("flex w-full min-w-0 flex-col gap-1", className)}
    {...props}
  />
))
SidebarMenu.displayName = "SidebarMenu"

const SidebarMenuItem = React.forwardRef<
  HTMLLIElement,
  React.ComponentProps<"li">
>(({ className, ...props }, ref) => (
  <li
    ref={ref}
    data-sidebar="menu-item"
    className={cn("group/menu-item relative", className)}
    {...props}
  />
))
SidebarMenuItem.displayName = "SidebarMenuItem"

const sidebarMenuButtonVariants = cva(
  "peer/menu-button flex w-full items-center gap-2 overflow-hidden rounded-md p-2 text-left text-sm outline-none ring-sidebar-ring transition-[width,height,padding] hover:bg-sidebar-accent hover:text-sidebar-accent-foreground focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-[[data-sidebar=menu-action]]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:bg-sidebar-accent data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:!size-8 group-data-[collapsible=icon]:!p-2 [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0",
  {
    variants: {
      variant: {
        default: "hover:bg-sidebar-accent hover:text-sidebar-accent-foreground",
        outline:
          "bg-background shadow-[0_0_0_1px_hsl(var(--sidebar-border))] hover:bg-sidebar-accent hover:text-sidebar-accent-foreground hover:shadow-[0_0_0_1px_hsl(var(--sidebar-accent))]",
      },
      size: {
        default: "h-8 text-sm",
        sm: "h-7 text-xs",
        lg: "h-12 text-sm group-data-[collapsible=icon]:!p-0",
      },
    },
    defaultVariants: {
      variant: "default",
      size: "default",
    },
  }
)

const SidebarMenuButton = React.forwardRef<
  HTMLButtonElement,
  React.ComponentProps<"button"> & {
    asChild?: boolean
    isActive?: boolean
    tooltip?: string | React.ComponentProps<typeof TooltipContent>
  } & VariantProps<typeof sidebarMenuButtonVariants>
>(
  (
    {
      asChild = false,
      isActive = false,
      variant = "default",
      size = "default",
      tooltip,
      className,
      ...props
    },
    ref
  ) => {
    const Comp = asChild ? Slot : "button"
    const { isMobile, state } = useSidebar()

    const button = (
      <Comp
        ref={ref}
        data-sidebar="menu-button"
        data-size={size}
        data-active={isActive}
        className={cn(sidebarMenuButtonVariants({ variant, size }), className)}
        {...props}
      />
    )

    if (!tooltip) {
      return button
    }

    if (typeof tooltip === "string") {
      tooltip = {
        children: tooltip,
      }
    }

    return (
      <Tooltip>
        <TooltipTrigger asChild>{button}</TooltipTrigger>
        <TooltipContent
          side="right"
          align="center"
          hidden={state !== "collapsed" || isMobile}
          {...tooltip}
        />
      </Tooltip>
    )
  }
)
SidebarMenuButton.displayName = "SidebarMenuButton"

const SidebarMenuAction = React.forwardRef<
  HTMLButtonElement,
  React.ComponentProps<"button"> & {
    asChild?: boolean
    showOnHover?: boolean
  }
>(({ className, asChild = false, showOnHover = false, ...props }, ref) => {
  const Comp = asChild ? Slot : "button"

  return (
    <Comp
      ref={ref}
      data-sidebar="menu-action"
      className={cn(
        "absolute right-1 top-1.5 flex aspect-square w-5 items-center justify-center rounded-md p-0 text-sidebar-foreground outline-none ring-sidebar-ring transition-transform hover:bg-sidebar-accent hover:text-sidebar-accent-foreground focus-visible:ring-2 peer-hover/menu-button:text-sidebar-accent-foreground [&>svg]:size-4 [&>svg]:shrink-0",
        // Increases the hit area of the button on mobile.
        "after:absolute after:-inset-2 after:md:hidden",
        "peer-data-[size=sm]/menu-button:top-1",
        "peer-data-[size=default]/menu-button:top-1.5",
        "peer-data-[size=lg]/menu-button:top-2.5",
        "group-data-[collapsible=icon]:hidden",
        showOnHover &&
          "group-focus-within/menu-item:opacity-100 group-hover/menu-item:opacity-100 data-[state=open]:opacity-100 peer-data-[active=true]/menu-button:text-sidebar-accent-foreground md:opacity-0",
        className
      )}
      {...props}
    />
  )
})
SidebarMenuAction.displayName = "SidebarMenuAction"

const SidebarMenuBadge = React.forwardRef<
  HTMLDivElement,
  React.ComponentProps<"div">
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    data-sidebar="menu-badge"
    className={cn(
      "absolute right-1 flex h-5 min-w-5 items-center justify-center rounded-md px-1 text-xs font-medium tabular-nums text-sidebar-foreground select-none pointer-events-none",
      "peer-hover/menu-button:text-sidebar-accent-foreground peer-data-[active=true]/menu-button:text-sidebar-accent-foreground",
      "peer-data-[size=sm]/menu-button:top-1",
      "peer-data-[size=default]/menu-button:top-1.5",
      "peer-data-[size=lg]/menu-button:top-2.5",
      "group-data-[collapsible=icon]:hidden",
      className
    )}
    {...props}
  />
))
SidebarMenuBadge.displayName = "SidebarMenuBadge"

const SidebarMenuSkeleton = React.forwardRef<
  HTMLDivElement,
  React.ComponentProps<"div"> & {
    showIcon?: boolean
  }
>(({ className, showIcon = false, ...props }, ref) => {
  // Random width between 50 to 90%.
  const width = React.useMemo(() => {
    return `${Math.floor(Math.random() * 40) + 50}%`
  }, [])

  return (
    <div
      ref={ref}
      data-sidebar="menu-skeleton"
      className={cn("rounded-md h-8 flex gap-2 px-2 items-center", className)}
      {...props}
    >
      {showIcon && (
        <Skeleton
          className="size-4 rounded-md"
          data-sidebar="menu-skeleton-icon"
        />
      )}
      <Skeleton
        className="h-4 flex-1 max-w-[--skeleton-width]"
        data-sidebar="menu-skeleton-text"
        style={
          {
            "--skeleton-width": width,
          } as React.CSSProperties
        }
      />
    </div>
  )
})
SidebarMenuSkeleton.displayName = "SidebarMenuSkeleton"

const SidebarMenuSub = React.forwardRef<
  HTMLUListElement,
  React.ComponentProps<"ul">
>(({ className, ...props }, ref) => (
  <ul
    ref={ref}
    data-sidebar="menu-sub"
    className={cn(
      "mx-3.5 flex min-w-0 translate-x-px flex-col gap-1 border-l border-sidebar-border px-2.5 py-0.5",
      "group-data-[collapsible=icon]:hidden",
      className
    )}
    {...props}
  />
))
SidebarMenuSub.displayName = "SidebarMenuSub"

const SidebarMenuSubItem = React.forwardRef<
  HTMLLIElement,
  React.ComponentProps<"li">
>(({ ...props }, ref) => <li ref={ref} {...props} />)
SidebarMenuSubItem.displayName = "SidebarMenuSubItem"

const SidebarMenuSubButton = React.forwardRef<
  HTMLAnchorElement,
  React.ComponentProps<"a"> & {
    asChild?: boolean
    size?: "sm" | "md"
    isActive?: boolean
  }
>(({ asChild = false, size = "md", isActive, className, ...props }, ref) => {
  const Comp = asChild ? Slot : "a"

  return (
    <Comp
      ref={ref}
      data-sidebar="menu-sub-button"
      data-size={size}
      data-active={isActive}
      className={cn(
        "flex h-7 min-w-0 -translate-x-px items-center gap-2 overflow-hidden rounded-md px-2 text-sidebar-foreground outline-none ring-sidebar-ring hover:bg-sidebar-accent hover:text-sidebar-accent-foreground focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 aria-disabled:pointer-events-none aria-disabled:opacity-50 [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 [&>svg]:text-sidebar-accent-foreground",
        "data-[active=true]:bg-sidebar-accent data-[active=true]:text-sidebar-accent-foreground",
        size === "sm" && "text-xs",
        size === "md" && "text-sm",
        "group-data-[collapsible=icon]:hidden",
        className
      )}
      {...props}
    />
  )
})
SidebarMenuSubButton.displayName = "SidebarMenuSubButton"

export {
  Sidebar,
  SidebarContent,
  SidebarFooter,
  SidebarGroup,
  SidebarGroupAction,
  SidebarGroupContent,
  SidebarGroupLabel,
  SidebarHeader,
  SidebarInput,
  SidebarInset,
  SidebarMenu,
  SidebarMenuAction,
  SidebarMenuBadge,
  SidebarMenuButton,
  SidebarMenuItem,
  SidebarMenuSkeleton,
  SidebarMenuSub,
  SidebarMenuSubButton,
  SidebarMenuSubItem,
  SidebarProvider,
  SidebarRail,
  SidebarSeparator,
  SidebarTrigger,
  useSidebar,
}



================================================
FILE: src/components/ui/skeleton.tsx
================================================
import { cn } from "@/lib/utils"

function Skeleton({
  className,
  ...props
}: React.HTMLAttributes<HTMLDivElement>) {
  return (
    <div
      className={cn("animate-pulse rounded-md bg-muted", className)}
      {...props}
    />
  )
}

export { Skeleton }



================================================
FILE: src/components/ui/slider.tsx
================================================
"use client"

import * as React from "react"
import * as SliderPrimitive from "@radix-ui/react-slider"

import { cn } from "@/lib/utils"

const Slider = React.forwardRef<
  React.ElementRef<typeof SliderPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof SliderPrimitive.Root>
>(({ className, ...props }, ref) => (
  <SliderPrimitive.Root
    ref={ref}
    className={cn(
      "relative flex w-full touch-none select-none items-center",
      className
    )}
    {...props}
  >
    <SliderPrimitive.Track className="relative h-2 w-full grow overflow-hidden rounded-full bg-secondary">
      <SliderPrimitive.Range className="absolute h-full bg-primary" />
    </SliderPrimitive.Track>
    <SliderPrimitive.Thumb className="block h-5 w-5 rounded-full border-2 border-primary bg-background ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50" />
  </SliderPrimitive.Root>
))
Slider.displayName = SliderPrimitive.Root.displayName

export { Slider }



================================================
FILE: src/components/ui/switch.tsx
================================================
"use client"

import * as React from "react"
import * as SwitchPrimitives from "@radix-ui/react-switch"

import { cn } from "@/lib/utils"

const Switch = React.forwardRef<
  React.ElementRef<typeof SwitchPrimitives.Root>,
  React.ComponentPropsWithoutRef<typeof SwitchPrimitives.Root>
>(({ className, ...props }, ref) => (
  <SwitchPrimitives.Root
    className={cn(
      "peer inline-flex h-6 w-11 shrink-0 cursor-pointer items-center rounded-full border-2 border-transparent transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 focus-visible:ring-offset-background disabled:cursor-not-allowed disabled:opacity-50 data-[state=checked]:bg-primary data-[state=unchecked]:bg-input",
      className
    )}
    {...props}
    ref={ref}
  >
    <SwitchPrimitives.Thumb
      className={cn(
        "pointer-events-none block h-5 w-5 rounded-full bg-background shadow-lg ring-0 transition-transform data-[state=checked]:translate-x-5 data-[state=unchecked]:translate-x-0"
      )}
    />
  </SwitchPrimitives.Root>
))
Switch.displayName = SwitchPrimitives.Root.displayName

export { Switch }



================================================
FILE: src/components/ui/table.tsx
================================================
import * as React from "react"

import { cn } from "@/lib/utils"

const Table = React.forwardRef<
  HTMLTableElement,
  React.HTMLAttributes<HTMLTableElement>
>(({ className, ...props }, ref) => (
  <div className="relative w-full overflow-auto">
    <table
      ref={ref}
      className={cn("w-full caption-bottom text-sm", className)}
      {...props}
    />
  </div>
))
Table.displayName = "Table"

const TableHeader = React.forwardRef<
  HTMLTableSectionElement,
  React.HTMLAttributes<HTMLTableSectionElement>
>(({ className, ...props }, ref) => (
  <thead ref={ref} className={cn("[&_tr]:border-b", className)} {...props} />
))
TableHeader.displayName = "TableHeader"

const TableBody = React.forwardRef<
  HTMLTableSectionElement,
  React.HTMLAttributes<HTMLTableSectionElement>
>(({ className, ...props }, ref) => (
  <tbody
    ref={ref}
    className={cn("[&_tr:last-child]:border-0", className)}
    {...props}
  />
))
TableBody.displayName = "TableBody"

const TableFooter = React.forwardRef<
  HTMLTableSectionElement,
  React.HTMLAttributes<HTMLTableSectionElement>
>(({ className, ...props }, ref) => (
  <tfoot
    ref={ref}
    className={cn(
      "border-t bg-muted/50 font-medium [&>tr]:last:border-b-0",
      className
    )}
    {...props}
  />
))
TableFooter.displayName = "TableFooter"

const TableRow = React.forwardRef<
  HTMLTableRowElement,
  React.HTMLAttributes<HTMLTableRowElement>
>(({ className, ...props }, ref) => (
  <tr
    ref={ref}
    className={cn(
      "border-b transition-colors hover:bg-muted/50 data-[state=selected]:bg-muted",
      className
    )}
    {...props}
  />
))
TableRow.displayName = "TableRow"

const TableHead = React.forwardRef<
  HTMLTableCellElement,
  React.ThHTMLAttributes<HTMLTableCellElement>
>(({ className, ...props }, ref) => (
  <th
    ref={ref}
    className={cn(
      "h-12 px-4 text-left align-middle font-medium text-muted-foreground [&:has([role=checkbox])]:pr-0",
      className
    )}
    {...props}
  />
))
TableHead.displayName = "TableHead"

const TableCell = React.forwardRef<
  HTMLTableCellElement,
  React.TdHTMLAttributes<HTMLTableCellElement>
>(({ className, ...props }, ref) => (
  <td
    ref={ref}
    className={cn("p-4 align-middle [&:has([role=checkbox])]:pr-0", className)}
    {...props}
  />
))
TableCell.displayName = "TableCell"

const TableCaption = React.forwardRef<
  HTMLTableCaptionElement,
  React.HTMLAttributes<HTMLTableCaptionElement>
>(({ className, ...props }, ref) => (
  <caption
    ref={ref}
    className={cn("mt-4 text-sm text-muted-foreground", className)}
    {...props}
  />
))
TableCaption.displayName = "TableCaption"

export {
  Table,
  TableHeader,
  TableBody,
  TableFooter,
  TableHead,
  TableRow,
  TableCell,
  TableCaption,
}



================================================
FILE: src/components/ui/tabs.tsx
================================================
"use client"

import * as React from "react"
import * as TabsPrimitive from "@radix-ui/react-tabs"

import { cn } from "@/lib/utils"

const Tabs = TabsPrimitive.Root

const TabsList = React.forwardRef<
  React.ElementRef<typeof TabsPrimitive.List>,
  React.ComponentPropsWithoutRef<typeof TabsPrimitive.List>
>(({ className, ...props }, ref) => (
  <TabsPrimitive.List
    ref={ref}
    className={cn(
      "inline-flex h-10 items-center justify-center rounded-md bg-muted p-1 text-muted-foreground",
      className
    )}
    {...props}
  />
))
TabsList.displayName = TabsPrimitive.List.displayName

const TabsTrigger = React.forwardRef<
  React.ElementRef<typeof TabsPrimitive.Trigger>,
  React.ComponentPropsWithoutRef<typeof TabsPrimitive.Trigger>
>(({ className, ...props }, ref) => (
  <TabsPrimitive.Trigger
    ref={ref}
    className={cn(
      "inline-flex items-center justify-center whitespace-nowrap rounded-sm px-3 py-1.5 text-sm font-medium ring-offset-background transition-all focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 data-[state=active]:bg-background data-[state=active]:text-foreground data-[state=active]:shadow-sm",
      className
    )}
    {...props}
  />
))
TabsTrigger.displayName = TabsPrimitive.Trigger.displayName

const TabsContent = React.forwardRef<
  React.ElementRef<typeof TabsPrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof TabsPrimitive.Content>
>(({ className, ...props }, ref) => (
  <TabsPrimitive.Content
    ref={ref}
    className={cn(
      "mt-2 ring-offset-background focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2",
      className
    )}
    {...props}
  />
))
TabsContent.displayName = TabsPrimitive.Content.displayName

export { Tabs, TabsList, TabsTrigger, TabsContent }



================================================
FILE: src/components/ui/textarea.tsx
================================================
import * as React from 'react';

import {cn} from '@/lib/utils';

const Textarea = React.forwardRef<HTMLTextAreaElement, React.ComponentProps<'textarea'>>(
  ({className, ...props}, ref) => {
    return (
      <textarea
        className={cn(
          'flex min-h-[80px] w-full rounded-md border border-input bg-background px-3 py-2 text-base ring-offset-background placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50 md:text-sm',
          className
        )}
        ref={ref}
        {...props}
      />
    );
  }
);
Textarea.displayName = 'Textarea';

export {Textarea};



================================================
FILE: src/components/ui/toast.tsx
================================================
"use client"

import * as React from "react"
import * as ToastPrimitives from "@radix-ui/react-toast"
import { cva, type VariantProps } from "class-variance-authority"
import { X } from "lucide-react"

import { cn } from "@/lib/utils"

const ToastProvider = ToastPrimitives.Provider

const ToastViewport = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Viewport>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Viewport>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Viewport
    ref={ref}
    className={cn(
      "fixed top-0 z-[100] flex max-h-screen w-full flex-col-reverse p-4 sm:bottom-0 sm:right-0 sm:top-auto sm:flex-col md:max-w-[420px]",
      className
    )}
    {...props}
  />
))
ToastViewport.displayName = ToastPrimitives.Viewport.displayName

const toastVariants = cva(
  "group pointer-events-auto relative flex w-full items-center justify-between space-x-4 overflow-hidden rounded-md border p-6 pr-8 shadow-lg transition-all data-[swipe=cancel]:translate-x-0 data-[swipe=end]:translate-x-[var(--radix-toast-swipe-end-x)] data-[swipe=move]:translate-x-[var(--radix-toast-swipe-move-x)] data-[swipe=move]:transition-none data-[state=open]:animate-in data-[state=closed]:animate-out data-[swipe=end]:animate-out data-[state=closed]:fade-out-80 data-[state=closed]:slide-out-to-right-full data-[state=open]:slide-in-from-top-full data-[state=open]:sm:slide-in-from-bottom-full",
  {
    variants: {
      variant: {
        default: "border bg-background text-foreground",
        destructive:
          "destructive group border-destructive bg-destructive text-destructive-foreground",
      },
    },
    defaultVariants: {
      variant: "default",
    },
  }
)

const Toast = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Root>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Root> &
    VariantProps<typeof toastVariants>
>(({ className, variant, ...props }, ref) => {
  return (
    <ToastPrimitives.Root
      ref={ref}
      className={cn(toastVariants({ variant }), className)}
      {...props}
    />
  )
})
Toast.displayName = ToastPrimitives.Root.displayName

const ToastAction = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Action>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Action>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Action
    ref={ref}
    className={cn(
      "inline-flex h-8 shrink-0 items-center justify-center rounded-md border bg-transparent px-3 text-sm font-medium ring-offset-background transition-colors hover:bg-secondary focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 group-[.destructive]:border-muted/40 group-[.destructive]:hover:border-destructive/30 group-[.destructive]:hover:bg-destructive group-[.destructive]:hover:text-destructive-foreground group-[.destructive]:focus:ring-destructive",
      className
    )}
    {...props}
  />
))
ToastAction.displayName = ToastPrimitives.Action.displayName

const ToastClose = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Close>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Close>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Close
    ref={ref}
    className={cn(
      "absolute right-2 top-2 rounded-md p-1 text-foreground/50 opacity-0 transition-opacity hover:text-foreground focus:opacity-100 focus:outline-none focus:ring-2 group-hover:opacity-100 group-[.destructive]:text-red-300 group-[.destructive]:hover:text-red-50 group-[.destructive]:focus:ring-red-400 group-[.destructive]:focus:ring-offset-red-600",
      className
    )}
    toast-close=""
    {...props}
  >
    <X className="h-4 w-4" />
  </ToastPrimitives.Close>
))
ToastClose.displayName = ToastPrimitives.Close.displayName

const ToastTitle = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Title>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Title>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Title
    ref={ref}
    className={cn("text-sm font-semibold", className)}
    {...props}
  />
))
ToastTitle.displayName = ToastPrimitives.Title.displayName

const ToastDescription = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Description>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Description>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Description
    ref={ref}
    className={cn("text-sm opacity-90", className)}
    {...props}
  />
))
ToastDescription.displayName = ToastPrimitives.Description.displayName

type ToastProps = React.ComponentPropsWithoutRef<typeof Toast>

type ToastActionElement = React.ReactElement<typeof ToastAction>

export {
  type ToastProps,
  type ToastActionElement,
  ToastProvider,
  ToastViewport,
  Toast,
  ToastTitle,
  ToastDescription,
  ToastClose,
  ToastAction,
}



================================================
FILE: src/components/ui/toaster.tsx
================================================
"use client"

import { useToast } from "@/hooks/use-toast"
import {
  Toast,
  ToastClose,
  ToastDescription,
  ToastProvider,
  ToastTitle,
  ToastViewport,
} from "@/components/ui/toast"

export function Toaster() {
  const { toasts } = useToast()

  return (
    <ToastProvider>
      {toasts.map(function ({ id, title, description, action, ...props }) {
        return (
          <Toast key={id} {...props}>
            <div className="grid gap-1">
              {title && <ToastTitle>{title}</ToastTitle>}
              {description && (
                <ToastDescription>{description}</ToastDescription>
              )}
            </div>
            {action}
            <ToastClose />
          </Toast>
        )
      })}
      <ToastViewport />
    </ToastProvider>
  )
}



================================================
FILE: src/components/ui/tooltip.tsx
================================================
"use client"

import * as React from "react"
import * as TooltipPrimitive from "@radix-ui/react-tooltip"

import { cn } from "@/lib/utils"

const TooltipProvider = TooltipPrimitive.Provider

const Tooltip = TooltipPrimitive.Root

const TooltipTrigger = TooltipPrimitive.Trigger

const TooltipContent = React.forwardRef<
  React.ElementRef<typeof TooltipPrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof TooltipPrimitive.Content>
>(({ className, sideOffset = 4, ...props }, ref) => (
  <TooltipPrimitive.Content
    ref={ref}
    sideOffset={sideOffset}
    className={cn(
      "z-50 overflow-hidden rounded-md border bg-popover px-3 py-1.5 text-sm text-popover-foreground shadow-md animate-in fade-in-0 zoom-in-95 data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=closed]:zoom-out-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2",
      className
    )}
    {...props}
  />
))
TooltipContent.displayName = TooltipPrimitive.Content.displayName

export { Tooltip, TooltipTrigger, TooltipContent, TooltipProvider }



================================================
FILE: src/hooks/use-mobile.tsx
================================================
import * as React from "react"

const MOBILE_BREAKPOINT = 768

export function useIsMobile() {
  const [isMobile, setIsMobile] = React.useState<boolean | undefined>(undefined)

  React.useEffect(() => {
    const mql = window.matchMedia(`(max-width: ${MOBILE_BREAKPOINT - 1}px)`)
    const onChange = () => {
      setIsMobile(window.innerWidth < MOBILE_BREAKPOINT)
    }
    mql.addEventListener("change", onChange)
    setIsMobile(window.innerWidth < MOBILE_BREAKPOINT)
    return () => mql.removeEventListener("change", onChange)
  }, [])

  return !!isMobile
}



================================================
FILE: src/hooks/use-toast.ts
================================================
"use client"

// Inspired by react-hot-toast library
import * as React from "react"

import type {
  ToastActionElement,
  ToastProps,
} from "@/components/ui/toast"

const TOAST_LIMIT = 1
const TOAST_REMOVE_DELAY = 1000000

type ToasterToast = ToastProps & {
  id: string
  title?: React.ReactNode
  description?: React.ReactNode
  action?: ToastActionElement
}

const actionTypes = {
  ADD_TOAST: "ADD_TOAST",
  UPDATE_TOAST: "UPDATE_TOAST",
  DISMISS_TOAST: "DISMISS_TOAST",
  REMOVE_TOAST: "REMOVE_TOAST",
} as const

let count = 0

function genId() {
  count = (count + 1) % Number.MAX_SAFE_INTEGER
  return count.toString()
}

type ActionType = typeof actionTypes

type Action =
  | {
      type: ActionType["ADD_TOAST"]
      toast: ToasterToast
    }
  | {
      type: ActionType["UPDATE_TOAST"]
      toast: Partial<ToasterToast>
    }
  | {
      type: ActionType["DISMISS_TOAST"]
      toastId?: ToasterToast["id"]
    }
  | {
      type: ActionType["REMOVE_TOAST"]
      toastId?: ToasterToast["id"]
    }

interface State {
  toasts: ToasterToast[]
}

const toastTimeouts = new Map<string, ReturnType<typeof setTimeout>>()

const addToRemoveQueue = (toastId: string) => {
  if (toastTimeouts.has(toastId)) {
    return
  }

  const timeout = setTimeout(() => {
    toastTimeouts.delete(toastId)
    dispatch({
      type: "REMOVE_TOAST",
      toastId: toastId,
    })
  }, TOAST_REMOVE_DELAY)

  toastTimeouts.set(toastId, timeout)
}

export const reducer = (state: State, action: Action): State => {
  switch (action.type) {
    case "ADD_TOAST":
      return {
        ...state,
        toasts: [action.toast, ...state.toasts].slice(0, TOAST_LIMIT),
      }

    case "UPDATE_TOAST":
      return {
        ...state,
        toasts: state.toasts.map((t) =>
          t.id === action.toast.id ? { ...t, ...action.toast } : t
        ),
      }

    case "DISMISS_TOAST": {
      const { toastId } = action

      // ! Side effects ! - This could be extracted into a dismissToast() action,
      // but I'll keep it here for simplicity
      if (toastId) {
        addToRemoveQueue(toastId)
      } else {
        state.toasts.forEach((toast) => {
          addToRemoveQueue(toast.id)
        })
      }

      return {
        ...state,
        toasts: state.toasts.map((t) =>
          t.id === toastId || toastId === undefined
            ? {
                ...t,
                open: false,
              }
            : t
        ),
      }
    }
    case "REMOVE_TOAST":
      if (action.toastId === undefined) {
        return {
          ...state,
          toasts: [],
        }
      }
      return {
        ...state,
        toasts: state.toasts.filter((t) => t.id !== action.toastId),
      }
  }
}

const listeners: Array<(state: State) => void> = []

let memoryState: State = { toasts: [] }

function dispatch(action: Action) {
  memoryState = reducer(memoryState, action)
  listeners.forEach((listener) => {
    listener(memoryState)
  })
}

type Toast = Omit<ToasterToast, "id">

function toast({ ...props }: Toast) {
  const id = genId()

  const update = (props: ToasterToast) =>
    dispatch({
      type: "UPDATE_TOAST",
      toast: { ...props, id },
    })
  const dismiss = () => dispatch({ type: "DISMISS_TOAST", toastId: id })

  dispatch({
    type: "ADD_TOAST",
    toast: {
      ...props,
      id,
      open: true,
      onOpenChange: (open) => {
        if (!open) dismiss()
      },
    },
  })

  return {
    id: id,
    dismiss,
    update,
  }
}

function useToast() {
  const [state, setState] = React.useState<State>(memoryState)

  React.useEffect(() => {
    listeners.push(setState)
    return () => {
      const index = listeners.indexOf(setState)
      if (index > -1) {
        listeners.splice(index, 1)
      }
    }
  }, [state])

  return {
    ...state,
    toast,
    dismiss: (toastId?: string) => dispatch({ type: "DISMISS_TOAST", toastId }),
  }
}

export { useToast, toast }



================================================
FILE: src/lib/audio-utils.ts
================================================

// @ts-nocheck
import type { EffectSettings } from '@/types/audio-forge';

// Helper function to convert ArrayBuffer to Base64 Data URL
export async function fileToDataUrl(file: File): Promise<string> {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onload = () => resolve(reader.result as string);
    reader.onerror = reject;
    reader.readAsDataURL(file);
  });
}

// Helper function to decode Base64 Data URL to ArrayBuffer
async function dataUrlToArrayBuffer(dataUrl: string): Promise<ArrayBuffer> {
  const response = await fetch(dataUrl);
  return response.arrayBuffer();
}

// Helper function to convert AudioBuffer to WAV Data URL
async function audioBufferToWavDataUrl(audioBuffer: AudioBuffer): Promise<string> {
  const inputNumChannels = audioBuffer.numberOfChannels;
  const sampleRate = audioBuffer.sampleRate;
  const length = audioBuffer.length;
  const bitDepth = 16;

  let interleaved: Int16Array;
  let outputNumChannelsWav: number;

  if (inputNumChannels === 1) {
    outputNumChannelsWav = 1;
    const channelData = audioBuffer.getChannelData(0);
    interleaved = new Int16Array(length);
    for (let i = 0; i < length; i++) {
      interleaved[i] = Math.max(-1, Math.min(1, channelData[i])) * 32767;
    }
  } else { // inputNumChannels >= 2
    outputNumChannelsWav = 2; // Output a stereo WAV, taking first two channels
    const leftChannel = audioBuffer.getChannelData(0);
    const rightChannel = inputNumChannels > 1 ? audioBuffer.getChannelData(1) : leftChannel; 
    
    interleaved = new Int16Array(length * 2);
    for (let i = 0; i < length; i++) {
      interleaved[i * 2] = Math.max(-1, Math.min(1, leftChannel[i])) * 32767;
      interleaved[i * 2 + 1] = Math.max(-1, Math.min(1, rightChannel[i])) * 32767;
    }
  }
  
  const dataSize = interleaved.byteLength;
  const blockAlign = outputNumChannelsWav * (bitDepth / 8);
  const byteRate = sampleRate * blockAlign;

  const buffer = new ArrayBuffer(44 + dataSize);
  const view = new DataView(buffer);

  writeString(view, 0, 'RIFF');
  view.setUint32(4, 36 + dataSize, true);
  writeString(view, 8, 'WAVE');
  writeString(view, 12, 'fmt ');
  view.setUint32(16, 16, true); // PCM
  view.setUint16(20, 1, true); // PCM format
  view.setUint16(22, outputNumChannelsWav, true);
  view.setUint32(24, sampleRate, true);
  view.setUint32(28, byteRate, true);
  view.setUint16(32, blockAlign, true);
  view.setUint16(34, bitDepth, true);
  writeString(view, 36, 'data');
  view.setUint32(40, dataSize, true);

  for (let i = 0; i < interleaved.length; i++) {
    view.setInt16(44 + i * 2, interleaved[i], true);
  }

  const blob = new Blob([view], { type: 'audio/wav' });
  return new Promise((resolve) => {
    const reader = new FileReader();
    reader.onloadend = () => resolve(reader.result as string);
    reader.readAsDataURL(blob);
  });
}

function writeString(view: DataView, offset: number, string: string) {
  for (let i = 0; i < string.length; i++) {
    view.setUint8(offset + i, string.charCodeAt(i));
  }
}


const getGlobalAudioContext = (() => {
  let audioContextInstance: AudioContext | null = null;
  return () => {
    if (typeof window !== 'undefined') {
      if (!audioContextInstance || audioContextInstance.state === 'closed') {
        audioContextInstance = new (window.AudioContext || (window as any).webkitAudioContext)();
      }
       if (audioContextInstance && audioContextInstance.state === 'suspended') {
        audioContextInstance.resume().catch(e => console.error("Error resuming global AudioContext:", e));
      }
    }
    return audioContextInstance;
  };
})();


const processAudioWithEffect = async (
  audioDataUrl: string,
  setupEffect: (audioContext: OfflineAudioContext, sourceNode: AudioBufferSourceNode, decodedAudioBuffer: AudioBuffer) => AudioNode[], 
  analysisMessage?: string,
  outputChannelCountForContext?: number 
): Promise<{ processedAudioDataUrl: string; analysis?: string }> => {
  const audioContext = getGlobalAudioContext();
  if (!audioContext) {
    throw new Error("AudioContext not supported or initialized.");
  }
  
  if (audioContext.state === 'suspended') {
    await audioContext.resume();
  }

  const arrayBuffer = await dataUrlToArrayBuffer(audioDataUrl);
  const decodedAudioBuffer = await audioContext.decodeAudioData(arrayBuffer);

  if (decodedAudioBuffer.length === 0) {
    console.warn("Decoded audio buffer has zero length. Skipping effect processing.");
    return { processedAudioDataUrl: audioDataUrl, analysis: "Audio is empty, no effect applied." };
  }

  const targetChannelCount = outputChannelCountForContext !== undefined ? outputChannelCountForContext : decodedAudioBuffer.numberOfChannels;

  const offlineContext = new OfflineAudioContext(
    targetChannelCount,
    decodedAudioBuffer.length, 
    decodedAudioBuffer.sampleRate
  );

  const sourceNode = offlineContext.createBufferSource();
  sourceNode.buffer = decodedAudioBuffer;

  const effectChain = setupEffect(offlineContext, sourceNode, decodedAudioBuffer);

  let currentNode = sourceNode as AudioNode;
  if (effectChain.length > 0) {
    effectChain.forEach(node => {
      currentNode.connect(node);
      currentNode = node;
    });
  }
  currentNode.connect(offlineContext.destination);
  
  sourceNode.start(0);
  const renderedBuffer = await offlineContext.startRendering();
  const processedAudioDataUrl = await audioBufferToWavDataUrl(renderedBuffer);
  
  return { processedAudioDataUrl, analysis: analysisMessage };
};


export const audioUtils = {
  alterResonance: async (audioDataUrl: string, { frequency }: { frequency: number }) => {
    return processAudioWithEffect(audioDataUrl, (context, source, buffer) => {
      const biquadFilter = context.createBiquadFilter();
      biquadFilter.type = 'peaking';
      const filterFreq = Math.max(20, 1000 + (frequency * 40)); 
      biquadFilter.frequency.setValueAtTime(filterFreq, context.currentTime);
      biquadFilter.Q.setValueAtTime(1.5, context.currentTime);
      biquadFilter.gain.setValueAtTime(frequency, context.currentTime);
      return [biquadFilter];
    }, `Altered resonance: Peaking filter with ${frequency}dB gain around ${ (1000 + (frequency * 40)).toFixed(0) }Hz.`);
  },

  temporalModification: async (audioDataUrl: string, { rate }: { rate: number }) => {
    const audioContext = getGlobalAudioContext();
     if (!audioContext) throw new Error("AudioContext not supported");

    const arrayBuffer = await dataUrlToArrayBuffer(audioDataUrl);
    const decodedAudioBuffer = await audioContext.decodeAudioData(arrayBuffer);
    
    if (decodedAudioBuffer.length === 0) return { processedAudioDataUrl: audioDataUrl, analysis: "Audio is empty."};

    const newRate = Math.max(0.1, Math.min(rate, 4)); 
    const numSamples = Math.max(1, Math.ceil(decodedAudioBuffer.length / newRate));

    const offlineContext = new OfflineAudioContext(
        decodedAudioBuffer.numberOfChannels,
        numSamples, 
        decodedAudioBuffer.sampleRate
    );

    const sourceNode = offlineContext.createBufferSource();
    sourceNode.buffer = decodedAudioBuffer;
    sourceNode.playbackRate.value = newRate;
    
    sourceNode.connect(offlineContext.destination);
    sourceNode.start(0);
    
    const renderedBuffer = await offlineContext.startRendering();
    const processedAudioDataUrl = await audioBufferToWavDataUrl(renderedBuffer);
    
    return { processedAudioDataUrl, analysis: `Temporal modification: Playback rate set to ${newRate.toFixed(2)}x.` };
  },
  stereoWidener: async (audioDataUrl: string, { width: widthParam }: { width: number }) => {
    return processAudioWithEffect(audioDataUrl, (offlineContext, sourceNode, decodedAudioBuffer) => {
      if (decodedAudioBuffer.numberOfChannels < 2) {
        return []; 
      }
  
      const width = widthParam / 100; 
      const splitter = offlineContext.createChannelSplitter(2);
      const merger = offlineContext.createChannelMerger(2);
      
      const gainL_L = offlineContext.createGain();
      gainL_L.gain.setValueAtTime(0.5 * (1 + width), offlineContext.currentTime);
      const gainL_R = offlineContext.createGain();
      gainL_R.gain.setValueAtTime(0.5 * (1 - width), offlineContext.currentTime);

      splitter.connect(gainL_L, 0, 0);
      splitter.connect(gainL_R, 1, 0);
      gainL_L.connect(merger, 0, 0);
      gainL_R.connect(merger, 0, 0);

      const gainR_L = offlineContext.createGain();
      gainR_L.gain.setValueAtTime(0.5 * (1 - width), offlineContext.currentTime);
      const gainR_R = offlineContext.createGain();
      gainR_R.gain.setValueAtTime(0.5 * (1 + width), offlineContext.currentTime);

      splitter.connect(gainR_L, 0, 0);
      splitter.connect(gainR_R, 1, 0);
      gainR_L.connect(merger, 0, 1);
      gainR_R.connect(merger, 0, 1);

      return [splitter, merger]; 
    }, `Stereo Widener: Width set to ${widthParam}%. Applied only if audio is stereo.`, 
       2 
    );
  },
  
  subharmonicIntensifier: async (audioDataUrl: string, { intensity: intensityParam }: { intensity: number }) => {
    const gainDb = (intensityParam / 100) * 12; 
    return processAudioWithEffect(audioDataUrl, (offlineContext, sourceNode, decodedAudioBuffer) => {
      const lowshelfFilter = offlineContext.createBiquadFilter();
      lowshelfFilter.type = 'lowshelf';
      lowshelfFilter.frequency.setValueAtTime(120, offlineContext.currentTime); 
      lowshelfFilter.gain.setValueAtTime(gainDb, offlineContext.currentTime); 
      return [lowshelfFilter];
    }, `Applied Subharmonic Intensifier: Low-shelf filter at 120Hz with ${gainDb.toFixed(1)}dB gain (Intensity: ${intensityParam}%). Effect is most noticeable on audio with existing low-frequency content.`);
  },

  frequencySculptor: async (audioDataUrl: string, { low, mid, high }: { low: number, mid: number, high: number }) => {
     return processAudioWithEffect(audioDataUrl, (context, source, buffer) => {
      const lowFilter = context.createBiquadFilter();
      lowFilter.type = 'lowshelf';
      lowFilter.frequency.setValueAtTime(250, context.currentTime);
      lowFilter.gain.setValueAtTime(low, context.currentTime);

      const midFilter = context.createBiquadFilter();
      midFilter.type = 'peaking';
      midFilter.frequency.setValueAtTime(1000, context.currentTime);
      midFilter.Q.setValueAtTime(0.707, context.currentTime); 
      midFilter.gain.setValueAtTime(mid, context.currentTime);

      const highFilter = context.createBiquadFilter();
      highFilter.type = 'highshelf';
      highFilter.frequency.setValueAtTime(4000, context.currentTime);
      highFilter.gain.setValueAtTime(high, context.currentTime);
      
      return [lowFilter, midFilter, highFilter];
    }, `Frequency Sculptor: Low ${low}dB @ 250Hz, Mid ${mid}dB @ 1kHz, High ${high}dB @ 4kHz.`);
  },

  keyTransposer: async (audioDataUrl: string, { semitones }: { semitones: number }) => {
    const audioContext = getGlobalAudioContext();
    if (!audioContext) throw new Error("AudioContext not supported");

    const arrayBuffer = await dataUrlToArrayBuffer(audioDataUrl);
    const decodedAudioBuffer = await audioContext.decodeAudioData(arrayBuffer);
    if (decodedAudioBuffer.length === 0) return { processedAudioDataUrl: audioDataUrl, analysis: "Audio is empty."};


    const playbackRate = Math.pow(2, semitones / 12);
    const clampedPlaybackRate = Math.max(0.1, Math.min(playbackRate, 4)); 
    
    const newLength = Math.max(1, Math.round(decodedAudioBuffer.length / clampedPlaybackRate));

    const offlineContext = new OfflineAudioContext(
        decodedAudioBuffer.numberOfChannels,
        newLength, 
        decodedAudioBuffer.sampleRate
    );

    const sourceNode = offlineContext.createBufferSource();
    sourceNode.buffer = decodedAudioBuffer;
    sourceNode.playbackRate.value = clampedPlaybackRate;
    
    sourceNode.connect(offlineContext.destination);
    sourceNode.start(0);
    
    const renderedBuffer = await offlineContext.startRendering();
    const processedAudioDataUrl = await audioBufferToWavDataUrl(renderedBuffer);

    return { processedAudioDataUrl, analysis: `Key Transposer: Shifted by ${semitones} semitones (playback rate ${clampedPlaybackRate.toFixed(2)}x). Note: This method affects duration.` };
  },

  echoGenerator: async (audioDataUrl: string, { delay, feedback, mix }: { delay: number, feedback: number, mix: number }) => {
    const audioContext = getGlobalAudioContext();
    if (!audioContext) throw new Error("AudioContext not supported");

    const arrayBuffer = await dataUrlToArrayBuffer(audioDataUrl);
    const decodedAudioBuffer = await audioContext.decodeAudioData(arrayBuffer);
    if (decodedAudioBuffer.length === 0) return { processedAudioDataUrl: audioDataUrl, analysis: "Audio is empty."};


    const clampedDelay = Math.max(0.001, Math.min(delay / 1000, 1)); 
    const clampedFeedback = Math.max(0, Math.min(feedback, 0.95)); 
    const clampedMix = Math.max(0, Math.min(mix, 1)); 

    let tailExtensionFactor = 0;
    if (clampedFeedback > 0) {
        const numSignificantTaps = clampedFeedback > 0.01 ? Math.abs(Math.log(0.001) / Math.log(clampedFeedback)) : 5; 
        tailExtensionFactor = numSignificantTaps * clampedDelay;
    } else {
        tailExtensionFactor = clampedDelay * 2; 
    }
    const tailExtensionSeconds = Math.min(tailExtensionFactor, 30); 
    
    const extendedLength = decodedAudioBuffer.length + Math.floor(audioContext.sampleRate * tailExtensionSeconds);
    
    const offlineContext = new OfflineAudioContext(
      decodedAudioBuffer.numberOfChannels,
      Math.max(1, extendedLength), 
      decodedAudioBuffer.sampleRate
    );
    
    const sourceNode = offlineContext.createBufferSource();
    sourceNode.buffer = decodedAudioBuffer;

    const delayNode = offlineContext.createDelay(Math.max(1, clampedDelay + 2)); 
    delayNode.delayTime.setValueAtTime(clampedDelay, offlineContext.currentTime);

    const feedbackNode = offlineContext.createGain();
    feedbackNode.gain.setValueAtTime(clampedFeedback, offlineContext.currentTime);

    const dryNode = offlineContext.createGain();
    dryNode.gain.setValueAtTime(1 - clampedMix, offlineContext.currentTime);
    
    const wetNode = offlineContext.createGain();
    wetNode.gain.setValueAtTime(clampedMix, offlineContext.currentTime);
    
    sourceNode.connect(dryNode);
    dryNode.connect(offlineContext.destination);

    sourceNode.connect(delayNode);
    delayNode.connect(wetNode);
    wetNode.connect(offlineContext.destination);

    delayNode.connect(feedbackNode);
    feedbackNode.connect(delayNode); 
    
    sourceNode.start(0);
    const renderedBuffer = await offlineContext.startRendering();
    const processedAudioDataUrl = await audioBufferToWavDataUrl(renderedBuffer);
    
    return { processedAudioDataUrl, analysis: `Echo: Delay ${(clampedDelay*1000).toFixed(0)}ms, Feedback ${(clampedFeedback*100).toFixed(0)}%, Mix ${(clampedMix*100).toFixed(0)}% wet.` };
  },

  reversePlayback: async (audioDataUrl: string, params: {}) => {
    const audioContext = getGlobalAudioContext();
    if (!audioContext) throw new Error("AudioContext not supported");

    const arrayBuffer = await dataUrlToArrayBuffer(audioDataUrl);
    const decodedAudioBuffer = await audioContext.decodeAudioData(arrayBuffer);
    if (decodedAudioBuffer.length === 0) return { processedAudioDataUrl: audioDataUrl, analysis: "Audio is empty."};


    const numChannels = decodedAudioBuffer.numberOfChannels;
    const length = decodedAudioBuffer.length;

    const reversedBuffer = audioContext.createBuffer(
      numChannels,
      length,
      decodedAudioBuffer.sampleRate
    );

    for (let i = 0; i < numChannels; i++) {
      const channelData = decodedAudioBuffer.getChannelData(i);
      const reversedChannelData = reversedBuffer.getChannelData(i);
      const originalChannelDataCopy = new Float32Array(channelData); 
      for (let j = 0; j < length; j++) {
        reversedChannelData[j] = originalChannelDataCopy[length - 1 - j];
      }
    }
    
    const offlineContext = new OfflineAudioContext(numChannels, length, decodedAudioBuffer.sampleRate);
    const sourceNode = offlineContext.createBufferSource();
    sourceNode.buffer = reversedBuffer; 
    sourceNode.connect(offlineContext.destination);
    sourceNode.start(0);

    const renderedOutputBuffer = await offlineContext.startRendering();
    const processedAudioDataUrl = await audioBufferToWavDataUrl(renderedOutputBuffer);
    return { processedAudioDataUrl, analysis: "Audio reversed." };
  },

  paceAdjuster: async (audioDataUrl: string, { tempo }: { tempo: number }) => {
    const audioContext = getGlobalAudioContext();
    if (!audioContext) throw new Error("AudioContext not supported");

    const arrayBuffer = await dataUrlToArrayBuffer(audioDataUrl);
    const decodedAudioBuffer = await audioContext.decodeAudioData(arrayBuffer);
    if (decodedAudioBuffer.length === 0) return { processedAudioDataUrl: audioDataUrl, analysis: "Audio is empty."};
    
    const newTempo = Math.max(0.1, Math.min(tempo, 4)); 
    const newLength = Math.max(1, Math.round(decodedAudioBuffer.length / newTempo));
    
    const offlineContext = new OfflineAudioContext(
        decodedAudioBuffer.numberOfChannels,
        newLength, 
        decodedAudioBuffer.sampleRate
    );

    const sourceNode = offlineContext.createBufferSource();
    sourceNode.buffer = decodedAudioBuffer;
    sourceNode.playbackRate.value = newTempo;
    
    sourceNode.connect(offlineContext.destination);
    sourceNode.start(0);
    
    const renderedBuffer = await offlineContext.startRendering();
    const processedAudioDataUrl = await audioBufferToWavDataUrl(renderedBuffer);

    return { processedAudioDataUrl, analysis: `Pace adjusted to ${newTempo.toFixed(2)}x. (Note: This basic method also affects pitch).` };
  },

  gainController: async (audioDataUrl: string, { gain }: { gain: number }) => {
    const gainValue = Math.pow(10, gain / 20); 
    return processAudioWithEffect(audioDataUrl, (context, source, buffer) => {
      const gainNode = context.createGain();
      gainNode.gain.setValueAtTime(gainValue, context.currentTime);
      return [gainNode];
    }, `Gain adjusted by ${gain}dB (linear gain: ${gainValue.toFixed(2)}).`);
  },

  rhythmDetector: async (audioDataUrl: string, params: {}): Promise<{ processedAudioDataUrl: string; analysis?: string }> => {
    const audioContext = getGlobalAudioContext();
    if (!audioContext) {
      return { processedAudioDataUrl: audioDataUrl, analysis: "BPM: N/A\nInterval: N/A (AudioContext not available.)" };
    }

    try {
      const arrayBuffer = await dataUrlToArrayBuffer(audioDataUrl);
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
      
      if (audioBuffer.length === 0) {
        return { processedAudioDataUrl: audioDataUrl, analysis: "BPM: N/A\nInterval: N/A (Audio empty)" };
      }
      
      const channelData = audioBuffer.getChannelData(0); 
      const sampleRate = audioBuffer.sampleRate;

      let maxAmplitude = 0;
      for (let i = 0; i < channelData.length; i++) {
        if (Math.abs(channelData[i]) > maxAmplitude) {
          maxAmplitude = Math.abs(channelData[i]);
        }
      }
      
      const dynamicThreshold = maxAmplitude * 0.5; 
      const threshold = dynamicThreshold > 0.05 ? dynamicThreshold : 0.05;

      const peaks = [];
      const minPeakDistanceSamples = Math.floor(sampleRate * 0.20); // 200ms, BPM range 40-240 implies interval 0.25s-1.5s

      let lastPeakSampleIndex = -minPeakDistanceSamples; 

      for (let i = 1; i < channelData.length - 1; i++) {
        if (channelData[i] > channelData[i-1] && channelData[i] > channelData[i+1]) { // Basic peak detection
          if (channelData[i] > threshold && (i - lastPeakSampleIndex) > minPeakDistanceSamples) {
            peaks.push(i); 
            lastPeakSampleIndex = i;
          }
        }
      }

      if (peaks.length < 2) {
        return { processedAudioDataUrl: audioDataUrl, analysis: "BPM: N/A\nInterval: N/A (Not enough peaks detected for reliable analysis.)" };
      }

      const intervalsInSeconds = [];
      for (let i = 1; i < peaks.length; i++) {
        intervalsInSeconds.push((peaks[i] - peaks[i-1]) / sampleRate);
      }

      if (intervalsInSeconds.length === 0) {
        return { processedAudioDataUrl: audioDataUrl, analysis: "BPM: N/A\nInterval: N/A (No intervals found between peaks.)" };
      }

      const intervalCounts: { [key: string]: number } = {};
      const intervalPrecision = 0.01; 

      intervalsInSeconds.forEach(interval => {
        const bin = (Math.round(interval / intervalPrecision) * intervalPrecision).toFixed(2);
        intervalCounts[bin] = (intervalCounts[bin] || 0) + 1;
      });

      let mostCommonIntervalSec = 0;
      let maxCount = 0;
      for (const intervalStr in intervalCounts) {
        if (intervalCounts[intervalStr] > maxCount) {
          maxCount = intervalCounts[intervalStr];
          mostCommonIntervalSec = parseFloat(intervalStr);
        }
      }
      
      if (mostCommonIntervalSec <= 0 || mostCommonIntervalSec < 60/240 || mostCommonIntervalSec > 60/40 ) { 
        let plausibleInterval = 0;
        let highestPlausibleCount = 0;

        for (const intervalStr in intervalCounts) {
            const currentInterval = parseFloat(intervalStr);
            if (currentInterval >= 60/240 && currentInterval <= 60/40) { 
                if (intervalCounts[intervalStr] > highestPlausibleCount) {
                    highestPlausibleCount = intervalCounts[intervalStr];
                    plausibleInterval = currentInterval;
                }
            }
        }
        if (plausibleInterval > 0) {
            mostCommonIntervalSec = plausibleInterval;
        } else {
            if (mostCommonIntervalSec > 0) { 
                if (mostCommonIntervalSec * 2 >= 60/240 && mostCommonIntervalSec * 2 <= 60/40) mostCommonIntervalSec *=2;
                else if (mostCommonIntervalSec / 2 >= 60/240 && mostCommonIntervalSec / 2 <= 60/40) mostCommonIntervalSec /=2;
            }
            if (mostCommonIntervalSec <= 0 || mostCommonIntervalSec < 60/240 || mostCommonIntervalSec > 60/40) {
                 return { processedAudioDataUrl: audioDataUrl, analysis: "BPM: N/A\nInterval: N/A (No consistent beat found in typical BPM range.)" };
            }
        }
      }

      const bpm = 60 / mostCommonIntervalSec;
      const analysis = `BPM: ${bpm.toFixed(1)}\nInterval: ${mostCommonIntervalSec.toFixed(2)}s`;
      
      return { processedAudioDataUrl: audioDataUrl, analysis };

    } catch (error) {
      console.error("Error in rhythmDetector:", error);
      return { processedAudioDataUrl: audioDataUrl, analysis: `BPM: N/A\nInterval: N/A (Error: ${error.message || 'Unknown error during analysis.'})` };
    }
  },

  dreamscapeMaker: async (audioDataUrl: string, params: {}) => {
    const slowedResult = await audioUtils.paceAdjuster(audioDataUrl, { tempo: 0.75 }); 
    const dreamResult = await audioUtils.echoGenerator(slowedResult.processedAudioDataUrl, { delay: 200, feedback: 0.4, mix: 0.35 });
    return { ...dreamResult, analysis: "Dreamscape Maker: Applied 0.75x slowdown and echo (200ms delay, 40% feedback, 35% mix)." };
  },

  frequencyTuner: async (audioDataUrl: string, params: {}) => { 
    const pitchShiftRatio = 432 / 440; 
    const semitones = 12 * Math.log2(pitchShiftRatio);
    const result = await audioUtils.keyTransposer(audioDataUrl, { semitones });
    return { ...result, analysis: `Tuned to 432Hz (shifted by approx. ${semitones.toFixed(2)} semitones from 440Hz standard).` };
  },
  apply8DEffect: async (audioDataUrl: string, params: {} = {}) => {
    const pannerParams = { speed: 0.08 }; 
    const sweepResult = await audioUtils.automatedSweep(audioDataUrl, pannerParams);
  
    const reverbParams = { 
      delay: 70,       
      feedback: 0.15,  
      mix: 0.4         
    };
    const finalResult = await audioUtils.echoGenerator(sweepResult.processedAudioDataUrl, reverbParams);
  
    return {
      ...finalResult,
      analysis: `8D Audio Effect Applied: Auto Panner (Speed: ${pannerParams.speed}Hz) with Diffuse Reverb (Delay: ${reverbParams.delay}ms, Feedback: ${(reverbParams.feedback*100).toFixed(0)}%, Mix: ${(reverbParams.mix*100).toFixed(0)}% Wet). Designed for headphone listening to create a spatially diffuse experience.`,
    };
  },

  subtleSubwoofer: async (audioDataUrl: string, params: EffectSettings) => {
    return audioUtils.subharmonicIntensifier(audioDataUrl, { intensity: 20 });
  },
  gentleBassBoost: async (audioDataUrl: string, params: EffectSettings) => {
    return audioUtils.subharmonicIntensifier(audioDataUrl, { intensity: 35 });
  },
  mediumBassEnhancement: async (audioDataUrl: string, params: EffectSettings) => {
    return audioUtils.subharmonicIntensifier(audioDataUrl, { intensity: 60 });
  },
  intenseBassAmplifier: async (audioDataUrl: string, params: EffectSettings) => {
    return audioUtils.subharmonicIntensifier(audioDataUrl, { intensity: 75 });
  },
  maximumBassOverdrive: async (audioDataUrl: string, params: EffectSettings) => {
    return audioUtils.subharmonicIntensifier(audioDataUrl, { intensity: 100 });
  },

  vocalAmbience: async (audioDataUrl: string, params: EffectSettings) => {
    return audioUtils.echoGenerator(audioDataUrl, { delay: 80, feedback: 0.2, mix: 0.2 });
  },
  washroomEcho: async (audioDataUrl: string, params: EffectSettings) => {
    return audioUtils.echoGenerator(audioDataUrl, { delay: 150, feedback: 0.5, mix: 0.4 });
  },
  compactRoomReflector: async (audioDataUrl: string, params: EffectSettings) => {
    return audioUtils.echoGenerator(audioDataUrl, { delay: 100, feedback: 0.3, mix: 0.25 });
  },
  averageRoomReverberator: async (audioDataUrl: string, params: EffectSettings) => {
    return audioUtils.echoGenerator(audioDataUrl, { delay: 250, feedback: 0.4, mix: 0.3 });
  },
  grandRoomReverb: async (audioDataUrl: string, params: EffectSettings) => {
    return audioUtils.echoGenerator(audioDataUrl, { delay: 400, feedback: 0.45, mix: 0.35 });
  },
  chapelEchoes: async (audioDataUrl: string, params: EffectSettings) => {
    return audioUtils.echoGenerator(audioDataUrl, { delay: 600, feedback: 0.5, mix: 0.3 });
  },
  cathedralAcoustics: async (audioDataUrl: string, params: EffectSettings) => {
    return audioUtils.echoGenerator(audioDataUrl, { delay: 800, feedback: 0.55, mix: 0.25 });
  },

  automatedSweep: async (audioDataUrl: string, { speed }: { speed: number }) => {
    const maxDelayTimePanning = 1; // Max allowed by StereoPannerNode for pan, but LFO range is -1 to 1
    return processAudioWithEffect(audioDataUrl, (context, sourceNode, buffer) => {
       if (buffer.numberOfChannels < 2 && buffer.numberOfChannels !== 0) { 
            console.warn("Automated Sweep: Input is mono. Effect will pan, but perception requires stereo playback.");
       }

       const panner = context.createStereoPanner();
       const lfo = context.createOscillator();
       lfo.type = 'sine';
       const clampedSpeed = Math.max(0.01, Math.min(speed, 10)); 
       lfo.frequency.setValueAtTime(clampedSpeed, context.currentTime);
       
       const lfoGain = context.createGain(); 
       lfoGain.gain.setValueAtTime(1, context.currentTime); // Pan from -1 (left) to 1 (right)
       
       lfo.connect(lfoGain);
       lfoGain.connect(panner.pan); 
       
       lfo.start();
       
       return [panner]; 
   }, `Automated Sweep: Speed ${speed}Hz. Output will be stereo.`, 2); 
 },

  audioSplitter: async (audioDataUrl: string, { startTime: startTimeMinutes, endTime: endTimeMinutes }: { startTime: number, endTime: number }) => {
    const audioContext = getGlobalAudioContext();
    if (!audioContext) throw new Error("AudioContext not supported");

    const arrayBuffer = await dataUrlToArrayBuffer(audioDataUrl);
    const decodedAudioBuffer = await audioContext.decodeAudioData(arrayBuffer);
    const originalDurationSeconds = decodedAudioBuffer.duration;
    const numChannels = decodedAudioBuffer.numberOfChannels;
    const sampleRate = decodedAudioBuffer.sampleRate;

    if (decodedAudioBuffer.length === 0) {
      return { 
        processedAudioDataUrl: audioDataUrl, 
        analysis: `Audio Splitter: Audio is empty. No changes made.` 
      };
    }

    let sTimeSeconds = Number(startTimeMinutes) * 60;
    let eTimeSeconds = Number(endTimeMinutes) * 60;
    
    if (isNaN(sTimeSeconds) || isNaN(eTimeSeconds) || sTimeSeconds < 0 || eTimeSeconds < 0) {
      return { 
        processedAudioDataUrl: audioDataUrl, 
        analysis: `Audio Splitter: Invalid start (${startTimeMinutes}min) or end time (${endTimeMinutes}min). Times must be non-negative numbers. No changes made.` 
      };
    }

    sTimeSeconds = Math.max(0, Math.min(sTimeSeconds, originalDurationSeconds));
    eTimeSeconds = Math.max(sTimeSeconds, Math.min(eTimeSeconds, originalDurationSeconds)); 
        
    if (eTimeSeconds <= sTimeSeconds) {
         return { 
            processedAudioDataUrl: audioDataUrl, 
            analysis: `Audio Splitter: End time (${endTimeMinutes.toFixed(2)}min / ${eTimeSeconds.toFixed(2)}s) must be after start time (${startTimeMinutes.toFixed(2)}min / ${sTimeSeconds.toFixed(2)}s). No changes made.` 
        };
    }
    
    const splitDurationSeconds = eTimeSeconds - sTimeSeconds; 
    if (splitDurationSeconds <= 0.001) { 
        return {
            processedAudioDataUrl: audioDataUrl, 
            analysis: `Audio Splitter: Selected segment from ${sTimeSeconds.toFixed(2)}s (${startTimeMinutes.toFixed(2)}min) to ${eTimeSeconds.toFixed(2)}s (${endTimeMinutes.toFixed(2)}min) has negligible or zero duration. No changes made.`
        };
    }
    const contextLengthInSamples = Math.max(1, Math.floor(splitDurationSeconds * sampleRate));

    const offlineContext = new OfflineAudioContext(
      numChannels,
      contextLengthInSamples,
      sampleRate
    );

    const bufferSource = offlineContext.createBufferSource();
    bufferSource.buffer = decodedAudioBuffer;
    bufferSource.connect(offlineContext.destination);
    
    bufferSource.start(0, sTimeSeconds, splitDurationSeconds); 

    const renderedBuffer = await offlineContext.startRendering();
    
    if (renderedBuffer.duration < 0.001) { 
         return {
            processedAudioDataUrl: audioDataUrl, 
            analysis: `Audio Splitter: Extracted segment from ${sTimeSeconds.toFixed(2)}s to ${eTimeSeconds.toFixed(2)}s resulted in an empty audio clip. Original audio duration: ${originalDurationSeconds.toFixed(2)}s. No changes made.`
        };
    }
    
    const processedAudioDataUrl = await audioBufferToWavDataUrl(renderedBuffer);
    const analysisMessage = `Audio Splitter: Extracted segment from ${startTimeMinutes.toFixed(2)}min (${sTimeSeconds.toFixed(2)}s) to ${endTimeMinutes.toFixed(2)}min (${eTimeSeconds.toFixed(2)}s). New duration: ${renderedBuffer.duration.toFixed(2)}s.`;
    
    return {
      processedAudioDataUrl,
      analysis: analysisMessage
    };
  },
  loopAudio: async (audioDataUrl: string, loopCount: number): Promise<string> => {
    if (loopCount <= 1) {
      return audioDataUrl; // No looping needed
    }

    const audioContext = getGlobalAudioContext();
    if (!audioContext) {
      throw new Error("AudioContext not supported or initialized for looping.");
    }

    const arrayBuffer = await dataUrlToArrayBuffer(audioDataUrl);
    const originalBuffer = await audioContext.decodeAudioData(arrayBuffer);

    if (originalBuffer.length === 0) {
      console.warn("Cannot loop empty audio buffer.");
      return audioDataUrl;
    }

    const numChannels = originalBuffer.numberOfChannels;
    const sampleRate = originalBuffer.sampleRate;
    const originalLength = originalBuffer.length;
    const newLength = originalLength * loopCount;

    const loopedBuffer = audioContext.createBuffer(numChannels, newLength, sampleRate);

    for (let channel = 0; channel < numChannels; channel++) {
      const originalChannelData = originalBuffer.getChannelData(channel);
      const newChannelData = loopedBuffer.getChannelData(channel);
      for (let i = 0; i < loopCount; i++) {
        newChannelData.set(originalChannelData, originalLength * i);
      }
    }
    // Use an OfflineAudioContext to "play" the loopedBuffer once to get a final render,
    // as audioBufferToWavDataUrl expects a buffer that could be from an OfflineAudioContext.
    // This step ensures consistency, though for simple concatenation it might seem redundant.
    const offlineContext = new OfflineAudioContext(numChannels, newLength, sampleRate);
    const sourceNode = offlineContext.createBufferSource();
    sourceNode.buffer = loopedBuffer;
    sourceNode.connect(offlineContext.destination);
    sourceNode.start(0);

    const renderedLoopedBuffer = await offlineContext.startRendering();
    return audioBufferToWavDataUrl(renderedLoopedBuffer);
  },
};


================================================
FILE: src/lib/error-utils.ts
================================================
/**
 * Utility functions for handling and formatting user-friendly error messages
 */

export const getLaymanErrorMessage = (error: any): string => {
  // Check for common Puter-specific errors first
  if (typeof error === 'object' && error !== null) {
    const errObj = error as any;
    
    // Usage limited chat error
    if (errObj.success === false && errObj.error && typeof errObj.error === 'object' && errObj.error.message) {
      const puterErrorDetails = errObj.error;
      if (puterErrorDetails.delegate === 'usage-limited-chat' || 
          puterErrorDetails.message.toLowerCase().includes('usage limit') ||
          puterErrorDetails.message.toLowerCase().includes('permission denied')) {
        return "An error occurred. Try again or Create a New Puter Account.";
      }
    }
    
    // Other permission denied errors
    if (errObj.error && errObj.error.message && 
        errObj.error.message.toLowerCase().includes('permission denied')) {
      return "An error occurred. Try again or Create a New Puter Account.";
    }
    
    // Empty object error
    if (Object.keys(errObj).length === 0 && errObj.constructor === Object) {
      return "An error occurred. Try again or Create a New Puter Account.";
    }
  }
  
  // Check for common error patterns in strings
  if (typeof error === 'string') {
    const lowerError = error.toLowerCase();
    if (lowerError.includes('usage limit') || 
        lowerError.includes('permission denied') ||
        lowerError.includes('authentication') ||
        lowerError.includes('unauthorized')) {
      return "An error occurred. Try again or Create a New Puter Account.";
    }
  }
  
  // Check for Error objects
  if (error instanceof Error) {
    const lowerMessage = error.message.toLowerCase();
    if (lowerMessage.includes('usage limit') || 
        lowerMessage.includes('permission denied') ||
        lowerMessage.includes('authentication') ||
        lowerMessage.includes('unauthorized')) {
      return "An error occurred. Try again or Create a New Puter Account.";
    }
    
    // For other errors, still show a friendly message but keep some context
    if (lowerMessage.includes('network') || lowerMessage.includes('fetch')) {
      return "Network error occurred. Please check your connection and try again.";
    }
    
    if (lowerMessage.includes('timeout')) {
      return "Request timed out. Please try again.";
    }
    
    if (lowerMessage.includes('invalid') || lowerMessage.includes('malformed')) {
      return "Invalid request. Please check your input and try again.";
    }
  }
  
  // Default friendly error message
  return "An error occurred. Try again or Create a New Puter Account.";
};


================================================
FILE: src/lib/image-utils.ts
================================================
export const preprocessImage = (
  file: File,
  targetWidth: number,
  quality: number = 0.85 // Default JPEG quality
): Promise<string> => {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onload = (event) => {
      if (!event.target?.result) {
        return reject(new Error("Failed to read file."));
      }
      
      const img = new Image();
      img.onload = () => {
        const canvas = document.createElement('canvas');
        const aspectRatio = img.width / img.height;
        
        canvas.width = targetWidth;
        canvas.height = targetWidth / aspectRatio;
        
        const ctx = canvas.getContext('2d');
        if (!ctx) {
          return reject(new Error("Failed to get canvas context."));
        }
        
        ctx.drawImage(img, 0, 0, canvas.width, canvas.height);
        
        // Determine output format based on original file type for transparency, default to JPEG
        let outputFormat = 'image/jpeg';
        if (file.type === 'image/png') {
          outputFormat = 'image/png';
        }
        
        const dataUrl = canvas.toDataURL(outputFormat, quality);
        resolve(dataUrl);
      };
      img.onerror = (error) => {
        reject(new Error(`Failed to load image: ${error}`));
      };
      img.src = event.target.result as string;
    };
    reader.onerror = (error) => {
      reject(new Error(`FileReader error: ${error}`));
    };
    reader.readAsDataURL(file);
  });
};



================================================
FILE: src/lib/utils.ts
================================================
import { clsx, type ClassValue } from "clsx"
import { twMerge } from "tailwind-merge"

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs))
}

export function downloadTextFile(content: string, filename: string) {
  const element = document.createElement("a");
  const file = new Blob([content], { type: 'text/plain' });
  element.href = URL.createObjectURL(file);
  element.download = filename;
  document.body.appendChild(element); // Required for this to work in FireFox
  element.click();
  document.body.removeChild(element);
  URL.revokeObjectURL(element.href); // Clean up
}



================================================
FILE: src/types/ai-audio-editor.ts
================================================
// Types for Bass Booster Levels
export type BassBoostLevel =
  | 'Subtle Subwoofer'
  | 'Gentle Boost'
  | 'Medium Enhancement'
  | 'Intense Amplifier'
  | 'Maximum Overdrive';

// Types for Reverb Presets
export type ReverbPreset =
  | 'Vocal Ambience'
  | 'Washroom'
  | 'Small Room'
  | 'Medium Room'
  | 'Large Room'
  | 'Chapel'
  | 'Hall'
  | 'Cathedral';

// Interface for individual audio editing feature settings
export interface AudioEffectSettings {
  lofi?: { intensity: number };
  eightDD?: {}; // Simple toggle or specific 8D parameters
  tune432Hz?: {}; // Simple toggle
  resonanceAlteration?: { frequency: number; amount: number };
  temporalModification?: { stretchRatio: number };
  stereoWidener?: { amount: number };
  automatedSweep?: { startFrequency: number; endFrequency: number; duration: number };
  subharmonicIntensifier?: { intensity: number; frequency: number };
  frequencySculptor?: { points: Array<{ frequency: number; gain: number }> };
  keyTransposer?: { semitones: number };
  paceAdjuster?: { speedRatio: number };
  echoGenerator?: { delay: number; decay: number; feedback: number };
  reversePlayback?: {}; // Simple toggle
  gainController?: { gainDb: number };
  audioSplitter?: { splitPoints: number[] };
  rhythmDetector?: {}; // Could have sensitivity or other parameters
  bassBooster?: { level: BassBoostLevel };
  reverb?: { preset: ReverbPreset };
}

// Interface for the state of the audio editor
export interface AudioEditorState {
  currentAudioFile: string | null; // Path or URL of the audio file
  isPlaying: boolean;
  currentTime: number; // Current playback time in seconds
  duration: number; // Total duration in seconds
  appliedEffects: AudioEffectSettings;
  aiChatHistory: ChatMessage[];
  isProcessing: boolean; // Indicates if an audio operation is in progress
}

// Interface for a message in the AI chatbot
export interface ChatMessage {
  sender: 'user' | 'ai';
  text: string;
  timestamp: number;
}

// Interface for actions that can be dispatched to the editor
export interface AudioEditorAction {
  type: string; // Type of action (e.g., 'LOAD_AUDIO', 'PLAY_PAUSE', 'APPLY_EFFECT', 'SEND_CHAT_MESSAGE')
  payload?: any; // Data associated with the action
}

// Interface for the AI chatbot's interaction
export interface AIChatInterface {
  sendMessage: (message: string) => Promise<void>;
  onMessageReceived: (handler: (message: ChatMessage) => void) => void;
  processAudioCommand: (command: string) => Promise<boolean>; // Returns true if command was successful
}

// Interface for the main AI Native Audio Editor tool
export interface AINativeAudioEditor {
  state: AudioEditorState;
  dispatch: (action: AudioEditorAction) => void;
  aiChat: AIChatInterface;
  // Potentially other methods for direct control
  loadAudio: (file: File | string) => void;
  play: () => void;
  pause: () => void;
  seek: (time: number) => void;
  applyEffect: (effect: keyof AudioEffectSettings, settings: AudioEffectSettings[keyof AudioEffectSettings]) => void;
  undoLastEffect: () => void;
  saveAudio: (format: string) => Promise<Blob | null>;
}


================================================
FILE: src/types/ai-date-time-checker.ts
================================================
export interface DateTimeRequest {
  queryType: 'date-to-info' | 'day-to-dates';
  // For date-to-info queries
  selectedDate?: string; // ISO date string
  // For day-to-dates queries
  selectedMonth?: number;
  selectedYear?: number;
  selectedDayOfWeek?: string;
}

export interface DateTimeReport {
  query_type: 'date-to-info' | 'day-to-dates';
  
  // For date-to-info responses
  date_info?: {
    formatted_date: string;
    day_of_week: string;
    day_number: number;
    month_name: string;
    year: number;
    century: string;
    millennium: string;
    julian_day?: number;
    historical_events?: string[];
    astronomical_info?: string[];
    cultural_significance?: string[];
    season: string;
    zodiac_sign?: string;
  };
  
  // For day-to-dates responses
  matching_dates?: {
    month_name: string;
    year: number;
    day_of_week: string;
    dates: number[];
    total_count: number;
    formatted_dates: string[];
  };
  
  calculation_method: string;
  confidence: 'High' | 'Medium' | 'Low';
  historical_accuracy_note?: string;
  disclaimer: string;
}

export interface AIDateTimeCheckerFormValues {
  queryType: 'date-to-info' | 'day-to-dates';
  selectedDate?: string;
  selectedMonth?: number;
  selectedYear?: number;
  selectedDayOfWeek?: string;
}


================================================
FILE: src/types/ai-infographics.ts
================================================
export interface InfographicData {
  type: 'pie' | 'bar' | 'line' | 'area' | 'scatter' | 'tree' | 'heatmap' | 'custom';
  title: string;
  description?: string;
  data: any; // This will be chart-specific data
  config?: any; // Chart configuration options
  svgContent?: string; // For custom SVG-based visualizations
}

export interface ChatMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
  timestamp: Date;
}

export interface AIInfographicsRequest {
  prompt: string;
  chartType?: string;
  data?: any;
  contextData?: any;
  imageData?: string;
}

export interface AIInfographicsResponse {
  message: string;
  visualization: InfographicData;
}


================================================
FILE: src/types/ai-problem-solver.ts
================================================
export interface ProblemSolverRequest {
  inputType: 'image' | 'text';
  imageFile?: File;
  textInput?: string;
  problemType: string;
  additionalContext?: string;
}

export interface ProblemStep {
  step_number: number;
  description: string;
  explanation: string;
  formula_used?: string;
}

export interface ProblemSolverReport {
  problem_description: string;
  problem_type: string;
  solution_steps: ProblemStep[];
  final_answer: string;
  key_concepts: string[];
  difficulty_level: 'Beginner' | 'Intermediate' | 'Advanced' | 'Expert';
  alternative_methods?: string[];
  common_mistakes?: string[];
  related_topics?: string[];
  image_description?: string; // For image input
  confidence: 'High' | 'Medium' | 'Low' | 'Not Applicable';
  disclaimer: string;
}

export interface AIProblemSolverFormValues {
  inputType: 'image' | 'text';
  imageFile?: FileList;
  textInput?: string;
  problemType: string;
  additionalContext?: string;
}


================================================
FILE: src/types/ai-spreadsheets.ts
================================================
export interface SpreadsheetCell {
  value: string;
  formula?: string;
  style?: {
    bold?: boolean;
    italic?: boolean;
    color?: string;
    backgroundColor?: string;
    textAlign?: 'left' | 'center' | 'right';
  };
}

export interface SpreadsheetData {
  rows: SpreadsheetCell[][];
  columnWidths?: number[];
  rowHeights?: number[];
  activeSheet: string;
  sheets: string[];
}

export interface ChatMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
  timestamp: Date;
}

export interface SpreadsheetOperation {
  type: 'update_cell' | 'update_row' | 'update_column' | 'add_row' | 'add_column' | 'delete_row' | 'delete_column' | 'format' | 'create_chart' | 'find_replace';
  details: any; // Specific details for each operation type
}

export interface AISpreadsheetResponse {
  operations: SpreadsheetOperation[];
  explanation: string;
}


================================================
FILE: src/types/ai-text-to-speech.ts
================================================
export type TextToSpeechInput =
  | { type: 'text'; content: string }
  | { type: 'file'; file: File };

export type TextToSpeechOutput = {
  type: 'audio';
  audioData: ArrayBuffer; // Or Blob, or a stream type depending on implementation
};

export type TextToSpeechError = {
  type: 'error';
  message: string;
  details?: string;
};

export type TextToSpeechResult = TextToSpeechOutput | TextToSpeechError;


================================================
FILE: src/types/ai-translator.ts
================================================
export interface TranslationRequest {
  inputType: 'image' | 'text';
  imageFile?: File;
  textInput?: string;
  sourceLanguage: string;
  targetLanguage: string;
}

export interface TranslationReport {
  original_text: string;
  translated_text: string;
  source_language_detected?: string;
  target_language: string;
  translation_confidence: 'High' | 'Medium' | 'Low';
  context_notes?: string[];
  alternative_translations?: string[];
  image_description?: string; // For image input
  text_extraction_quality?: 'High' | 'Medium' | 'Low'; // For image input
  disclaimer: string;
}

export interface AITranslatorFormValues {
  inputType: 'image' | 'text';
  imageFile?: FileList;
  textInput?: string;
  sourceLanguage: string;
  targetLanguage: string;
}


================================================
FILE: src/types/appliance-troubleshooter.ts
================================================
export interface ApplianceTroubleshootingReport {
  image_description: string;
  device_type: string;
  identified_issues: string[];
  possible_causes: string[];
  recommended_solutions: string[];
  safety_warnings?: string[];
  confidence: 'High' | 'Medium' | 'Low' | 'Not Applicable';
  disclaimer: string;
}

export interface ApplianceTroubleshooterFormValues {
  imageFile: FileList;
  issueDescription: string;
  deviceType: string;
  additionalDetails?: string;
}


================================================
FILE: src/types/audio-forge.ts
================================================
import type { LucideIcon } from 'lucide-react';

export type ControlType = 'slider' | 'button' | 'toggle' | 'select' | 'number_input' | 'group' | 'textarea';

export interface EffectParameterOption {
  value: string | number;
  label: string;
}

export interface EffectParameter {
  name: string;
  label: string;
  type: 'slider' | 'number_input' | 'select' | 'textarea' | 'button'; // Added 'button' for grouped buttons
  defaultValue: number | string;
  min?: number;
  max?: number;
  step?: number;
  options?: EffectParameterOption[];
  placeholder?: string;
  rows?: number;
  handlerKey?: string; // For buttons within a group that have specific actions
}

export interface Effect {
  id: string;
  name:string;
  description: string;
  icon: LucideIcon;
  controlType: ControlType;
  parameters?: EffectParameter[];
  actionLabel?: string; // For buttons
  handlerKey?: string; // Key to map to a handler function
  groupName?: string; // For grouping effects in UI
  outputsAnalysis?: boolean; // If tool outputs analysis text
}

export interface EffectSettings {
  [key: string]: any;
}


================================================
FILE: src/types/effects.ts
================================================

import type { Effect } from '@/types/audio-forge';
import {
  Waves,
  Clock,
  Download,
  Expand,
  Shuffle,
  SignalLow,
  SlidersHorizontal,
  Music2,
  Repeat,
  Rewind,
  Spline,
  Gauge,
  Scissors,
  Volume2,
  HeartPulse,
  Building,
  Moon,
  Copyleft,
  Headphones,
  TrendingDown,
  HelpingHand,
  CassetteTape, // Added CassetteTape
} from 'lucide-react';

export const effectsList: Effect[] = [
  // Creative Presets
  {
    id: 'dreamscapeMaker',
    name: "Lo-fi",
    description: 'Create lo-fi music with a slowed and reverb effect for chill, atmospheric soundscapes. Perfect for lo-fi beats, study music, and relaxing background audio.',
    icon: CassetteTape, // Changed from Moon to CassetteTape
    controlType: 'button',
    actionLabel: "Apply Lo-fi Effect",
    handlerKey: 'dreamscapeMaker',
    groupName: 'Creative Presets',
  },
  {
    id: 'audio8DConverter',
    name: '8D Audio Converter',
    description: 'Transform any song or audio file into immersive 8D audio. Combine panning and reverb to simulate a surround sound experience in your headphones.',
    icon: Headphones,
    controlType: 'button',
    actionLabel: 'Apply 8D Effect',
    handlerKey: 'apply8DEffect',
    groupName: 'Creative Presets',
  },
  {
    id: 'frequencyTuner432',
    name: 'Tune to 432Hz',
    description: 'Convert music from standard 440Hz tuning to 432Hz for a warmer, more natural sound. Ideal for musicians and audiophiles seeking 432Hz audio.',
    icon: Copyleft, 
    controlType: 'button',
    actionLabel: 'Tune to 432Hz',
    handlerKey: 'frequencyTuner',
    groupName: 'Creative Presets',
  },
  // Core Effects
  {
    id: 'resonanceAlteration',
    name: 'Resonance Alteration',
    description: 'Shift the frequency of your audio with a pitch shifter. Change how high or low your audio sounds for creative or corrective purposes.',
    icon: Waves,
    controlType: 'slider',
    parameters: [
      { name: 'frequency', label: 'Frequency Shift', type: 'slider', defaultValue: 0, min: -12, max: 12, step: 1 }
    ],
    handlerKey: 'alterResonance',
    groupName: 'Core Effects',
  },
  {
    id: 'temporalModification',
    name: 'Temporal Modification',
    description: 'Change the playback speed of audio without affecting pitch. Speed up or slow down music, podcasts, and more.',
    icon: Clock,
    controlType: 'slider',
    parameters: [
      { name: 'rate', label: 'Playback Rate', type: 'slider', defaultValue: 1, min: 0.5, max: 2, step: 0.01 }
    ],
    handlerKey: 'temporalModification',
    groupName: 'Core Effects',
  },
  // Spatial Effects
  {
    id: 'stereoWidener',
    name: 'Stereo Widener',
    description: 'Widen the stereo image of your audio for a fuller, more spacious sound. Enhance stereo separation for music or podcasts.',
    icon: Expand,
    controlType: 'slider',
    parameters: [
      { name: 'width', label: 'Stereo Width', type: 'slider', defaultValue: 100, min: 0, max: 200, step: 1 }
    ],
    handlerKey: 'stereoWidener',
    groupName: 'Spatial Effects',
  },
  {
    id: 'automatedSweep',
    name: 'Automated Sweep',
    description: 'Pan audio from left to right automatically. Create dynamic, moving effects for binaural and immersive listening.',
    icon: Shuffle,
    controlType: 'slider',
    parameters: [
      { name: 'speed', label: 'Sweep Speed (Hz)', type: 'slider', defaultValue: 0.5, min: 0.05, max: 5, step: 0.01 }
    ],
    handlerKey: 'automatedSweep',
    groupName: 'Spatial Effects',
  },
  // Frequency Tools
  {
    id: 'subharmonicIntensifier',
    name: 'Subharmonic Intensifier',
    description: 'Boost the bass and sub-bass frequencies in your audio. Use this bass booster to add depth and power to any track.',
    icon: TrendingDown,
    controlType: 'slider',
    parameters: [
      { name: 'intensity', label: 'Intensity', type: 'slider', defaultValue: 50, min: 0, max: 100, step: 1 }
    ],
    handlerKey: 'subharmonicIntensifier',
    groupName: 'Frequency Tools',
  },
  {
    id: 'frequencySculptor',
    name: 'Frequency Sculptor',
    description: 'Shape your sound with a 3-band equalizer (EQ). Adjust bass, mid, and treble frequencies for precise audio control.',
    icon: SlidersHorizontal,
    controlType: 'group', // Implies multiple sliders
    parameters: [
      { name: 'low', label: 'Low Gain (dB)', type: 'slider', defaultValue: 0, min: -12, max: 12, step: 0.5 },
      { name: 'mid', label: 'Mid Gain (dB)', type: 'slider', defaultValue: 0, min: -12, max: 12, step: 0.5 },
      { name: 'high', label: 'High Gain (dB)', type: 'slider', defaultValue: 0, min: -12, max: 12, step: 0.5 },
    ],
    handlerKey: 'frequencySculptor',
    groupName: 'Frequency Tools',
  },
  // Pitch & Time
  {
    id: 'keyTransposer',
    name: 'Key Transposer',
    description: 'Transpose the key of your audio up or down in semitones. Perfect for musicians and vocalists wanting to shift pitch.',
    icon: Music2, 
    controlType: 'number_input',
    parameters: [
      { name: 'semitones', label: 'Semitones', type: 'number_input', defaultValue: 0, min: -12, max: 12, step: 1 }
    ],
    handlerKey: 'keyTransposer',
    groupName: 'Pitch & Time',
  },
  {
    id: 'paceAdjuster',
    name: 'Pace Adjuster',
    description: 'Adjust tempo without changing pitch. Speed up or slow down your audio to match any project or practice needs.',
    icon: Gauge,
    controlType: 'slider',
    parameters: [
      { name: 'tempo', label: 'Tempo Adjust', type: 'slider', defaultValue: 1, min: 0.5, max: 2, step: 0.01 }
    ],
    handlerKey: 'paceAdjuster',
    groupName: 'Pitch & Time',
  },
  // Creative Effects
  {
    id: 'echoGenerator',
    name: 'Echo Generator',
    description: 'Add customizable echo and delay effects to your audio. Create depth and atmosphere with professional-quality echo controls.',
    icon: Repeat,
    controlType: 'group',
    parameters: [
      { name: 'delay', label: 'Delay (ms)', type: 'slider', defaultValue: 300, min: 10, max: 1000, step: 10 },
      { name: 'feedback', label: 'Feedback', type: 'slider', defaultValue: 0.5, min: 0, max: 0.95, step: 0.01 },
      { name: 'mix', label: 'Mix', type: 'slider', defaultValue: 0.5, min: 0, max: 1, step: 0.01 },
    ],
    handlerKey: 'echoGenerator',
    groupName: 'Creative Effects',
  },
  {
    id: 'reversePlayback',
    name: 'Reverse Playback',
    description: 'Play any audio file in reverse. Create experimental sounds or uncover hidden audio details.',
    icon: Rewind,
    controlType: 'button',
    actionLabel: 'Reverse Audio',
    handlerKey: 'reversePlayback',
    groupName: 'Creative Effects',
  },
  // Utility Tools
  {
    id: 'gainController',
    name: 'Gain Controller',
    description: 'Increase or decrease the volume of your audio with a precise gain control slider.',
    icon: Volume2,
    controlType: 'slider',
    parameters: [
      { name: 'gain', label: 'Gain (dB)', type: 'slider', defaultValue: 0, min: -24, max: 24, step: 0.5 }
    ],
    handlerKey: 'gainController',
    groupName: 'Utility Tools',
  },
   {
    id: 'audioSplitter',
    name: 'Audio Splitter',
    description: 'Cut and extract sections from your audio by selecting start and end times. Ideal for trimming music, podcasts, and samples.',
    icon: Scissors,
    controlType: 'group',
    parameters: [
      { name: 'startTime', label: 'Start Time (min)', type: 'number_input', defaultValue: 0, min: 0, step: 0.01 },
      { name: 'endTime', label: 'End Time (min)', type: 'number_input', defaultValue: 0.1, min: 0, step: 0.01 } // Default 0.1 min = 6 seconds
    ],
    handlerKey: 'audioSplitter',
    groupName: 'Utility Tools',
  },
  // Analysis Tools
  {
    id: 'rhythmDetector',
    name: 'Rhythm Detector',
    description: 'Detect and analyze the BPM (beats per minute) of any audio file. Perfect for DJs, remixes, and tempo-matching.',
    icon: HeartPulse,
    controlType: 'button',
    actionLabel: 'Analyze BPM',
    handlerKey: 'rhythmDetector',
    groupName: 'Analysis Tools',
    outputsAnalysis: true,
  },
  // Bass Boost Presets
  {
    id: 'bassBoosterPresets',
    name: 'Bass Booster',
    description: 'Choose from a range of bass booster presets to enhance low frequencies: subtle, gentle, medium, intense, or maximum bass.',
    icon: SignalLow,
    controlType: 'group', 
    groupName: 'Bass Boost Presets',
    parameters: [
      { name: 'subtleSubwoofer', label: 'Subtle Subwoofer', type: 'button', handlerKey: 'subtleSubwoofer', defaultValue: '' },
      { name: 'gentleBassBoost', label: 'Gentle Boost', type: 'button', handlerKey: 'gentleBassBoost', defaultValue: '' },
      { name: 'mediumBassEnhancement', label: 'Medium Enhancement', type: 'button', handlerKey: 'mediumBassEnhancement', defaultValue: '' },
      { name: 'intenseBassAmplifier', label: 'Intense Amplifier', type: 'button', handlerKey: 'intenseBassAmplifier', defaultValue: '' },
      { name: 'maximumBassOverdrive', label: 'Maximum Overdrive', type: 'button', handlerKey: 'maximumBassOverdrive', defaultValue: '' },
    ]
  },
  // Reverb Presets
  {
    id: 'reverbPresets',
    name: 'Reverb Presets',
    description: 'Simulate real acoustic spaces with reverb presets: vocal ambience, washroom, small room, medium room, large room, chapel hall, or cathedral.',
    icon: Building, 
    controlType: 'group', 
    groupName: 'Reverb Presets',
    parameters: [
      { name: 'vocalAmbience', label: 'Vocal Ambience', type: 'button', handlerKey: 'vocalAmbience', defaultValue: '' },
      { name: 'washroomEcho', label: 'Washroom', type: 'button', handlerKey: 'washroomEcho', defaultValue: '' },
      { name: 'compactRoomReflector', label: 'Small Room', type: 'button', handlerKey: 'compactRoomReflector', defaultValue: '' },
      { name: 'averageRoomReverberator', label: 'Medium Room', type: 'button', handlerKey: 'averageRoomReverberator', defaultValue: '' },
      { name: 'grandRoomReverb', label: 'Large Room', type: 'button', handlerKey: 'grandRoomReverb', defaultValue: '' },
      { name: 'chapelEchoes', label: 'Chapel Hall', type: 'button', handlerKey: 'chapelEchoes', defaultValue: '' }, 
      { name: 'cathedralAcoustics', label: 'Cathedral', type: 'button', handlerKey: 'cathedralAcoustics', defaultValue: '' }, 
    ]
  },
];

export const effectGroups = [
    'Creative Presets',
    'Core Effects',
    'Spatial Effects',
    'Frequency Tools',
    'Pitch & Time',
    'Creative Effects',
    'Utility Tools',
    'Analysis Tools',
    'Bass Boost Presets',
    'Reverb Presets'
];


export const fallbackIcon = HelpingHand;

// Features that might be represented differently or are not direct effects
// - Audio Upload & Processing: Handled by FileUploadArea
// - Export Configuration: Handled by ExportPanel
// - Format Shifter: Part of ExportPanel
// - Frequency Visualizer: Component in MainDisplayPanel
// - Amplitude Plotter: Component in MainDisplayPanel
// - AI Tools: Removed


================================================
FILE: src/types/ethnicity-certifier.ts
================================================

export interface EthnicityAnalysisInput {
  type: 'image' | 'text';
  imageDataUrl?: string; // For image
  textData?: string;     // For text
}

export interface EthnicityAnalysisReport {
  image_description?: string; // General description of the image (for image analysis)
  representation_summary: string;
  ethical_assessment: string;
  concerns_raised: string[];
  confidence: 'High' | 'Medium' | 'Low' | 'Not Applicable' | 'Unable to determine';
  disclaimer?: string; // Optional: To reinforce AI limitations
}

export interface EthnicityCertifierFormValues {
  inputType: 'image' | 'text';
  imageFile?: FileList;
  textInput?: string;
  textFile?: FileList;
}




================================================
FILE: src/types/heatmap-generator.ts
================================================

export interface ImageAttentionArea {
  area_description: string; // e.g., "The main subject's face", "Top-left logo"
  reason: string;         // Why it attracts attention
  attention_level: 'high' | 'medium' | 'low';
  location_hint?: 'center' | 'top-center' | 'bottom-center' | 'left-center' | 'right-center' | 'top-left' | 'top-right' | 'bottom-left' | 'bottom-right' | string; // string for more general AI descriptions
}

export interface ImageHeatmapReport {
  image_description: string; // General description of the image content
  high_attention_areas: ImageAttentionArea[];
  low_attention_areas: ImageAttentionArea[];
  confidence: 'High' | 'Medium' | 'Low' | 'Not Applicable';
  disclaimer: string;
}

export interface TextSegmentEngagement {
  segment: string;
  engagement_level: 'high' | 'medium' | 'low' | 'neutral';
  reason?: string; // Optional: why this engagement level
}

export interface TextHeatmapReport {
  overall_summary: string;
  segments: TextSegmentEngagement[];
  confidence: 'High' | 'Medium' | 'Low' | 'Not Applicable';
  disclaimer: string;
}

export interface HeatmapGeneratorFormValues {
  inputType: 'image' | 'text';
  imageFile?: FileList;
  textInput?: string;
  textFile?: FileList;
}



================================================
FILE: src/types/image-to-text.ts
================================================
export interface ImageToTextRequest {
  imageFile: File;
  analysisType?: 'basic' | 'detailed';
  language?: string;
}

export interface ExtractedText {
  content: string;
  confidence: number;
  location?: string;
  formatting?: string;
}

export interface ImageToTextReport {
  image_description: string;
  extracted_text: string;
  text_analysis: {
    word_count: number;
    character_count: number;
    language_detected?: string;
    text_quality: 'High' | 'Medium' | 'Low';
    formatting_notes: string[];
  };
  text_segments?: ExtractedText[];
  confidence: 'High' | 'Medium' | 'Low' | 'Not Applicable';
  limitations: string[];
  disclaimer: string;
}

export interface ImageToTextFormValues {
  imageFile: FileList;
  analysisType?: string;
  language?: string;
}


================================================
FILE: src/types/ingredients-checker.ts
================================================
export interface IngredientsAnalysisInput {
  type: 'image' | 'text';
  imageData?: string;
  textData?: string;
  manufacturer?: string;
}

export interface Ingredient {
  name: string;
  description: string;
  safety_rating: 'Safe' | 'Caution' | 'Warning' | 'Unknown';
  common_uses: string[];
  potential_concerns: string[];
  alternatives?: string[];
  source?: 'visible' | 'typical_recipe' | 'likely_additive' | 'provided' | 'uncertain' | 'unknown';
  confidence_note?: string;
}

export interface IngredientsAnalysisReport {
  product_name?: string;
  manufacturer?: string;
  analysis_type?: 'ingredients_label' | 'food_item' | 'raw_ingredients' | 'text_input' | 'unknown';
  ingredients_list: Ingredient[];
  overall_assessment: {
    safety_rating: 'Safe' | 'Moderate Concern' | 'High Concern' | 'Insufficient Data';
    summary: string;
    key_concerns: string[];
    recommendations: string[];
  };
  dietary_flags?: {
    vegan: boolean;
    vegetarian: boolean;
    gluten_free: boolean;
    common_allergens: string[];
    reliability_note?: string;
  };
  analysis_limitations?: string[];
  confidence: 'High' | 'Medium' | 'Low' | 'Not Applicable';
  disclaimer: string;
}

export interface IngredientsCheckerFormValues {
  inputType: 'image' | 'text';
  imageFile?: FileList;
  textInput?: string;
  manufacturer?: string;
}


================================================
FILE: src/types/measuring-tool.ts
================================================
export interface MeasurementRequest {
  imageFile: File;
  metricSystem: 'metric' | 'imperial';
  measurementTarget: string;
  additionalContext?: string;
}

export interface MeasurementReport {
  image_description: string;
  measurements: {
    target: string;
    value: number;
    unit: string;
    confidence: number;
  }[];
  visual_reference_points: string[];
  confidence: 'High' | 'Medium' | 'Low' | 'Not Applicable';
  limitations: string[];
  disclaimer: string;
}

export interface MeasuringToolFormValues {
  imageFile: FileList;
  metricSystem: string;
  measurementTarget: string;
  additionalContext?: string;
}


================================================
FILE: src/types/mediscan.ts
================================================
export type MedicalImageType = 'x-ray' | 'mri' | 'ct scan' | 'ultrasound' | 'other';

export interface MedicalImageAnalysisRequest {
  image: string; // Base64 encoded image
  imageType: MedicalImageType;
  additionalInfo?: string;
}

export interface MedicalReport {
  findings: string;
  possibleDiagnoses: string[];
  recommendations: string;
}

export interface NextSteps {
  nextSteps: string;
}

export interface AnalysisResult {
  report: MedicalReport | null;
  nextSteps: NextSteps | null;
  error?: string;
}

export interface MedicalImageAnalysisResponse {
  abnormalities: string;
  diagnosis: string;
  nextSteps: string;
}



================================================
FILE: src/types/neurodiversity-checker.ts
================================================

export interface NeurodiversityAnalysisInput {
  type: 'image' | 'text';
  imageDataUrl?: string; // For image
  textData?: string;     // For text
}

export interface NeurodiversityAnalysisReport {
  image_description?: string; // General description of the image (for image analysis)
  neurodiversity_friendliness_assessment: string; // e.g., "Appears generally neurodiversity-friendly", "Potential areas for improvement", "Significant concerns"
  positive_aspects: string[]; // Elements identified as good for neurodiversity
  areas_for_improvement: string[]; // Specific suggestions or identified issues
  confidence: 'High' | 'Medium' | 'Low' | 'Not Applicable' | 'Unable to determine';
  disclaimer?: string; // Standard AI limitations disclaimer
}

export interface NeurodiversityCheckerFormValues {
  inputType: 'image' | 'text';
  imageFile?: FileList;
  textInput?: string;
  textFile?: FileList;
}



================================================
FILE: src/types/puter.d.ts
================================================
// src/types/puter.d.ts

interface PuterAuth {
  getUser: () => Promise<any>;
  isSignedIn: () => Promise<boolean>;
  signIn: (options?: any) => Promise<any>;
  signOut: () => Promise<void>;
}

interface PuterAIChatOptions {
  model?: string;
  stream?: boolean;
  tools?: any[];
  testMode?: boolean;
}

interface PuterAIChatResponse {
  message: {
    role: string;
    content: string;
    tool_calls?: any[];
  };
  text: string; // For non-streaming response text shortcut
  // other properties if stream=true
}


interface PuterAI {
  chat: (prompt: string, options?: PuterAIChatOptions) => Promise<PuterAIChatResponse>;
  chat: (prompt: string, imageURL: string, options?: PuterAIChatOptions) => Promise<PuterAIChatResponse>;
  chat: (prompt: string, imageURL: string, testMode?: boolean, options?: PuterAIChatOptions) => Promise<PuterAIChatResponse>;
  chat: (prompt: string, imageURLArray: string[], options?: PuterAIChatOptions) => Promise<PuterAIChatResponse>;
  chat: (prompt: string, imageURLArray: string[], testMode?: boolean, options?: PuterAIChatOptions) => Promise<PuterAIChatResponse>;
  chat: (messages: Array<{role: string, content: any}>, testMode?: boolean, options?: PuterAIChatOptions) => Promise<PuterAIChatResponse>;

  img2txt: (image: string | File | Blob, testMode?: boolean) => Promise<string>;
  txt2img: (prompt: string, testMode?: boolean) => Promise<HTMLImageElement>;
  txt2speech: (text: string, language?: string, testMode?: boolean) => Promise<HTMLAudioElement>;
}

interface PuterFSItem {
  id: string;
  uid: string;
  name: string;
  path: string;
  is_dir: boolean;
  parent_id: string;
  parent_uid: string;
  created: number;
  modified: number;
  accessed: number;
  size: number | null;
  writable: boolean;
  read?: () => Promise<Blob>; // Method if item is a file
  readdir?: () => Promise<PuterFSItem[]>; // Method if item is a directory
}

interface PuterFSWriteOptions {
  overwrite?: boolean;
  dedupeName?: boolean;
  createMissingParents?: boolean;
}

interface PuterFSUploadOptions {
  // Define options if needed, e.g. for progress
}

interface PuterFS {
  copy: (source: string, destination: string, options?: any) => Promise<PuterFSItem>;
  delete: (path: string, options?: any) => Promise<void>;
  mkdir: (path: string, options?: any) => Promise<PuterFSItem>;
  move: (source: string, destination: string, options?: any) => Promise<PuterFSItem>;
  read: (path: string) => Promise<Blob>;
  readdir: (path: string) => Promise<PuterFSItem[]>;
  rename: (path: string, newName: string) => Promise<PuterFSItem>;
  stat: (path: string) => Promise<PuterFSItem>;
  upload: (items: FileList | File[] | InputFileList, dirPath?: string, options?: PuterFSUploadOptions) => Promise<PuterFSItem[]>;
  write: (path: string, data: string | File | Blob, options?: PuterFSWriteOptions) => Promise<PuterFSItem>;
}

interface PuterUI {
    alert: (message: string, buttons?: Array<{label: string, value?: any, type?: string}>) => Promise<any>;
    // ... other UI methods from docs
}

interface Puter {
  ai: PuterAI;
  auth: PuterAuth;
  fs: PuterFS;
  ui: PuterUI;
  randName: () => string;
  // ... other puter modules and properties like appID, env
}

// This is for <input type="file" />.files which is FileList
interface InputFileList extends FileList {
    item(index: number): File | null;
    [index: number]: File;
}


declare global {
  interface Window {
    puter: Puter;
  }
}

// Export empty object to make it a module
export {};



================================================
FILE: src/types/text-to-image-generator.ts
================================================
export interface TextToImageGenerationInput {
  description: string;
  style?: string;
  aspectRatio?: string;
  additionalContext?: string;
}

export interface ImageAnalysisResult {
  dalle_prompt: string;
}

export interface TextToImageGenerationReport {
  generated_image: string;
  prompt_used: string;
  style_applied: string;
  confidence: 'High' | 'Medium' | 'Low' | 'Not Applicable';
  disclaimer: string;
}

export interface TextToImageGeneratorFormValues {
  description: string;
  style?: string;
  aspectRatio?: string;
  additionalContext?: string;
}


================================================
FILE: src/types/thumbnail-checker.ts
================================================

export interface ThumbnailAnalysisResponse {
  summary: string;
  // Potentially add keywords, dominant_colors etc. in future
}

export interface TitleAnalysisResponse {
  summary: string;
  // Potentially add sentiment, keywords etc. in future
}

export interface ConsistencyReport {
  is_consistent: boolean;
  explanation: string;
  confidence_score: number; // 0.0 to 1.0
}

export interface ThumbnailCheckerFormValues {
  thumbnailImage: FileList;
  titleText: string;
  titleFile?: FileList;
}



================================================
FILE: src/types/vehicle-troubleshooter.ts
================================================
export interface VehicleTroubleshootingReport {
  image_description: string;
  vehicle_type: string;
  identified_issues: string[];
  possible_causes: string[];
  recommended_solutions: string[];
  safety_warnings?: string[];
  maintenance_tips?: string[];
  estimated_severity: 'Minor' | 'Moderate' | 'Severe' | 'Critical';
  confidence: 'High' | 'Medium' | 'Low' | 'Not Applicable';
  disclaimer: string;
}

export interface VehicleTroubleshooterFormValues {
  imageFile: FileList;
  issueDescription: string;
  vehicleType: string;
  vehicleInfo?: string;
  additionalDetails?: string;
}


================================================
FILE: src/workers/audioWorker.ts
================================================
// audioWorker.ts

// This worker handles heavy audio processing for amplitude and frequency data extraction.

self.onmessage = async (e: MessageEvent) => {
    const { type, audioBufferData, sampleRate, numPlotPoints, numBars, fftSize } = e.data;
  
    if (!audioBufferData || !sampleRate) {
      self.postMessage({ error: "Missing audioBufferData or sampleRate" });
      return;
    }
  
    if (type === "amplitude") {
      // Downsample amplitude data for plotting
      const channelData = audioBufferData[0]; // Use first channel
      const totalSamples = channelData.length;
      const pointsToRender = Math.min(numPlotPoints, totalSamples);
      const step = totalSamples / pointsToRender;
      const dataPoints = [];
  
      for (let i = 0; i < pointsToRender; i++) {
        const sampleIndex = Math.floor(i * step);
        const boundedSampleIndex = Math.min(sampleIndex, totalSamples - 1);
        const amplitudeValue = channelData[boundedSampleIndex];
        const timeMs = (boundedSampleIndex / sampleRate) * 1000;
        dataPoints.push({ time: timeMs, amplitude: amplitudeValue });
      }
  
      // Ensure last sample is included
      if (pointsToRender > 0 && dataPoints.length > 0) {
        const lastSampledIndexInLoop = Math.min(Math.floor((pointsToRender - 1) * step), totalSamples - 1);
        if (lastSampledIndexInLoop < totalSamples - 1) {
          const finalSampleIndex = totalSamples - 1;
          const amplitudeValue = channelData[finalSampleIndex];
          const timeMs = (finalSampleIndex / sampleRate) * 1000;
          if (dataPoints[dataPoints.length - 1].time < timeMs) {
            dataPoints.push({ time: timeMs, amplitude: amplitudeValue });
          }
        }
      }
  
      self.postMessage({ type: "amplitude", data: dataPoints });
    }
  
    if (type === "frequency") {
      // Compute frequency data using FFT
      // We'll use a simple FFT implementation (since we can't use WebAudio API in worker)
      // For real-world, consider importing an FFT library like fft.js or dsp.js
      // Here, we use a naive implementation for demonstration
  
      function fftMag(buffer: Float32Array, fftSize: number) {
        // Zero-pad if needed
        const N = fftSize;
        const re = new Float32Array(N);
        const im = new Float32Array(N);
        for (let i = 0; i < Math.min(buffer.length, N); i++) {
          re[i] = buffer[i];
        }
        // DFT (slow, for small N)
        const mags = new Float32Array(N / 2);
        for (let k = 0; k < N / 2; k++) {
          let sumRe = 0, sumIm = 0;
          for (let n = 0; n < N; n++) {
            const angle = (2 * Math.PI * k * n) / N;
            sumRe += re[n] * Math.cos(angle) + im[n] * Math.sin(angle);
            sumIm += -re[n] * Math.sin(angle) + im[n] * Math.cos(angle);
          }
          mags[k] = Math.sqrt(sumRe * sumRe + sumIm * sumIm);
        }
        return mags;
      }
  
      const channelData = audioBufferData[0];
      const N = fftSize || 256;
      const mags = fftMag(channelData, N);
  
      // Group into bars
      const bars = [];
      const binCount = mags.length;
      const step = Math.max(1, Math.floor(binCount / numBars));
      for (let i = 0; i < numBars; i++) {
        let sum = 0;
        const startBin = i * step;
        const endBin = Math.min(startBin + step, binCount);
        if (startBin >= binCount) break;
        for (let j = startBin; j < endBin; j++) {
          sum += mags[j];
        }
        const countInStep = endBin - startBin;
        const average = countInStep > 0 ? sum / countInStep : 0;
        // Normalize to 0-255 for display
        bars.push({ band: `${i + 1}`, level: Math.min(255, Math.max(0, average * 2)) });
      }
  
      self.postMessage({ type: "frequency", data: bars });
    }
  };
  
  export {};


================================================
FILE: .idx/dev.nix
================================================
# To learn more about how to use Nix to configure your environment
# see: https://firebase.google.com/docs/studio/customize-workspace
{pkgs}: {
  # Which nixpkgs channel to use.
  channel = "stable-24.11"; # or "unstable"
  # Use https://search.nixos.org/packages to find packages
  packages = [
    pkgs.nodejs_20
    pkgs.zulu
  ];
  # Sets environment variables in the workspace
  env = {};
  # This adds a file watcher to startup the firebase emulators. The emulators will only start if
  # a firebase.json file is written into the user's directory
  services.firebase.emulators = {
    detect = true;
    projectId = "demo-app";
    services = ["auth" "firestore"];
  };
  idx = {
    # Search for the extensions you want on https://open-vsx.org/ and use "publisher.id"
    extensions = [
      # "vscodevim.vim"
    ];
    workspace = {
      onCreate = {
        default.openFiles = [
          "src/app/page.tsx"
        ];
      };
    };
    # Enable previews and customize configuration
    previews = {
      enable = true;
      previews = {
        web = {
          command = ["npm" "run" "dev" "--" "--port" "$PORT" "--hostname" "0.0.0.0"];
          manager = "web";
        };
      };
    };
  };
}


